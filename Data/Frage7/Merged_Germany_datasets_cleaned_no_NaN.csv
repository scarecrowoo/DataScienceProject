ORCID,Author,Institution,Title,PubDate,Abstract,DOI,IDlist,flag,found_words
0000-0001-5093-9997,Pasquale Pavone,Humboldt-Universität zu Berlin,Ab initio study of the beta$-tin->Imma->sh phase transitions in silicon   and germanium,1970,"  We have investigated the structural sequence of the high-pressure phases of silicon and germanium. We have focussed on the cd->beta-tin->Imma->sh phase transitions. We have used the plane-wave pseudopotential approach to the density-functional theory implemented within the Vienna ab-initio simulation package (VASP). We have determined the equilibrium properties of each structure and the values of the critical parameters including a hysteresis effect at the phase transitions. The order of the phase transitions has been obtained alternatively from the pressure dependence of the enthalpy and of the internal structure parameters. The commonly used tangent construction is shown to be very unreliable. Our calculations identify a first-order phase transition from the cd to the beta-tin and from the Imma to the sh phase, and they indicate the possibility of a second-order phase-transition from the beta-tin to the Imma phase. Finally, we have derived the enthalpy barriers between the phases. ",https://doi.org/10.1103/PhysRevB.69.134112,cond-mat/0308314v2,Yes,potent(1)
0000-0001-5093-9997,Pasquale Pavone,Humboldt-Universität zu Berlin,Shared Metadata for Data-Centric Materials Science,1970,"  The expansive production of data in materials science, their widespread sharing and repurposing requires educated support and stewardship. In order to ensure that this need helps rather than hinders scientific work, the implementation of the FAIR-data principles (Findable, Accessible, Interoperable, and Reusable) must not be too narrow. Besides, the wider materials-science community ought to agree on the strategies to tackle the challenges that are specific to its data, both from computations and experiments. In this paper, we present the result of the discussions held at the workshop on ""Shared Metadata and Data Formats for Big-Data Driven Materials Science"". We start from an operative definition of metadata, and what features a FAIR-compliant metadata schema should have. We will mainly focus on computational materials-science data and propose a constructive approach for the FAIRification of the (meta)data related to ground-state and excited-states calculations, potential-energy sampling, and generalized workflows. Finally, challenges with the FAIRification of experimental (meta)data and materials-science ontologies are presented together with an outlook of how to meet them. ",Kein DOI-Link verfügbar,2205.14774v2,Yes,potent(1)
0000-0001-5103-9632,Uwe Morgner,Leibniz Universität Hannover,The concept of laser-based conversion electron Mössbauer spectroscopy   for a precise energy determination of $^{229m}$Th,1970,"  $^{229}$Th is the only nucleus currently under investigation for the development of a nuclear optical clock (NOC) of ultra-high accuracy. The insufficient knowledge of the first nuclear excitation energy of $^{229}$Th has so far hindered direct nuclear laser spectroscopy of thorium ions and thus the development of a NOC. Here, a nuclear laser excitation scheme is detailed, which makes use of thorium atoms instead of ions. This concept, besides potentially leading to the first nuclear laser spectroscopy, would determine the isomeric energy to 40 $\mu$eV resolution, corresponding to 10 GHz, which is a $10^4$ times improvement compared to the current best energy constraint. This would determine the nuclear isomeric energy to a sufficient accuracy to allow for nuclear laser spectroscopy of individual thorium ions in a Paul trap and thus the development of a single-ion nuclear optical clock. ",https://doi.org/10.1007/s10751-019-1564-0,1904.01245v1,Yes,potent(1)
0000-0001-5103-9632,Uwe Morgner,Leibniz Universität Hannover,Evidence of the quantum-optical nature of high-harmonic generation,1970,"  High-harmonic generation is a light up-conversion process occurring in a strong laser field, leading to coherent bursts of extreme ultrashort broadband radiation [1]. As a new perspective, we propose that ultrafast strong-field electronic or photonic processes such as high-harmonic generation can potentially generate non-classical states of light well before the decoherence of the system occurs [2, 3]. This could address fundamental challenges in quantum technology such as scalability, decoherence or the generation of massively entangled states [4]. Here, we report experimental evidence of the non-classical nature of the harmonic emission in several semiconductors excited by a femtosecond infrared laser. By investigating single- and double beam intensity cross-correlation [5], we measure characteristic, non-classical features in the single photon statistics. We observe two-mode squeezing in the generated harmonic radiation, which depends on the laser intensity that governs the transition from Super-Poissonian to Poissonian photon statistics. The measured violation of the Cauchy-Schwarz inequality realizes a direct test of multipartite entanglement in high-harmonic generation [6]. This result is supported by the theory of multimodal detection and the Hamiltonian from which the effective squeezing modes of the harmonics can be derived [7, 8]. With this work, we show experimentally that high-harmonic generation is a new quantum bosonic platform that intrinsically produces non-classical states of light with unique features such as multipartite broadband entanglement or multimode squeezing. The source operates at room temperature using standard semiconductors and a standard commercial fiber laser, opening new routes for the quantum industry, such as optical quantum computing, communication and imaging. ",Kein DOI-Link verfügbar,2405.15022v2,Yes,potent(1)
0000-0001-5184-4252,Michael Haider,Universität Regensburg,Stochastic correction to the Maxwell-Bloch equations via the positive   $P$ representation,1970,"  Focusing on two-level atoms, we apply the positive $P$ representation to a full-wave mixed bosonic and fermionic system of Jaynes-Cummings type and identify an advantageous degree of freedom in the choice of the involved nonorthogonal fermionic basis states. On this basis, we propose a stochastic correction to the Maxwell-Bloch equations by relating them to a stochastic differential equation on a nonclassical phase space, which captures the full second quantization dynamics of the system. This approach explores the connection between semiclassical and field-quantized treatments of light-matter interaction and can potentially be used for the simulation of nonclassical light sources while retaining the main advantages of a semiclassical model. ",https://doi.org/10.1103/PhysRevA.110.013704,2404.00402v2,Yes,potent(1)
0000-0001-5193-8574,Timo Kaufmann,Ludwig-Maximilians-Universität München,A Survey of Reinforcement Learning from Human Feedback,1970,"  Reinforcement learning from human feedback (RLHF) is a variant of reinforcement learning (RL) that learns from human feedback instead of relying on an engineered reward function. Building on prior work on the related setting of preference-based reinforcement learning (PbRL), it stands at the intersection of artificial intelligence and human-computer interaction. This positioning offers a promising avenue to enhance the performance and adaptability of intelligent systems while also improving the alignment of their objectives with human values. The training of large language models (LLMs) has impressively demonstrated this potential in recent years, where RLHF played a decisive role in directing the model's capabilities toward human objectives. This article provides a comprehensive overview of the fundamentals of RLHF, exploring the intricate dynamics between RL agents and human input. While recent focus has been on RLHF for LLMs, our survey adopts a broader perspective, examining the diverse applications and wide-ranging impact of the technique. We delve into the core principles that underpin RLHF, shedding light on the symbiotic relationship between algorithms and human feedback, and discuss the main research trends in the field. By synthesizing the current landscape of RLHF research, this article aims to provide researchers as well as practitioners with a comprehensive understanding of this rapidly growing field of research. ",Kein DOI-Link verfügbar,2312.14925v2,Yes,"intricate(1), potent(1), impressively(1)"
0000-0001-5193-8574,Timo Kaufmann,Ludwig-Maximilians-Universität München,Inverse Constitutional AI: Compressing Preferences into Principles,1970,"  Feedback data plays an important role in fine-tuning and evaluating state-of-the-art AI models. Often pairwise text preferences are used: given two texts, human (or AI) annotators select the ""better"" one. Such feedback data is widely used to align models to human preferences (e.g., reinforcement learning from human feedback), or to rank models according to human preferences (e.g., Chatbot Arena). Despite its wide-spread use, prior work has demonstrated that human-annotated pairwise text preference data often exhibits unintended biases. For example, human annotators have been shown to prefer assertive over truthful texts in certain contexts. Models trained or evaluated on this data may implicitly encode these biases in a manner hard to identify. In this paper, we formulate the interpretation of existing pairwise text preference data as a compression task: the Inverse Constitutional AI (ICAI) problem. In constitutional AI, a set of principles (or constitution) is used to provide feedback and fine-tune AI models. The ICAI problem inverts this process: given a dataset of feedback, we aim to extract a constitution that best enables a large language model (LLM) to reconstruct the original annotations. We propose a corresponding initial ICAI algorithm and validate its generated constitutions quantitatively based on reconstructed annotations. Generated constitutions have many potential use-cases -- they may help identify undesirable biases, scale feedback to unseen data or assist with adapting LLMs to individual user preferences. We demonstrate our approach on a variety of datasets: (a) synthetic feedback datasets with known underlying principles; (b) the AlpacaEval dataset of cross-annotated human feedback; and (c) the crowdsourced Chatbot Arena data set. We release the code for our algorithm and experiments at https://github.com/rdnfn/icai . ",Kein DOI-Link verfügbar,2406.06560v1,Yes,potent(1)
0000-0001-5193-8574,Timo Kaufmann,Ludwig-Maximilians-Universität München,Problem Solving Through Human-AI Preference-Based Cooperation,1970,"  While there is a widespread belief that artificial general intelligence (AGI) -- or even superhuman AI -- is imminent, complex problems in expert domains are far from being solved. We argue that such problems require human-AI cooperation and that the current state of the art in generative AI is unable to play the role of a reliable partner due to a multitude of shortcomings, including inability to keep track of a complex solution artifact (e.g., a software program), limited support for versatile human preference expression and lack of adapting to human preference in an interactive setting. To address these challenges, we propose HAI-Co2, a novel human-AI co-construction framework. We formalize HAI-Co2 and discuss the difficult open research problems that it faces. Finally, we present a case study of HAI-Co2 and demonstrate its efficacy compared to monolithic generative AI models. ",Kein DOI-Link verfügbar,2408.07461v2,Yes,versatile(1)
0000-0001-5200-8870,Gerik Scheuermann,Leipzig Universität,Detection of Total Rotations on 2D-Vector Fields with Geometric   Correlation,1970,  Correlation is a common technique for the detection of shifts. Its generalization to the multidimensional geometric correlation in Clifford algebras additionally contains information with respect to rotational misalignment. It has been proven a useful tool for the registration of vector fields that differ by an outer rotation. In this paper we proof that applying the geometric correlation iteratively has the potential to detect the total rotational misalignment for linear two-dimensional vector fields. We further analyze its effect on general analytic vector fields and show how the rotation can be calculated from their power series expansions. ,https://doi.org/10.1063/1.4765489,1306.2201v1,Yes,potent(1)
0000-0001-5200-8870,Gerik Scheuermann,Leipzig Universität,Detection of Outer Rotations on 3D-Vector Fields with Iterative   Geometric Correlation and its Efficiency,1970,"  Correlation is a common technique for the detection of shifts. Its generalization to the multidimensional geometric correlation in Clifford algebras has been proven a useful tool for color image processing, because it additionally contains information about a rotational misalignment. But so far the exact correction of a three-dimensional outer rotation could only be achieved in certain special cases. In this paper we prove that applying the geometric correlation iteratively has the potential to detect the outer rotational misalignment for arbitrary three-dimensional vector fields. We further present the explicit iterative algorithm, analyze its efficiency detecting the rotational misalignment in the color space of a color image. The experiments suggest a method for the acceleration of the algorithm, which is practically tested with great success. ",Kein DOI-Link verfügbar,1307.2457v1,Yes,potent(1)
0000-0001-5200-8870,Gerik Scheuermann,Leipzig Universität,An Introduction to the Deviatoric Tensor Decomposition in Three   Dimensions and its Multipole Representation,1970,"  The analysis and visualization of tensor fields is a very challenging task. Besides the cases of zeroth- and first-order tensors, most techniques focus on symmetric second-order tensors. Only a few works concern totally symmetric tensors of higher-order. Work on other tensors of higher-order than two is exceptionally rare. We believe that one major reason for this gap is the lack of knowledge about suitable tensor decompositions for the general higher-order tensors. We focus here on three dimensions as most applications are concerned with three-dimensional space. A lot of work on symmetric second-order tensors uses the spectral decomposition. The work on totally symmetric higher-order tensors deals frequently with a decomposition based on spherical harmonics. These decompositions do not directly apply to general tensors of higher-order in three dimensions. However, another option available is the deviatoric decomposition for such tensors, splitting them into deviators. Together with the multipole representation of deviators, it allows to describe any tensor in three dimensions uniquely by a set of directions and non-negative scalars. The specific appeal of this methodology is its general applicability, opening up a potentially general route to tensor interpretation. The underlying concepts, however, are not broadly understood in the engineering community. In this article, we therefore gather information about this decomposition from a range of literature sources. The goal is to collect and prepare the material for further analysis and give other researchers the chance to work in this direction. This article wants to stimulate the use of this decomposition and the search for interpretation of this unique algebraic property. A first step in this direction is given by a detailed analysis of the multipole representation of symmetric second-order three-dimensional tensors. ",Kein DOI-Link verfügbar,2009.11723v1,Yes,potent(1)
0000-0001-5200-8870,Gerik Scheuermann,Leipzig Universität,Effect of the output activation function on the probabilities and errors   in medical image segmentation,1970,"  The sigmoid activation is the standard output activation function in binary classification and segmentation with neural networks. Still, there exist a variety of other potential output activation functions, which may lead to improved results in medical image segmentation. In this work, we consider how the asymptotic behavior of different output activation and loss functions affects the prediction probabilities and the corresponding segmentation errors. For cross entropy, we show that a faster rate of change of the activation function correlates with better predictions, while a slower rate of change can improve the calibration of probabilities. For dice loss, we found that the arctangent activation function is superior to the sigmoid function. Furthermore, we provide a test space for arbitrary output activation functions in the area of medical image segmentation. We tested seven activation functions in combination with three loss functions on four different medical image segmentation tasks to provide a classification of which function is best suited in this application scenario. ",Kein DOI-Link verfügbar,2109.00903v1,Yes,potent(1)
0000-0001-5200-8870,Gerik Scheuermann,Leipzig Universität,A Mathematical Foundation for the Spatial Uncertainty of Critical Points   in Probabilistic Scalar Fields,1970,"  Critical points mark locations in the domain where the level-set topology of a scalar function undergoes fundamental changes and thus indicate potentially interesting features in the data. Established methods exist to locate and relate such points in a deterministic setting, but it is less well understood how the concept of critical points can be extended to the analysis of uncertain data. Most methods for this task aim at finding likely locations of critical points or estimate the probability of their occurrence locally but do not indicate if critical points at potentially different locations in different realizations of a stochastic process are manifestations of the same feature, which is required to characterize the spatial uncertainty of critical points. Previous work on relating critical points across different realizations reported challenges for interpreting the resulting spatial distribution of critical points but did not investigate the causes. In this work, we provide a mathematical formulation of the problem of finding critical points with spatial uncertainty and computing their spatial distribution, which leads us to the notion of uncertain critical points. We analyze the theoretical properties of these structures and highlight connections to existing works for special classes of uncertain fields. We derive conditions under which well-interpretable results can be obtained and discuss the implications of those restrictions for the field of visualization. We demonstrate that the discussed limitations are not purely academic but also arise in real-world data. ",Kein DOI-Link verfügbar,2308.05710v1,Yes,potent(2)
0000-0001-5239-5305,Franziska Mathis-Ullrich,Friedrich-Alexander-Universität Erlangen-Nürnberg,LapGym -- An Open Source Framework for Reinforcement Learning in   Robot-Assisted Laparoscopic Surgery,1970,"  Recent advances in reinforcement learning (RL) have increased the promise of introducing cognitive assistance and automation to robot-assisted laparoscopic surgery (RALS). However, progress in algorithms and methods depends on the availability of standardized learning environments that represent skills relevant to RALS. We present LapGym, a framework for building RL environments for RALS that models the challenges posed by surgical tasks, and sofa_env, a diverse suite of 12 environments. Motivated by surgical training, these environments are organized into 4 tracks: Spatial Reasoning, Deformable Object Manipulation & Grasping, Dissection, and Thread Manipulation. Each environment is highly parametrizable for increasing difficulty, resulting in a high performance ceiling for new algorithms. We use Proximal Policy Optimization (PPO) to establish a baseline for model-free RL algorithms, investigating the effect of several environment parameters on task difficulty. Finally, we show that many environments and parameter configurations reflect well-known, open problems in RL research, allowing researchers to continue exploring these fundamental problems in a surgical context. We aim to provide a challenging, standard environment suite for further development of RL for RALS, ultimately helping to realize the full potential of cognitive surgical robotics. LapGym is publicly accessible through GitHub (https://github.com/ScheiklP/lap_gym). ",Kein DOI-Link verfügbar,2302.09606v1,Yes,potent(1)
0000-0001-5239-5305,Franziska Mathis-Ullrich,Friedrich-Alexander-Universität Erlangen-Nürnberg,Movement Primitive Diffusion: Learning Gentle Robotic Manipulation of   Deformable Objects,1970,"  Policy learning in robot-assisted surgery (RAS) lacks data efficient and versatile methods that exhibit the desired motion quality for delicate surgical interventions. To this end, we introduce Movement Primitive Diffusion (MPD), a novel method for imitation learning (IL) in RAS that focuses on gentle manipulation of deformable objects. The approach combines the versatility of diffusion-based imitation learning (DIL) with the high-quality motion generation capabilities of Probabilistic Dynamic Movement Primitives (ProDMPs). This combination enables MPD to achieve gentle manipulation of deformable objects, while maintaining data efficiency critical for RAS applications where demonstration data is scarce. We evaluate MPD across various simulated and real world robotic tasks on both state and image observations. MPD outperforms state-of-the-art DIL methods in success rate, motion quality, and data efficiency.   Project page: https://scheiklp.github.io/movement-primitive-diffusion/ ",https://doi.org/10.1109/LRA.2024.3382529,2312.10008v2,Yes,versatile(1)
0000-0001-5239-5305,Franziska Mathis-Ullrich,Friedrich-Alexander-Universität Erlangen-Nürnberg,Sim-To-Real Transfer for Visual Reinforcement Learning of Deformable   Object Manipulation for Robot-Assisted Surgery,1970,"  Automation holds the potential to assist surgeons in robotic interventions, shifting their mental work load from visuomotor control to high level decision making. Reinforcement learning has shown promising results in learning complex visuomotor policies, especially in simulation environments where many samples can be collected at low cost. A core challenge is learning policies in simulation that can be deployed in the real world, thereby overcoming the sim-to-real gap.   In this work, we bridge the visual sim-to-real gap with an image-based reinforcement learning pipeline based on pixel-level domain adaptation and demonstrate its effectiveness on an image-based task in deformable object manipulation. We choose a tissue retraction task because of its importance in clinical reality of precise cancer surgery. After training in simulation on domain-translated images, our policy requires no retraining to perform tissue retraction with a 50% success rate on the real robotic system using raw RGB images. Furthermore, our sim-to-real transfer method makes no assumptions on the task itself and requires no paired images. This work introduces the first successful application of visual sim-to-real transfer for robotic manipulation of deformable objects in the surgical field, which represents a notable step towards the clinical translation of cognitive surgical robotics. ",https://doi.org/10.1109/LRA.2022.3227873,2406.06092v1,Yes,"notable(1), potent(1)"
0000-0001-5239-5305,Franziska Mathis-Ullrich,Friedrich-Alexander-Universität Erlangen-Nürnberg,Cooperative Assistance in Robotic Surgery through Multi-Agent   Reinforcement Learning,1970,"  Cognitive cooperative assistance in robot-assisted surgery holds the potential to increase quality of care in minimally invasive interventions. Automation of surgical tasks promises to reduce the mental exertion and fatigue of surgeons. In this work, multi-agent reinforcement learning is demonstrated to be robust to the distribution shift introduced by pairing a learned policy with a human team member. Multi-agent policies are trained directly from images in simulation to control multiple instruments in a sub task of the minimally invasive removal of the gallbladder. These agents are evaluated individually and in cooperation with humans to demonstrate their suitability as autonomous assistants. Compared to human teams, the hybrid teams with artificial agents perform better considering completion time (44.4% to 71.2% shorter) as well as number of collisions (44.7% to 98.0% fewer). Path lengths, however, increase under control of an artificial agent (11.4% to 33.5% longer). A multi-agent formulation of the learning problem was favored over a single-agent formulation on this surgical sub task, due to the sequential learning of the two instruments. This approach may be extended to other tasks that are difficult to formulate within the standard reinforcement learning framework. Multi-agent reinforcement learning may shift the paradigm of cognitive robotic surgery towards seamless cooperation between surgeons and assistive technologies. ",https://doi.org/10.1109/IROS51168.2021.9636193,2110.04857v1,Yes,potent(1)
0000-0001-5309-4301,Florian Pielnhofer,Universität Regensburg,Chemical Principles of Topological Semimetals,1970,"  Initiated by the discovery of topological insulators, topologically non-trivial materials have attracted immense interest in the physics community in the past decade. One of the latest additions to the field, the material class of topological semimetals, has grown at an extremely fast rate . While the prototype of a topological semimetal, graphene, has been known for a while, the first 3D analogues of graphene have only been discovered recently. This review, written from a chemistry perspective, intends to make the growing field of topological semimetals accessible to the wider community of materials scientists and scholars from related disciplines. To this end, we describe key features of topological semimetals, embedded in their electronic structure, and how they can be achieved based on chemical principles. We introduce the different classes of topological semimetals and review their salient representatives. Finally, selected properties and potential applications of these materials are discussed. ",https://doi.org/10.1021/acs.chemmater.7b05133,1804.10649v1,Yes,potent(1)
0000-0001-5309-4301,Florian Pielnhofer,Universität Regensburg,"Synthesis of an aqueous, air-stable, superconducting 1T'-WS$_2$   monolayer-ink",1970,"  Liquid-phase chemical exfoliation is ideal to achieve industry scale production of two-dimensional (2D) materials for a wide range of application such as printable electronics, catalysis and energy storage. However, many impactful 2D materials with potentials in quantum technologies can only be studied in lab settings due to their air-sensitivity, and loss of physical performance after chemical processing. Here, we report a simple chemical exfoliation method to create a stable, aqueous, surfactant-free, superconducting ink containing phase-pure 1T'-WS$_2$ monolayers that are isotructural to the air-sensitive topological insulator 1T'-WTe$_2$. We demonstrate that thin films can be cast on both hard and flexible substrates. The printed film is metallic at room temperature and superconducting below 7.3 K, shows strong anisotropic unconventional superconducting behavior with an in-plane and out-of-plane upper critical magnetic field of 30.1 T and 5.3 T, has a critical current of 44 mA, and is stable at ambient conditions for at least 30 days. Our results show that chemical processing can provide an engineering solution, which makes non-trivial 2D materials that used to be only studied in laboratories commercially accessible. ",Kein DOI-Link verfügbar,2206.01648v1,Yes,potent(1)
0000-0001-5309-4301,Florian Pielnhofer,Universität Regensburg,Possible Experimental Realization of a Basic Z2 Topological Semimetal,1970,"  We report experimental and theoretical evidence that GaGeTe is a basic $Z_2$ topological semimetal with three types of charge carriers: bulk-originated electrons and holes as well as surface state electrons. This electronic situation is qualitatively similar to the primer 3D topological insulator Bi2Se3, but important differences account for an unprecedented transport scenario in GaGeTe. High-resolution angle-resolved photoemission spectroscopy combined with advanced band structure calculations show a small indirect energy gap caused by a peculiar band inversion in the \textit{T}-point of the Brillouin zone in GaGeTe. An energy overlap of the valence and conduction bands brings both electron- and hole-like carriers to the Fermi level, while the momentum gap between the corresponding dispersions remains finite. We argue that peculiarities of the electronic spectrum of GaGeTe have a fundamental importance for the physics of topological matter and may boost the material's application potential. ",https://doi.org/10.1063/1.5124563,1812.01668v1,Yes,potent(1)
0000-0001-5335-5428,Daniel Steck,Julius-Maximilians-Universität Würzburg,Regularization of Limited Memory Quasi-Newton Methods for Large-Scale   Nonconvex Minimization,1970,"  This paper deals with regularized Newton methods, a flexible class of unconstrained optimization algorithms that is competitive with line search and trust region methods and potentially combines attractive elements of both. The particular focus is on combining regularization with limited memory quasi-Newton methods by exploiting the special structure of limited memory algorithms. Global convergence of regularization methods is shown under mild assumptions and the details of regularized limited memory quasi-Newton updates are discussed including their compact representations.   Numerical results using all large-scale test problems from the CUTEst collection indicate that our regularized version of L-BFGS is competitive with state-of-the-art line search and trust-region L-BFGS algorithms and previous attempts at combining L-BFGS with regularization, while potentially outperforming some of them, especially when nonmonotonicity is involved. ",Kein DOI-Link verfügbar,1911.04584v4,Yes,potent(2)
0000-0001-5408-2177,Ahmad Ibrahim,Universität Hohenheim,Microarchitectural Leakage Templates and Their Application to   Cache-Based Side Channels,1970,"  The complexity of modern processor architectures has given rise to sophisticated interactions among their components. Such interactions may result in potential attack vectors in terms of side channels, possibly available to user-land exploits to leak secret data. Exploitation and countering of such side channels require a detailed understanding of the target component. However, such detailed information is commonly unpublished for many CPUs.   In this paper, we introduce the concept of Leakage Templates to abstractly describe specific side channels and identify their occurrences in binary applications. We design and implement Plumber, a framework to derive the generic Leakage Templates from individual code sequences that are known to cause leakage (e.g., found by prior work). Plumber uses a combination of instruction fuzzing, instructions' operand mutation and statistical analysis to explore undocumented behavior of microarchitectural optimizations and derive sufficient conditions on vulnerable code inputs that, if hold can trigger a distinguishing behavior. Using Plumber we identified novel leakage primitives based on Leakage Templates (for ARM Cortex-A53 and -A72 cores), in particular related to previction (a new premature cache eviction), and prefetching behavior. We show the utility of Leakage Templates by re-identifying a prefetcher-based vulnerability in OpenSSL 1.1.0g first reported by Shin et al. [40]. ",https://doi.org/10.1145/3548606.3560613,2211.13958v1,Yes,potent(1)
0000-0001-5453-8007,Hongchao Chu,Rheinisch-Westfälische Technische Hochschule Aachen,Three-dimensional numerical investigation of flashback in premixed   hydrogen flames within perforated burners,1970,"  Predicting flashback represents a pivotal challenge in the development of innovative perforated burners for household appliances, especially for substituting natural gas with hydrogen as fuel. Most existing numerical studies have utilized two-dimensional (2D) simulations to investigate flashback in these burners, primarily to reduce computational costs. However, the inherent complexity of flashback phenomena suggests that 2D models may inadequately capture the flame dynamics, potentially leading to inaccurate estimations of flashback limits. In this study, three-dimensional (3D) simulations are employed to examine the impact of the actual slit shapes on the flashback velocities of hydrogen-premixed flames. Steady-state simulations are conducted to compute flashback velocities for three equivalence ratios ($\phi=0.6$, $0.8$, and $1.0$), investigating slits with fixed width and varying lengths. Additionally, transient simulations are performed to investigate the flashback dynamics. The results are compared with those from 2D configurations to assess the reliability of the infinite slit approximation. For stable flames, 2D simulations underpredict the burner plate temperature compared to slits with lengths typical of practical devices but match the 3D results as $L\to\infty$. Conversely, flashback velocities are consistently underpredicted in 2D simulations compared to 3D simulations, even as $L\to\infty$. This is due to the critical role of the slit ends in flashback dynamics, where preferential diffusion effects and enhanced heat transfer trigger the initiation of flashback in those regions. These findings underscore the necessity of employing 3D simulations to estimate the flashback velocities in domestic perforated burners accurately. ",Kein DOI-Link verfügbar,2312.00744v4,Yes,"innovative(1), pivotal(1), potent(1)"
0000-0001-5597-1160,Stephan Gekle,Universität Bayreuth,Numerical-experimental observation of shape bistability of red blood   cells flowing in a microchannel,1970,"  Red blood cells flowing through capillaries assume a wide variety of different shapes owing to their high deformability. Predicting the realized shapes is a complex field as they are determined by the intricate interplay between the flow conditions and the membrane mechanics. In this work we construct the shape phase diagram of a single red blood cell with a physiological viscosity ratio flowing in a microchannel. We use both experimental in-vitro measurements as well as 3D numerical simulations to complement the respective other one. Numerically, we have easy control over the initial starting configuration and natural access to the full 3D shape. With this information we obtain the phase diagram as a function of initial position, starting shape and cell velocity. Experimentally, we measure the occurrence frequency of the different shapes as a function of the cell velocity to construct the experimental diagram which is in good agreement with the numerical observations. Two different major shapes are found, namely croissants and slippers. Notably, both shapes show coexistence at low (<1 mm/s) and high velocities (>3 mm/s) while in-between only croissants are stable. This pronounced bistability indicates that RBC shapes are not only determined by system parameters such as flow velocity or channel size, but also strongly depend on the initial conditions. ",Kein DOI-Link verfügbar,1711.06986v1,Yes,intricate(1)
0000-0001-5597-1160,Stephan Gekle,Universität Bayreuth,Red blood cell shape transitions and dynamics in time-dependent   capillary flows,1970,"  The dynamics of single red blood cells (RBCs) determine microvascular blood flow by adapting their shape to the flow conditions in the narrow vessels. In this study, we explore the dynamics and shape transitions of RBCs on the cellular scale under confined and unsteady flow conditions using a combination of microfluidic experiments and numerical simulations. Tracking RBCs in a comoving frame in time-dependent flows reveals that the mean transition time from the symmetric croissant to the off-centered, non-symmetric slipper shape is significantly faster than the opposite shape transition, which exhibits pronounced cell rotations. Complementary simulations indicate that these dynamics depend on the orientation of the RBC membrane in the channel during the time-dependent flow. Moreover, we show how the tank-treading movement of slipper-shaped RBCs in combination with the narrow channel leads to oscillations of the cell's center of mass. The frequency of these oscillations depends on the cell velocity, the viscosity of the surrounding fluid, and the cytosol viscosity. These results provide a potential framework to identify and study pathological changes of RBC properties. ",https://doi.org/10.1016/j.bpj.2021.12.009,2112.10442v1,Yes,potent(1)
0000-0001-5624-4459,Tobias Neumann,Ruhr-Universität Bochum,Precision phenomenology with MCFM,1970,"  Without proper control of numerical and methodological errors in theoretical predictions at the per mille level it is not possible to study the effect of input parameters in current hadron-collider measurements at the required precision. We present a new version of the parton-level code MCFM that achieves this requirement through its highly-parallelized nature, significant performance improvements and new features. An automatic differential cutoff extrapolation is introduced to assess the cutoff dependence of all results, thus ensuring their reliability and potentially improving fixed-cutoff results by an order of magnitude. The efficient differential study of PDF uncertainties and PDF set differences at NNLO, for multiple PDF sets simultaneously, is achieved by exploiting correlations. We use these improvements to study uncertainties and PDF sensitivity at NNLO, using 371 PDF set members. The work described here permits NNLO studies that were previously prohibitively expensive, and lays the groundwork necessary for a future implementation of NNLO calculations with a jet at Born level in MCFM. ",https://doi.org/10.1007/JHEP12(2019)034,1909.09117v1,Yes,potent(1)
0000-0001-5624-4459,Tobias Neumann,Ruhr-Universität Bochum,$Zγ$ production at NNLO including anomalous couplings,1970,"  In this paper we present a next-to-next-to-leading order (NNLO) QCD calculation of the processes $pp\rightarrow l^+l^-\gamma$ and $pp\rightarrow \nu\bar\nu\gamma$ that we have implemented in MCFM. Our calculation includes QCD corrections at NNLO both for the Standard Model (SM) and additionally in the presence of $Z\gamma\gamma$ and $ZZ\gamma$ anomalous couplings. We compare our implementation, obtained using the jettiness slicing approach, with a previous SM calculation and find broad agreement. Focusing on the sensitivity of our results to the slicing parameter, we show that using our setup we are able to compute NNLO cross sections with numerical uncertainties of about $0.1\%$, which is small compared to residual scale uncertainties of a few percent. We study potential improvements using two different jettiness definitions and the inclusion of power corrections. At $\sqrt{s}=13$ TeV we present phenomenological results and consider $Z\gamma$ as a background to $H\to Z\gamma$ production. We find that, with typical cuts, the inclusion of NNLO corrections represents a small effect and loosens the extraction of limits on anomalous couplings by about $10\%$. ",https://doi.org/10.1007/JHEP11(2017)150,1708.02925v1,Yes,potent(1)
0000-0001-5624-4459,Tobias Neumann,Ruhr-Universität Bochum,Computational challenges for multi-loop collider phenomenology,1970,"  Precision measurements at the LHC and future colliders require theory predictions with uncertainties at the percent level for many observables. Theory uncertainties due to the perturbative truncation are particularly relevant and must be reduced to fully exploit the physics potential of collider experiments. In recent years the theoretical high energy physics community has made tremendous analytical and numerical advances to address this challenge. In this white paper, we survey state-of-the-art calculations in perturbative quantum field theory for collider phenomenology with a particular focus on the computational requirements at high perturbative orders. We show that these calculations can have specific high-performance-computing (HPC) profiles that should to be taken into account in future HPC resource planning. ",https://doi.org/10.1007/s41781-022-00088-0,2204.04200v1,Yes,potent(1)
0000-0001-5707-3751,Lukas Gienapp,Leipzig Universität,Tracking Discourse Influence in Darknet Forums,1970,"  This technical report documents our efforts in addressing the tasks set forth by the 2021 AMoC (Advanced Modelling of Cyber Criminal Careers) Hackathon. Our main contribution is a joint visualisation of semantic and temporal features, generating insight into the supplied data on darknet cybercrime through the aspects of novelty, transience, and resonance, which describe the potential impact a message might have on the overall discourse in darknet communities. All code and data produced by us as part of this hackathon is publicly available. ",Kein DOI-Link verfügbar,2202.02081v1,Yes,potent(1)
0000-0001-5707-3751,Lukas Gienapp,Leipzig Universität,The Impact of Main Content Extraction on Near-Duplicate Detection,1970,"  Commercial web search engines employ near-duplicate detection to ensure that users see each relevant result only once, albeit the underlying web crawls typically include (near-)duplicates of many web pages. We revisit the risks and potential of near-duplicates with an information retrieval focus, motivating that current efforts toward an open and independent European web search infrastructure should maintain metadata on duplicate and near-duplicate documents in its index.   Near-duplicate detection implemented in an open web search infrastructure should provide a suitable similarity threshold, a difficult choice since identical pages may substantially differ in parts of a page that are irrelevant to searchers (templates, advertisements, etc.). We study this problem by comparing the similarity of pages for five (main) content extraction methods in two studies on the ClueWeb crawls. We find that the full content of pages serves precision-oriented near-duplicate-detection, while main content extraction is more recall-oriented. ",Kein DOI-Link verfügbar,2111.10864v1,Yes,potent(1)
0000-0001-5786-7113,Samuel Klein,Saarland Universität,FETA: Flow-Enhanced Transportation for Anomaly Detection,1970,"  Resonant anomaly detection is a promising framework for model-independent searches for new particles. Weakly supervised resonant anomaly detection methods compare data with a potential signal against a template of the Standard Model (SM) background inferred from sideband regions. We propose a means to generate this background template that uses a flow-based model to create a mapping between high-fidelity SM simulations and the data. The flow is trained in sideband regions with the signal region blinded, and the flow is conditioned on the resonant feature (mass) such that it can be interpolated into the signal region. To illustrate this approach, we use simulated collisions from the Large Hadron Collider (LHC) Olympics Dataset. We find that our flow-constructed background method has competitive sensitivity with other recent proposals and can therefore provide complementary information to improve future searches. ",https://doi.org/10.1103/PhysRevD.107.096025,2212.11285v2,Yes,potent(1)
0000-0001-5859-185X,Christoph Dreissigacker,Leibniz Universität Hannover,Deep-Learning Continuous Gravitational Waves: Multiple detectors and   realistic noise,1970,"  The sensitivity of wide-parameter-space searches for continuous gravitational waves is limited by computational cost. Recently it was shown that Deep Neural Networks (DNNs) can perform all-sky searches directly on (single-detector) strain data, potentially providing a low-computing-cost search method that could lead to a better overall sensitivity. Here we expand on this study in two respects: (i) using (simulated) strain data from two detectors simultaneously, and (ii) training for directed (i.e.\ single sky-position) searches in addition to all-sky searches. For a data timespan of $T = 10^5\, s$, the all-sky two-detector DNN is about $7\%$ less sensitive (in amplitude $h_0$) at low frequency ($f=20\,Hz$), and about $51\,\%$ less sensitive at high frequency ($f=1000\,Hz$) compared to fully-coherent matched-filtering (using WEAVE). In the directed case the sensitivity gap compared to matched-filtering ranges from about $7-14\%$ at $f=20\,Hz$ to about $37-49\%$ at $f=1500\,Hz$. Furthermore we assess the DNN's ability to generalize in signal frequency, spindown and sky-position, and we test its robustness to realistic data conditions, namely gaps in the data and using real LIGO detector noise. We find that the DNN performance is not adversely affected by gaps in the test data or by using a relatively undisturbed band of LIGO detector data instead of Gaussian noise. However, when using a more disturbed LIGO band for the tests, the DNN's detection performance is substantially degraded due to the increase in false alarms, as expected. ",https://doi.org/10.1103/PhysRevD.102.022005,2005.04140v2,Yes,potent(1)
0000-0001-5859-185X,Christoph Dreissigacker,Leibniz Universität Hannover,OctApps: a library of Octave functions for continuous gravitational-wave   data analysis,1970,"  Gravitational waves are minute ripples in spacetime, first predicted by Einstein's general theory of relativity in 1916. Gravitational waves from rapidly-rotating neutron stars, whose shape deviates from perfect axisymmetry, are a potential astrophysical source of gravitational waves, but which so far have not been detected. The search for this type of signals, also known as continuous waves, presents a significant data analysis challenge, as their weak signatures are expected to be buried deep within the instrumental noise of the LIGO and Virgo detectors. The OctApps library provides various functions, written in Octave, intended to aid research scientists who perform searches for continuous gravitational waves. ",https://doi.org/10.21105/joss.00707,1806.07442v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,The effects of data preprocessing on probability of default model   fairness,1970,"  In the context of financial credit risk evaluation, the fairness of machine learning models has become a critical concern, especially given the potential for biased predictions that disproportionately affect certain demographic groups. This study investigates the impact of data preprocessing, with a specific focus on Truncated Singular Value Decomposition (SVD), on the fairness and performance of probability of default models. Using a comprehensive dataset sourced from Kaggle, various preprocessing techniques, including SVD, were applied to assess their effect on model accuracy, discriminatory power, and fairness. ",https://doi.org/10.30574/wjaets.2024.12.2.0354,2408.15452v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Electron Tunneling in Monolayer and Bilayer Graphene,1970,"  Electron's tunneling through potential barrier in monolayer and bilayer graphene lattices is investigated by using full tight-binding model. Emphasis is placed on the resonance tunneling feature and inter-valley scattering probability. It is shown that normal incidence transmission probabilities for monolayer and bilayer graphene exhibit different properties. Our calculation indicates that valleytronics in graphene systems may be detected, generated and controlled by changing the structure parameters of the external electric potential. ",Kein DOI-Link verfügbar,0808.3032v1,Yes,potent(2)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Visualization of Surface-acoustic-wave Potential by Transmission-mode   Microwave Impedance Microscopy,1970,"  Elastic waves propagating in piezoelectric materials are accompanied by a time-varying electric potential, which is of critical importance for acousto-electronic applications. The spatial mapping of such a potential at microwave frequencies is challenging since the characteristic length scale is determined by the acoustic wavelength of several micrometers. In this work, we report the visualization of surface acoustic waves (SAWs) on ferroelectric samples by transmission-mode microwave impedance microscopy (T-MIM). The SAW potential launched by the interdigital transducer is detected by the tip and demodulated by the microwave electronics as time-independent spatial patterns. Wave phenomena such as interference and diffraction are imaged and the results are in excellent agreement with the theoretical analysis. Our work opens up a new avenue to study various electromechanical systems in a spatially resolved manner. ",https://doi.org/10.1103/PhysRevApplied.9.061002,1805.07421v1,Yes,potent(3)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,MetaKP: On-Demand Keyphrase Generation,1970,"  Traditional keyphrase prediction methods predict a single set of keyphrases per document, failing to cater to the diverse needs of users and downstream applications. To bridge the gap, we introduce on-demand keyphrase generation, a novel paradigm that requires keyphrases that conform to specific high-level goals or intents. For this task, we present MetaKP, a large-scale benchmark comprising four datasets, 7500 documents, and 3760 goals across news and biomedical domains with human-annotated keyphrases. Leveraging MetaKP, we design both supervised and unsupervised methods, including a multi-task fine-tuning approach and a self-consistency prompting method with large language models. The results highlight the challenges of supervised fine-tuning, whose performance is not robust to distribution shifts. By contrast, the proposed self-consistency prompting approach greatly improves the performance of large language models, enabling GPT-4o to achieve 0.548 SemF1, surpassing the performance of a fully fine-tuned BART-base model. Finally, we demonstrate the potential of our method to serve as a general NLP infrastructure, exemplified by its application in epidemic event detection from social media. ",Kein DOI-Link verfügbar,2407.00191v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Consistent mass formulas for the four-dimensional dyonic NUT-charged   spacetimes,1970,"  In our previous work, a novel idea that the NUT charge can be thought of as a thermodynamical multi-hair has been advocated to describe perfectly the thermodynamical character of the generic four-dimensional Taub-NUT spacetimes. According to this scheme, the Komar mass M, the gravito-magnetic charge and/or the dual (magnetic) mass N, together with a new secondary hair J_N=MN, namely, a Kerr-like conserved angular momentum, enter into the standard forms of the first law and Bekenstein-Smarr mass formula. Distinguished from other recent attempts, our consistent thermodynamic differential and integral mass formulae are both obtainable from a meaningful Christodoulou-Ruffini-type squared mass formula of almost all of the four-dimensional NUT-charged spacetimes. As an excellent consequence, the famous Bekenstein-Hawking one-quarter area-entropy relation can be naturally restored not only in the Lorentzian sector and but also in the Euclidian counterpart of the generic Taub-NUT-type spacetimes without imposing any constraint condition. However, only purely electric-charged cases in the four-dimensional Einstein-Maxwell gravity theory with a NUT charge have been addressed there. In this paper, we shall follow the simple, systematic way proposed in that article to further investigate the dyonic NUT-charged case. It is shown that the standard thermodynamic relations continue to hold true provided that no new secondary charge is added, however, the so-obtained electrostatic and magneto-static potentials are not coincident with those computed via the standard method. To rectify this inconsistence, a simple strategy is provided by further introducing two additional secondary hairs: Q_N=QN and P_N=PN, together with their thermodynamical conjugate potentials, so that the first law and Bekenstein-Smarr mass formula are still satisfied. ",https://doi.org/10.1103/PhysRevD.105.124013,2202.09251v3,Yes,potent(2)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Constrained Adaptive Projection with Pretrained Features for Anomaly   Detection,1970,"  Anomaly detection aims to separate anomalies from normal samples, and the pretrained network is promising for anomaly detection. However, adapting the pretrained features would be confronted with the risk of pattern collapse when finetuning on one-class training data. In this paper, we propose an anomaly detection framework called constrained adaptive projection with pretrained features (CAP). Combined with pretrained features, a simple linear projection head applied on a specific input and its k most similar pretrained normal representations is designed for feature adaptation, and a reformed self-attention is leveraged to mine the inner-relationship among one-class semantic features. A loss function is proposed to avoid potential pattern collapse. Concretely, it considers the similarity between a specific data and its corresponding adaptive normal representation, and incorporates a constraint term slightly aligning pretrained and adaptive spaces. Our method achieves state-ofthe-art anomaly detection performance on semantic anomaly detection and sensory anomaly detection benchmarks including 96.5% AUROC on CIFAR- 100 dataset, 97.0% AUROC on CIFAR-10 dataset and 89.9% AUROC on MvTec dataset. ",Kein DOI-Link verfügbar,2112.02597v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Machine Learning for Building Energy and Indoor Environment: A   Perspective,1970,"  Machine learning is a promising technique for many practical applications. In this perspective, we illustrate the development and application for machine learning. It is indicated that the theories and applications of machine learning method in the field of energy conservation and indoor environment are not mature, due to the difficulty of the determination for model structure with better prediction. In order to significantly contribute to the problems, we utilize the ANN model to predict the indoor culturable fungi concentration, which achieves the better accuracy and convenience. The proposal of hybrid method is further expand the application fields of machine learning method. Further, ANN model based on HTS was successfully applied for the optimization of building energy system. We hope that this novel method could capture more attention from investigators via our introduction and perspective, due to its potential development with accuracy and reliability. However, its feasibility in other fields needs to be promoted further. ",Kein DOI-Link verfügbar,1801.00779v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Time Series Anomaly Detection for Smart Grids: A Survey,1970,"  With the rapid increase in the integration of renewable energy generation and the wide adoption of various electric appliances, power grids are now faced with more and more challenges. One prominent challenge is to implement efficient anomaly detection for different types of anomalous behaviors within power grids. These anomalous behaviors might be induced by unusual consumption patterns of the users, faulty grid infrastructures, outages, external cyberattacks, or energy fraud. Identifying such anomalies is of critical importance for the reliable and efficient operation of modern power grids. Various methods have been proposed for anomaly detection on power grid time-series data. This paper presents a short survey of the recent advances in anomaly detection for power grid time-series data. Specifically, we first outline current research challenges in the power grid anomaly detection domain and further review the major anomaly detection approaches. Finally, we conclude the survey by identifying the potential directions for future research. ",Kein DOI-Link verfügbar,2107.08835v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,MetaEMS: A Meta Reinforcement Learning-based Control Framework for   Building Energy Management System,1970,"  The building sector has been recognized as one of the primary sectors for worldwide energy consumption. Improving the energy efficiency of the building sector can help reduce the operation cost and reduce the greenhouse gas emission. The energy management system (EMS) can monitor and control the operations of built-in appliances in buildings, so an efficient EMS is of crucial importance to improve the building operation efficiency and maintain safe operations. With the growing penetration of renewable energy and electrical appliances, increasing attention has been paid to the development of intelligent building EMS. Recently, reinforcement learning (RL) has been applied for building EMS and has shown promising potential. However, most of the current RL-based EMS solutions would need a large amount of data to learn a reliable control policy, which limits the applicability of these solutions in the real world. In this work, we propose MetaEMS, which can help achieve better energy management performance with the benefits of RL and meta-learning. Experiment results showcase that our proposed MetaEMS can adapt faster to environment changes and perform better in most situations compared with other baselines. ",Kein DOI-Link verfügbar,2210.12590v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,MonoDETRNext: Next-generation Accurate and Efficient Monocular 3D Object   Detection Method,1970,"  Monocular vision-based 3D object detection is crucial in various sectors, yet existing methods face significant challenges in terms of accuracy and computational efficiency. Building on the successful strategies in 2D detection and depth estimation, we propose MonoDETRNext, which seeks to optimally balance precision and processing speed. Our methodology includes the development of an efficient hybrid visual encoder, enhancement of depth prediction mechanisms, and introduction of an innovative query generation strategy, augmented by an advanced depth predictor. Building on MonoDETR, MonoDETRNext introduces two variants: MonoDETRNext-F, which emphasizes speed, and MonoDETRNext-A, which focuses on precision. We posit that MonoDETRNext establishes a new benchmark in monocular 3D object detection and opens avenues for future research. We conducted an exhaustive evaluation demonstrating the model's superior performance against existing solutions. Notably, MonoDETRNext-A demonstrated a 4.60% improvement in the AP3D metric on the KITTI test benchmark over MonoDETR, while MonoDETRNext-F showed a 2.21% increase. Additionally, the computational efficiency of MonoDETRNext-F slightly exceeds that of its predecessor. ",Kein DOI-Link verfügbar,2405.15176v1,Yes,innovative(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,VORTEX: Real-Time Off-Chain Payments and Cross-Chain Swaps for   Cryptocurrencies,1970,"  In this paper, we present VERTEX, a TEE-based layer-2 solution that tackles two crucial challenges in the realm of cryptocurrencies: off-chain payments and cross-chain swaps. It offers three notable features: - Channel-free off-chain payments: it allows a payer to make direct payments to anyone without requiring any on-chain relationship or intermediary channels. - Real-time yet decentralized cross-chain swaps: it is the first known solution that enables real-time cross-chain swaps without relying on a central server. This novel feature is made possible through a ground-breaking fair exchange protocol. - TEE crash-tolerance: it offers two solutions to handle TEE crashes, one of which involves an innovative application of time-lock puzzles in this context. We evaluate ECHO on a network consists of 1000 nodes and the evaluation results show that ECHO can achieve 7000 TPS ",Kein DOI-Link verfügbar,2403.15191v3,Yes,"innovative(1), notable(1)"
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Neuro-BERT: Rethinking Masked Autoencoding for Self-supervised   Neurological Pretraining,1970,"  Deep learning associated with neurological signals is poised to drive major advancements in diverse fields such as medical diagnostics, neurorehabilitation, and brain-computer interfaces. The challenge in harnessing the full potential of these signals lies in the dependency on extensive, high-quality annotated data, which is often scarce and expensive to acquire, requiring specialized infrastructure and domain expertise. To address the appetite for data in deep learning, we present Neuro-BERT, a self-supervised pre-training framework of neurological signals based on masked autoencoding in the Fourier domain. The intuition behind our approach is simple: frequency and phase distribution of neurological signals can reveal intricate neurological activities. We propose a novel pre-training task dubbed Fourier Inversion Prediction (FIP), which randomly masks out a portion of the input signal and then predicts the missing information using the Fourier inversion theorem. Pre-trained models can be potentially used for various downstream tasks such as sleep stage classification and gesture recognition. Unlike contrastive-based methods, which strongly rely on carefully hand-crafted augmentations and siamese structure, our approach works reasonably well with a simple transformer encoder with no augmentation requirements. By evaluating our method on several benchmark datasets, we show that Neuro-BERT improves downstream neurological-related tasks by a large margin. ",Kein DOI-Link verfügbar,2204.12440v2,Yes,"intricate(1), potent(2)"
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Dual Class-Aware Contrastive Federated Semi-Supervised Learning,1970,"  Federated semi-supervised learning (FSSL), facilitates labeled clients and unlabeled clients jointly training a global model without sharing private data. Existing FSSL methods predominantly employ pseudo-labeling and consistency regularization to exploit the knowledge of unlabeled data, achieving notable success in raw data utilization. However, these training processes are hindered by large deviations between uploaded local models of labeled and unlabeled clients, as well as confirmation bias introduced by noisy pseudo-labels, both of which negatively affect the global model's performance. In this paper, we present a novel FSSL method called Dual Class-aware Contrastive Federated Semi-Supervised Learning (DCCFSSL). This method accounts for both the local class-aware distribution of each client's data and the global class-aware distribution of all clients' data within the feature space. By implementing a dual class-aware contrastive module, DCCFSSL establishes a unified training objective for different clients to tackle large deviations and incorporates contrastive information in the feature space to mitigate confirmation bias. Moreover, DCCFSSL introduces an authentication-reweighted aggregation technique to improve the server's aggregation robustness. Our comprehensive experiments show that DCCFSSL outperforms current state-of-the-art methods on three benchmark datasets and surpasses the FedAvg with relabeled unlabeled clients on CIFAR-10, CIFAR-100, and STL-10 datasets. To our knowledge, we are the first to present an FSSL method that utilizes only 10\% labeled clients, while still achieving superior performance compared to standard federated supervised learning, which uses all clients with labeled data. ",Kein DOI-Link verfügbar,2211.08914v2,Yes,notable(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,HAIFIT: Human-to-AI Fashion Image Translation,1970,"  In the realm of fashion design, sketches serve as the canvas for expressing an artist's distinctive drawing style and creative vision, capturing intricate details like stroke variations and texture nuances. The advent of sketch-to-image cross-modal translation technology has notably aided designers. However, existing methods often compromise these sketch details during image generation, resulting in images that deviate from the designer's intended concept. This limitation hampers the ability to offer designers a precise preview of the final output. To overcome this challenge, we introduce HAIFIT, a novel approach that transforms sketches into high-fidelity, lifelike clothing images by integrating multi-scale features and capturing extensive feature map dependencies from diverse perspectives. Through extensive qualitative and quantitative evaluations conducted on our self-collected dataset, our method demonstrates superior performance compared to existing methods in generating photorealistic clothing images. Our method excels in preserving the distinctive style and intricate details essential for fashion design applications. In addition, our method also has obvious advantages in model training and inference speed, contributing to reducing designers' time costs and improving design efficiency. ",Kein DOI-Link verfügbar,2403.08651v5,Yes,intricate(2)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,An Online Spatial-Temporal Graph Trajectory Planner for Autonomous   Vehicles,1970,"  The autonomous driving industry is expected to grow by over 20 times in the coming decade and, thus, motivate researchers to delve into it. The primary focus of their research is to ensure safety, comfort, and efficiency. An autonomous vehicle has several modules responsible for one or more of the aforementioned items. Among these modules, the trajectory planner plays a pivotal role in the safety of the vehicle and the comfort of its passengers. The module is also responsible for respecting kinematic constraints and any applicable road constraints. In this paper, a novel online spatial-temporal graph trajectory planner is introduced to generate safe and comfortable trajectories. First, a spatial-temporal graph is constructed using the autonomous vehicle, its surrounding vehicles, and virtual nodes along the road with respect to the vehicle itself. Next, the graph is forwarded into a sequential network to obtain the desired states. To support the planner, a simple behavioral layer is also presented that determines kinematic constraints for the planner. Furthermore, a novel potential function is also proposed to train the network. Finally, the proposed planner is tested on three different complex driving tasks, and the performance is compared with two frequently used methods. The results show that the proposed planner generates safe and feasible trajectories while achieving similar or longer distances in the forward direction and comparable comfort ride. ",https://doi.org/10.1109/TIV.2024.3389640,2404.12256v1,Yes,"pivotal(1), potent(1)"
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Comparison of Binary Classification Based on Signed Distance Functions   with Support Vector Machines,1970,"  We investigate the performance of a simple signed distance function (SDF) based method by direct comparison with standard SVM packages, as well as K-nearest neighbor and RBFN methods. We present experimental results comparing the SDF approach with other classifiers on both synthetic geometric problems and five benchmark clinical microarray data sets. On both geometric problems and microarray data sets, the non-optimized SDF based classifiers perform just as well or slightly better than well-developed, standard SVM methods. These results demonstrate the potential accuracy of SDF-based methods on some types of problems. ",Kein DOI-Link verfügbar,0812.3147v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,LoAS: Fully Temporal-Parallel Dataflow for Dual-Sparse Spiking Neural   Networks,1970,"  Spiking Neural Networks (SNNs) have gained significant research attention in the last decade due to their potential to drive resource-constrained edge devices. Though existing SNN accelerators offer high efficiency in processing sparse spikes with dense weights, opportunities are less explored in SNNs with sparse weights, i.e., dual-sparsity. In this work, we study the acceleration of dual-sparse SNNs, focusing on their core operation, sparse-matrix-sparse-matrix multiplication (spMspM). We observe that naively running a dual-sparse SNN on existing spMspM accelerators designed for dual-sparse Artificial Neural Networks (ANNs) exhibits sub-optimal efficiency. The main challenge is that processing timesteps, a natural property of SNNs, introduces an extra loop to ANN spMspM, leading to longer latency and more memory traffic. To address the problem, we propose a fully temporal-parallel (FTP) dataflow, which minimizes both data movement across timesteps and the end-to-end latency of dual-sparse SNNs. To maximize the efficiency of FTP dataflow, we propose an FTP-friendly spike compression mechanism that efficiently compresses single-bit spikes and ensures contiguous memory access. We further propose an FTP-friendly inner-join circuit that can lower the cost of the expensive prefix-sum circuits with almost no throughput penalty. All the above techniques for FTP dataflow are encapsulated in LoAS, a Low-latency inference Accelerator for dual-sparse SNNs. With FTP dataflow, compression, and inner-join, running dual-sparse SNN workloads on LoAS demonstrates significant speedup (up to $8.51\times$) and energy reduction (up to $3.68\times$) compared to running it on prior dual-sparse accelerators. ",Kein DOI-Link verfügbar,2407.14073v3,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,On Leveraging Encoder-only Pre-trained Language Models for Effective   Keyphrase Generation,1970,"  This study addresses the application of encoder-only Pre-trained Language Models (PLMs) in keyphrase generation (KPG) amidst the broader availability of domain-tailored encoder-only models compared to encoder-decoder models. We investigate three core inquiries: (1) the efficacy of encoder-only PLMs in KPG, (2) optimal architectural decisions for employing encoder-only PLMs in KPG, and (3) a performance comparison between in-domain encoder-only and encoder-decoder PLMs across varied resource settings. Our findings, derived from extensive experimentation in two domains reveal that with encoder-only PLMs, although KPE with Conditional Random Fields slightly excels in identifying present keyphrases, the KPG formulation renders a broader spectrum of keyphrase predictions. Additionally, prefix-LM fine-tuning of encoder-only PLMs emerges as a strong and data-efficient strategy for KPG, outperforming general-domain seq2seq PLMs. We also identify a favorable parameter allocation towards model depth rather than width when employing encoder-decoder architectures initialized with encoder-only PLMs. The study sheds light on the potential of utilizing encoder-only PLMs for advancing KPG systems and provides a groundwork for future KPG methods. Our code and pre-trained checkpoints are released at https://github.com/uclanlp/DeepKPG. ",Kein DOI-Link verfügbar,2402.14052v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Design of Small Multi-band Full-screen Smartwatch Antenna for IoT   applications,1970,"  Smartwatch is a potential candidate for the Internet of Things (IoT) hub. However, the performance of smartwatch antennas is severely restricted by the smartwatch structure, especially when the antennas are designed by traditional methods. For adapting smartwatches to the role of IoT hub, a novel method of designing multi-band smartwatch antenna is presented in this paper, aiming at increasing the number of frequency bands, omni-directivity, and structural suitability. Firstly, the fundamental structure (including the full screen and the system PCB) of the smartwatch is analyzed as a whole by characteristic mode analysis (CMA). Thus, abundant resources of characteristic modes are introduced. The fundamental structure is then modified as the radiator of a multi-band antenna. Then, a non-radiating capacitive coupling element (CCE) excites the desired four 0.5-wavelength modes from this structure. This method could fully utilize the intrinsic modes of the smartwatch structure itself, thus exhibits multiple advantages: significantly small size, smaller ground, omni-directional radiation, and fitting to the full-screen smartwatch structure. ",https://doi.org/10.1109/JIOT.2021.3082535,1912.12788v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Exploring Localization for Self-supervised Fine-grained Contrastive   Learning,1970,"  Self-supervised contrastive learning has demonstrated great potential in learning visual representations. Despite their success in various downstream tasks such as image classification and object detection, self-supervised pre-training for fine-grained scenarios is not fully explored. We point out that current contrastive methods are prone to memorizing background/foreground texture and therefore have a limitation in localizing the foreground object. Analysis suggests that learning to extract discriminative texture information and localization are equally crucial for fine-grained self-supervised pre-training. Based on our findings, we introduce cross-view saliency alignment (CVSA), a contrastive learning framework that first crops and swaps saliency regions of images as a novel view generation and then guides the model to localize on foreground objects via a cross-view alignment loss. Extensive experiments on both small- and large-scale fine-grained classification benchmarks show that CVSA significantly improves the learned representation. ",Kein DOI-Link verfügbar,2106.15788v4,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,ModelLight: Model-Based Meta-Reinforcement Learning for Traffic Signal   Control,1970,"  Traffic signal control is of critical importance for the effective use of transportation infrastructures. The rapid increase of vehicle traffic and changes in traffic patterns make traffic signal control more and more challenging. Reinforcement Learning (RL)-based algorithms have demonstrated their potential in dealing with traffic signal control. However, most existing solutions require a large amount of training data, which is unacceptable for many real-world scenarios. This paper proposes a novel model-based meta-reinforcement learning framework (ModelLight) for traffic signal control. Within ModelLight, an ensemble of models for road intersections and the optimization-based meta-learning method are used to improve the data efficiency of an RL-based traffic light control method. Experiments on real-world datasets demonstrate that ModelLight can outperform state-of-the-art traffic light control algorithms while substantially reducing the number of required interactions with the real-world environment. ",Kein DOI-Link verfügbar,2111.08067v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Decoding Modular Reconfigurable Robots: A Survey on Mechanisms and   Design,1970,"  The intrinsic modularity and reconfigurability of modular reconfigurable robots (MRR) confer advantages such as versatility, fault tolerance, and economic efficacy, thereby showcasing considerable potential across diverse applications. The continuous evolution of the technology landscape and the emergence of diverse conceptual designs have generated multiple MRR categories, each described by its respective morphology or capability characteristics, leading to some ambiguity in the taxonomy. This paper conducts a comprehensive survey encompassing the entirety of MRR hardware and design, spanning from the inception in 1985 to 2023. This paper introduces an innovative, unified conceptual framework for understanding MRR hardware, which encompasses three pivotal elements: connectors, actuators, and homogeneity. Through the utilization of this trilateral framework, this paper provide an intuitive understanding of the diverse spectrum of MRR hardware iterations while systematically deciphering and classifying the entire range, offering a more structured perspective. This survey elucidates the fundamental attributes characterizing MRRs and their compositional aspects, providinig insights into their design, technology, functionality, and categorization. Augmented by the proposed trilateral framework, this paper also elaborates on the trajectory of evolution, prevailing trends, principal challenges, and potential prospects within the field of MRRs. ",Kein DOI-Link verfügbar,2310.09743v1,Yes,"innovative(1), pivotal(1), potent(2)"
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,The Factuality Tax of Diversity-Intervened Text-to-Image Generation:   Benchmark and Fact-Augmented Intervention,1970,"  Prompt-based ""diversity interventions"" are commonly adopted to improve the diversity of Text-to-Image (T2I) models depicting individuals with various racial or gender traits. However, will this strategy result in nonfactual demographic distribution, especially when generating real historical figures? In this work, we propose DemOgraphic FActualIty Representation (DoFaiR), a benchmark to systematically quantify the trade-off between using diversity interventions and preserving demographic factuality in T2I models. DoFaiR consists of 756 meticulously fact-checked test instances to reveal the factuality tax of various diversity prompts through an automated evidence-supported evaluation pipeline. Experiments on DoFaiR unveil that diversity-oriented instructions increase the number of different gender and racial groups in DALLE-3's generations at the cost of historically inaccurate demographic distributions. To resolve this issue, we propose Fact-Augmented Intervention (FAI), which instructs a Large Language Model (LLM) to reflect on verbalized or retrieved factual information about gender and racial compositions of generation subjects in history, and incorporate it into the generation context of T2I models. By orienting model generations using the reflected historical truths, FAI significantly improves the demographic factuality under diversity interventions while preserving diversity. ",Kein DOI-Link verfügbar,2407.00377v1,Yes,"meticulous(1), meticulously(1)"
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Robust Load Prediction of Power Network Clusters Based on   Cloud-Model-Improved Transformer,1970,"  Load data from power network clusters indicates economic development in each area, crucial for predicting regional trends and guiding power enterprise decisions. The Transformer model, a leading method for load prediction, faces challenges modeling historical data due to variables like weather, events, festivals, and data volatility. To tackle this, the cloud model's fuzzy feature is utilized to manage uncertainties effectively. Presenting an innovative approach, the Cloud Model Improved Transformer (CMIT) method integrates the Transformer model with the cloud model utilizing the particle swarm optimization algorithm, with the aim of achieving robust and precise power load predictions. Through comparative experiments conducted on 31 real datasets within a power network cluster, it is demonstrated that CMIT significantly surpasses the Transformer model in terms of prediction accuracy, thereby highlighting its effectiveness in enhancing forecasting capabilities within the power network cluster sector. ",Kein DOI-Link verfügbar,2407.20817v1,Yes,innovative(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,From Distributed Machine Learning To Federated Learning: In The View Of   Data Privacy And Security,1970,"  Federated learning is an improved version of distributed machine learning that further offloads operations which would usually be performed by a central server. The server becomes more like an assistant coordinating clients to work together rather than micro-managing the workforce as in traditional DML. One of the greatest advantages of federated learning is the additional privacy and security guarantees it affords. Federated learning architecture relies on smart devices, such as smartphones and IoT sensors, that collect and process their own data, so sensitive information never has to leave the client device. Rather, clients train a sub-model locally and send an encrypted update to the central server for aggregation into the global model. These strong privacy guarantees make federated learning an attractive choice in a world where data breaches and information theft are common and serious threats. This survey outlines the landscape and latest developments in data privacy and security for federated learning. We identify the different mechanisms used to provide privacy and security, such as differential privacy, secure multi-party computation and secure aggregation. We also survey the current attack models, identifying the areas of vulnerability and the strategies adversaries use to penetrate federated systems. The survey concludes with a discussion on the open challenges and potential directions of future work in this increasingly popular learning paradigm. ",https://doi.org/10.1002/cpe.6002,2010.09258v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Realizing XR Applications Using 5G-Based 3D Holographic Communication   and Mobile Edge Computing,1970,"  3D holographic communication has the potential to revolutionize the way people interact with each other in virtual spaces, offering immersive and realistic experiences. However, demands for high data rates, extremely low latency, and high computations to enable this technology pose a significant challenge. To address this challenge, we propose a novel job scheduling algorithm that leverages Mobile Edge Computing (MEC) servers in order to minimize the total latency in 3D holographic communication. One of the motivations for this work is to prevent the uncanny valley effect, which can occur when the latency hinders the seamless and real-time rendering of holographic content, leading to a less convincing and less engaging user experience. Our proposed algorithm dynamically allocates computation tasks to MEC servers, considering the network conditions, computational capabilities of the servers, and the requirements of the 3D holographic communication application. We conduct extensive experiments to evaluate the performance of our algorithm in terms of latency reduction, and the results demonstrate that our approach significantly outperforms other baseline methods. Furthermore, we present a practical scenario involving Augmented Reality (AR), which not only illustrates the applicability of our algorithm but also highlights the importance of minimizing latency in achieving high-quality holographic views. By efficiently distributing the computation workload among MEC servers and reducing the overall latency, our proposed algorithm enhances the user experience in 3D holographic communications and paves the way for the widespread adoption of this technology in various applications, such as telemedicine, remote collaboration, and entertainment. ",Kein DOI-Link verfügbar,2310.03908v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts,1970,"  DeFi incidents stemming from various smart contract vulnerabilities have culminated in financial damages exceeding 3 billion USD. The attacks causing such incidents commonly commence with the deployment of adversarial contracts, subsequently leveraging these contracts to execute adversarial transactions that exploit vulnerabilities in victim contracts. Existing defense mechanisms leverage heuristic or machine learning algorithms to detect adversarial transactions, but they face significant challenges in detecting private adversarial transactions. Namely, attackers can send adversarial transactions directly to miners, evading visibility within the blockchain network and effectively bypassing the detection. In this paper, we propose a new direction for detecting DeFi attacks, i.e., detecting adversarial contracts instead of adversarial transactions, allowing us to proactively identify potential attack intentions, even if they employ private adversarial transactions. Specifically, we observe that most adversarial contracts follow a similar pattern, e.g., anonymous fund source, closed-source, frequent token-related function calls. Based on this observation, we build a machine learning classifier that can effectively distinguish adversarial contracts from benign ones. We build a dataset consists of features extracted from 269 adversarial contracts and 13,000 benign contracts. Based on this dataset, we evaluate different classifiers, the results of which show that our method for identifying DeFi adversarial contracts performs exceptionally well. For example, the F1-Score for LightGBM-based classifier is 0.9541, with a remarkably low false positive rate of only 0.15%. ",Kein DOI-Link verfügbar,2401.07261v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Scalar Induced Gravitational Waves from Finslerian Inflation and Pulsar   Timing Arrays Observations,1970,"  The recent data from NANOGrav provide strong evidence of the existence of the \acp{SGWB}. We investigate \acp{SIGW} from Finslerian inflation as a potential source of stochastic gravitational wave background. Small-scale ($\lesssim$1 Mpc) statistically anisotropic primordial scalar perturbations can be generated in Finslerian inflation. The second order \acp{SIGW} from Finslerian inflation are also anisotropic on small scales. After spatially averaging the small-scale anisotropic \acp{SIGW}, we obtain the large-scale isotropic \acp{SGWB}. We find that the parameters of small-scale anisotropic primordial power spectrum generated by Finslerian inflation affect the \acp{PTA} observations of large-scale isotropic gravitational wave background. ",Kein DOI-Link verfügbar,2309.06676v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Colossal electroresistance in metal/ferroelectric/semiconductor tunnel   diodes for resistive switching memories,1970,"  We propose a tunneling heterostructure by replacing one of the metal electrodes in a metal/ferroelectric/metal ferroelectric tunnel junction with a heavily doped semiconductor. In this metal/ferroelectric/semiconductor tunnel diode, both the height and the width of the tunneling barrier can be electrically modulated due to the ferroelectric field effect, leading to a colossal tunneling electroresistance. This idea is implemented in Pt/BaTiO3/Nb:SrTiO3 heterostructures, in which an ON/OFF conductance ratio above 10$^4$ can be readily achieved at room temperature. The colossal tunneling electroresistance, reliable switching reproducibility and long data retention observed in these ferroelectric tunnel diodes suggest their great potential in non-destructive readout nonvolatile memories. ",https://doi.org/10.1038/nmat3649,1208.5300v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,FedDWA: Personalized Federated Learning with Dynamic Weight Adjustment,1970,"  Different from conventional federated learning, personalized federated learning (PFL) is able to train a customized model for each individual client according to its unique requirement. The mainstream approach is to adopt a kind of weighted aggregation method to generate personalized models, in which weights are determined by the loss value or model parameters among different clients. However, such kinds of methods require clients to download others' models. It not only sheer increases communication traffic but also potentially infringes data privacy. In this paper, we propose a new PFL algorithm called \emph{FedDWA (Federated Learning with Dynamic Weight Adjustment)} to address the above problem, which leverages the parameter server (PS) to compute personalized aggregation weights based on collected models from clients. In this way, FedDWA can capture similarities between clients with much less communication overhead. More specifically, we formulate the PFL problem as an optimization problem by minimizing the distance between personalized models and guidance models, so as to customize aggregation weights for each client. Guidance models are obtained by the local one-step ahead adaptation on individual clients. Finally, we conduct extensive experiments using five real datasets and the results demonstrate that FedDWA can significantly reduce the communication traffic and achieve much higher model accuracy than the state-of-the-art approaches. ",Kein DOI-Link verfügbar,2305.06124v3,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Repoformer: Selective Retrieval for Repository-Level Code Completion,1970,"  Recent advances in retrieval-augmented generation (RAG) have initiated a new era in repository-level code completion. However, the invariable use of retrieval in existing methods exposes issues in both efficiency and robustness, with a large proportion of the retrieved contexts proving unhelpful or harmful to code language models (code LMs). In this paper, we propose a selective RAG framework to avoid retrieval when unnecessary. To power this framework, we design a self-supervised learning approach to enable a code LM to accurately self-evaluate whether retrieval can improve its output quality and robustly leverage the potentially noisy retrieved contexts. Using this LM as both the selective RAG policy and the generation model, our framework achieves state-of-the-art repository-level code completion performance on diverse benchmarks including RepoEval, CrossCodeEval, and CrossCodeLongEval, a new long-form code completion benchmark. Meanwhile, our analyses show that selectively retrieving brings as much as 70% inference speedup in the online serving setting without harming the performance. We further demonstrate that our framework is able to accommodate different generation models, retrievers, and programming languages. These advancements position our framework as an important step towards more accurate and efficient repository-level code completion. ",Kein DOI-Link verfügbar,2403.10059v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,BRIEDGE: EEG-Adaptive Edge AI for Multi-Brain to Multi-Robot Interaction,1970,"  Recent advances in EEG-based BCI technologies have revealed the potential of brain-to-robot collaboration through the integration of sensing, computing, communication, and control. In this paper, we present BRIEDGE as an end-to-end system for multi-brain to multi-robot interaction through an EEG-adaptive neural network and an encoding-decoding communication framework, as illustrated in Fig.1. As depicted, the edge mobile server or edge portable server will collect EEG data from the users and utilize the EEG-adaptive neural network to identify the users' intentions. The encoding-decoding communication framework then encodes the EEG-based semantic information and decodes it into commands in the process of data transmission. To better extract the joint features of heterogeneous EEG data as well as enhance classification accuracy, BRIEDGE introduces an informer-based ProbSparse self-attention mechanism. Meanwhile, parallel and secure transmissions for multi-user multi-task scenarios under physical channels are addressed by dynamic autoencoder and autodecoder communications. From mobile computing and edge AI perspectives, model compression schemes composed of pruning, weight sharing, and quantization are also used to deploy lightweight EEG-adaptive models running on both transmitter and receiver sides. Based on the effectiveness of these components, a code map representing various commands enables multiple users to control multiple intelligent agents concurrently. Our experiments in comparison with state-of-the-art works show that BRIEDGE achieves the best classification accuracy of heterogeneous EEG data, and more stable performance under noisy environments. ",Kein DOI-Link verfügbar,2403.15432v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,A Practical Marine Wireless Sensor Network Monitoring System Based on   LoRa and MQTT,1970,"  Under the advocacy of the international community, more and more research topics have been built around the ocean. This paper proposed an implementation scheme of marine wireless sensor network monitoring system based on LoRa and MQTT. Different from the traditional network architecture, the system was constructed by combining with two network forms, and according to their respective characteristics, the overall design followed the transition from LoRa to MQTT. We first used LoRa to interconnect the sensor nodes with the gateway, and on this basis, the collected data was sent to the server visualization platform through MQTT, the backend management server would continuously refresh the monitoring page. At the same time, the client could use a browser-based web application to directly access and call data for global maritime information monitoring. In the future, we will further improve the system and optimize the algorithm, to achieve more dimensions and deeper exploration of the underwater world. ",Kein DOI-Link verfügbar,1906.09571v1,Yes,fresh(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Virtual Reality: A Survey of Enabling Technologies and its Applications   in IoT,1970,"  Virtual Reality (VR) has shown great potential to revolutionize the market by providing users immersive experiences with freedom of movement. Compared to traditional video streaming, VR is with ultra high-definition and dynamically changes with users' head and eye movements, which poses significant challenges for the realization of such potential. In this paper, we provide a detailed and systematic survey of enabling technologies of virtual reality and its applications in Internet of Things (IoT). We identify major challenges of virtual reality on system design, view prediction, computation, streaming, and quality of experience evaluation. We discuss each of them by extensively surveying and reviewing related papers in the recent years. We also introduce several use cases of VR for IoT. Last, issues and future research directions are also identified and discussed. ",Kein DOI-Link verfügbar,2103.06472v1,Yes,potent(2)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Adaptive Dynamic Programming for Energy-Efficient Base Station Cell   Switching,1970,"  Energy saving in wireless networks is growing in importance due to increasing demand for evolving new-gen cellular networks, environmental and regulatory concerns, and potential energy crises arising from geopolitical tensions. In this work, we propose an approximate dynamic programming (ADP)-based method coupled with online optimization to switch on/off the cells of base stations to reduce network power consumption while maintaining adequate Quality of Service (QoS) metrics. We use a multilayer perceptron (MLP) given each state-action pair to predict the power consumption to approximate the value function in ADP for selecting the action with optimal expected power saved. To save the largest possible power consumption without deteriorating QoS, we include another MLP to predict QoS and a long short-term memory (LSTM) for predicting handovers, incorporated into an online optimization algorithm producing an adaptive QoS threshold for filtering cell switching actions based on the overall QoS history. The performance of the method is evaluated using a practical network simulator with various real-world scenarios with dynamic traffic patterns. ",Kein DOI-Link verfügbar,2310.12999v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Meta-Task Prompting Elicits Embeddings from Large Language Models,1970,"  We introduce a new unsupervised text embedding method, Meta-Task Prompting with Explicit One-Word Limitation (MetaEOL), for generating high-quality sentence embeddings from Large Language Models (LLMs) without the need for model fine-tuning. Leveraging meta-task prompting, MetaEOL guides LLMs to produce embeddings through a series of carefully designed prompts that address multiple representational aspects. Our comprehensive experiments demonstrate that embeddings averaged from various meta-tasks are versatile embeddings that yield competitive performance on Semantic Textual Similarity (STS) benchmarks and excel in downstream tasks, surpassing contrastive-trained models. Our findings suggest a new scaling law, offering a versatile and resource-efficient approach for embedding generation across diverse scenarios. ",Kein DOI-Link verfügbar,2402.18458v2,Yes,versatile(2)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Induced gravitational waves for arbitrary higher orders: vertex rules   and loop diagrams in cosmological perturbation theory,1970,"  Gravitational waves induced by primordial perturbations serve as crucial probes for studying the early universe, providing a significant window into potential new physics during cosmic evolution. Due to the potentially large amplitudes of primordial perturbations on small scales, the contributions of high-order cosmological perturbations are highly significant. We propose a vertex approach applicable to the study of induced gravitational waves for arbitrary higher orders. Using the vertex approach and tree diagrams, we can directly derive the explicit expressions of higher-order induced gravitational waves without involving the complex and lengthy calculations of higher-order cosmological perturbations. Correlations between different tree diagrams correspond to the loop diagrams of two-point correlation functions of induced gravitational waves. Our investigation reveals that one-particle reducible diagrams impact tensor-scalar induced gravitational waves while leaving scalar induced gravitational waves unaffected. ",Kein DOI-Link verfügbar,2408.14052v1,Yes,potent(2)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,An Edge Computing-based Photo Crowdsourcing Framework for Real-time 3D   Reconstruction,1970,"  Image-based three-dimensional (3D) reconstruction utilizes a set of photos to build 3D model and can be widely used in many emerging applications such as augmented reality (AR) and disaster recovery. Most of existing 3D reconstruction methods require a mobile user to walk around the target area and reconstruct objectives with a hand-held camera, which is inefficient and time-consuming. To meet the requirements of delay intensive and resource hungry applications in 5G, we propose an edge computing-based photo crowdsourcing (EC-PCS) framework in this paper. The main objective is to collect a set of representative photos from ubiquitous mobile and Internet of Things (IoT) devices at the network edge for real-time 3D model reconstruction, with network resource and monetary cost considerations. Specifically, we first propose a photo pricing mechanism by jointly considering their freshness, resolution and data size. Then, we design a novel photo selection scheme to dynamically select a set of photos with the required target coverage and the minimum monetary cost. We prove the NP-hardness of such problem, and develop an efficient greedy-based approximation algorithm to obtain a near-optimal solution. Moreover, an optimal network resource allocation scheme is presented, in order to minimize the maximum uploading delay of the selected photos to the edge server. Finally, a 3D reconstruction algorithm and a 3D model caching scheme are performed by the edge server in real time. Extensive experimental results based on real-world datasets demonstrate the superior performance of our EC-PCS system over the existing mechanisms. ",Kein DOI-Link verfügbar,2007.01562v1,Yes,fresh(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,When Deep Reinforcement Learning Meets Federated Learning: Intelligent   Multi-Timescale Resource Management for Multi-access Edge Computing in 5G   Ultra Dense Network,1970,"  Ultra-dense edge computing (UDEC) has great potential, especially in the 5G era, but it still faces challenges in its current solutions, such as the lack of: i) efficient utilization of multiple 5G resources (e.g., computation, communication, storage and service resources); ii) low overhead offloading decision making and resource allocation strategies; and iii) privacy and security protection schemes. Thus, we first propose an intelligent ultra-dense edge computing (I-UDEC) framework, which integrates blockchain and Artificial Intelligence (AI) into 5G ultra-dense edge computing networks. First, we show the architecture of the framework. Then, in order to achieve real-time and low overhead computation offloading decisions and resource allocation strategies, we design a novel two-timescale deep reinforcement learning (\textit{2Ts-DRL}) approach, consisting of a fast-timescale and a slow-timescale learning process, respectively. The primary objective is to minimize the total offloading delay and network resource usage by jointly optimizing computation offloading, resource allocation and service caching placement. We also leverage federated learning (FL) to train the \textit{2Ts-DRL} model in a distributed manner, aiming to protect the edge devices' data privacy. Simulation results corroborate the effectiveness of both the \textit{2Ts-DRL} and FL in the I-UDEC framework and prove that our proposed algorithm can reduce task execution time up to 31.87%. ",Kein DOI-Link verfügbar,2009.10601v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Multi-Metric AutoRec for High Dimensional and Sparse User Behavior Data   Prediction,1970,"  User behavior data produced during interaction with massive items in the significant data era are generally heterogeneous and sparse, leaving the recommender system (RS) a large diversity of underlying patterns to excavate. Deep neural network-based models have reached the state-of-the-art benchmark of the RS owing to their fitting capabilities. However, prior works mainly focus on designing an intricate architecture with fixed loss function and regulation. These single-metric models provide limited performance when facing heterogeneous and sparse user behavior data. Motivated by this finding, we propose a multi-metric AutoRec (MMA) based on the representative AutoRec. The idea of the proposed MMA is mainly two-fold: 1) apply different $L_p$-norm on loss function and regularization to form different variant models in different metric spaces, and 2) aggregate these variant models. Thus, the proposed MMA enjoys the multi-metric orientation from a set of dispersed metric spaces, achieving a comprehensive representation of user data. Theoretical studies proved that the proposed MMA could attain performance improvement. The extensive experiment on five real-world datasets proves that MMA can outperform seven other state-of-the-art models in predicting unobserved user behavior data. ",Kein DOI-Link verfügbar,2212.13879v1,Yes,intricate(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Thermodynamic topology of Phantom AdS Black Holes in Massive Gravity,1970,"  In this work, we explore the thermodynamic topology of phantom AdS black holes in the context of massive gravity. To this end, we evaluate these black holes in two distinct ensembles: the canonical and grand canonical ensembles (GCE). We begin by examining the topological charge linked to the critical point and confirming the existence of a conventional critical point $(CP_{1})$ in the canonical ensemble (CE), this critical point has a topological charge of $-1$ and acts as a point of phase annihilation, this situation can only be considered within the context of the classical Einstein-Maxwell (CEM) theory $(\eta=1)$, while no critical point is identified in the GCE. Furthermore, we consider black holes as a topological defect within the thermodynamic space. To gain an understanding of the local and global topological configuration of this defect, we will analyze its winding numbers, and observe that the total topological charge in the CE consistently remains at $1$. When the system experiences a pressure below the critical threshold, it gives rise to the occurrence of annihilation and generation points. The value of electric potential determines whether the total topological charge in the GCE is zero or one. As a result, we detect a point of generation point or absence of generation/annihilation point. Based on our analysis, it can be inferred that ensembles significantly impact the topological class of phantom AdS black holes in massive gravity. ",https://doi.org/10.1016/j.dark.2024.101617,2404.08243v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,PPVF: An Efficient Privacy-Preserving Online Video Fetching Framework   with Correlated Differential Privacy,1970,"  Online video streaming has evolved into an integral component of the contemporary Internet landscape. Yet, the disclosure of user requests presents formidable privacy challenges. As users stream their preferred online videos, their requests are automatically seized by video content providers, potentially leaking users' privacy.   Unfortunately, current protection methods are not well-suited to preserving user request privacy from content providers while maintaining high-quality online video services. To tackle this challenge, we introduce a novel Privacy-Preserving Video Fetching (PPVF) framework, which utilizes trusted edge devices to pre-fetch and cache videos, ensuring the privacy of users' requests while optimizing the efficiency of edge caching. More specifically, we design PPVF with three core components: (1) \textit{Online privacy budget scheduler}, which employs a theoretically guaranteed online algorithm to select non-requested videos as candidates with assigned privacy budgets. Alternative videos are chosen by an online algorithm that is theoretically guaranteed to consider both video utilities and available privacy budgets. (2) \textit{Noisy video request generator}, which generates redundant video requests (in addition to original ones) utilizing correlated differential privacy to obfuscate request privacy. (3) \textit{Online video utility predictor}, which leverages federated learning to collaboratively evaluate video utility in an online fashion, aiding in video selection in (1) and noise generation in (2). Finally, we conduct extensive experiments using real-world video request traces from Tencent Video. The results demonstrate that PPVF effectively safeguards user request privacy while upholding high video caching performance. ",Kein DOI-Link verfügbar,2408.14735v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,NoteLLM: A Retrievable Large Language Model for Note Recommendation,1970,"  People enjoy sharing ""notes"" including their experiences within online communities. Therefore, recommending notes aligned with user interests has become a crucial task. Existing online methods only input notes into BERT-based models to generate note embeddings for assessing similarity. However, they may underutilize some important cues, e.g., hashtags or categories, which represent the key concepts of notes. Indeed, learning to generate hashtags/categories can potentially enhance note embeddings, both of which compress key note information into limited content. Besides, Large Language Models (LLMs) have significantly outperformed BERT in understanding natural languages. It is promising to introduce LLMs into note recommendation. In this paper, we propose a novel unified framework called NoteLLM, which leverages LLMs to address the item-to-item (I2I) note recommendation. Specifically, we utilize Note Compression Prompt to compress a note into a single special token, and further learn the potentially related notes' embeddings via a contrastive learning approach. Moreover, we use NoteLLM to summarize the note and generate the hashtag/category automatically through instruction tuning. Extensive validations on real scenarios demonstrate the effectiveness of our proposed method compared with the online baseline and show major improvements in the recommendation system of Xiaohongshu. ",Kein DOI-Link verfügbar,2403.01744v2,Yes,potent(2)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,NoteLLM-2: Multimodal Large Representation Models for Recommendation,1970,"  Large Language Models (LLMs) have demonstrated exceptional text understanding. Existing works explore their application in text embedding tasks. However, there are few works utilizing LLMs to assist multimodal representation tasks. In this work, we investigate the potential of LLMs to enhance multimodal representation in multimodal item-to-item (I2I) recommendations. One feasible method is the transfer of Multimodal Large Language Models (MLLMs) for representation tasks. However, pre-training MLLMs usually requires collecting high-quality, web-scale multimodal data, resulting in complex training procedures and high costs. This leads the community to rely heavily on open-source MLLMs, hindering customized training for representation scenarios. Therefore, we aim to design an end-to-end training method that customizes the integration of any existing LLMs and vision encoders to construct efficient multimodal representation models. Preliminary experiments show that fine-tuned LLMs in this end-to-end method tend to overlook image content. To overcome this challenge, we propose a novel training framework, NoteLLM-2, specifically designed for multimodal representation. We propose two ways to enhance the focus on visual information. The first method is based on the prompt viewpoint, which separates multimodal content into visual content and textual content. NoteLLM-2 adopts the multimodal In-Content Learning method to teach LLMs to focus on both modalities and aggregate key information. The second method is from the model architecture, utilizing a late fusion mechanism to directly fuse visual information into textual information. Extensive experiments have been conducted to validate the effectiveness of our method. ",Kein DOI-Link verfügbar,2405.16789v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Differentially Private AUC Computation in Vertical Federated Learning,1970,"  Federated learning has gained great attention recently as a privacy-enhancing tool to jointly train a machine learning model by multiple parties. As a sub-category, vertical federated learning (vFL) focuses on the scenario where features and labels are split into different parties. The prior work on vFL has mostly studied how to protect label privacy during model training. However, model evaluation in vFL might also lead to potential leakage of private label information. One mitigation strategy is to apply label differential privacy (DP) but it gives bad estimations of the true (non-private) metrics. In this work, we propose two evaluation algorithms that can more accurately compute the widely used AUC (area under curve) metric when using label DP in vFL. Through extensive experiments, we show our algorithms can achieve more accurate AUCs compared to the baselines. ",Kein DOI-Link verfügbar,2205.12412v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,DPAUC: Differentially Private AUC Computation in Federated Learning,1970,"  Federated learning (FL) has gained significant attention recently as a privacy-enhancing tool to jointly train a machine learning model by multiple participants. The prior work on FL has mostly studied how to protect label privacy during model training. However, model evaluation in FL might also lead to potential leakage of private label information. In this work, we propose an evaluation algorithm that can accurately compute the widely used AUC (area under the curve) metric when using the label differential privacy (DP) in FL. Through extensive experiments, we show our algorithms can compute accurate AUCs compared to the ground truth. The code is available at {\url{https://github.com/bytedance/fedlearner/tree/master/example/privacy/DPAUC}}. ",Kein DOI-Link verfügbar,2208.12294v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Unleashing the Potential of LLMs for Quantum Computing: A Study in   Quantum Architecture Design,1970,"  Large Language Models (LLMs) contribute significantly to the development of conversational AI and has great potentials to assist the scientific research in various areas. This paper attempts to address the following questions: What opportunities do the current generation of generative pre-trained transformers (GPTs) offer for the developments of noisy intermediate-scale quantum (NISQ) technologies? Additionally, what potentials does the forthcoming generation of GPTs possess to push the frontier of research in fault-tolerant quantum computing (FTQC)? In this paper, we implement a QGAS model, which can rapidly propose promising ansatz architectures and evaluate them with application benchmarks including quantum chemistry and quantum finance tasks. Our results demonstrate that after a limited number of prompt guidelines and iterations, we can obtain a high-performance ansatz which is able to produce comparable results that are achieved by state-of-the-art quantum architecture search methods. This study provides a simple overview of GPT's capabilities in supporting quantum computing research while highlighting the limitations of the current GPT at the same time. Additionally, we discuss futuristic applications for LLM in quantum research. ",Kein DOI-Link verfügbar,2307.08191v1,Yes,potent(2)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Appformer: A Novel Framework for Mobile App Usage Prediction Leveraging   Progressive Multi-Modal Data Fusion and Feature Extraction,1970,"  This article presents Appformer, a novel mobile application prediction framework inspired by the efficiency of Transformer-like architectures in processing sequential data through self-attention mechanisms. Combining a Multi-Modal Data Progressive Fusion Module with a sophisticated Feature Extraction Module, Appformer leverages the synergies of multi-modal data fusion and data mining techniques while maintaining user privacy. The framework employs Points of Interest (POIs) associated with base stations, optimizing them through comprehensive comparative experiments to identify the most effective clustering method. These refined inputs are seamlessly integrated into the initial phases of cross-modal data fusion, where temporal units are encoded via word embeddings and subsequently merged in later stages. The Feature Extraction Module, employing Transformer-like architectures specialized for time series analysis, adeptly distils comprehensive features. It meticulously fine-tunes the outputs from the fusion module, facilitating the extraction of high-calibre, multi-modal features, thus guaranteeing a robust and efficient extraction process. Extensive experimental validation confirms Appformer's effectiveness, attaining state-of-the-art (SOTA) metrics in mobile app usage prediction, thereby signifying a notable progression in this field. ",Kein DOI-Link verfügbar,2407.19414v1,Yes,"meticulous(1), notable(1), meticulously(1)"
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Energy Model for UAV Communications: Experimental Validation and Model   Generalization,1970,"  Wireless communication involving unmanned aerial vehicles (UAVs) is expected to play an important role in future wireless networks. However, different from conventional terrestrial communication systems, UAVs typically have rather limited onboard energy on one hand, and require additional flying energy consumption on the other hand, which renders energy-efficient UAV communication with smart energy expenditure of paramount importance. In this paper, via extensive flight experiments, we aim to firstly validate the recently derived theoretical energy model for rotary-wing UAVs, and then develop a general model for those complicated flight scenarios where rigorous theoretical model derivation is quite challenging, if not impossible. Specifically, we first investigate how UAV power consumption varies with its flying speed for the simplest straight-and-level flight. With about 12,000 valid power-speed data points collected, we first apply the model-based curve fitting to obtain the modelling parameters based on the theoretical closed-form energy model in the existing literature. In addition, in order to exclude the potential bias caused by the theoretical energy model, the obtained measurement data is also trained using a model-free deep neural network. It is found that the obtained curve from both methods can match quite well with the theoretical energy model. Next, we further extend the study to arbitrary 2-dimensional (2-D) flight, where, to our best knowledge, no rigorous theoretical derivation is available for the closed-form energy model as a function of its flying speed, direction, and acceleration. To fill the gap, we first propose a heuristic energy model for these more complicated cases, and then provide experimental validation based on the measurement results for circular level flight. ",Kein DOI-Link verfügbar,2005.01305v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,OpenMixup: A Comprehensive Mixup Benchmark for Visual Classification,1970,"  Data mixing, or mixup, is a data-dependent augmentation technique that has greatly enhanced the generalizability of modern deep neural networks. However, a full grasp of mixup methodology necessitates a top-down hierarchical understanding from systematic impartial evaluations and empirical analysis, both of which are currently lacking within the community. In this paper, we present OpenMixup, the first comprehensive mixup benchmarking study for supervised visual classification. OpenMixup offers a unified mixup-based model design and training framework, encompassing a wide collection of data mixing algorithms, a diverse range of widely-used backbones and modules, and a set of model analysis toolkits. To ensure fair and complete comparisons, large-scale standard evaluations of various mixup baselines are conducted across 12 diversified image datasets with meticulous confounders and tweaking powered by our modular and extensible codebase framework. Interesting observations and insights are derived through detailed empirical analysis of how mixup policies, network architectures, and dataset properties affect the mixup visual classification performance. We hope that OpenMixup can bolster the reproducibility of previously gained insights and facilitate a better understanding of mixup properties, thereby giving the community a kick-start for the development and evaluation of new mixup methods. The source code and user documents are available at \url{https://github.com/Westlake-AI/openmixup}. ",Kein DOI-Link verfügbar,2209.04851v2,Yes,meticulous(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,MogaNet: Multi-order Gated Aggregation Network,1970,"  By contextualizing the kernel as global as possible, Modern ConvNets have shown great potential in computer vision tasks. However, recent progress on \textit{multi-order game-theoretic interaction} within deep neural networks (DNNs) reveals the representation bottleneck of modern ConvNets, where the expressive interactions have not been effectively encoded with the increased kernel size. To tackle this challenge, we propose a new family of modern ConvNets, dubbed MogaNet, for discriminative visual representation learning in pure ConvNet-based models with favorable complexity-performance trade-offs. MogaNet encapsulates conceptually simple yet effective convolutions and gated aggregation into a compact module, where discriminative features are efficiently gathered and contextualized adaptively. MogaNet exhibits great scalability, impressive efficiency of parameters, and competitive performance compared to state-of-the-art ViTs and ConvNets on ImageNet and various downstream vision benchmarks, including COCO object detection, ADE20K semantic segmentation, 2D\&3D human pose estimation, and video prediction. Notably, MogaNet hits 80.0\% and 87.8\% accuracy with 5.2M and 181M parameters on ImageNet-1K, outperforming ParC-Net and ConvNeXt-L, while saving 59\% FLOPs and 17M parameters, respectively. The source code is available at \url{https://github.com/Westlake-AI/MogaNet}. ",Kein DOI-Link verfügbar,2211.03295v3,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Mixed-Variable PSO with Fairness on Multi-Objective Field Data   Replication in Wireless Networks,1970,"  Digital twins have shown a great potential in supporting the development of wireless networks. They are virtual representations of 5G/6G systems enabling the design of machine learning and optimization-based techniques. Field data replication is one of the critical aspects of building a simulation-based twin, where the objective is to calibrate the simulation to match field performance measurements. Since wireless networks involve a variety of key performance indicators (KPIs), the replication process becomes a multi-objective optimization problem in which the purpose is to minimize the error between the simulated and field data KPIs. Unlike previous works, we focus on designing a data-driven search method to calibrate the simulator and achieve accurate and reliable reproduction of field performance. This work proposes a search-based algorithm based on mixedvariable particle swarm optimization (PSO) to find the optimal simulation parameters. Furthermore, we extend this solution to account for potential conflicts between the KPIs using {\alpha}-fairness concept to adjust the importance attributed to each KPI during the search. Experiments on field data showcase the effectiveness of our approach to (i) improve the accuracy of the replication, (ii) enhance the fairness between the different KPIs, and (iii) guarantee faster convergence compared to other methods. ",Kein DOI-Link verfügbar,2303.13686v1,Yes,potent(2)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,VQDNA: Unleashing the Power of Vector Quantization for Multi-Species   Genomic Sequence Modeling,1970,"  Similar to natural language models, pre-trained genome language models are proposed to capture the underlying intricacies within genomes with unsupervised sequence modeling. They have become essential tools for researchers and practitioners in biology. However, the hand-crafted tokenization policies used in these models may not encode the most discriminative patterns from the limited vocabulary of genomic data. In this paper, we introduce VQDNA, a general-purpose framework that renovates genome tokenization from the perspective of genome vocabulary learning. By leveraging vector-quantized codebooks as learnable vocabulary, VQDNA can adaptively tokenize genomes into pattern-aware embeddings in an end-to-end manner. To further push its limits, we propose Hierarchical Residual Quantization (HRQ), where varying scales of codebooks are designed in a hierarchy to enrich the genome vocabulary in a coarse-to-fine manner. Extensive experiments on 32 genome datasets demonstrate VQDNA's superiority and favorable parameter efficiency compared to existing genome language models. Notably, empirical analysis of SARS-CoV-2 mutations reveals the fine-grained pattern awareness and biological significance of learned HRQ vocabulary, highlighting its untapped potential for broader applications in genomics. ",Kein DOI-Link verfügbar,2405.10812v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,"A Comprehensive Survey on Machine Learning Driven Material Defect   Detection: Challenges, Solutions, and Future Prospects",1970,"  Material defects (MD) represent a primary challenge affecting product performance and giving rise to safety issues in related products. The rapid and accurate identification and localization of MD constitute crucial research endeavours in addressing contemporary challenges associated with MD. Although conventional non-destructive testing methods such as ultrasonic and X-ray approaches have mitigated issues related to low efficiency in manual inspections, they struggle to meet the diverse requirements of high precision, real-time speed, automation, and intelligence. In recent years, propelled by the swift advancement of machine learning (ML) technologies, particularly exemplified by deep learning, ML has swiftly emerged as the core technology and a prominent research direction for material defect detection (MDD). Through a comprehensive review of the latest literature, we systematically survey the ML techniques applied in MDD into five categories: unsupervised learning, supervised learning, semi-supervised learning, reinforcement learning, and generative learning. We provide a detailed analysis of the main principles and techniques used, together with the advantages and potential challenges associated with these techniques. Furthermore, the survey focuses on the techniques for defect detection in composite materials, which are important types of materials enjoying increasingly wide application in various industries such as aerospace, automotive, construction, and renewable energy. Finally, the survey explores potential future directions in MDD utilizing ML technologies. This comprehensive survey not only consolidates existing literature on ML-based MDD technologies but also serves as a foundational reference for future researchers and industrial practitioners, providing valuable insights and guidance in developing advanced and efficient MDD systems. ",Kein DOI-Link verfügbar,2406.07880v1,Yes,potent(2)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Large Language Model (LLM)-enabled In-context Learning for Wireless   Network Optimization: A Case Study of Power Control,1970,"  Large language model (LLM) has recently been considered a promising technique for many fields. This work explores LLM-based wireless network optimization via in-context learning. To showcase the potential of LLM technologies, we consider the base station (BS) power control as a case study, a fundamental but crucial technique that is widely investigated in wireless networks. Different from existing machine learning (ML) methods, our proposed in-context learning algorithm relies on LLM's inference capabilities. It avoids the complexity of tedious model training and hyper-parameter fine-tuning, which is a well-known bottleneck of many ML algorithms. Specifically, the proposed algorithm first describes the target task via formatted natural language, and then designs the in-context learning framework and demonstration examples. After that, it considers two cases, namely discrete-state and continuous-state problems, and proposes state-based and ranking-based methods to select appropriate examples for these two cases, respectively. Finally, the simulations demonstrate that the proposed algorithm can achieve comparable performance as conventional deep reinforcement learning (DRL) techniques without dedicated model training or fine-tuning. Such an efficient and low-complexity approach has great potential for future wireless network optimization. ",Kein DOI-Link verfügbar,2408.00214v1,Yes,potent(2)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Uncovering edge states and electrical inhomogeneity in MoS2 field-effect   transistors,1970,"  The understanding of various types of disorders in atomically thin transition metal dichalcogenides (TMDs), including dangling bonds at the edges, chalcogen deficiencies in the bulk, and charges in the substrate, is of fundamental importance for their applications in electronics and photonics. Because of the imperfections, electrons moving on these two-dimensional (2D) crystals experience a spatially non-uniform Coulomb environment, whose effect on the charge transport has not been microscopically studied. Here, we report the mesoscopic conductance mapping in monolayer and few-layer MoS2 field-effect transistors (FETs) by microwave impedance microscopy (MIM). The spatial evolution of the insulator-to-metal transition is clearly resolved. Interestingly, as the transistors are gradually turned on, electrical conduction emerges initially at the edges before appearing in the bulk of MoS2 flakes, which can be explained by our first-principles calculations. The results unambiguously confirm that the contribution of edge states to the channel conductance is significant under the threshold voltage but negligible once the bulk of the TMD device becomes conductive. Strong conductance inhomogeneity, which is associated with the fluctuations of disorder potential in the 2D sheets, is also observed in the MIM images, providing a guideline for future improvement of the device performance. ",https://doi.org/10.1073/pnas.1605982113,1607.06855v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Out-of-plane Piezoelectricity and Ferroelectricity in Layered   $α$-In2Se3 Nano-flakes,1970,"  Piezoelectric and ferroelectric properties in the two dimensional (2D) limit are highly desired for nanoelectronic, electromechanical, and optoelectronic applications. Here we report the first experimental evidence of out-of-plane piezoelectricity and ferroelectricity in van der Waals layered ${\alpha}$-In2Se3 nano-flakes. The non-centrosymmetric R3m symmetry of the ${\alpha}$-In2Se3 samples is confirmed by scanning transmission electron microscopy, second-harmonic generation, and Raman spectroscopy measurements. Domains with opposite polarizations are visualized by piezo-response force microscopy. Single-point poling experiments suggest that the polarization is potentially switchable for ${\alpha}$-In2Se3 nano-flakes with thicknesses down to ~ 10 nm. The piezotronic effect is demonstrated in two-terminal devices, where the Schottky barrier can be modulated by the strain-induced piezopotential. Our work on polar ${\alpha}$-In2Se3, one of the model 2D piezoelectrics and ferroelectrics with simple crystal structures, shows its great potential in electronic and photonic applications. ",https://doi.org/10.1021/acs.nanolett.7b02198,1708.09049v1,Yes,potent(3)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,"In Vivo Renal Clearance, Biodistribution, Toxicity of Gold nanoclusters",1970,"  Gold nanoparticles have shown great prospective in cancer diagnosis and therapy, but they can not be metabolized and prefer to accumulate in liver and spleen due to their large size. The gold nanoclusters with small size can penetrate kidney tissue and have promise to decrease in vivo toxicity by renal clearance. In this work, we explore the in vivo renal clearance, biodistribution, and toxicity responses of the BSA- and GSH-protected gold nanoclusters for 24 hours and 28 days. The BSA-protected gold nanoclusters have low-efficient renal clearance and only 1% of gold can be cleared, but the GSH-protected gold nanoclusters have high-efficient renal clearance and 36 % of gold can be cleared after 24 hours. The biodistribution further reveals that 94% of gold can be metabolized for the GSH-protected nanoclusters, but only less than 5% of gold can be metabolized for the BSA-protected nanoclusters after 28 days. Both of the GSH- and BSA-protected gold nanoclusters cause acute infection, inflammation, and kidney function damage after 24 hours, but these toxicity responses for the GSH-protected gold nanoclusters can be eliminated after 28 days. Immune system can also be affected by the two kinds of gold nanoclusters, but the immune response for the GSH-protected gold nanoclusters can also be recovered after 28 days. These findings show that the GSH-protected gold nanoclusters have small size and can be metabolized by renal clearance and thus the toxicity can be significantly decreased. The BSA- protected gold nanoclusters, however, can form large compounds and further accumulate in liver and spleen which can cause irreparable toxicity response. Therefore, the GSH-protected gold nanoclusters have great potential for in vivo imaging and therapy, and the BSA-protected gold nanoclusters can be used as the agent of liver cancer therapy. ",https://doi.org/10.1016/j.biomaterials.2012.03.020,1210.0037v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Enhancing Building Energy Efficiency through Advanced Sizing and   Dispatch Methods for Energy Storage,1970,"  Energy storage and electrification of buildings hold great potential for future decarbonized energy systems. However, there are several technical and economic barriers that prevent large-scale adoption and integration of energy storage in buildings. These barriers include integration with building control systems, high capital costs, and the necessity to identify and quantify value streams for different stakeholders. To overcome these obstacles, it is crucial to develop advanced sizing and dispatch methods to assist planning and operational decision-making for integrating energy storage in buildings. This work develops a simple and flexible optimal sizing and dispatch framework for thermal energy storage (TES) and battery energy storage (BES) systems in large-scale office buildings. The optimal sizes of TES, BES, as well as other building assets are determined in a joint manner instead of sequentially to avoid sub-optimal solutions. The solution is determined considering both capital costs in optimal sizing and operational benefits in optimal dispatch. With the optimally sized systems, we implemented real-time operation using the model-based control (MPC), facilitating the effective and efficient management of energy resources. Comprehensive assessments are performed using simulation studies to quantify potential energy and economic benefits by different utility tariffs and climate locations, to improve our understanding of the techno-economic performance of different TES and BES systems, and to identify barriers to adopting energy storage for buildings. Finally, the proposed framework will provide guidance to a broad range of stakeholders to properly design energy storage in buildings and maximize potential benefits, thereby advancing affordable building energy storage deployment and helping accelerate the transition towards a cleaner and more equitable energy economy. ",Kein DOI-Link verfügbar,2310.13177v1,Yes,potent(3)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,A Tutorial on Environment-Aware Communications via Channel Knowledge Map   for 6G,1970,"  Sixth-generation (6G) mobile communication networks are expected to have dense infrastructures, large antenna size, wide bandwidth, cost-effective hardware, diversified positioning methods, and enhanced intelligence. Such trends bring both new challenges and opportunities for the practical design of 6G. On one hand, acquiring channel state information (CSI) in real time for all wireless links becomes quite challenging in 6G. On the other hand, there would be numerous data sources in 6G containing high-quality location-tagged channel data, e.g., the estimated channels or beams between base station (BS) and user equipment (UE), making it possible to better learn the local wireless environment. By exploiting this new opportunity and for tackling the CSI acquisition challenge, there is a promising paradigm shift from the conventional environment-unaware communications to the new environment-aware communications based on the novel approach of channel knowledge map (CKM). This article aims to provide a comprehensive overview on environment-aware communications enabled by CKM to fully harness its benefits for 6G. First, the basic concept of CKM is presented, followed by the comparison of CKM with various existing channel inference techniques. Next, the main techniques for CKM construction are discussed, including both environment model-free and environment model-assisted approaches. Furthermore, a general framework is presented for the utilization of CKM to achieve environment-aware communications, followed by some typical CKM-aided communication scenarios. Finally, important open problems in CKM research are highlighted and potential solutions are discussed to inspire future work. ",Kein DOI-Link verfügbar,2309.07460v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Masked Modeling for Self-supervised Representation Learning on Vision   and Beyond,1970,"  As the deep learning revolution marches on, self-supervised learning has garnered increasing attention in recent years thanks to its remarkable representation learning ability and the low dependence on labeled data. Among these varied self-supervised techniques, masked modeling has emerged as a distinctive approach that involves predicting parts of the original data that are proportionally masked during training. This paradigm enables deep models to learn robust representations and has demonstrated exceptional performance in the context of computer vision, natural language processing, and other modalities. In this survey, we present a comprehensive review of the masked modeling framework and its methodology. We elaborate on the details of techniques within masked modeling, including diverse masking strategies, recovering targets, network architectures, and more. Then, we systematically investigate its wide-ranging applications across domains. Furthermore, we also explore the commonalities and differences between masked modeling methods in different fields. Toward the end of this paper, we conclude by discussing the limitations of current techniques and point out several potential avenues for advancing masked modeling research. A paper list project with this survey is available at \url{https://github.com/Lupin1998/Awesome-MIM}. ",Kein DOI-Link verfügbar,2401.00897v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,A Systematic Literature Review on Explainability for Machine/Deep   Learning-based Software Engineering Research,1970,"  The remarkable achievements of Artificial Intelligence (AI) algorithms, particularly in Machine Learning (ML) and Deep Learning (DL), have fueled their extensive deployment across multiple sectors, including Software Engineering (SE). However, due to their black-box nature, these promising AI-driven SE models are still far from being deployed in practice. This lack of explainability poses unwanted risks for their applications in critical tasks, such as vulnerability detection, where decision-making transparency is of paramount importance. This paper endeavors to elucidate this interdisciplinary domain by presenting a systematic literature review of approaches that aim to improve the explainability of AI models within the context of SE. The review canvasses work appearing in the most prominent SE & AI conferences and journals, and spans 63 papers across 21 unique SE tasks. Based on three key Research Questions (RQs), we aim to (1) summarize the SE tasks where XAI techniques have shown success to date; (2) classify and analyze different XAI techniques; and (3) investigate existing evaluation approaches. Based on our findings, we identified a set of challenges remaining to be addressed in existing studies, together with a roadmap highlighting potential opportunities we deemed appropriate and important for future work. ",Kein DOI-Link verfügbar,2401.14617v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,"Large Language Model (LLM) for Telecommunications: A Comprehensive   Survey on Principles, Key Techniques, and Opportunities",1970,"  Large language models (LLMs) have received considerable attention recently due to their outstanding comprehension and reasoning capabilities, leading to great progress in many fields. The advancement of LLM techniques also offers promising opportunities to automate many tasks in the telecommunication (telecom) field. After pre-training and fine-tuning, LLMs can perform diverse downstream tasks based on human instructions, paving the way to artificial general intelligence (AGI)-enabled 6G. Given the great potential of LLM technologies, this work aims to provide a comprehensive overview of LLM-enabled telecom networks. In particular, we first present LLM fundamentals, including model architecture, pre-training, fine-tuning, inference and utilization, model evaluation, and telecom deployment. Then, we introduce LLM-enabled key techniques and telecom applications in terms of generation, classification, optimization, and prediction problems. Specifically, the LLM-enabled generation applications include telecom domain knowledge, code, and network configuration generation. After that, the LLM-based classification applications involve network security, text, image, and traffic classification problems. Moreover, multiple LLM-enabled optimization techniques are introduced, such as automated reward function design for reinforcement learning and verbal reinforcement learning. Furthermore, for LLM-aided prediction problems, we discussed time-series prediction models and multi-modality prediction problems for telecom. Finally, we highlight the challenges and identify the future directions of LLM-enabled telecom networks. ",Kein DOI-Link verfügbar,2405.10825v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Ferromagnetic MnSn monolayer epitaxially grown on silicon substrate,1970,"  Two-dimensional (2D) ferromagnetic materials have been exhibiting promising potential in applications, such as spintronics devices. To grow epitaxial magnetic films on silicon substrate, in the single-layer limit, is practically important but challenging. In this study, we realized the epitaxial growth of MnSn monolayer on Si(111) substrate, with an atomically thin Sn/Si(111)-$2\sqrt{3}\times2\sqrt{3}$- buffer layer, and controlled the MnSn thickness with atomic-layer precision. We discovered the ferromagnetism in MnSn monolayer with the Curie temperature (Tc) of ~54 K. As the MnSn film is grown to 4 monolayers, Tc increases accordingly to ~235 K. The lattice of the epitaxial MnSn monolayer as well as the Sn/Si(111)-$2\sqrt{3}\times2\sqrt{3}$ is perfectly compatible with silicon, and thus an sharp interface is formed between MnSn, Sn and Si. This system provides a new platform for exploring the 2D ferromagnetism, integrating magnetic monolayers into silicon-based technology, and engineering the spintronics heterostructures. ",https://doi.org/10.1088/0256-307X/37/7/077502,2006.00333v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Tailoring Semiconductor Lateral Multi-junctions for Giant   Photoconductivity Enhancement,1970,"  Semiconductor heterostructures have played a critical role as the enabler for new science and technology. The emergence of transition metal dichalcogenides (TMDs) as atomically thin semiconductors has opened new frontiers in semiconductor heterostructures either by stacking different TMDs to form vertical heterojunctions or by stitching them laterally to form lateral heterojunctions via direct growth. In conventional semiconductor heterostructures, the design of multi-junctions is critical to achieve carrier confinement. Analogously, we report successful synthesis of monolayer WS2/WS2(1-x)Se2x/WS2 multi-junction lateral heterostructure via direct growth by chemical vapor deposition. The grown structures are characterized by Raman, photoluminescence, and annular dark-field scanning transmission electron microscopy to determine its lateral compositional profile. More importantly, using microwave impedance microscopy, we demonstrate that the local photoconductivity in the alloy region can be tailored and enhanced by 2 orders of magnitude over pure WS2. Finite element analysis confirms that this effect is due to the carrier diffusion and confinement into the alloy region. Our work exemplifies the technological potential of atomically thin lateral heterostructures in optoelectronic applications. ",https://doi.org/10.1002/adma.201703680,1709.05410v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Imaging Quantum Spin Hall Edges in Monolayer WTe2,1970,"  A two-dimensional (2D) topological insulator (TI) exhibits the quantum spin Hall (QSH) effect, in which topologically protected spin-polarized conducting channels exist at the sample edges. Experimental signatures of the QSH effect have recently been reported for the first time in an atomically thin material, monolayer WTe2. Electrical transport measurements on exfoliated samples and scanning tunneling spectroscopy on epitaxially grown monolayer islands signal the existence of edge modes with conductance approaching the quantized value. Here, we directly image the local conductivity of monolayer WTe2 devices using microwave impedance microscopy, establishing beyond doubt that conduction is indeed strongly localized to the physical edges at temperatures up to 77 K and above. The edge conductivity shows no gap as a function of gate voltage, ruling out trivial conduction due to band bending or in-gap states, and is suppressed by magnetic field as expected. Interestingly, we observe additional conducting lines and rings within most samples which can be explained by edge states following boundaries between topologically trivial and non-trivial regions. These observations will be critical for interpreting and improving the properties of devices incorporating WTe2 or other air-sensitive 2D materials. At the same time, they reveal the robustness of the QSH channels and the potential to engineer and pattern them by chemical or mechanical means in the monolayer material platform. ",https://doi.org/10.1126/sciadv.aat8799,1807.09342v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Flexoelectricity-stabilized ferroelectric phase with enhanced   reliability in ultrathin La:HfO2 films,1970,"  Doped HfO2 thin films exhibit robust ferroelectric properties even for nanometric thicknesses, are compatible with current Si technology and thus have great potential for the revival of integrated ferroelectrics. Phase control and reliability are core issues for their applications. Here we show that, in (111)-oriented 5%La:HfO2 (HLO) epitaxial thin films deposited on (La0.3Sr0.7)(Al0.65Ta0.35)O3 substrates, the flexoelectric effect, arising from the strain gradient along the films normal, induces a rhombohedral distortion in the otherwise Pca21 orthorhombic structure. Density functional calculations reveal that the distorted structure is indeed more stable than the pure Pca21 structure, when applying an electric field mimicking the flexoelectric field. This rhombohedral distortion greatly improves the fatigue endurance of HLO thin films by further stabilizing the metastable ferroelectric phase against the transition to the thermodynamically stable non-polar monoclinic phase during repetitive cycling. Our results demonstrate that the flexoelectric effect, though negligibly weak in bulk, is crucial to optimize the structure and properties of doped HfO2 thin films with nanometric thicknesses for integrated ferroelectric applications. ",https://doi.org/10.1063/5.0144958,2302.11171v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Switch EMA: A Free Lunch for Better Flatness and Sharpness,1970,"  Exponential Moving Average (EMA) is a widely used weight averaging (WA) regularization to learn flat optima for better generalizations without extra cost in deep neural network (DNN) optimization. Despite achieving better flatness, existing WA methods might fall into worse final performances or require extra test-time computations. This work unveils the full potential of EMA with a single line of modification, i.e., switching the EMA parameters to the original model after each epoch, dubbed as Switch EMA (SEMA). From both theoretical and empirical aspects, we demonstrate that SEMA can help DNNs to reach generalization optima that better trade-off between flatness and sharpness. To verify the effectiveness of SEMA, we conduct comparison experiments with discriminative, generative, and regression tasks on vision and language datasets, including image classification, self-supervised learning, object detection and segmentation, image generation, video prediction, attribute regression, and language modeling. Comprehensive results with popular optimizers and networks show that SEMA is a free lunch for DNN training by improving performances and boosting convergence speeds. ",Kein DOI-Link verfügbar,2402.09240v1,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Ultrafast switching of sliding ferroelectricity and dynamical magnetic   field in van der Waals bilayer induced by light,1970,"  Sliding ferroelectricity is a unique type of polarity recently observed in a properly stacked van der Waals bilayer. However, electric-field control of sliding ferroelectricity is hard and could induce large coercive electric fields and serious leakage currents which corrode the ferroelectricity and electronic properties, which are essential for modern two-dimensional electronics and optoelectronics. Here, we proposed laser-pulse deterministic control of sliding ferroelectricity in bilayer h-BN by first principles and molecular dynamics simulation with machine-learned force fields. The laser pulses excite shear modes which exhibit certain directional movements of lateral sliding between bilayers. The vibration of excited modes under laser pulses is predicted to overcome the energy barrier and achieve the switching of sliding ferroelectricity. Furthermore, it is found that three possible sliding transitions - between AB (BA) and BA (AB) stacking - can lead to the occurrence of dynamical magnetic fields along three different directions. Remarkably, the magnetic fields are generated by the simple linear motion of nonmagnetic species, without any need for more exotic (circular, spiral) pathways. Such predictions of deterministic control of sliding ferroelectricity and multi-states of dynamical magnetic field thus expand the potential applications of sliding ferroelectricity in memory and electronic devices. ",Kein DOI-Link verfügbar,2403.06531v2,Yes,potent(1)
0000-0001-5919-7010,Di Wu,Leibniz Universität Hannover,Enhanced Tumor Accumulation of Sub-2 nm Gold Nanoclusters for Cancer   Radiation Therapy,1970,"  A new type of metabolizable and efficient radiosensitizer for cancer radiotherapy is presented in this study by combining ultrasmall Au nanoclusters (NCs, <2 nm) with biocompatible coating ligands (glutathione, GSH). The new nano-construct (GSH-coated Au25 NCs) inherits attractive features of both the Au core (strong radiosensitizing effect) and GSH shell (good biocompatibility). It can preferentially accumulate in tumor via the improved EPR effect, which leads to strong enhancement for cancer radiotherapy. After the treatment, the small-sized GSH-Au25 NCs can be efficiently cleared by the kidney, minimizing any potential side effects due to the accumulation of Au25 NCs in the body. ",https://doi.org/10.1002/adhm.201300189,1308.6737v1,Yes,potent(1)
0000-0001-5970-3366,Martina Rossi,Christian-Albrechts-Universität zu Kiel,Hidden Population III Descendants in Ultra-Faint Dwarf Galaxies,1970,"  The elusive properties of the first (Pop III) stars can be indirectly unveiled by uncovering their true descendants. To this aim, we exploit our data-calibrated model for the best-studied ultra-faint dwarf (UFD) galaxy, Bo\""otes I, which tracks the chemical evolution (from carbon to zinc) of individual stars from their formation to the present day. We explore the chemical imprint of Pop III supernovae (SNe), with different explosion energies and masses, showing that they leave distinct chemical signatures in their descendants. We find that UFDs are strongly affected by SNe-driven feedback resulting in a very low fraction of metals retained by their gravitational potential well (< 2.5 %). Furthermore, the higher the Pop III SN explosion energy, the lower the fraction of metals retained. Thus, the probability to find descendants of energetic Pair Instability SNe is extremely low in these systems. Conversely, UFDs are ideal cosmic laboratories to identify the fingerprints of less massive and energetic Pop III SNe through their [X/Fe] abundance ratios. Digging into the literature data of Bo\""otes I, we uncover three hidden Pop III descendants: one mono-enriched and two multi-enriched. These stars show the chemical signature of Pop III SNe in the mass range $[20-60]\rm M_{\odot}$, spanning a wide range in explosion energies $[0.3-5] 10^{51}$ erg. In conclusion, Pop III descendants are hidden in ancient UFDs but those mono-enriched by a single Pop III SN are extremely rare. Thus, self-consistent models such as the one presented here are required to uncover these precious fossils and probe the properties of the first Pop III supernovae. ",Kein DOI-Link verfügbar,2406.12960v1,Yes,potent(1)
0000-0001-5970-3366,Martina Rossi,Christian-Albrechts-Universität zu Kiel,The earliest phases of CNO enrichment in galaxies,1970,"  Context. The recent detection of nitrogen-enhanced, metal-poor galaxies at high redshift by the James Webb Space Telescope has sparked renewed interest in exploring the chemical evolution of carbon, nitrogen, and oxygen (the CNO elements) at early times, prompting fresh inquiries into their origins. Aims. The main goal of this paper is to shed light onto the early evolution of the main CNO isotopes in our Galaxy and in young distant systems, such as GN-z11 at z=10.6. Methods. To this aim, we incorporate a stochastic star-formation component into a chemical evolution model calibrated with high-quality Milky Way (MW) data, focusing on the contribution of Population III (Pop III) stars to the early chemical enrichment. Results. By comparing the model predictions with CNO abundance measurements from high-resolution spectroscopy of an homogeneous sample of Galactic halo stars, we first demonstrate that the scatter observed in the metallicity range -4.5 < [Fe/H] <-1.5 can be explained by pre-enrichment from Pop III stars that explode as supernovae (SNe) with different initial masses and energies. Then, by exploiting the chemical evolution model, we provide testable predictions for log(C/N), log(N/O), and log(C/O) vs. log(O/H)+12 in MW-like galaxies observed at different cosmic epochs/redshifts. Finally, by calibrating the chemical evolution model to replicate the observed properties of GN-z11, we provide an alternative interpretation of its log(N/O) abundance ratio, demonstrating that its high N content can be reproduced through enrichment from high-mass faint Pop III SNe. Conclusions. Stochastic chemical enrichment from primordial stars explains both the observed scatter in CNO abundances in MW halo stars and the exceptionally high N/O ratios in some distant galaxies. These findings emphasize the critical role of Pop III stars in shaping early chemical evolution. ",Kein DOI-Link verfügbar,2406.14615v1,Yes,fresh(1)
0000-0001-5970-3366,Martina Rossi,Christian-Albrechts-Universität zu Kiel,Using Shor's algorithm on near term Quantum computers: a reduced version,1970,"  Considering its relevance in the field of cryptography, integer factorization is a prominent application where Quantum computers are expected to have a substantial impact. Thanks to Shor's algorithm this peculiar problem can be solved in polynomial time. However, both the number of qubits and applied gates detrimentally affect the ability to run a particular quantum circuit on the near term Quantum hardware. In this work, we help addressing both these problems by introducing a reduced version of Shor's algorithm that proposes a step forward in increasing the range of numbers that can be factorized on noisy Quantum devices. The implementation presented in this work is general and does not use any assumptions on the number to factor. In particular, we have found noteworthy results in most cases, often being able to factor the given number with only one iteration of the proposed algorithm. Finally, comparing the original quantum algorithm with our version on simulator, the outcomes are identical for some of the numbers considered. ",Kein DOI-Link verfügbar,2112.12647v1,Yes,noteworthy(1)
0000-0001-6042-8437,Constantin Seibold,Karlsruher Institut für Technologie,Breaking with Fixed Set Pathology Recognition through Report-Guided   Contrastive Training,1970,"  When reading images, radiologists generate text reports describing the findings therein. Current state-of-the-art computer-aided diagnosis tools utilize a fixed set of predefined categories automatically extracted from these medical reports for training. This form of supervision limits the potential usage of models as they are unable to pick up on anomalies outside of their predefined set, thus, making it a necessity to retrain the classifier with additional data when faced with novel classes. In contrast, we investigate direct text supervision to break away from this closed set assumption. By doing so, we avoid noisy label extraction via text classifiers and incorporate more contextual information.   We employ a contrastive global-local dual-encoder architecture to learn concepts directly from unstructured medical reports while maintaining its ability to perform free form classification.   We investigate relevant properties of open set recognition for radiological data and propose a method to employ currently weakly annotated data into training.   We evaluate our approach on the large-scale chest X-Ray datasets MIMIC-CXR, CheXpert, and ChestX-Ray14 for disease classification. We show that despite using unstructured medical report supervision, we perform on par with direct label supervision through a sophisticated inference setting. ",https://doi.org/10.1007/978-3-031-16443-9_66,2205.07139v1,Yes,potent(1)
0000-0001-6042-8437,Constantin Seibold,Karlsruher Institut für Technologie,Prediction of low-keV monochromatic images from polyenergetic CT scans   for improved automatic detection of pulmonary embolism,1970,"  Detector-based spectral computed tomography is a recent dual-energy CT (DECT) technology that offers the possibility of obtaining spectral information. From this spectral data, different types of images can be derived, amongst others virtual monoenergetic (monoE) images. MonoE images potentially exhibit decreased artifacts, improve contrast, and overall contain lower noise values, making them ideal candidates for better delineation and thus improved diagnostic accuracy of vascular abnormalities.   In this paper, we are training convolutional neural networks~(CNN) that can emulate the generation of monoE images from conventional single energy CT acquisitions. For this task, we investigate several commonly used image-translation methods. We demonstrate that these methods while creating visually similar outputs, lead to a poorer performance when used for automatic classification of pulmonary embolism (PE). We expand on these methods through the use of a multi-task optimization approach, under which the networks achieve improved classification as well as generation results, as reflected by PSNR and SSIM scores. Further, evaluating our proposed framework on a subset of the RSNA-PE challenge data set shows that we are able to improve the Area under the Receiver Operating Characteristic curve (AuROC) in comparison to a na\""ive classification approach from 0.8142 to 0.8420. ",https://doi.org/10.1109/ISBI48211.2021.9433966,2102.01445v2,Yes,potent(1)
0000-0001-6042-8437,Constantin Seibold,Karlsruher Institut für Technologie,CellViT: Vision Transformers for Precise Cell Segmentation and   Classification,1970,"  Nuclei detection and segmentation in hematoxylin and eosin-stained (H&E) tissue images are important clinical tasks and crucial for a wide range of applications. However, it is a challenging task due to nuclei variances in staining and size, overlapping boundaries, and nuclei clustering. While convolutional neural networks have been extensively used for this task, we explore the potential of Transformer-based networks in this domain. Therefore, we introduce a new method for automated instance segmentation of cell nuclei in digitized tissue samples using a deep learning architecture based on Vision Transformer called CellViT. CellViT is trained and evaluated on the PanNuke dataset, which is one of the most challenging nuclei instance segmentation datasets, consisting of nearly 200,000 annotated Nuclei into 5 clinically important classes in 19 tissue types. We demonstrate the superiority of large-scale in-domain and out-of-domain pre-trained Vision Transformers by leveraging the recently published Segment Anything Model and a ViT-encoder pre-trained on 104 million histological image patches - achieving state-of-the-art nuclei detection and instance segmentation performance on the PanNuke dataset with a mean panoptic quality of 0.50 and an F1-detection score of 0.83. The code is publicly available at https://github.com/TIO-IKIM/CellViT ",Kein DOI-Link verfügbar,2306.15350v2,Yes,potent(1)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,Collective octahedral tilting in ultrathin Ruddlesden-Popper perovskite   under terahertz light,1970,"  Perovskites have been applied in a wide range of fields such as solar cells and non-volatile memories due to their multiferroic nature and excellent photo-electric conversion capabilities. Recently, two-dimensional (2D) perovskites with a few atomic layers have been successfully synthesized, attracting significant attention for potential applications. In this work, we perform first-principles calculations to investigate an ultrathin prototypical Ruddlesden-Popper phase, $\mathrm{Bi}_2\mathrm{FeO}_4$, with its thickness down to one unit cell. We show that this compound could exist in two (meta-)stable octahedral tilting phases, belonging to $P2_1/c$ and $C2/m$ space groups, respectively. Using the optomechanical theory, we suggest that reversible and non-volatile phase switching can be triggered using non-destructive terahertz light. In addition, the two phases show distinct optical reflectance spectrum in the visible light range, which can be used as an optical probe for phase transformation. This enables both ""write"" and ""read"" in an all-optical route. ",https://doi.org/10.1063/5.0174032,2312.16757v1,Yes,potent(1)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,Language Guided Networks for Cross-modal Moment Retrieval,1970,"  We address the challenging task of cross-modal moment retrieval, which aims to localize a temporal segment from an untrimmed video described by a natural language query. It poses great challenges over the proper semantic alignment between vision and linguistic domains. Existing methods independently extract the features of videos and sentences and purely utilize the sentence embedding in the multi-modal fusion stage, which do not make full use of the potential of language. In this paper, we present Language Guided Networks (LGN), a new framework that leverages the sentence embedding to guide the whole process of moment retrieval. In the first feature extraction stage, we propose to jointly learn visual and language features to capture the powerful visual information which can cover the complex semantics in the sentence query. Specifically, the early modulation unit is designed to modulate the visual feature extractor's feature maps by a linguistic embedding. Then we adopt a multi-modal fusion module in the second fusion stage. Finally, to get a precise localizer, the sentence information is utilized to guide the process of predicting temporal positions. Specifically, the late guidance module is developed to linearly transform the output of localization networks via the channel attention mechanism. The experimental results on two popular datasets demonstrate the superior performance of our proposed method on moment retrieval (improving by 5.8\% in terms of Rank1@IoU0.5 on Charades-STA and 5.2\% on TACoS). The source code for the complete system will be publicly available. ",Kein DOI-Link verfügbar,2006.10457v2,Yes,potent(1)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,Enabling High Performance Debugging for Variational Quantum Algorithms   using Compressed Sensing,1970,"  Variational quantum algorithms (VQAs) can potentially solve practical problems using contemporary Noisy Intermediate Scale Quantum (NISQ) computers. VQAs find near-optimal solutions in the presence of qubit errors by classically optimizing a loss function computed by parameterized quantum circuits. However, developing and testing VQAs is challenging due to the limited availability of quantum hardware, their high error rates, and the significant overhead of classical simulations. Furthermore, VQA researchers must pick the right initialization for circuit parameters, utilize suitable classical optimizer configurations, and deploy appropriate error mitigation methods. Unfortunately, these tasks are done in an ad-hoc manner today, as there are no software tools to configure and tune the VQA hyperparameters.   In this paper, we present OSCAR (cOmpressed Sensing based Cost lAndscape Reconstruction) to help configure: 1) correct initialization, 2) noise mitigation techniques, and 3) classical optimizers to maximize the quality of the solution on NISQ hardware. OSCAR enables efficient debugging and performance tuning by providing users with the loss function landscape without running thousands of quantum circuits as required by the grid search. Using OSCAR, we can accurately reconstruct the complete cost landscape with up to 100X speedup. Furthermore, OSCAR can compute an optimizer function query in an instant by interpolating a computed landscape, thus enabling the trial run of a VQA configuration with considerably reduced overhead. ",https://doi.org/10.1145/3579371.3589044,2308.03213v1,Yes,potent(1)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,SigFormer: Sparse Signal-Guided Transformer for Multi-Modal Human Action   Segmentation,1970,"  Multi-modal human action segmentation is a critical and challenging task with a wide range of applications. Nowadays, the majority of approaches concentrate on the fusion of dense signals (i.e., RGB, optical flow, and depth maps). However, the potential contributions of sparse IoT sensor signals, which can be crucial for achieving accurate recognition, have not been fully explored. To make up for this, we introduce a Sparse signalguided Transformer (SigFormer) to combine both dense and sparse signals. We employ mask attention to fuse localized features by constraining cross-attention within the regions where sparse signals are valid. However, since sparse signals are discrete, they lack sufficient information about the temporal action boundaries. Therefore, in SigFormer, we propose to emphasize the boundary information at two stages to alleviate this problem. In the first feature extraction stage, we introduce an intermediate bottleneck module to jointly learn both category and boundary features of each dense modality through the inner loss functions. After the fusion of dense modalities and sparse signals, we then devise a two-branch architecture that explicitly models the interrelationship between action category and temporal boundary. Experimental results demonstrate that SigFormer outperforms the state-of-the-art approaches on a multi-modal action segmentation dataset from real industrial environments, reaching an outstanding F1 score of 0.958. The codes and pre-trained models have been available at https://github.com/LIUQI-creat/SigFormer. ",Kein DOI-Link verfügbar,2311.17428v2,Yes,potent(1)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,Generalized Zero-Shot Learning for Action Recognition with Web-Scale   Video Data,1970,"  Action recognition in surveillance video makes our life safer by detecting the criminal events or predicting violent emergencies. However, efficient action recognition is not free of difficulty. First, there are so many action classes in daily life that we cannot pre-define all possible action classes beforehand. Moreover, it is very hard to collect real-word videos for certain particular actions such as steal and street fight due to legal restrictions and privacy protection. These challenges make existing data-driven recognition methods insufficient to attain desired performance. Zero-shot learning is potential to be applied to solve these issues since it can perform classification without positive example. Nevertheless, current zero-shot learning algorithms have been studied under the unreasonable setting where seen classes are absent during the testing phase. Motivated by this, we study the task of action recognition in surveillance video under a more realistic \emph{generalized zero-shot setting}, where testing data contains both seen and unseen classes. To our best knowledge, this is the first work to study video action recognition under the generalized zero-shot setting. We firstly perform extensive empirical studies on several existing zero-shot leaning approaches under this new setting on a web-scale video data. Our experimental results demonstrate that, under the generalize setting, typical zero-shot learning methods are no longer effective for the dataset we applied. Then, we propose a method for action recognition by deploying generalized zero-shot learning, which transfers the knowledge of web video to detect the anomalous actions in surveillance videos. To verify the effectiveness of our proposed method, we further construct a new surveillance video dataset consisting of nine action classes related to the public safety situation. ",Kein DOI-Link verfügbar,1710.07455v1,Yes,potent(1)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,Early Risk Assessment Model for ICA Timing Strategy in Unstable Angina   Patients Using Multi-Modal Machine Learning,1970,"  Background: Invasive coronary arteriography (ICA) is recognized as the gold standard for diagnosing cardiovascular diseases, including unstable angina (UA). The challenge lies in determining the optimal timing for ICA in UA patients, balancing the need for revascularization in high-risk patients against the potential complications in low-risk ones. Unlike myocardial infarction, UA does not have specific indicators like ST-segment deviation or cardiac enzymes, making risk assessment complex. Objectives: Our study aims to enhance the early risk assessment for UA patients by utilizing machine learning algorithms. These algorithms can potentially identify patients who would benefit most from ICA by analyzing less specific yet related indicators that are challenging for human physicians to interpret. Methods: We collected data from 640 UA patients at Shanghai General Hospital, including medical history and electrocardiograms (ECG). Machine learning algorithms were trained using multi-modal demographic characteristics including clinical risk factors, symptoms, biomarker levels, and ECG features extracted by pre-trained neural networks. The goal was to stratify patients based on their revascularization risk. Additionally, we translated our models into applicable and explainable look-up tables through discretization for practical clinical use. Results: The study achieved an Area Under the Curve (AUC) of $0.719 \pm 0.065$ in risk stratification, significantly surpassing the widely adopted GRACE score's AUC of $0.579 \pm 0.044$. Conclusions: The results suggest that machine learning can provide superior risk stratification for UA patients. This improved stratification could help in balancing the risks, costs, and complications associated with ICA, indicating a potential shift in clinical assessment practices for unstable angina. ",Kein DOI-Link verfügbar,2408.04276v1,Yes,potent(3)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,Flexible single multimode fiber imaging using white LED,1970,"  Multimode fiber (MMF) has been proven to have good potential in imaging and optical communication because of its advantages of small diameter and large mode numbers. However, due to the mode coupling and modal dispersion, it is very sensitive to environmental changes. Minor changes in the fiber shape can lead to difficulties in information reconstruction. Here, white LED and cascaded Unet are used to achieve MMF imaging to eliminate the effect of fiber perturbations. The output speckle patterns in three different color channels of the CCD camera produced by transferring images through the MMF are concatenated and inputted into the cascaded Unet using channel stitching technology to improve the reconstruction effects. The average Pearson correlation coefficient (PCC) of the reconstructed images from the Fashion-MINIST dataset is 0.83. In order to check the flexibility of such a system, perturbation tests on the image reconstruction capability by changing the fiber shapes are conducted. The experimental results show that the MMF imaging system has good robustness properties, i. e. the average PCC remains 0.83 even after completely changing the shape of the MMF. This research potentially provides a flexible approach for the practical application of MMF imaging. ",Kein DOI-Link verfügbar,2307.09714v1,Yes,potent(2)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,Superconducting Magnetic Bearings Simulation using an H-formulation   Finite Element Model,1970,"  The modeling of superconducting magnetic bearing (SMB) is of great significance for predicting and optimizing its levitation performance before construction. Although lots of efforts have been made in this area, it still remains some space for improvements. Thus the goal of this work is to report a flexible, fast and trustworthy H-formulation finite element model. First the methodology for modeling and calibrating both bulk-type and stack-type SMB is summarized. Then its effectiveness for simulating SMBs in 2-D, 2-D axisymmetric and 3-D is evaluated by comparison with measurements. In particular, original solutions to overcome several obstacles are given: clarification of the calibration procedure for stack-type and bulk-type SMBs, details on the experimental protocol to obtain reproducible measurements, validation of the 2-D model for a stack-type SMB modeling the tapes real thickness, implementation of a 2-D axisymmetric SMB model, implementation of a 3-D SMB model, extensive validation of the models by comparison with experimental results for field cooling and zero field cooling, for both vertical and lateral movements. The accuracy of the model being proved, it has now a strong potential for speeding up the development of numerous applications including maglev vehicles, magnetic launchers, flywheel energy storage systems, motor bearings and cosmic microwave background polarimeters. ",https://doi.org/10.1088/1361-6668/aac55d,1803.06741v1,Yes,potent(1)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,Semiclassical analysis of photoelectron interference in a synthesized   two-color laser pulse,1970,"  We measure the photoelectron energy spectra from strong-field ionization of Kr in a two-color laser pulse consisting of a strong 400-nm field and a weak 800-nm field. The intensities of the main above-threshold ionization (ATI) and sideband peaks in the photoelectron energy spectra oscillate roughly oppositely with respect to the relative phase between the two-color components. We study the photoelectron interferometry in strong-field ATI regime from the view of interference of different electron trajectories in order to extend RABBITT type analysis to the strong-field regime. Based on the strong-field approximation model, we obtain analytical expressions for the oscillations of both ATI and sideband peaks with the relative phase. A phase shift of \pi/4 with respect to the field maximum of the two-color laser pulse is revealed for the interference maximum in the main ATI peak without including the effect of the atomic potential. ",https://doi.org/10.1103/PhysRevA.100.063411,1911.04035v1,Yes,potent(1)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,Ball Mill Fault Prediction Based on Deep Convolutional Auto-Encoding   Network,1970,"  Ball mills play a critical role in modern mining operations, making their bearing failures a significant concern due to the potential loss of production efficiency and economic consequences. This paper presents an anomaly detection method based on Deep Convolutional Auto-encoding Neural Networks (DCAN) for addressing the issue of ball mill bearing fault detection. The proposed approach leverages vibration data collected during normal operation for training, overcoming challenges such as labeling issues and data imbalance often encountered in supervised learning methods. DCAN includes the modules of convolutional feature extraction and transposed convolutional feature reconstruction, demonstrating exceptional capabilities in signal processing and feature extraction. Additionally, the paper describes the practical deployment of the DCAN-based anomaly detection model for bearing fault detection, utilizing data from the ball mill bearings of Wuhan Iron & Steel Resources Group and fault data from NASA's bearing vibration dataset. Experimental results validate the DCAN model's reliability in recognizing fault vibration patterns. This method holds promise for enhancing bearing fault detection efficiency, reducing production interruptions, and lowering maintenance costs. ",Kein DOI-Link verfügbar,2311.13571v1,Yes,potent(1)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,Building spin-1/2 antiferromagnetic Heisenberg chains with   diaza-nanographenes,1970,"  Understanding and engineering the coupling of spins in nanomaterials is of central importance for designing novel devices. Graphene nanostructures with {\pi}-magnetism offer a chemically tunable platform to explore quantum magnetic interactions. However, realizing spin chains bearing controlled odd-even effects with suitable nanographene systems is challenging. Here, we demonstrate the successful on-surface synthesis of spin-1/2 antiferromagnetic Heisenberg chains with parity-dependent magnetization based on antiaromatic diaza-hexa-peri-hexabenzocoronene (diaza-HBC) units. Using distinct synthetic strategies, two types of spin chains with different terminals were synthesized, both exhibiting a robust odd-even effect on the spin coupling along the chain. Combined investigations using scanning tunneling microscopy, non-contact atomic force microscopy, density functional theory calculations, and quantum spin models confirmed the structures of the diaza-HBC chains and revealed their magnetic properties, which has an S = 1/2 spin per unit through electron donation from the diaza-HBC core to the Au(111) substrate. Gapped excitations were observed in even-numbered chains, while enhanced Kondo resonance emerged in odd-numbered units of odd-numbered chains due to the redistribution of the unpaired spin along the chain. Our findings provide an effective strategy to construct nanographene spin chains and unveil the odd-even effect in their magnetic properties, offering potential applications in nanoscale spintronics. ",Kein DOI-Link verfügbar,2407.20511v1,Yes,potent(1)
0000-0001-6048-0622,Kun Liu,Universität Freiburg,Design of a LYSO Crystal Electromagnetic Calorimeter for DarkSHINE   Experiment,1970,"  This paper presents the design and optimization of a LYSO crystal-based electromagnetic calorimeter (ECAL) for the DarkSHINE experiment, which aims to search for dark photon as potential dark force mediator. The ECAL design has been meticulously evaluated through comprehensive simulations, focusing on optimizing dimensions, material choices, and placement within the detector array to enhance sensitivity in search for dark photon signatures while balancing cost and performance. The concluded ECAL design, comprising 2.5$\times$2.5$\times$4 cm$^3$ LYSO crystals arranged in a 52.5$\times$52.5$\times$44 cm$^3$ structure, ensures high energy resolution and effective energy containment. The study also explored the energy distribution across different ECAL regions and established a dynamic range for energy measurements, with a 4 GeV limit per crystal deemed sufficient. Additionally, the radiation tolerance of ECAL components was assessed, confirming the sustainability of LYSO crystals and radiation-resistant silicon sensors. ",Kein DOI-Link verfügbar,2407.17800v1,Yes,"meticulous(1), potent(1), meticulously(1)"
0000-0001-6049-3132,Andreas Eckart,Universität zu Köln,On the charge of the Galactic centre black hole,1970,"  The Galactic centre supermassive black hole (SMBH), in sharp contrast with its complex environment, is characterized by only three classical parameters -- mass, spin, and electric charge. Its charge is poorly constrained. It is, however, usually assumed to be zero because of neutralization due to the presence of plasma. We revisit the question of the SMBH charge and put realistic limits on its value, timescales of charging and discharging, and observable consequences of the potential, small charge associated with the Galactic centre black hole. The electric charge due to classical arguments based on the mass difference between protons and electrons is $\lesssim 10^9\,{\rm C}$ and is of a transient nature on the viscous time-scale. However, the rotation of a black hole in magnetic field generates electric field due to the twisting of magnetic field lines. This electric field can be associated with induced charge, for which we estimate an upper limit of $\lesssim 10^{15}\,{\rm C}$. Moreover, this charge is most likely positive due to an expected alignment between the magnetic field and the black-hole spin. Even a small charge of this order significantly shifts the position of the innermost stable circular orbit (ISCO) of charged particles. In addition, we propose a novel observational test based on the presence of the bremsstrahlung surface brightness decrease, which is more sensitive for smaller unshielded electric charges than the black-hole shadow size. Based on this test, the current upper observational limit on the charge of Sgr A* is $\lesssim 3\times 10^{8}\,{\rm C}$. ",https://doi.org/10.1093/mnras/sty2182,1808.07327v1,Yes,potent(1)
0000-0001-6049-3132,Andreas Eckart,Universität zu Köln,Perspective for optical high-angular resolution follow-up studies of   X-raying AGNs,1970,"  We explore the scientific potential of next-generation high-angular resolution optical imager to study the AGN/Host connection. The availability of a significant number of X-raying AGN with natural guide stars, allowing for adaptive optics at optical wavelengths, offers an interesting perspective to complement high-resolution work currently done in the near-infrared. ",Kein DOI-Link verfügbar,1403.1744v2,Yes,potent(1)
0000-0001-6049-3132,Andreas Eckart,Universität zu Köln,Star formation and gas flows in the centre of the NUGA galaxy NGC 1808   observed with SINFONI,1970,"  NGC 1808 is a nearby barred spiral galaxy which hosts young stellar clusters in a patchy circumnuclear ring with a radius of $\sim 240\,\mathrm{pc}$. In order to study the gaseous and stellar kinematics and the star formation properties of the clusters, we perform seeing-limited $H+K$-band near-infrared integral-field spectroscopy with SINFONI of the inner $\sim 600\,\mathrm{pc}$. From the $M_\mathrm{BH}-\sigma_*$ relation, we find a black hole mass of a few $10^7\,M_\odot$. We estimate the age of the young stellar clusters in the circumnuclear ring to be $\lesssim 10\,\mathrm{Myr}$. No age gradient along the ring is visible. However, the starburst age is comparable to the travel time along the ring, indicating that the clusters almost completed a full orbit along the ring during their life time. In the central $\sim 600\,\mathrm{pc}$, we find a hot molecular gas mass of $\sim 730\,M_\odot$ which, with standard conversion factors, corresponds to a large cold molecular gas reservoir of several $10^8\,M_\odot$, in accordance with CO measurements from the literature. The gaseous and stellar kinematics show several deviations from pure disc motion, including a circumnuclear disc and signs of a nuclear bar potential. In addition, we confirm streaming motions on $\sim 200\,\mathrm{pc}$ scale that have recently been detected in CO(1-0) emission. Due to our enhanced angular resolution of $<1\,\mathrm{arcsec}$, we find further streaming motion within the inner arcsecond, that have not been detected until now. Despite the flow of gas towards the centre, no signs for significant AGN activity are found. This raises the questions what determines whether the infalling gas will fuel an AGN or star formation. ",https://doi.org/10.1051/0004-6361/201629440,1611.07868v1,Yes,potent(1)
0000-0001-6049-3132,Andreas Eckart,Universität zu Köln,Near- and mid-infrared observations in the inner tenth of a parsec of   the Galactic center -- Detection of proper motion of a filament very close to   Sgr~A*,1970,"  We analyze the gas and dust emission in the immediate vicinity of the supermassive black hole Sgr~A* at the Galactic center (GC) with the ESO VLT (Paranal/Chile) instruments SINFONI and VISIR. The SINFONI H+K data cubes show several emission lines with related line map counterparts. From these lines, the Br$\gamma$ emission is the most prominent one and appears to be shaped as a bar extending along the North-South direction. With VISIR, we find a dusty counterpart to this filamentary emission. In this work, we present evidence that this feature can be most likely connected to the mini-spiral and potentially influenced by the winds of the massive stars in the central cluster or an accretion wind from Sgr~A*. To this end, we co-add the SINFONI data between 2005 and 2015. The spectroscopic analysis reveals a range of Doppler-shifted emission lines. We also detect substructures in the shape of clumps that can be investigated in the channel maps of the Br$\gamma$-bar. In addition, we compare the detection of the near-infrared (NIR) Br$\gamma$ feature to PAH1 mid-infrared (MIR) observations and published 226 GHz radio data. These clumps show a proper motion of about $320$km/s that are consistent with other infrared continuum detected filaments in the Galactic center. Deriving a mass of $2.5\,\times\,10^{-5}\,M_{\odot}$ for the investigated Br$\gamma$-feature shows an agreement with former derived masses for similar objects. Besides the North-South Br$\gamma$-bar, we find a comparable additional East-West feature. Also, we identify several gas reservoirs that are located west of Sgr~A* that may harbor dusty objects. ",https://doi.org/10.3847/1538-4357/ab9826,2006.03648v1,Yes,potent(1)
0000-0001-6049-3132,Andreas Eckart,Universität zu Köln,Constraining the accretion flow density profile near Sgr A* using the   $L'$-band emission of the S2 star,1970,"  The density profile of the ambient medium around a supermassive black hole plays an important role in understanding the inflow-outflow mechanisms in the Galactic Centre. We constrain the spherical density profile using the stellar bow shock of the star S2 which orbits the supermassive black hole at the Galactic Centre with the pericentre distance of 14.4 mas ($\sim$ 1500 R$_\text{s}$). Assuming an elliptical orbit, we apply celestial mechanics and the theory of bow shocks that are at ram pressure equilibrium. We analyse the measured infrared flux density and magnitudes of S2 in the L'-band (3.8 micron) obtained over seven epochs in the years between 2004-2018. We detect no significant change in S2 flux density until the recent periapse in May 2018. The intrinsic flux variability of S2 is at the level of 2 - 3%. Based on the dust-extinction model, the upper limit on the number density at the S2 periapse is $\sim$1.87$\times$10$^9$ cm$^{-3}$, which yields a density slope of at most 3.20. Using the synchrotron bow-shock emission, we obtain an ambient density of $\leq$ 1.01$\times$10$^5$ cm$^{-3}$ and a slope of $\leq$ 1.47. These values are consistent with a wide variety of media from hot accretion flows to potentially colder and denser media comparable in properties to broad-line region clouds. A standard thin disc can be, however, excluded at the distance of the S2 pericentre. Based on our sensitivity of 0.01 mag, we can distinguish between hot accretion flows and thin, cold discs, where the latter can be excluded at the scale of the S2 periapse. Future observations of stars with smaller pericentre distances in the S cluster using instruments such as METIS@ELT with a photometric sensitivity of as much as 10$^{-3}$ mag will allow to probe the Galactic Centre medium at intermediate scales at densities as low as $\sim$ 700 cm$^{-3}$ in case of non-thermal bow-shock emission. ",https://doi.org/10.1051/0004-6361/202037724,2010.00530v1,Yes,potent(1)
0000-0001-6049-3132,Andreas Eckart,Universität zu Köln,The Evaporating Massive Embedded Stellar Cluster IRS 13 Close to Sgr A*.   II. Kinematic structure,1970,"  The existence of two distinct and apparently unrelated populations of dusty stellar objects in the Nuclear Stellar Cluster (NSC) of the Milky Way, namely IRS 13 and the S-cluster, are potentially prone to a general process describing the star formation history in the Galactic Center (GC). The former cluster is thought to be entangled in the clockwise and counterclockwise disks, a large-scale stellar distribution revealed by the analysis of stars at different distances from Sgr A*, the supermassive black hole in the GC. Recently, this large-scale distribution was reported to exhibit a multi-disk structure with at least four components. Motivated by this finding, we revisit the anisotropic IRS 13 cluster and find strong evidence for a disk-like structure. An examination of about 50 individual stellar orbits reveals a new structure that does not follow any trend known in the literature. Furthermore, we investigate the possibility of an inspiral cluster undergoing star formation processes, as proposed by several authors. Using a simplified N-body simulation to reproduce our observational results, we conclude that, under certain conditions, a massive cluster can migrate from the Circum Nuclear Disk toward the inner parsec. Based on this classification, we revisit the large-scale NACO (VLT) observations of IRS 13 and find evidence for a separation of the cluster into a gravitationally stable core remnant and a dissipating part. With the velocity-resolved H30{\alpha} line and the broadband spectral energy distribution of IRS 13E3, we provide tentative support for the existence of an intermediate-mass black hole of ~ 3 x 10^26 M_sun surrounded by a hot gaseous stream. ",https://doi.org/10.3847/1538-4357/ad4098,2407.15800v1,Yes,potent(1)
0000-0001-6049-3132,Andreas Eckart,Universität zu Köln,Effect of an isotropic outflow from the Galactic centre on the bow-shock   evolution along the orbit,1970,"  Motivated by the observations of several infrared-excess bow-shock sources and proplyd-like objects near the Galactic centre, we analyse the effect of a potential outflow from the centre on bow shock properties. We show that due to the non-negligible isotropic central outflow the bow-shock evolution along the orbit becomes asymmetric between the pre-peribothron and post-peribothron phases. This is demonstrated by the calculation of the bow-shock size evolution, the velocity along the shocked layer, the surface density of the bow-shock, and by emission-measure maps close to the peribothron passage. Within the ambient velocity range of $\lesssim 2000\,{\rm km\, s^{-1}}$ the asymmetry is profound and the changes are considerable for different outflow velocities. As a case study we perform model calculations for the Dusty S-cluster Object (DSO/G2) as a potential young stellar object that is currently being monitored and has passed the pericentre at $\sim 2000$ Schwarzschild radii from the supermassive black hole (Sgr A*) in 2014. We show that the velocity field of the shocked layer can contribute to the observed increasing line width of the DSO source up to the peribothron. Subsequently, supposing that the line emission originates in the bow shock, a decrease of the line width is expected. Furthermore, the decline of the bow-shock emission measure in the post-peribothron phase could help to reveal the emission of the putative star. The dominant contribution of circumstellar matter (either inflow or outflow) is consistent with the observed stable luminosity and compactness of the DSO/G2 source during its pericentre passage. ",https://doi.org/10.1093/mnras/stv2357,1510.02285v1,Yes,potent(2)
0000-0001-6049-9390,Martin Rumpf,Rheinische Friedrich-Wilhelms-Universität Bonn,Stochastic Dominance Constraints in Elastic Shape Optimization,1970,"  This paper deals with shape optimization for elastic materials under stochastic loads. It transfers the paradigm of stochastic dominance, which allows for flexible risk aversion via comparison with benchmark random variables, from finite-dimensional stochastic programming to shape optimization. Rather than handling risk aversion in the objective, this enables risk aversion by including dominance constraints that single out subsets of nonanticipative shapes which compare favorably to a chosen stochastic benchmark. This new class of stochastic shape optimization problems arises by optimizing over such feasible sets. The analytical description is built on risk-averse cost measures. The underlying cost functional is of compliance type plus a perimeter term, in the implementation shapes are represented by a phase field which permits an easy estimate of a regularized perimeter. The analytical description and the numerical implementation of dominance constraints are built on risk-averse measures for the cost functional. A suitable numerical discretization is obtained using finite elements both for the displacement and the phase field function. Different numerical experiments demonstrate the potential of the proposed stochastic shape optimization model and in particular the impact of high variability of forces or probabilities in the different realizations. ",Kein DOI-Link verfügbar,1606.09461v1,Yes,potent(1)
0000-0001-6049-9390,Martin Rumpf,Rheinische Friedrich-Wilhelms-Universität Bonn,Smooth Interpolation of Key Frames in a Riemannian Shell Space,1970,"  Splines and subdivision curves are flexible tools in the design and manipulation of curves in Euclidean space. In this paper we study generalizations of interpolating splines and subdivision schemes to the Riemannian manifold of shell surfaces in which the associated metric measures both bending and membrane distortion. The shells under consideration are assumed to be represented by Loop subdivision surfaces. This enables the animation of shells via the smooth interpolation of a given set of key frame control meshes. Using a variational time discretization of geodesics efficient numerical implementations can be derived. These are based on a discrete geodesic interpolation, discrete geometric logarithm, discrete exponential map, and discrete parallel transport. With these building blocks at hand discrete Riemannian cardinal splines and three different types of discrete, interpolatory subdivision schemes are defined. Numerical results for two different subdivision shell models underline the potential of this approach in key frame animation. ",Kein DOI-Link verfügbar,1702.06746v1,Yes,potent(1)
0000-0001-6102-7547,Julian Struck,Friedrich Schiller Universität Jena,Tunable gauge potential for neutral and spinless particles in driven   lattices,1970,"  We present a universal method to create a tunable, artificial vector gauge potential for neutral particles trapped in an optical lattice. The necessary Peierls phase of the hopping parameters between neighboring lattice sites is generated by applying a suitable periodic inertial force such that the method does not rely on any internal structure of the particles. We experimentally demonstrate the realization of such artificial potentials, which generate ground state superfluids at arbitrary non-zero quasi-momentum. We furthermore investigate possible implementations of this scheme to create tuneable magnetic fluxes, going towards model systems for strong-field physics. ",https://doi.org/10.1103/PhysRevLett.108.225304,1203.0049v1,Yes,potent(2)
0000-0001-6102-7547,Julian Struck,Friedrich Schiller Universität Jena,In Situ Thermometry of Fermionic Cold-Atom Quantum Wires,1970,"  We study ensembles of fermionic cold-atom quantum wires with tunable transverse mode population and single-wire resolution. From in situ density profiles, we determine the temperature of the atomic wires in the weakly interacting limit and reconstruct the underlying potential landscape. By varying atom number and temperature, we control the occupation of the transverse modes and study the 1D-3D crossover. In the 1D limit, we observe an increase of the reduced temperature $T/T_{F}$ at nearly constant entropy per particle $S/N k_{B}$. The ability to probe individual atomic wires in situ paves the way to quantitatively study equilibrium and transport properties of strongly interacting 1D Fermi gases. ",https://doi.org/10.1103/PhysRevLett.127.113602,2102.01589v3,Yes,potent(1)
0000-0001-6102-7547,Julian Struck,Friedrich Schiller Universität Jena,Homogeneous Atomic Fermi Gases,1970,"  We report on the creation of homogeneous Fermi gases of ultracold atoms in a uniform potential. In the momentum distribution of a spin-polarized gas, we observe the emergence of the Fermi surface and the saturated occupation of one particle per momentum state. This directly confirms Pauli blocking in momentum space. For the spin-balanced unitary Fermi gas, we observe spatially uniform pair condensates. For thermodynamic measurements, we introduce a hybrid potential that is harmonic in one dimension and uniform in the other two. The spatially resolved compressibility reveals the superfluid transition in a spin-balanced Fermi gas, saturation in a fully polarized Fermi gas, and strong attraction in the polaronic regime of a partially polarized Fermi gas. ",https://doi.org/10.1103/PhysRevLett.118.123401,1610.10100v1,Yes,potent(2)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Multidimensional quantum calculation of the infrared spectra under   polaritonic vibrational strong and ultrastrong coupling,1970,"  Recent experiments and theory demonstrate that the the ground state properties and chemical reactivity of molecules can be modified inside an optical cavity. The vibrational strong or ultrastrong coupling results in the formation of vibrational polaritons which are usually observed through infrared spectra (IR). Here, we provide a theoretical framework to conduct multidimensional quantum simulations of the infrared spectra when the molecule is interacting with cavity modes. Taking single water molecule as an example, combing with accurate potential energy and dipole moment surfaces, our implemented cavity vibrational self-consistent field/virtual state configuration interaction (cVSCF/VCI) is shown to be able to provide quantitative predictions of the IR spectra when the molecule is inside or outside the cavity. The spectral signatures of resonance splittings and blue/red shift of certain bands are found to be highly related with the frequency and polarization direction of the cavity modes. Further analyses of the simulated spectra shows that polaritonic strong vibrational coupling greatly induce the coupling between molecule's vibrational modes, indicating the intramolecular vibrational energy transfer may be significantly accelerated by the cavity. ",https://doi.org/10.1021/acs.jpclett.2c03245,2204.05474v1,Yes,potent(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Bayesian Nonparametric Submodular Video Partition for Robust Anomaly   Detection,1970,"  Multiple-instance learning (MIL) provides an effective way to tackle the video anomaly detection problem by modeling it as a weakly supervised problem as the labels are usually only available at the video level while missing for frames due to expensive labeling cost. We propose to conduct novel Bayesian non-parametric submodular video partition (BN-SVP) to significantly improve MIL model training that can offer a highly reliable solution for robust anomaly detection in practical settings that include outlier segments or multiple types of abnormal events. BN-SVP essentially performs dynamic non-parametric hierarchical clustering with an enhanced self-transition that groups segments in a video into temporally consistent and semantically coherent hidden states that can be naturally interpreted as scenes. Each segment is assumed to be generated through a non-parametric mixture process that allows variations of segments within the same scenes to accommodate the dynamic and noisy nature of many real-world surveillance videos. The scene and mixture component assignment of BN-SVP also induces a pairwise similarity among segments, resulting in non-parametric construction of a submodular set function. Integrating this function with an MIL loss effectively exposes the model to a diverse set of potentially positive instances to improve its training. A greedy algorithm is developed to optimize the submodular function and support efficient model training. Our theoretical analysis ensures a strong performance guarantee of the proposed algorithm. The effectiveness of the proposed approach is demonstrated over multiple real-world anomaly video datasets with robust detection performance. ",Kein DOI-Link verfügbar,2203.12840v1,Yes,potent(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Balancing Bias and Variance for Active Weakly Supervised Learning,1970,"  As a widely used weakly supervised learning scheme, modern multiple instance learning (MIL) models achieve competitive performance at the bag level. However, instance-level prediction, which is essential for many important applications, remains largely unsatisfactory. We propose to conduct novel active deep multiple instance learning that samples a small subset of informative instances for annotation, aiming to significantly boost the instance-level prediction. A variance regularized loss function is designed to properly balance the bias and variance of instance-level predictions, aiming to effectively accommodate the highly imbalanced instance distribution in MIL and other fundamental challenges. Instead of directly minimizing the variance regularized loss that is non-convex, we optimize a distributionally robust bag level likelihood as its convex surrogate. The robust bag likelihood provides a good approximation of the variance based MIL loss with a strong theoretical guarantee. It also automatically balances bias and variance, making it effective to identify the potentially positive instances to support active sampling. The robust bag likelihood can be naturally integrated with a deep architecture to support deep model training using mini-batches of positive-negative bag pairs. Finally, a novel P-F sampling function is developed that combines a probability vector and predicted instance scores, obtained by optimizing the robust bag likelihood. By leveraging the key MIL assumption, the sampling function can explore the most challenging bags and effectively detect their positive instances for annotation, which significantly improves the instance-level prediction. Experiments conducted over multiple real-world datasets clearly demonstrate the state-of-the-art instance-level prediction achieved by the proposed model. ",Kein DOI-Link verfügbar,2206.05682v1,Yes,potent(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Comprehensive fabrication of SNAP microresonators by a femtosecond laser,1970,"  Surface nanoscale axial photonics (SNAP) microresonators with nanoscale effective radius variation (ERV) along optical fiber axis can be fabricated by inscribing axially oriented lines inside the fiber with a femtosecond laser. The optimization of variable parameters in the femtosecond laser inscription technique is of great significance for flexible and ultra-high precision control of ERV, which is vital to the performance of SNAP devices. Here, we present the first systematical investigation on the relationships between the various controllable fabrication parameters and the introduced ERV of the SNAP microresonators. Specifically, both the qualitative and quantitative processing principles were revealed. As a proof-of-principle, by comprehensively optimizing the fabrication parameters, we realized a SNAP microresonator with the characteristics of both small axial size and maximal ERV, which is almost impossible to realize with other SNAP fabrication techniques. Our work promotes the fs laser inscription technology to be a flexible and versatile approach for fabricating the SNAP devices with ultra-high precision, ultra-low loss and high robustness. ",https://doi.org/10.1364/OE.418731,2011.07810v1,Yes,versatile(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Latent Space Energy-based Model for Fine-grained Open Set Recognition,1970,"  Fine-grained open-set recognition (FineOSR) aims to recognize images belonging to classes with subtle appearance differences while rejecting images of unknown classes. A recent trend in OSR shows the benefit of generative models to discriminative unknown detection. As a type of generative model, energy-based models (EBM) are the potential for hybrid modeling of generative and discriminative tasks. However, most existing EBMs suffer from density estimation in high-dimensional space, which is critical to recognizing images from fine-grained classes. In this paper, we explore the low-dimensional latent space with energy-based prior distribution for OSR in a fine-grained visual world. Specifically, based on the latent space EBM, we propose an attribute-aware information bottleneck (AIB), a residual attribute feature aggregation (RAFA) module, and an uncertainty-based virtual outlier synthesis (UVOS) module to improve the expressivity, granularity, and density of the samples in fine-grained classes, respectively. Our method is flexible to take advantage of recent vision transformers for powerful visual classification and generation. The method is validated on both fine-grained and general visual classification datasets while preserving the capability of generating photo-realistic fake images with high resolution. ",Kein DOI-Link verfügbar,2309.10711v2,Yes,potent(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Reinforced Compressive Neural Architecture Search for Versatile   Adversarial Robustness,1970,"  Prior neural architecture search (NAS) for adversarial robustness works have discovered that a lightweight and adversarially robust neural network architecture could exist in a non-robust large teacher network, generally disclosed by heuristic rules through statistical analysis and neural architecture search, generally disclosed by heuristic rules from neural architecture search. However, heuristic methods cannot uniformly handle different adversarial attacks and ""teacher"" network capacity. To solve this challenge, we propose a Reinforced Compressive Neural Architecture Search (RC-NAS) for Versatile Adversarial Robustness. Specifically, we define task settings that compose datasets, adversarial attacks, and teacher network information. Given diverse tasks, we conduct a novel dual-level training paradigm that consists of a meta-training and a fine-tuning phase to effectively expose the RL agent to diverse attack scenarios (in meta-training), and making it adapt quickly to locate a sub-network (in fine-tuning) for any previously unseen scenarios. Experiments show that our framework could achieve adaptive compression towards different initial teacher networks, datasets, and adversarial attacks, resulting in more lightweight and adversarially robust architectures. ",Kein DOI-Link verfügbar,2406.06792v2,Yes,versatile(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Can We Learn the Energy of Sublimation of Ice from Water Clusters?,1970,"  This short paper reports a study of the electronic dissociation energies, De, of water clusters from direct ab initio (mostly CCSD(T)) calculations and the q-AQUA and MB-pol potentials. These clusters range in size from 6-25 monomers. These are all in very good agreement with each other, as shown in a recent Perspective by Herman and Xantheas. To the best of our knowledge, we present for the first time results for the De per monomer. To our surprise this quantity appears to be converging to a value close to 12 kcal/mol. An estimate of 1.5 - 2 kcal/mol for the {\Delta}ZPE for these clusters puts the value of D0 at 10 to 10.5 kcal/mol. This value is remarkably (and probably fortuitously) close to the reported sublimation enthalpy of 10.2 kcal/mol at 10 K. However, given that these De energies correspond to dissociation of the cluster to N isolated monomers the interpretation of ``vaporization"" of these ``solid"" clusters is qualitatively reasonable. ",Kein DOI-Link verfügbar,2408.05234v1,Yes,potent(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Rectangular SNAP microresonator fabricated with a femtosecond laser,1970,"  SNAP microresonators, which are fabricated by nanoscale effective radius variation (ERV) of the optical fiber with sub-angstrom precision, can be potentially used as miniature classical and quantum signal processors, frequency comb generators, as well as ultraprecise microfluidic and environmental optical sensors. Many of these applications require the introduction of nanoscale ERV with a large contrast {\alpha} which is defined as the maximum shift of the fiber cutoff wavelength introduced per unit length of the fiber axis. The previously developed fabrication methods of SNAP structures, which used focused CO2 and femtosecond laser beams, achieved {\alpha} ~ 0.02 nm/um. Here we develop a new fabrication method of SNAP microresonators with a femtosecond laser which allows us to demonstrate a 50-fold improvement of previous results and achieve {\alpha} ~ 1 nm/um. Furthermore, our fabrication method enables the introduction of ERV which is several times larger than the maximum ERV demonstrated previously. As an example, we fabricate a rectangular SNAP resonator and investigate its group delay characteristics. Our experimental results are in good agreement with theoretical simulations. Overall, the developed approach allows us to reduce the axial scale of SNAP structures by an order of magnitude. ",https://doi.org/10.1364/OL.44.005606,1911.01246v1,Yes,potent(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Quantum speed-up in solving the maximal clique problem,1970,"  The maximal clique problem, to find the maximally sized clique in a given graph, is classically an NP-complete computational problem, which has potential applications ranging from electrical engineering, computational chemistry, bioinformatics to social networks. Here we develop a quantum algorithm to solve the maximal clique problem for any graph $G$ with $n$ vertices with quadratic speed-up over its classical counterparts, where the time and spatial complexities are reduced to, respectively, $O(\sqrt{2^{n}})$ and $O(n^{2})$. With respect to oracle-related quantum algorithms for the NP-complete problems, we identify our algorithm to be optimal. To justify the feasibility of the proposed quantum algorithm, we have successfully solved an exemplified clique problem for a graph $G$ with two vertices and one edge by carrying out a nuclear magnetic resonance experiment involving four qubits. ",https://doi.org/10.1103/PhysRevA.97.032344,1803.11356v1,Yes,potent(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Spiking Graph Convolutional Networks,1970,"  Graph Convolutional Networks (GCNs) achieve an impressive performance due to the remarkable representation ability in learning the graph information. However, GCNs, when implemented on a deep network, require expensive computation power, making them difficult to be deployed on battery-powered devices. In contrast, Spiking Neural Networks (SNNs), which perform a bio-fidelity inference process, offer an energy-efficient neural architecture. In this work, we propose SpikingGCN, an end-to-end framework that aims to integrate the embedding of GCNs with the biofidelity characteristics of SNNs. The original graph data are encoded into spike trains based on the incorporation of graph convolution. We further model biological information processing by utilizing a fully connected layer combined with neuron nodes. In a wide range of scenarios (e.g. citation networks, image graph classification, and recommender systems), our experimental results show that the proposed method could gain competitive performance against state-of-the-art approaches. Furthermore, we show that SpikingGCN on a neuromorphic chip can bring a clear advantage of energy efficiency into graph data analysis, which demonstrates its great potential to construct environment-friendly machine learning models. ",Kein DOI-Link verfügbar,2205.02767v2,Yes,potent(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Presenting and Evaluating the Impact of Experiential Learning in   Computing Accessibility Education,1970,"  Studies indicate that much of the software created today is not accessible to all users, indicating that developers don't see the need to devote sufficient resources to creating accessible software. Compounding this problem, there is a lack of robust, easily adoptable educational accessibility material available to instructors for inclusion in their curricula. To address these issues, we have created five Accessibility Learning Labs (ALL) using an experiential learning structure. The labs are designed to educate and create awareness of accessibility needs in computing. The labs enable easy classroom integration by providing instructors with complete educational materials including lecture slides, activities, and quizzes. The labs are hosted on our servers and require only a browser to be utilized.   To demonstrate the benefit of our material and the potential benefits of our experiential lab format with empathy-creating material, we conducted a study involving 276 students in ten sections of an introductory computing course. Our findings include: (I) The demonstrated potential of the proposed experiential learning format and labs are effective in motivating and educating students about the importance of accessibility (II) The labs are effective in informing students about foundational accessibility topics (III) Empathy-creating material is demonstrated to be a beneficial component in computing accessibility education, supporting students in placing a higher value on the importance of creating accessible software. Created labs and project materials are publicly available on the project website: http://all.rit.edu ",Kein DOI-Link verfügbar,2002.06445v3,Yes,potent(2)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,"q-AQUA: a many-body CCSD(T) water potential, including 4-body   interactions, demonstrates the quantum nature of water from clusters to the   liquid phase",1970,"  Many model potential energy surfaces (PESs) have been reported for water; however, none are strictly from ""first principles"". Here we report such a potential, based on a many-body representation at the CCSD(T) level of theory up to the ultimate 4-body interaction. The new PES is benchmarked for the isomers of the water hexamer for dissociation energies, harmonic frequencies, and unrestricted diffusion Monte Carlo (DMC) calculations of the zero-point energies of the Prism, Book, and Cage isomers. Dissociation energies of several isomers of the 20-mer agree well with recent benchmark energies. Exploratory DMC calculations on this cluster verify the robustness of the new PES for quantum simulations. The accuracy and speed of the new PES are demonstrated for standard condensed phase properties, i.e., the radial distribution function and the self-diffusion constant. Quantum effects are shown to be substantial for these observables and also needed to bring theory into an excellent agreement with experiment. ",https://doi.org/10.1021/acs.jpclett.2c00966,2204.01804v1,Yes,potent(2)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,No Headache for PIPs: A PIP Potential for Aspirin Outperforms Other   Machine-Learned Potentials,1970,"  Assessments of machine-learned (ML) potentials are an important aspect of the rapid development of this field. We recently reported an assessment of the linear-regression permutationally invariant polynomial (PIP) method for ethanol, using the widely used (revised) MD17 dataset. We demonstrated that the PIP approach outperformed numerous other methods, e.g., ANI, PhysNet, sGDML, p-KRR, with respect to precision and notably with respect to speed [Houston $et$ $al$., $J. Chem. Phys.$ 2022, 156, 044120.]. Here we extend this assessment to the 21-atom aspirin molecule, using the rMD17 dataset. Both energies and forces are used for training and the precision of several PIPs is examined for both. Normal mode frequencies, the methyl torsional potential, and 1d vibrational energies for an OH stretch are presented. Overall, we show that the PIPs approach outperforms other ML methods, including sGDML, ANI, GAP, PhysNet, and ACE, as reported by Kov\'acs $et$ $al.$ in $J. Chem. Theory$ $Comput.$ 2021, 17, 7696-7711. ",https://doi.org/10.1021/acs.jctc.4c00054,2401.09316v1,Yes,potent(2)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,"Permutationally invariant polynomial regression for energies and   gradients, using reverse differentiation, achieves orders of magnitude   speed-up with high precision compared to other machine learning methods",1970,"  Permutationally invariant polynomial (PIP) regression has been used to obtain machine-learned (ML) potential energy surfaces, including analytical gradients, for many molecules and chemical reactions. Recently, the approach has been extended to moderate size molecules and applied to systems up to 15 atoms. The algorithm, including ""purification of the basis"", is computationally efficient for energies; however, we found that the recent extension to obtain analytical gradients, despite being a remarkable advance over previous methods, could be further improved. Here we report developments to compact further a purified basis and, more significantly, to use the reverse gradient approach to greatly speed up gradient evaluation. We demonstrate this for our recent 4-body water interaction potential. Comparisons of training and testing precision on the MD17 database of energies and gradients (forces) for ethanol against GP-SOAP, ANI, sGDML, PhysNet, pKREG, KRR, and other methods, which were recently assessed by Dral and co-workers, are given. The PIP fits are as precise as those using these methods, but the PIP computation time for energy and force evaluation is shown to be 10 to 1000 times faster. Finally, a new PIP PES is reported for ethanol based on a more extensive dataset of energies and gradients than in the MD17 database. Diffusion Monte Carlo calculations which fail on MD17-based PESs are successful using the new PES. ",https://doi.org/10.1063/5.0080506,2112.01734v1,Yes,potent(2)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,"The MD17 Datasets from the Perspective of Datasets for Gas-Phase ""Small""   Molecule Potentials",1970,"  There has been great progress in developing methods for machine-learned potential energy surfaces. There have also been important assessments of these methods by comparing so-called learning curves on datasets of electronic energies and forces, notably the MD17 database. The dataset for each molecule in this database generally consists of tens of thousands of energies and forces obtained from DFT direct dynamics at 500 K. We contrast the datasets from this database for three ""small"" molecules, ethanol, malonaldehyde, and glycine, with datasets we have generated with specific targets for the PESs in mind: a rigorous calculation of the zero-point energy and wavefunction, the tunneling splitting in malonaldehyde and in the case of glycine a description of all eight low-lying conformers. We found that the MD17 datasets are too limited for these targets. We also examine recent datasets for several PESs that describe small-molecule but complex chemical reactions. Finally, we introduce a new database, ""QM-22"", which contains datasets of molecules ranging from 4 to 15 atoms that extend to high energies and a large span of configurations. ",https://doi.org/10.1063/5.0089200,2205.11663v1,Yes,potent(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,Quantum calculations on a new CCSD(T) machine-learned PES reveal the   leaky nature of gas-phase $trans$ and $gauche$ ethanol conformers,1970,"  Ethanol is a molecule of fundamental interest in combustion, astrochemistry, and condensed phase as a solvent. It is characterized by two methyl rotors and $trans$ ($anti$) and $gauche$ conformers, which are known to be very close in energy. Here we show that based on rigorous quantum calculations of the vibrational zero-point state, using a new ab initio potential energy surface (PES), the ground state resembles the $trans$ conformer but substantial delocalization to the $gauche$ conformer is present. This explains experimental issues about the identification and isolation of the two conformers. This ""leak"" effect is partially quenched when deuterating the OH group, which further demonstrates the need for a quantum mechanical approach. Diffusion Monte Carlo (DMC) and full-dimensional semiclassical dynamics calculations are employed. The new PES is obtained by means of a $\Delta$-Machine learning approach starting from a pre-existing low level (LL) density functional theory (DFT) surface. This surface is brought to the CCSD(T) level of theory using a relatively small number of $ab$ $initio$ CCSD(T) energies. Agreement between the corrected PES and direct $ab$ $initio$ results for standard fidelity tests is excellent. One- and two-dimensional discrete variable representation calculations focusing on the $trans$-$gauche$ torsional motion are also reported, in reasonable agreement with the experiment. ",https://doi.org/10.1021/acs.jctc.2c00760,2206.02297v2,Yes,potent(1)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,"A $Δ$-Machine Learning Approach for Force Fields, Illustrated by a   CCSD(T) 4-body Correction to the MB-pol Water Potential",1970,"  $\Delta$-Machine Learning ($\Delta$-ML) has been shown to effectively and efficiently bring a low-level ML potential energy surface to CCSD(T) quality. Here we propose extending this approach to general force fields, which implicitly or explicitly contain many-body effects. After describing this general approach, we illustrate it for the MB-pol water potential which contains CCSD(T) 2-body and 3-body interactions but relies on the TTM4-F 4-body and higher body interactions. The 4-body MB-pol (TTM4-F) interaction fails at a very short range and for the water hexamer errors up to 0.84 kcal/mol are seen for some isomers, owing mainly to 4-body errors. We apply $\Delta$-ML for the 4-body interaction, using a recent dataset of CCSD(T) 4-body energies that we used to develop a new water potential, q-AQUA. This 4-body correction is shown to improve the accuracy of the MB-pol potential for the relative energies of 8 isomers of the water hexamer as well as the harmonic frequencies. The new potential is robust in the very short range and so should be reliable for simulations at high pressure and/or high temperature. ",https://doi.org/10.1039/D2DD00057A,2206.04254v1,Yes,potent(5)
0000-0001-6116-5181,Qi Yu,Universität Konstanz,$Δ$-Machine Learning to Elevate DFT-based Potentials and a Force   Field to the CCSD(T) Level Illustrated for Ethanol,1970,"  Progress in machine learning has facilitated the development of potentials that offer both the accuracy of first-principles techniques and vast increases in the speed of evaluation. Recently,""$\Delta$-machine learning"" has been used to elevate the quality of a potential energy surface (PES) based on low-level, e.g., density functional theory (DFT) energies and gradients to close to the gold-standard coupled cluster level of accuracy. We have demonstrated the success of this approach for molecules, ranging in size from H$_3$O$^+$ to 15-atom acetyl-acetone and tropolone. These were all done using the B3LYP functional. Here we investigate the generality of this approach for the PBE, M06, M06-2X, and PBE0+MBD functionals, using ethanol as the example molecule. Linear regression with permutationally invariant polynomials is used to fit both low-level and correction PESs. These PESs are employed for standard RMSE analysis for training and test datasets, and then general fidelity tests such as energetics of stationary points, normal mode frequencies, and torsional potentials are examined. We achieve similar improvements in all cases. Interestingly, we obtained significant improvement over DFT gradients where coupled cluster gradients were not used to correct the low-level PES. Finally, we present some results for correcting a recent molecular mechanics force field for ethanol and comment on the possible generality of this approach. ",Kein DOI-Link verfügbar,2407.20050v1,Yes,potent(3)
0000-0001-6122-839X,Minh Nguyen,Technische Universität Dresden,Generalized knowledge-enhanced framework for biomedical entity and   relation extraction,1970,"  In recent years, there has been an increasing number of frameworks developed for biomedical entity and relation extraction. This research effort aims to address the accelerating growth in biomedical publications and the intricate nature of biomedical texts, which are written for mainly domain experts. To handle these challenges, we develop a novel framework that utilizes external knowledge to construct a task-independent and reusable background knowledge graph for biomedical entity and relation extraction. The design of our model is inspired by how humans learn domain-specific topics. In particular, humans often first acquire the most basic and common knowledge regarding a field to build the foundational knowledge and then use that as a basis for extending to various specialized topics. Our framework employs such common-knowledge-sharing mechanism to build a general neural-network knowledge graph that is learning transferable to different domain-specific biomedical texts effectively. Experimental evaluations demonstrate that our model, equipped with this generalized and cross-transferable knowledge base, achieves competitive performance benchmarks, including BioRelEx for binding interaction detection and ADE for Adverse Drug Effect identification. ",Kein DOI-Link verfügbar,2408.06618v1,Yes,intricate(1)
0000-0001-6283-8763,Thomas Weigel,Ruhr-Universität Bochum,Outer restricted derivations of nilpotent restricted Lie algebras,1970,"  In this paper we prove that every finite-dimensional nilpotent restricted Lie algebra over a field of prime characteristic has an outer restricted derivation whose square is zero unless the restricted Lie algebra is a torus or it is one-dimensional or it is isomorphic to the three-dimensional Heisenberg algebra in characteristic two as an ordinary Lie algebra. This result is the restricted analogue of a result of T\^og\^o on the existence of nilpotent outer derivations of ordinary nilpotent Lie algebras in arbitrary characteristic and the Lie-theoretic analogue of a classical group-theoretic result of Gasch\""utz on the existence of $p$-power automorphisms of $p$-groups. As a consequence we obtain that every finite-dimensional non-toral nilpotent restricted Lie algebra has an outer restricted derivation. ",Kein DOI-Link verfügbar,1102.2629v2,Yes,potent(4)
0000-0001-6298-2327,Ina Schieferdecker,Technische Universität Berlin,A Taxonomy to Assess and Tailor Risk-based Testing in Recent Testing   Standards,1970,"  This article provides a taxonomy for risk-based testing that serves as a tool to define, tailor, or assess risk-based testing approaches in general and to instantiate risk-based testing approaches for the current testing standards ISO/IEC/IEEE 29119, ETSI EG and OWASP Security Testing Guide in particular. We demonstrate the usefulness of the taxonomy by applying it to the aforementioned standards as well as to the risk-based testing approaches SmartTesting, RACOMAT, PRISMA and risk-based test case prioritization using fuzzy expert systems. In this setting, the taxonomy is used to systematically identify deviations between the standards' requirements and the individual testing approaches so that we are able to position and compare the testing approaches and discuss their potential for practical application. ",Kein DOI-Link verfügbar,1905.10676v1,Yes,potent(1)
0000-0001-6350-516X,Lars Lauke,Karlsruher Institut für Technologie,Band Engineering of Dirac cones in Iron Chalcogenides,1970,"  By band engineering the iron chalcogenide Fe(Se,Te) via ab-initio calculations, we search for topological surface states and realizations of Majorana bound states. Proposed topological states are expected to occur for non-stoichiometric compositions on a surface Dirac cone where issues like disorder scattering and charge transfer between relevant electronic states have to be addressed. However, this surface Dirac cone is well above the Fermi-level. Our goal is to theoretically design a substituted crystal in which the surface Dirac cone is shifted towards the Fermi-level by modifying the bulk material without disturbing the surface. Going beyond conventional density functional theory (DFT), we apply the coherent potential approximation (BEB-CPA) in a mixed basis pseudo-potential framework to scan the substitutional phase-space of co-substitutions on the Se-sites. We have identified iodine as a promising candidate for intrinsic doping. Our specific proposal is that FeSe$_{0.325}$I$_{0.175}$Te$_{0.5}$ is a very likely candidate to exhibit a Dirac cone right at the Fermi energy without inducing strong disorder scattering. ",https://doi.org/10.1103/PhysRevB.102.054209,2003.05732v2,Yes,potent(2)
0000-0001-6356-7790,Sebastian Milster,Albert-Ludwigs-Universität Freiburg,Feedback-controlled solute transport through chemo-responsive polymer   membranes,1970,"  Polymer membranes are typically assumed to be inert and nonresponsive to the flux and density of the permeating particles in transport processes. Here, we study theoretically the consequences of membrane responsiveness and feedback on the steady-state force--flux relations and membrane permeability using a nonlinear-feedback solution-diffusion model of transport through a slab-like membrane. Therein, the solute concentration inside the membrane depends on the bulk concentration, $c_0$, the driving force, $f$, and the polymer volume fraction, $\phi$. In our model, solute accumulation in the membrane causes a sigmoidal volume phase transition of the polymer, changing its permeability, which, in return, affects the membrane's solute uptake. This feedback leads to nonlinear force--flux relations, $j(f)$, which we quantify in terms of the system's differential permeability, $\mathcal{P}_\text{sys}^{\Delta}\propto {\mathrm{d}j}/{\mathrm{d}f}$. We find that the membrane feedback can increase or decrease the solute flux by orders of magnitude, triggered by a small change in the driving force, and largely tunable by attractive versus repulsive solute--membrane interactions. Moreover, controlling the input, $c_0$ and $f$, can lead to steady-state bistability of $\phi$ and hysteresis in the force--flux relations. This work advocates that the fine-tuning of the membrane's chemo-responsiveness will enhance the nonlinear transport control features, providing great potential for future (self-)regulating membrane devices. ",https://doi.org/10.1063/5.0135707,2212.00537v1,Yes,potent(1)
0000-0001-6419-4340,Han Ye,Universität Mannheim,Design of spontaneous parametric down-conversion in integrated hybrid   SixNy-PPLN waveguides,1970,"  High-efficient and high-purity photon sources are highly desired for quantum information processing. We report the design of a chip-scale hybrid SixNy and thin film periodically-poled lithium niobate waveguide for generating high-purity type-II spontaneous parametric down conversion (SPDC) photons in telecommunication band. The modeled second harmonic generation efficiency of 225% W^(-1)*cm^(-2) is obtained at 1560nm. Joint spectral analysis is performed to estimate the frequency correlation of SPDC photons, yielding intrinsic purity with up to 95.17%. The generation rate of these high-purity photon pairs is estimated to be 2.87 * 10^7 pairs/s/mW within the bandwidth of SPDC. Our chip-scale hybrid waveguide design has the potential for large scale on-chip quantum information processing and integrated photon-efficient quantum key distribution through high-dimensional time-energy encoding. ",https://doi.org/10.1364/OE.27.030773,1910.14225v1,Yes,potent(1)
0000-0001-6434-8020,Johannes Voit,Universität Bielefeld,An Exactly Solvable Kondo Problem for Interacting One-Dimensional   Fermions,1970,"  The single impurity Kondo problem in the one-dimensional $\delta$-potential Fermi gas is exactly solved for two sets of special coupling constants via Bethe ansatz. It is found that ferromagnetic Kondo screening does occur in one case which confirms the Furusaki-Nagaosa conjecture while in the other case it does not, which we explain in a simple physical picture. The surface energy, the low temperature specific heat and the Pauli susceptibility induced by the impurity and thereby the Kondo temperature are derived explicitly. ",https://doi.org/10.1103/PhysRevLett.77.4934,cond-mat/9609171v1,Yes,potent(1)
0000-0001-6491-2082,Matthew Johnson,Universität Hamburg,Complexity Framework for Forbidden Subgraphs IV: The Steiner Forest   Problem,1970,"  We study Steiner Forest on $H$-subgraph-free graphs, that is, graphs that do not contain some fixed graph $H$ as a (not necessarily induced) subgraph. We are motivated by a recent framework that completely characterizes the complexity of many problems on $H$-subgraph-free graphs. However, in contrast to e.g. the related Steiner Tree problem, Steiner Forest falls outside this framework. Hence, the complexity of Steiner Forest on $H$-subgraph-free graphs remained tantalizingly open. In this paper, we make significant progress towards determining the complexity of Steiner Forest on $H$-subgraph-free graphs. Our main results are four novel polynomial-time algorithms for different excluded graphs $H$ that are central to further understand its complexity. Along the way, we study the complexity of Steiner Forest for graphs with a small $c$-deletion set, that is, a small set $S$ of vertices such that each component of $G-S$ has size at most $c$. Using this parameter, we give two noteworthy algorithms that we later employ as subroutines. First, we prove Steiner Forest is FPT parameterized by $|S|$ when $c=1$ (i.e. the vertex cover number). Second, we prove Steiner Forest is polynomial-time solvable for graphs with a 2-deletion set of size at most 2. The latter result is tight, as the problem is NP-complete for graphs with a 3-deletion set of size 2. ",Kein DOI-Link verfügbar,2305.01613v2,Yes,noteworthy(1)
0000-0001-6515-1481,Jonas Walter,FAU Erlangen-Nürnberg,Fast Lane-Level Intersection Estimation using Markov Chain Monte Carlo   Sampling and B-Spline Refinement,1970,"  Estimating the current scene and understanding the potential maneuvers are essential capabilities of automated vehicles. Most approaches rely heavily on the correctness of maps, but neglect the possibility of outdated information.   We present an approach that is able to estimate lanes without relying on any map prior. The estimation is based solely on the trajectories of other traffic participants and is thereby able to incorporate complex environments. In particular, we are able to estimate the scene in the presence of heavy traffic and occlusions.   The algorithm first estimates a coarse lane-level intersection model by Markov chain Monte Carlo sampling and refines it later by aligning the lane course with the measurements using a non-linear least squares formulation. We model the lanes as 1D cubic B-splines and can achieve error rates of less than 10cm within real-time. ",Kein DOI-Link verfügbar,2007.06904v1,Yes,potent(1)
0000-0001-6515-1481,Jonas Walter,FAU Erlangen-Nürnberg,MyoGestic: EMG Interfacing Framework for Decoding Multiple Spared   Degrees of Freedom of the Hand in Individuals with Neural Lesions,1970,"  Restoring limb motor function in individuals with spinal cord injury (SCI), stroke, or amputation remains a critical challenge, one which affects millions worldwide. Recent studies show through surface electromyography (EMG) that spared motor neurons can still be voluntarily controlled, even without visible limb movement . These signals can be decoded and used for motor intent estimation; however, current wearable solutions lack the necessary hardware and software for intuitive interfacing of the spared degrees of freedom after neural injuries. To address these limitations, we developed a wireless, high-density EMG bracelet, coupled with a novel software framework, MyoGestic. Our system allows rapid and tailored adaptability of machine learning models to the needs of the users, facilitating real-time decoding of multiple spared distinctive degrees of freedom. In our study, we successfully decoded the motor intent from two participants with SCI, two with spinal stroke , and three amputees in real-time, achieving several controllable degrees of freedom within minutes after wearing the EMG bracelet. We provide a proof-of-concept that these decoded signals can be used to control a digitally rendered hand, a wearable orthosis, a prosthesis, or a 2D cursor. Our framework promotes a participant-centered approach, allowing immediate feedback integration, thus enhancing the iterative development of myocontrol algorithms. The proposed open-source software framework, MyoGestic, allows researchers and patients to focus on the augmentation and training of the spared degrees of freedom after neural lesions, thus potentially bridging the gap between research and clinical application and advancing the development of intuitive EMG interfaces for diverse neural lesions. ",Kein DOI-Link verfügbar,2408.07817v1,Yes,potent(1)
0000-0001-6557-5604,Kathrin Dörfler,Technische Universität München,Mobile Robotic Fabrication at 1:1 scale: the In situ Fabricator,1970,"  This paper presents the concept of an In situ Fabricator, a mobile robot intended for on-site manufacturing, assembly and digital fabrication. We present an overview of a prototype system, its capabilities, and highlight the importance of high-performance control, estimation and planning algorithms for achieving desired construction goals. Next, we detail on two architectural application scenarios: first, building a full-size undulating brick wall, which required a number of repositioning and autonomous localisation manoeuvres. Second, the Mesh Mould concrete process, which shows that an In situ Fabricator in combination with an innovative digital fabrication tool can be used to enable completely novel building technologies. Subsequently, important limitations and disadvantages of our approach are discussed. Based on that, we identify the need for a new type of robotic actuator, which facilitates the design of novel full-scale construction robots. We provide brief insight into the development of this actuator and conclude the paper with an outlook on the next-generation In situ Fabricator, which is currently under development. ",https://doi.org/10.1007/s41693-017-0003-5,1701.03573v1,Yes,innovative(1)
0000-0001-6710-0493,Daniel Becker,Universität Köln,Open-Source Tool Based Framework for Automated Performance Evaluation of   an AD Function,1970,"  As automation in the field of automated driving (AD) progresses, ensuring the safety and functionality of AD functions (ADFs) becomes crucial. Virtual scenario-based testing has emerged as a prevalent method for evaluating these systems, allowing for a wider range of testing environments and reproducibility of results. This approach involves AD-equipped test vehicles operating within predefined scenarios to achieve specific driving objectives. To comprehensively assess the impact of road network properties on the performance of an ADF, varying parameters such as intersection angle, curvature and lane width is essential. However, covering all potential scenarios is impractical, necessitating the identification of feasible parameter ranges and automated generation of corresponding road networks for simulation. Automating the workflow of road network generation, parameter variation, simulation, and evaluation leads to a comprehensive understanding of an ADF's behavior in diverse road network conditions. This paper aims to investigate the influence of road network parameters on the performance of a prototypical ADF through virtual scenario-based testing, ultimately advocating the importance of road topology in assuring safety and reliability of ADFs. ",https://doi.org/10.1109/ICECCME55909.2022.9988312,2406.16362v1,Yes,potent(1)
0000-0001-6710-0493,Daniel Becker,Universität Köln,Perfectly Secure Key Agreement Over a Full Duplex Wireless Channel,1970,"  Secret key generation (SKG) between authenticated devices is a pivotal task for secure communications. Diffie-Hellman (DH) is de-facto standard but not post-quantum secure. In this paper, we shall invent and analyze a new security primitive that is specifically designed for WPAN. For WPAN, wireless channel-based SKG has been proposed but was not widely deployed due to its critical dependence on the channel's entropy which is uncontrollable. We formulate a different approach: We still exploit channel properties but mainly hinge on the reciprocity of the wireless channel and not on the channel's entropy. The radio advantage comes from the use of full duplex communication. We show that in this situation both legitimate parties can agree on a common secret key even without ever probing the channel at all. At the core is a new bisparse blind deconvolution scheme for which we prove correctness and information-theoretic, i.e. perfect, security. We show that, ultimately, a secret key can be extracted and give a lower bound for the number of secret key bits which is then verified by experiments. ",Kein DOI-Link verfügbar,2404.06952v2,Yes,pivotal(1)
0000-0001-6710-0493,Daniel Becker,Universität Köln,On avoiding Ostrogradski instabilities within Asymptotic Safety,1970,  We study the renormalization group flow of gravity coupled to scalar matter using functional renormalization group techniques. The novel feature is the inclusion of higher-derivative terms in the scalar propagator. Such terms give rise to Ostrogradski ghosts which signal an instability of the system and are therefore dangerous for the consistency of the theory. Since it is expected that such terms are generated dynamically by the renormalization group flow they provide a potential threat when constructing a theory of quantum gravity based on Asymptotic Safety. Our work then establishes the following picture: upon incorporating higher-derivative terms in the scalar propagator the flow of the gravity-matter system possesses a fixed point structure suitable for Asymptotic Safety. This structure includes an interacting renormalization group fixed point where the Ostrogradski ghosts acquire an infinite mass and decouple from the system. Tracing the flow towards the infrared it is found that there is a subset of complete renormalization group trajectories which lead to stable renormalized propagators. This subset is in one-to-one correspondence to the complete renormalization group trajectories obtained in computations which do not track of the higher-derivative terms. Thus our asymptotically safe gravity-matter systems are not haunted by Ostrogradski ghosts. ,https://doi.org/10.1007/JHEP12(2017)121,1709.09098v2,Yes,potent(1)
0000-0001-6710-0493,Daniel Becker,Universität Köln,Momentum distributions and numerical methods for strongly interacting   one-dimensional spinor gases,1970,"  One-dimensional spinor gases with strong delta interaction fermionize and form a spin chain. The spatial degrees of freedom of this atom chain can be described by a mapping to spinless noninteracting fermions and the spin degrees of freedom are described by a spin-chain model with nearest-neighbor interactions. Here, we compute momentum and occupation-number distributions of up to 16 strongly interacting spinor fermions and bosons as a function of their spin imbalance, the strength of an externally applied magnetic field gradient, the length of their spin, and for different excited states of the multiplet. We show that the ground-state momentum distributions resemble those of the corresponding noninteracting systems, apart from flat background distributions, which extend to high momenta. Moreover, we show that the spin order of the spin chain---in particular antiferromagnetic spin order---may be deduced from the momentum and occupation-number distributions of the system. Finally, we present efficient numerical methods for the calculation of the single-particle densities and one-body density matrix elements and of the local exchange coefficients of the spin chain for large systems containing more than 20 strongly interacting particles in arbitrary confining potentials. ",https://doi.org/10.1103/PhysRevA.94.023606,1602.06816v4,Yes,potent(1)
0000-0001-6721-7034,Theresa Bender,Georg-August-Universität Göttingen,Benchmarking the Impact of Noise on Deep Learning-based Classification   of Atrial Fibrillation in 12-Lead ECG,1970,"  Electrocardiography analysis is widely used in various clinical applications and Deep Learning models for classification tasks are currently in the focus of research. Due to their data-driven character, they bear the potential to handle signal noise efficiently, but its influence on the accuracy of these methods is still unclear. Therefore, we benchmark the influence of four types of noise on the accuracy of a Deep Learning-based method for atrial fibrillation detection in 12-lead electrocardiograms. We use a subset of a publicly available dataset (PTBXL) and use the metadata provided by human experts regarding noise for assigning a signal quality to each electrocardiogram. Furthermore, we compute a quantitative signal-to-noise ratio for each electrocardiogram. We analyze the accuracy of the Deep Learning model with respect to both metrics and observe that the method can robustly identify atrial fibrillation, even in cases signals are labelled by human experts as being noisy on multiple leads. False positive and false negative rates are slightly worse for data being labelled as noisy. Interestingly, data annotated as showing baseline drift noise results in an accuracy very similar to data without. We conclude that the issue of processing noisy electrocardiography data can be addressed successfully by Deep Learning methods that might not need preprocessing as many conventional methods do. ",https://doi.org/10.3233/SHTI230321,2303.13915v1,Yes,potent(1)
0000-0001-6736-1378,Herbert Koch,Universität Bonn,Convexity and concavity of the ground state energy,1970,"  This note proves convexity resp. concavity of the ground state energy of one dimensional Schr\""odinger operators as a function of an endpoint of the interval for convex resp. concave potentials. ",Kein DOI-Link verfügbar,1502.07290v2,Yes,potent(1)
0000-0001-6736-1378,Herbert Koch,Universität Bonn,Dispersive estimates for principally normal pseudodifferential operators,1970,"  The aim of these notes is to describe some recent results concerning dispersive estimates for principally normal pseudodifferential operators. The main motivation for this comes from unique continuation problems. Such estimates can be used to prove Carleman inequalities, which in turn yield unique continuation results for various partial differential operators with rough potentials. ",Kein DOI-Link verfügbar,math/0401234v1,Yes,potent(1)
0000-0001-6736-1378,Herbert Koch,Universität Bonn,Carleman estimates and absence of embedded eigenvalues,1970,"  Let L be a Schroedinger operator with potential W in L^{(n+1)/2}. We prove that there is no embedded eigenvalue. The main tool is an Lp Carleman type estimate, which builds on delicate dispersive estimates established in a previous paper. The arguments extend to variable coefficient operators with long range potentials and with gradient potentials. ",https://doi.org/10.1007/s00220-006-0060-y,math-ph/0508052v1,Yes,potent(3)
0000-0001-6736-1378,Herbert Koch,Universität Bonn,Higher order time asymptotics of fast diffusion in euclidean space: a   dynamical systems approach,1970,"  This paper quantifies the speed of convergence and higher- order asymptotics of fast diffusion dynamics on R^n to the Barenblatt (self similar) solution. Degeneracies in the parabolicity of this equation are cured by re-expressing the dynamics on a manifold with a cylindrical end, called the cigar. The nonlinear evolution becomes differentiable in Hoelder spaces on the cigar. The linearization of the dynamics is given by the Laplace-Beltrami operator plus a transport term (which can be suppressed by introducing appropriate weights into the function space norm), plus a finite-depth potential well with a universal profile. In the limiting case of the (linear) heat equation, the depth diverges, the number of eigenstates increases without bound, and the continuous spectrum recedes to infinity. We provide a detailed study of the linear and nonlinear problems in Hoelder spaces on the cigar, including a sharp boundedness estimate for the semi-group, and use this as a tool to obtain sharp convergence results toward the Barenblatt solution, and higher order asymptotics. In finer convergence results (after modding out symmetries of the problem), a subtle interplay between convergence rates and tail behavior is revealed. The difficulties involved in choosing the right functional spaces in which to carry out the analysis can be interpreted as genuine features of the equation rather than mere annoying technicalities. ",Kein DOI-Link verfügbar,1204.6434v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Robust Object Modeling for Visual Tracking,1970,"  Object modeling has become a core part of recent tracking frameworks. Current popular tackers use Transformer attention to extract the template feature separately or interactively with the search region. However, separate template learning lacks communication between the template and search regions, which brings difficulty in extracting discriminative target-oriented features. On the other hand, interactive template learning produces hybrid template features, which may introduce potential distractors to the template via the cluttered search regions. To enjoy the merits of both methods, we propose a robust object modeling framework for visual tracking (ROMTrack), which simultaneously models the inherent template and the hybrid template features. As a result, harmful distractors can be suppressed by combining the inherent features of target objects with search regions' guidance. Target-related features can also be extracted using the hybrid template, thus resulting in a more robust object modeling framework. To further enhance robustness, we present novel variation tokens to depict the ever-changing appearance of target objects. Variation tokens are adaptable to object deformation and appearance variations, which can boost overall performance with negligible computation. Experiments show that our ROMTrack sets a new state-of-the-art on multiple benchmarks. ",Kein DOI-Link verfügbar,2308.05140v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Intense X-ray laser-induced proton emission from halo nuclei,1970,"  We investigate the intense X-ray laser-induced proton emission from halo nuclei within the framework of a nonperturbative quantum $S$-matrix approach. We have analytically deduced the angular differential as well as the total multi-photon rates of the proton emissions. For a linearly polarized X-ray laser field, we find that the angular distributions of proton emission sensitively depend on the laser frequency and show an interesting petal structure with increasing the laser frequency as well as the number of absorbed photons. Meanwhile, we find the Coulomb repulsion potential between the proton and the remainder nucleus has a strong hindering effect on the total multi-photon rates of the proton emissions and leads to the blue shifts of the multi-photon transition frequency. Moreover, the polarization effects of laser fields on total rates of proton emission have also been addressed. We find that the polarized ellipticity corresponding to the maximum of the total rates depend on the laser frequency showing a transition from perturbative to nonperturbative proton emission. The underlying mechanism of the above findings is uncovered, and some implications are discussed. ",Kein DOI-Link verfügbar,2210.08199v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,RAVSS: Robust Audio-Visual Speech Separation in Multi-Speaker Scenarios   with Missing Visual Cues,1970,"  While existing Audio-Visual Speech Separation (AVSS) methods primarily concentrate on the audio-visual fusion strategy for two-speaker separation, they demonstrate a severe performance drop in the multi-speaker separation scenarios. Typically, AVSS methods employ guiding videos to sequentially isolate individual speakers from the given audio mixture, resulting in notable missing and noisy parts across various segments of the separated speech. In this study, we propose a simultaneous multi-speaker separation framework that can facilitate the concurrent separation of multiple speakers within a singular process. We introduce speaker-wise interactions to establish distinctions and correlations among speakers. Experimental results on the VoxCeleb2 and LRS3 datasets demonstrate that our method achieves state-of-the-art performance in separating mixtures with 2, 3, 4, and 5 speakers, respectively. Additionally, our model can utilize speakers with complete audio-visual information to mitigate other visual-deficient speakers, thereby enhancing its resilience to missing visual cues. We also conduct experiments where visual information for specific speakers is entirely absent or visual frames are partially missing. The results demonstrate that our model consistently outperforms others, exhibiting the smallest performance drop across all settings involving 2, 3, 4, and 5 speakers. ",https://doi.org/10.1145/3664647.3681261,2407.19224v2,Yes,notable(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,A Multiple Step-like Spectrum of Primordial Perturbation,1970,"  We show that if the inflaton effective potential has multiple discontinuous points in its first derivative, the spectrum of primordial perturbation will be multiple step-like. We give a general analysis by applying a simple model. In principle, as long as the height of step is low enough, the result of spectrum will be consistent with observations. ",https://doi.org/10.1016/j.physletb.2011.09.077,1106.5608v2,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Topological Spin Texture in a Quantum Anomalous Hall Insulator,1970,"  The quantum anomalous Hall (QAH) effect has been recently discovered in experiment using thin-film topological insulator with ferromagnetic ordering and strong spin-orbit coupling. Here we investigate the spin degree of freedom of a QAH insulator and uncover a fundamental phenomenon that the edge states exhibit topologically stable spin texture in the boundary when a chiral-like symmetry is present. This result shows that edge states are chiral in both the orbital and spin degrees of freedom, and the chiral edge spin texture corresponds to the bulk topological states of the QAH insulator. We also study the potential applications of the edge spin texture in designing topological-state-based spin devices which might be applicable to future spintronic technologies. ",https://doi.org/10.1103/PhysRevLett.113.136403,1401.0415v3,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Classical Trajectory Perspective on Double Ionization Dynamics of   Diatomic Molecules Irradiated by Ultrashort Intense Laser Pulses,1970,"  In the present paper, we develop a semiclassical quasi-static model accounting for molecular double ionization in an intense laser pulse. With this model, we achieve insight into the dynamics of two highly-correlated valence electrons under the combined influence of a two-center Coulomb potential and an intense laser field, and reveal the significant influence of molecular alignment on the ratio of double over single ion yield. Analysis on the classical trajectories unveils sub-cycle dynamics of the molecular double ionization. Many interesting features, such as the accumulation of emitted electrons in the first and third quadrants of parallel momentum plane, the regular pattern of correlated momentum with respect to the time delay between closest collision and ionization moment, are revealed and successfully explained by back analyzing the classical trajectories. Quantitative agreement with experimental data over a wide range of laser intensities from tunneling to over-the-barrier regime is presented. ",https://doi.org/10.1103/PhysRevA.77.013403,0708.2132v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Simulating periodic systems on quantum computer,1970,"  The variational quantum eigensolver (VQE) is one of the most appealing quantum algorithms to simulate electronic structure properties of molecules on near-term noisy intermediate-scale quantum devices. In this work, we generalize the VQE algorithm for simulating extended systems. However, the numerical study of an one-dimensional (1D) infinite hydrogen chain using existing VQE algorithms shows a remarkable deviation of the ground state energy with respect to the exact full configuration interaction (FCI) result. Here, we present two schemes to improve the accuracy of quantum simulations for extended systems. The first one is a modified VQE algorithm, which introduces an unitary transformation of Hartree-Fock orbitals to avoid the complex Hamiltonian. The second one is a Post-VQE approach combining VQE with the quantum subspace expansion approach (VQE/QSE). Numerical benchmark calculations demonstrate that both of two schemes provide an accurate enough description of the potential energy curve of the 1D hydrogen chain. In addition, excited states computed with the VQE/QSE approach also agree very well with FCI results. ",https://doi.org/10.1021/acs.jctc.0c00881,2008.02946v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Balancing truncation and round-off errors in practical FEM:   one-dimensional analysis,1970,"  In finite element methods (FEMs), the accuracy of the solution cannot increase indefinitely because the round-off error increases when the number of degrees of freedom (DoFs) is large enough. This means that the accuracy that can be reached is limited. A priori information of the highest attainable accuracy is therefore of great interest. In this paper, we devise an innovative method to obtain the highest attainable accuracy. In this method, the truncation error is extrapolated when it converges at the analytical rate, for which only a few primary $h$-refinements are required, and the bound of the round-off error is provided through extensive numerical experiments. The highest attainable accuracy is obtained by minimizing the sum of these two types of errors. We validate this method using a one-dimensional Helmholtz equation in space. It shows that the highest attainable accuracy can be accurately predicted, and the CPU time required is much less compared with that using the successive $h$-refinement. ",Kein DOI-Link verfügbar,1912.08004v1,Yes,innovative(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,An efficient adaptive variational quantum solver of the Schrodinger   equation based on reduced density matrices,1970,"  Recently, an adaptive variational algorithm termed Adaptive Derivative-Assembled Pseudo-Trotter ansatz Variational Quantum Eigensolver (ADAPT-VQE) has been proposed by Grimsley et al. (Nat. Commun. 10, 3007) while the number of measurements required to perform this algorithm scales O(N^8). In this work, we present an efficient adaptive variational quantum solver of the Schrodinger equation based on ADAPT-VQE together with the reduced density matrix reconstruction approach, which reduces the number of measurements from O(N^8) to O(N^4). This new algorithm is quite suitable for quantum simulations of chemical systems on near-term noisy intermediate-scale hardware due to low circuit complexity and reduced measurement. Numerical benchmark calculations for small molecules demonstrate that this new algorithm provides an accurate description of the ground-state potential energy curves. In addition, we generalize this new algorithm for excited states with the variational quantum deflation approach and achieve the same accuracy as ground-state simulations. ",https://doi.org/10.1063/5.0054822,2012.07047v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,"Energy transfer, weak resonance, and Fermi's golden rule in Hamiltonian   nonlinear Klein-Gordon equations",1970,"  This paper focuses on a class of nonlinear Klein-Gordon equations in three dimensions, which are Hamiltonian perturbations of the linear Klein-Gordon equation with potential. The unperturbed dynamical system has a bound state with frequency $\omega$, a spatially localized and time periodic solution. In quantum mechanics, metastable states, which last longer than expected, have been observed. These metastable states are a consequence of the instability of the bound state under the nonlinear Fermi's Golden Rule.   In this study, we explore the underlying mathematical instability mechanism from the bound state to these metastable states. Besides, we derive the sharp energy transfer rate from discrete to continuum modes, when the discrete spectrum was not close to the continuous spectrum of the Sch\""ordinger operator $H= -\Delta + V + m^2$, i.e. weak resonance regime $ \sigma_c(\sqrt{H}) = [m, \infty)$, $0< 3\omega < m$. This extends the work of Soffer and Weinstein \cite{SW1999} for resonance regime $3\omega > m$ and confirms their conjecture in \cite{SW1999}. Our proof relies on a more refined version of normal form transformation of Bambusi and Cuccagna \cite{BC}, the generalized Fermi's Golden Rule, as well as certain weighted dispersive estimates. ",Kein DOI-Link verfügbar,2201.06490v2,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Energy transfer and radiation in Hamiltonian nonlinear Klein-Gordon   equations: general case,1970,"  In this paper, we consider Klein-Gordon equations with cubic nonlinearity in three spatial dimensions, which are Hamiltonian perturbations of the linear one with potential. It is assumed that the corresponding Klein-Gordon operator $B = \sqrt{-\Delta + V(x) + m^2} $ admits an arbitrary number of possibly degenerate eigenvalues in $(0, m)$, and hence the unperturbed linear equation has multiple time-periodic solutions known as bound states. In \cite{SW1999}, Soffer and Weinstein discovered a mechanism called Fermi's Golden Rule for this nonlinear system in the case of one simple but relatively large eigenvalue $\Omega\in (\frac{m}{3}, m)$, by which energy is transferred from discrete to continuum modes and the solution still decays in time. In particular, the exact energy transfer rate is given. In \cite{LLY22}, we solved the general one simple eigenvalue case. In this paper, we solve this problem in full generality: multiple and simple or degenerate eigenvalues in $(0, m)$. The proof is based on a kind of pseudo-one-dimensional cancellation structure in each eigenspace, a renormalized damping mechanism, and an enhanced damping effect. It also relies on a refined Birkhoff normal form transformation and an accurate generalized Fermi's Golden Rule over those of Bambusi--Cuccagna \cite{BC}. ",Kein DOI-Link verfügbar,2307.16191v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Quantum engineering for compactly localized states in disordered Lieb   lattices,1970,"  Blending ordering within an uncorrelated disorder potential in families of 3D Lieb lattices preserves the macroscopic degeneracy of compact localized states and yields unconventional combinations of localized and delocalized phases -- as shown in Phys.Rev.B 106, 214204 (2022). We proceed to reintroduce translation invariance in the system by further ordering the disorder, and discuss the spectral structure and eigenstates features of the resulting perturbed lattices. We restore order in steps by first (i) rendering the disorder binary -- i.e. yielding a randomized checkerboard potential, then (ii) reordering the randomized checkerboard into an ordered one, and at last (iii) realigning all the checkerboard values yielding a constant potential shift, but only on a sub-lattice. Along this path, we test the influence of additional random impurities on the order restoration. We find that in each of these steps, sub-families of states are projected upon the location of the degenerate compact states, while the complementary ones are localized in the perturbed sites with energy determined by the strength of checkerboard. This strategy, herewith implemented in the 3D Lieb, highlights order restoration as experimental pathway to engineer spectral and states features in disordered lattice structures in the pursuit of quantum storage and memory applications. ",Kein DOI-Link verfügbar,2309.04227v1,Yes,potent(3)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Comparison of quantum kinetic theory and time-dependent Dirac equation   approaches in vacuum pair production and the bound states resonance enhanced   mechanism,1970,"  A remarkable quantitative agreement is found between the non-Markovian quantum kinetic approach and the time-dependent Dirac equation approach for a large region of Keldysh parameter, in the investigation of electron-positron pair production in the electric fields which is spatially homogeneous and envelope pulse shaped. If a sub-critical bound potential is immersed in this background field, the TDDE results show that the creation probability will be enhanced by the bound states resonance by two orders of magnitude. We also establish a computing resources greatly saved TDDE formalism for spatially homogeneous field. ",Kein DOI-Link verfügbar,1708.08565v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Absorption of Carbon Dioxide in Kerogen Nanopores: A Mechanism Study   using the Molecular Dynamics Monte Carlo Method,1970,"  Carbon capture and storage (CCS) technology has been applied successfully in recent decades to reduce carbon emissions and alleviate global warming. In this regard, shale reservoirs present tremendous potential for carbon dioxide (CO2) sequestration as they have a large number of nanopores. Molecular dynamics (MD) and MD-Monte Carlo (MDMC) methods were employed in this work to study the absorption behavior of CO2 in shale organic porous media. The MDMC method is used to analyze the spatial states of CO2, and the results are in good agreement with MD results, and it also performs well in the acceleration compared to the classical MD. With regard to the kerogen matrix, its properties, such as the pore size distribution (PSD), pore volume, and surface area, are determined to describe its different compression states and the effects of CO2 absorption on it. The potential energy distribution and potential of mean force are analyzed to verify the spatial distribution of CO2 molecules. The heterogeneity of the pore structure resulted in heterogeneous distributions of CO2 molecules in kerogen porous media. Moreover, strong compression of the matrix reduces the number of large pores, and the PSD is mainly between 0 and 15 Angstrom. Despite the high interaction force of the kerogen matrix, the high-potential-energy region induced by the kerogen skeleton also contributes to the formation of low-energy regions that encourage the entry of CO2. An increase in temperature facilitates the absorption process, allowing CO2 molecules to enter the isolated pores with stronger thermal motion, thereby increasing the storage capacity for CO2. However, the development of geothermal energy may not be suitable for CO2 sequestration. ",Kein DOI-Link verfügbar,2308.05116v1,Yes,potent(4)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,The dynamical behavior of the Extended Holographic Dark Energy with   Hubble Horizon,1970,"  The extended holographic dark energy model with the Hubble horizon as the infrared cutoff avoids the problem of the circular reasoning of the holographic dark energy model. Unfortunately, it is hit with the no-go theorem. In this paper, we consider the extended holographic dark energy model with a potential, $V(\phi)$, for the Brans-Dicke scalar field. With the addition of a potential for the Brans-Dicke scalar field, the extended holographic dark energy model using the Hubble horizon as the infrared cutoff is a viable dark energy model, and the model has the dark energy dominated attractor solution. ",https://doi.org/10.1103/PhysRevD.81.083536,0912.0802v2,Yes,potent(2)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Pump Electron-Positron Pairs from Potential Well,1970,"  In this paper we show that electron-positron pairs can be pumped inexhaustibly with a constant production rate from the one dimensional potential well with oscillating depth or width. Bound states embedded in the the Dirac sea can be pulled out and pushed to the positive continuum, and become scattering states. Pauli block, which dominant the saturation of pair creation in the static super-critical potential well, can be broken by the ejection of electrons. We find that the width oscillating mode is more efficient that the depth oscillating mode. In the adiabatic limit, pair number as a function of upper boundary of the oscillating, will reveal the diving of the bound states. ",Kein DOI-Link verfügbar,1504.06405v2,Yes,potent(2)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Resonant tunneling of deuteron-triton fusion in strong high-frequency   electromagnetic fields,1970,"  We investigate deuteron-triton (DT) fusion in the presence of linearly polarized strong electromagnetic fields in high-frequency limit, in which a complex spherical square-well potential is exploited to describe the nuclear potential. Within the framework of the Kramers-Henneberger (KH) transformation, we have calculated the total and angular differential fusion cross sections by investigating the asymptotical phase shifts of the Coulomb wavefunctions. With introducing a dimensionless quantity of $n_d$ representing the ratio of the particle quiver oscillation amplitude to the radius of nuclear potential, we find that, even though the tunneling probability of passing through the Coulomb repulsive potential keeps almost identical to that in the absence of electromagnetic fields, the peak of total fusion sections shows an apparent shift from the well known value of 110 keV to 78 keV for $n_d=0.01$. The angular differential cross sections also show some resonance peaks that shift from zero inclination angle to $\pi/2$ with increasing the parameter $n_d$. The corresponding astrophysical $S$-factors are found to be enhanced by several times in amplitudes. With the help of Wentzel-Kramers-Brillouin (WKB) approximate wavefunctions, the shape-resonance tunneling mechanism of the above findings are uncovered and some implications are discussed. ",https://doi.org/10.1103/PhysRevC.105.064615,2112.12384v1,Yes,potent(4)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Cyclotron dynamics of a Bose-Einstein condensate in a quadruple-well   potential with synthetic gauge fields,1970,"  We investigate the cyclotron dynamics of Bose-Einstein condensate (BEC) in a quadruple-well potential with synthetic gauge fields. We use laser-assisted tunneling to generate large tunable effective magnetic fields for BEC. The mean position of BEC follows an orbit that simulated the cyclotron orbits of charged particles in a magnetic field. In the absence of atomic interaction, atom dynamics may exhibit periodic or quasi-periodic cyclotron orbits. In the presence of atomic interaction, the system may exhibit self-trapping, which depends on synthetic gauge fields and atomic interaction strength. In particular, the competition between synthetic gauge fields and atomic interaction leads to the generation of several discontinuous parameter windows for the transition to self-trapping, which is obviously different from that without synthetic gauge fields. ",https://doi.org/10.1007/s11467-021-1078-5,2105.09487v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,"Phase modulation of directed transport, energy diffusion and quantum   scrambling in a Floquet non-Hermitian system",1970,"  We investigate both theoretically and numerically the wavepacket's dynamics in momentum space for a Floquet non-Hermitian system with a periodically-kicked driven potential. We have deduced the exact expression of a time-evolving wavepacket under the condition of quantum resonance. With this analytical expression, we can investigate thoroughly the temporal behaviors of the directed transport, energy diffusion and quantum scrambling. We find interestingly that, by tuning the relative phase between the real part and imaginary part of the kicking potential, one can manipulate the directed propagation, energy diffusion and quantum scrambling efficiently: when the phase equals to $\pi/2$, we observe a maximum directed current and energy diffusion, while a minimum scrambling phenomenon protected by the $\mathcal{PT}$-symmetry; when the phase is $\pi$, both the directed transport and the energy diffusion are suppressed, in contrast, the quantum scrambling is enhanced by the non-Hermiticity. Possible applications of our findings are discussed. ",Kein DOI-Link verfügbar,2312.08082v1,Yes,potent(2)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Constant-roll inflation with non-minimally derivative coupling,1970,"  We investigate the constant-roll inflation with non-minimally kinetic coupling to the Einstein tensor. With the slow-roll parameter $\eta_\phi = -\ddot{\phi}/(H\dot{\phi})$ being a constant, we calculate the power spectra for scalar and tensor perturbations, and derive the expressions for the scalar spectral tilt $n_s$, the tensor spectral tilt $n_T$, and the tensor-to-scalar ratio $r$. We find that the expressions for $n_s$ are different with different ordering of taking the derivative of the scalar power spectrum with respect to the scale $k$ and the horizon crossing condition $c_sk=aH$ in the constant-roll inflation, the consistency relation $r=-8n_T$ does not hold if $|\eta_\phi|$ is not small, and the duality of the tensor-to-scalar ratio between the slow-roll inflation and ultra-slow-roll inflation does not exist in inflationary models with non-minimally derivative coupling. The result offers a fresh perspective on the understanding of the inflationary models with non-minimally derivative coupling and is helpful for the production of scalar induced gravitational waves in the framework of ultra-slow-roll inflation with non-minimally derivative coupling. ",https://doi.org/10.1088/1572-9494/ad51ef,2404.04978v2,Yes,fresh(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,3DMeshNet: A Three-Dimensional Differential Neural Network for   Structured Mesh Generation,1970,"  Mesh generation is a crucial step in numerical simulations, significantly impacting simulation accuracy and efficiency. However, generating meshes remains time-consuming and requires expensive computational resources. In this paper, we propose a novel method, 3DMeshNet, for three-dimensional structured mesh generation. The method embeds the meshing-related differential equations into the loss function of neural networks, formulating the meshing task as an unsupervised optimization problem. It takes geometric points as input to learn the potential mapping between parametric and computational domains. After suitable offline training, 3DMeshNet can efficiently output a three-dimensional structured mesh with a user-defined number of quadrilateral/hexahedral cells through the feed-forward neural prediction. To enhance training stability and accelerate convergence, we integrate loss function reweighting through weight adjustments and gradient projection alongside applying finite difference methods to streamline derivative computations in the loss. Experiments on different cases show that 3DMeshNet is robust and fast. It outperforms neural network-based methods and yields superior meshes compared to traditional mesh partitioning methods. 3DMeshNet significantly reduces training times by up to 85% compared to other neural network-based approaches and lowers meshing overhead by 4 to 8 times relative to traditional meshing methods. ",Kein DOI-Link verfügbar,2407.01560v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Simulation studies on compensation for space-charge-induced half-integer   and 3rd-order resonance crossing in HIAF-BRing,1970,  Space-charge-induced resonance crossing is one notable limitation of beam intensity in high-intensity synchrotrons. This paper proposes a modification to the Resonance Driving Terms (RDTs) to compensate for the combined effects of space charge and magnetic field imperfections under resonance crossing. The new RDTs are named modified RDTs. The effectiveness of the modified RDTs is demonstrated through simulations of half-integer and 3rd-order resonance crossings using the lattice of the High Intensity Heavy-Ion Accelerator Facility Booster Ring (HIAF-BRing). The simulations illustrate that the compensation provided by the modified RDTs significantly suppresses emittance growth and reduces distortion in the phase space. ,Kein DOI-Link verfügbar,2408.01954v2,Yes,notable(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Optical potential parameters of light nuclear fusion based on precise   Coulomb wave functions,1970,"  Based on precise Coulomb wave functions (CWFs), we attempt to calculate the fusion cross sections of light nuclei in a complex spherical square-well nuclear potential (i.e., optical potential model). Comparing with experimental benchmark cross section data, we can calibrate optical potential parameters associated with D+D, D+T, D+3He, p+D, p+6Li and p+7Li fusion reactions. Surprisingly, we find that our calculated optical potential parameters are quite different from those of many previous results (e.g., Phys. Rev. C. 61 (2000) 024610, Nucl. Phys. A 986 (2019) 98, etc.), in which approximate Coulomb wave functions (ACWFs) with only retaining the leading terms are exploited for the continuity conditions at the radius of nuclear potential. Furthermore, with the obtained optical potential parameters, we compare the fusion cross sections and astrophysical S-factors with that formulated from ACWFs approach, and also find apparent deviations especially for the fusion reactions with resonance peaks such as D+T and D+3He fusion reactions. We then calculate the phase diagrams of the fusion cross sections with respect to the optical potential parameters and demonstrate several narrow shape resonance belts. It implies that a small deviation of ACWFs from the exact CWFs at nuclear radius might lead to fall off the resonance regimes and therefore causes the big difference on the optical parameters as well as the cross sections. ",https://doi.org/10.1016/j.nuclphysa.2021.122340,2109.13699v1,Yes,potent(7)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Enhanced proton-boron nuclear fusion cross sections in intense   high-frequency laser,1970,"  We investigate the proton-boron nuclear fusion cross sections under the influence of the intense linearly polarized monochromatic laser fields with high frequency. First, we rewrite the time-dependent Schr\""{o}dinger equation using Kramers-Henneberger (KH) transformation which allows for shifting all time dependence of the problem into the potential function. Then, for the intense laser fields that satisfy the high frequency limit, the time-averaged scheme in the KH framework should be valid. We can use WKB approximation to evaluate Coulomb barrier penetrability and then calculate proton-boron nuclear fusion cross sections by a phenomenological Gamow form. We show that the corresponding Coulomb barrier penetrability increases significantly due to the depression of the time-averaged potential barrier. As a result, we find that proton-boron nuclear fusion cross sections can be enhanced effectively depending on a dimensionless quantity $n_{\mathrm{d}}$, which equals the ratio of the quiver oscillation amplitude to the geometrical touching radius of the proton and boron nucleus. For $n_{\mathrm{d}}=9$, we predict that the resonance peak of the fusion cross-section is enhanced by about $26$ times at the incident energy of $\varepsilon=148$ keV. And for another incident energy of $\varepsilon=586$ keV, the resonance peak of fusion cross-section is not only enhanced but also shifted to lower energy of $\varepsilon=392$ keV due to the mechanism of over-barrier fusion. ",https://doi.org/10.1016/j.nuclphysa.2022.122490,2204.08667v1,Yes,potent(2)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Deuterium-tritium fusion process in strong laser fields: Semiclassical   simulation,1970,"  In this paper, we investigate the deuterium-tritium (DT) fusion process in the presence of strong laser fields with a semiclassical (SC) method. In this model, two nuclei with a given incident kinetic energy that closely approach each other are simulated by tracing the classical Newtonian trajectories in the combined Coulomb repulsive potentials and laser fields. At the nearest position or classical turning point, quantum tunneling through the Coulomb barrier emerges, and its penetrability is estimated with the Wentzel-Kramers-Brillouin formula. Nuclear fusion occurs after the tunneling, and the total fusion cross section takes the Gamow form. We find that the tunneling penetrability can be enhanced dramatically because the nuclei can closely approach each other due to the quiver motion of the charged nuclei driven by the intense laser fields. We then calculate the DT fusion section for a wide range of laser parameters according to various incident nuclei kinetic energies and obtain the phase diagrams for the enhanced DT fusion. We compare our SC results with the quantum results of the Kramers-Henneberger approximation and the Volkov state approximation. ",https://doi.org/10.1103/PhysRevC.104.044614,2103.14391v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Walking-dilaton hybrid inflation with $B-L$ Higgs embedded in dynamical   scalegenesis,1970,"  We propose a hybrid inflationary scenario based on eight-flavor hidden QCD with the hidden colored fermions being in part gauged under $U(1)_{B-L}$. This hidden QCD is almost scale-invariant, so-called walking, and predicts the light scalar meson (the walking dilaton) associated with the spontaneous scale breaking, which develops the Coleman-Weinberg (CW) type potential as the consequence of the nonperturbative scale anomaly, hence plays the role of an inflaton of the small-field inflation. The $U(1)_{B-L}$ Higgs is coupled to the walking dilaton inflaton, which is dynamically induced from the so-called bosonic seesaw mechanism. We explore the hybrid inflation system involving the walking dilaton inflaton and the $U(1)_{B-L}$ Higgs as a waterfall field. We find that observed inflation parameters tightly constrain the $U(1)_{B-L}$ breaking scale as well as the walking dynamical scale to be $\sim 10^9$ GeV and $\sim 10^{14}$ GeV, respectively, so as to make the waterfall mechanism worked. The lightest walking pion mass is then predicted to be around 500 GeV. Phenomenological perspectives including embedding of the dynamical electroweak scalegenesis and possible impacts on the thermal leptogenesis are also addressed. ",Kein DOI-Link verfügbar,2407.17748v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,GEM: Context-Aware Gaze EstiMation with Visual Search Behavior Matching   for Chest Radiograph,1970,"  Gaze estimation is pivotal in human scene comprehension tasks, particularly in medical diagnostic analysis. Eye-tracking technology facilitates the recording of physicians' ocular movements during image interpretation, thereby elucidating their visual attention patterns and information-processing strategies. In this paper, we initially define the context-aware gaze estimation problem in medical radiology report settings. To understand the attention allocation and cognitive behavior of radiologists during the medical image interpretation process, we propose a context-aware Gaze EstiMation (GEM) network that utilizes eye gaze data collected from radiologists to simulate their visual search behavior patterns throughout the image interpretation process. It consists of a context-awareness module, visual behavior graph construction, and visual behavior matching. Within the context-awareness module, we achieve intricate multimodal registration by establishing connections between medical reports and images. Subsequently, for a more accurate simulation of genuine visual search behavior patterns, we introduce a visual behavior graph structure, capturing such behavior through high-order relationships (edges) between gaze points (nodes). To maintain the authenticity of visual behavior, we devise a visual behavior-matching approach, adjusting the high-order relationships between them by matching the graph constructed from real and estimated gaze points. Extensive experiments on four publicly available datasets demonstrate the superiority of GEM over existing methods and its strong generalizability, which also provides a new direction for the effective utilization of diverse modalities in medical image interpretation and enhances the interpretability of models in the field of medical imaging. https://github.com/Tiger-SN/GEM ",Kein DOI-Link verfügbar,2408.05502v1,Yes,"intricate(1), pivotal(1)"
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Periodic Modulation Effect on Self-Trapping of Two weakly coupled   Bose-Einstein Condensates,1970,"  With phase space analysis approach, we investigate thoroughly the self-trapping phenomenon for two weakly coupled Bose-Einstein condensates (BEC) in a symmetric double-well potential. We identify two kinds of self-trapping by their different relative phase behavior. With applying a periodic modulation on the energy bias of the system we find the occurrence of the self-trapping can be controlled, saying, the transition parameters can be adjusted effectively by the periodic modulation. Analytic expressions for the dependence of the transition parameters on the modulation parameters are derived for high and low frequency modulations. For an intermediate frequency modulation, we find the resonance between the periodic modulation and nonlinear Rabi oscillation dramatically affects the tunnelling dynamics and demonstrate many novel phenomena. Finally, we study the effects of many-body quantum fluctuation on self-trapping and discuss the possible experimental realization of the model. ",https://doi.org/10.1103/PhysRevA.73.013619,cond-mat/0509572v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Self-trapping of Bose-Einstein condensates in optical lattices,1970,"  The self-trapping phenomenon of Bose-Einstein condensates (BECs) in optical lattices is studied extensively by numerically solving the Gross-Pitaevskii equation. Our numerical results not only reproduce the phenomenon that was observed in a recent experiment [Anker {\it et al.}, Phys. Rev. Lett. {\bf 94} (2005)020403], but also find that the self-trapping breaks down at long evolution times, that is, the self-trapping in optical lattices is only temporary. The analysis of our numerical results shows that the self-trapping in optical lattices is related to the self-trapping of BECs in a double-well potential. A possible mechanism of the formation of steep edges in the wave packet evolution is explored in terms of the dynamics of relative phases between neighboring wells. ",https://doi.org/10.1103/PhysRevA.74.063610,cond-mat/0601249v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Classification of Dark Solitons via Topological Vector Potentials,1970,"  Dark soliton is one of most interesting nonlinear excitations in physical systems, manifesting a spatially localized density ""dip"" on a uniform background accompanied with a phase jump across the dip. However, the topological properties of the dark solitons are far from fully understood. Our investigation for the first time uncover a vector potential underlying the nonlinear excitation whose line integral gives the striking phase jump. More importantly, we find that the vector potential field has a topological configuration in analogous to the Wess-Zumino term in a Lagrangian representation. It can induce some point-like magnetic fields scattered periodically on a complex plane, each of them has a quantized magnetic flux of elementary $\pi$. We then calculate the Euler characteristic of the topological manifold of the vector potential field and classify all known dark solitions according to the index. ",https://doi.org/10.1103/PhysRevE.103.L040204,2006.10234v1,Yes,potent(3)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Coexistence of directed momentum current and ballistic energy diffusion   in coupled non-Hermitian kicked rotors,1970,"  We numerically investigate the quantum transport in a coupled kicked rotors with the $\mathcal{PT}$-symmetric potential. We find that the spontaneous $\mathcal{PT}$-symmetry breaking of wavefunctions emerges when the amplitude of the imaginary part of the complex potential is beyond a threshold value, which can be modulated by the coupling strength effectively. In the regime of the $\mathcal{PT}$-symmetry breaking, the particles driven by the periodical kicks move unidirectionally in momentum space, indicating the emergence of a directed current. Meanwhile, with increasing the coupling strength, we find a transition from the ballistic energy diffusion to a kind of the modified ballistic energy diffusion where the width of the wavepacket also increases with time in a power law. Our findings suggest that the decoherence effect induced by the interplay between the inter-particle coupling and the non-Hermitian driving potential is responsible for these particular transport behaviors. ",https://doi.org/10.1103/PhysRevA.107.032208,2211.00831v1,Yes,potent(3)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Cross-domain User Preference Learning for Cold-start Recommendation,1970,"  Cross-domain cold-start recommendation is an increasingly emerging issue for recommender systems. Existing works mainly focus on solving either cross-domain user recommendation or cold-start content recommendation. However, when a new domain evolves at its early stage, it has potential users similar to the source domain but with much fewer interactions. It is critical to learn a user's preference from the source domain and transfer it into the target domain, especially on the newly arriving contents with limited user feedback. To bridge this gap, we propose a self-trained Cross-dOmain User Preference LEarning (COUPLE) framework, targeting cold-start recommendation with various semantic tags, such as attributes of items or genres of videos. More specifically, we consider three levels of preferences, including user history, user content and user group to provide reliable recommendation. With user history represented by a domain-aware sequential model, a frequency encoder is applied to the underlying tags for user content preference learning. Then, a hierarchical memory tree with orthogonal node representation is proposed to further generalize user group preference across domains. The whole framework updates in a contrastive way with a First-In-First-Out (FIFO) queue to obtain more distinctive representations. Extensive experiments on two datasets demonstrate the efficiency of COUPLE in both user and content cold-start situations. By deploying an online A/B test for a week, we show that the Click-Through-Rate (CTR) of COUPLE is superior to other baselines used on Taobao APP. Now the method is serving online for the cross-domain cold micro-video recommendation. ",Kein DOI-Link verfügbar,2112.03667v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Deep Convolutional Neural Network-based Bernoulli Heatmap for Head Pose   Estimation,1970,"  Head pose estimation is a crucial problem for many tasks, such as driver attention, fatigue detection, and human behaviour analysis. It is well known that neural networks are better at handling classification problems than regression problems. It is an extremely nonlinear process to let the network output the angle value directly for optimization learning, and the weight constraint of the loss function will be relatively weak. This paper proposes a novel Bernoulli heatmap for head pose estimation from a single RGB image. Our method can achieve the positioning of the head area while estimating the angles of the head. The Bernoulli heatmap makes it possible to construct fully convolutional neural networks without fully connected layers and provides a new idea for the output form of head pose estimation. A deep convolutional neural network (CNN) structure with multiscale representations is adopted to maintain high-resolution information and low-resolution information in parallel. This kind of structure can maintain rich, high-resolution representations. In addition, channelwise fusion is adopted to make the fusion weights learnable instead of simple addition with equal weights. As a result, the estimation is spatially more precise and potentially more accurate. The effectiveness of the proposed method is empirically demonstrated by comparing it with other state-of-the-art methods on public datasets. ",Kein DOI-Link verfügbar,2005.11780v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Basic quantities of the Equation of State in isospin asymmetric nuclear   matter,1970,"  Based on the Hugenholtz-Van Hove theorem, six basic quantities of the EoS in isospin asymmetric nuclear matter are expressed in terms of the nucleon kinetic energy $t(k)$, the isospin symmetric and asymmetric parts of the single-nucleon potentials $U_0(\rho,k)$ and $U_{\text{\text{sym,i}}}(\rho,k)$. The six basic quantities include the quadratic symmetry energy $E_{\text{sym,2}}(\rho)$, the quartic symmetry energy $E_{\text{sym,4}}(\rho)$, their corresponding density slopes $L_2(\rho)$ and $L_4(\rho)$, and the incompressibility coefficients $K_2(\rho)$ and $K_4(\rho)$. By using four types of well-known effective nucleon-nucleon interaction models, namely the BGBD, MDI, Skyrme, and Gogny forces, the density- and isospin-dependent properties of these basic quantities are systematically calculated and their values at the saturation density $\rho_0$ are explicitly given. The contributions to these quantities from $t(k)$, $U_0(\rho,k)$, and $U_{\text{sym,i}}(\rho,k)$ are also analyzed at the normal nuclear density $\rho_0$. It is clearly shown that the first-order asymmetric term $U_{\text{sym,1}}(\rho,k)$ (also known as the symmetry potential in Lane potential) plays a vital role in determining the density dependence of the quadratic symmetry energy $E_{\text{sym,2}}(\rho)$. It is also shown that the contributions from high-order asymmetric parts of the single-nucleon potentials ($U_{\text{sym,i}}(\rho,k)$ with $i>1$) cannot be neglected in the calculations of the other five basic quantities. Moreover, by analyzing the properties of asymmetric nuclear matter at the exact saturation density $\rho_{\text{sat}}(\delta)$, the corresponding quadratic incompressibility coefficient is found to have a simple empirical relation $K_{\text{sat,2}}=K_{2}(\rho_0)-4.14 L_2(\rho_0)$. ",Kein DOI-Link verfügbar,2109.11141v1,Yes,potent(4)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,AI for Earth: Rainforest Conservation by Acoustic Surveillance,1970,"  Saving rainforests is a key to halting adverse climate changes. In this paper, we introduce an innovative solution built on acoustic surveillance and machine learning technologies to help rainforest conservation. In particular, We propose new convolutional neural network (CNN) models for environmental sound classification and achieved promising preliminary results on two datasets, including a public audio dataset and our real rainforest sound dataset. The proposed audio classification models can be easily extended in an automated machine learning paradigm and integrated in cloud-based services for real world deployment. ",Kein DOI-Link verfügbar,1908.07517v1,Yes,innovative(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Nonlinear Ramsey interferometry with the Rosen-Zener pulses on a   two-component Bose-Einstein condensate,1970,"  We propose a feasible scheme to realize nonlinear Ramsey interferometry with a two-component Bose-Einstein condensate, where the nonlinearity arises from the interaction between coherent atoms. In our scheme, two Rosen-Zener pulses are separated by an intermediate holding period of variable duration and through varying the holding period we have observed nice Ramsey interference patterns in time domain. In contrast to the standard Ramsey fringes our nonlinear Ramsey patterns display diversiform structures ascribed to the interplay of the nonlinearity and asymmetry. In particular, we find that the frequency of the nonlinear Ramsey fringes exactly reflects the strength of nonlinearity as well as the asymmetry of system. Our finding suggests a potential application of the nonlinear Ramsey interferometry in calibrating the atomic parameters such as scattering length and energy spectrum. ",https://doi.org/10.1103/PhysRevA.78.063621,0810.1593v2,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Flux-induced Topological Superconductor in Planar Josephson Junction,1970,"  A planar Josephson junction with a normal metal attached on its top surface will form a hollow nanowire structure due to its three dimensional nature. In such hollow nanowire structure, the magnetic flux induced by a small magnetic field (about 0.01T) will tune the system into topologically non-trivial phase and therefore two Majorana zero-modes will form at the ends of the nanowire. Through tuning the chemical potential of the normal metal, the topologically non-trivial phase can be obtained for almost all energy within the band. Furthermore, the system can be conveniently tuned between the topologically trivial and non-trivial phases via the phase difference between the superconductors. Such device, manipulable through flux, can be conveniently fabricated into desired 2D networks. Finally, we also propose a cross-shaped junction realizing the braiding of Majorana zero-modes through manipulating the phase differences. ",https://doi.org/10.1103/PhysRevB.100.235131,1906.11504v1,Yes,potent(1)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,Exploring accurate potential energy surfaces via integrating variational   quantum eigensovler with machine learning,1970,"  The potential energy surface (PES) is crucial for interpreting a variety of chemical reaction processes. However, predicting accurate PESs with high-level electronic structure methods is a challenging task due to the high computational cost. As an appealing application of quantum computing, we show in this work that variational quantum algorithms can be integrated with machine learning (ML) techniques as a promising scheme for exploring accurate PESs. Different from using a ML model to represent the potential energy, we encode the molecular geometry information into a deep neural network (DNN) for representing parameters of the variational quantum eigensolver (VQE), leaving the PES to the wave function ansatz. Once the DNN model is trained, the variational optimization procedure that hinders the application of the VQE to complex systems is avoided and thus the evaluation of PESs is significantly accelerated. Numerical results demonstrate that a simple DNN model is able to reproduce accurate PESs for small molecules. ",Kein DOI-Link verfügbar,2206.03637v1,Yes,potent(2)
0000-0001-6820-3048,Jie Liu,Christian-Albrechts-Universität zu Kiel,An Ant-Based Algorithm with Local Optimization for Community Detection   in Large-Scale Networks,1970,"  In this paper, we propose a multi-layer ant-based algorithm MABA, which detects communities from networks by means of locally optimizing modularity using individual ants. The basic version of MABA, namely SABA, combines a self-avoiding label propagation technique with a simulated annealing strategy for ant diffusion in networks. Once the communities are found by SABA, this method can be reapplied to a higher level network where each obtained community is regarded as a new vertex. The aforementioned process is repeated iteratively, and this corresponds to MABA. Thanks to the intrinsic multi-level nature of our algorithm, it possesses the potential ability to unfold multi-scale hierarchical structures. Furthermore, MABA has the ability that mitigates the resolution limit of modularity. The proposed MABA has been evaluated on both computer-generated benchmarks and widely used real-world networks, and has been compared with a set of competitive algorithms. Experimental results demonstrate that MABA is both effective and efficient (in near linear time with respect to the size of network) for discovering communities. ",https://doi.org/10.1142/S0219525912500361,1303.4711v1,Yes,potent(1)
0000-0001-6904-1909,Torsten Fritz,Friedrich-Schiller-Universität Jena,Lifshitz Transition and Band Structure Evolution in Alkali Metal   Intercalated 1Tprime-MoTe2,1970,"  MoTe2 is a paradigmatic van der Waals layered semimetal with two energetically close electronic phases, the topologically trivial 1Tprime and the low-temperature Td type-II Weyl semimetal phase. The ability to manipulate this phase transition, perhaps towards occurring near room temperature, would open new avenues for harnessing the full potential of Weyl semimetals for high-efficiency electronic and spintronic applications. Here, we show that potassium dosing on 1Tprime-MoTe2 induces a Lifshitz transition by a combination of angle-resolved photoemission spectroscopy, scanning tunneling microscopy, x-ray spectroscopy and density functional theory. While the electronic structure shifts rigidly for small concentrations of K, MoTe2 undergoes significant band structure renormalization for larger concentrations. Our results demonstrate that the origin of this electronic structure change stems from alkali metal intercalation. We show that these profound changes are caused by effectively decoupling the 2D sheets, bringing K-intercalated 1Tprime-MoTe2 to the quasi-2D limit, but do not cause a topological phase transition. ",Kein DOI-Link verfügbar,2312.15360v2,Yes,potent(1)
0000-0001-6904-1909,Torsten Fritz,Friedrich-Schiller-Universität Jena,Frontier Orbital Degeneracy: A new Concept for Tailoring the Magnetic   State in Organic Semiconductor Adsorbates,1970,"  Kondo resonances in molecular adsorbates are an important building block for applications in the field of molecular spintronics. Here, we introduce the novel concept of using frontier orbital degeneracy for tailoring the magnetic state, which is demonstrated for the case of the organic semiconductor 1,4,5,8,9,11-Hexaazatriphenylenehexacarbonitrile (HATCN, C18N12) on Ag(111). Low-temperature scanning tunneling microscopy/spectroscopy (LT-STM/STS) measurements reveal the existence of two types of adsorbed HATCN molecules with distinctly different appearances and magnetic states, as evident from the presence or absence of an Abrikosov-Suhl-Kondo resonance. Our DFT results show that HATCN on Ag(111) supports two almost isoenergetic states, both with one excess electron transferred from the Ag surface, but with magnetic moments of either 0 or 0.65 uB. Therefore, even though all molecules undergo charge transfer of one electron from the Ag substrate, they exist in two different molecular magnetic states that resemble a free doublet or an entangled spin state. We explain how the origin of this behavior lies in the twofold degeneracy of the lowest unoccupied molecular orbitals of gas phase HATCN, lifted upon adsorption and charge-transfer from Ag(111). Our combined STM and DFT study introduces a new pathway to tailoring the magnetic state of molecular adsorbates on surfaces, with significant potential for spintronics and quantum information science. ",Kein DOI-Link verfügbar,2212.06943v2,Yes,potent(1)
0000-0001-6908-452X,Sebastian Schuhmacher,Albert-Ludwigs-Universität Freiburg,Integrating out heavy fields in the path integral using the   background-field method: general formalism,1970,"  Building on an older method used to derive non-decoupling effects of a heavy Higgs boson in the Standard Model, we describe a general procedure to integrate out heavy fields in the path integral. The derivation of the corresponding effective Lagrangian including the one-loop contributions of the heavy particle(s) is particularly transparent, flexible, and algorithmic. The background-field formalism allows for a clear separation of tree-level and one-loop effects involving the heavy fields. Using expansion by regions the one-loop effects are further split into contributions from large and small momentum modes. The former are contained in Wilson coefficients of effective operators, the latter are reproduced by one-loop diagrams involving effective tree-level couplings. The method is illustrated by calculating potential non-decoupling effects of a heavy Higgs boson in a singlet Higgs extension of the Standard Model. In particular, we work in a field basis corresponding to mass eigenstates and properly take into account non-vanishing mixing between the two Higgs fields of the model. We also show that a proper choice of renormalization scheme for the non-standard sector of the underlying full theory is crucial for the construction of a consistent effective field theory. ",https://doi.org/10.1140/epjc/s10052-021-09587-7,2102.12020v2,Yes,potent(1)
0000-0001-6928-7335,Kevin Gomez,Universität Leipzig,CHIME: Energy-Efficient STT-RAM-based Concurrent Hierarchical In-Memory   Processing,1970,"  Processing-in-cache (PiC) and Processing-in-memory (PiM) architectures, especially those utilizing bit-line computing, offer promising solutions to mitigate data movement bottlenecks within the memory hierarchy. While previous studies have explored the integration of compute units within individual memory levels, the complexity and potential overheads associated with these designs have often limited their capabilities. This paper introduces a novel PiC/PiM architecture, Concurrent Hierarchical In-Memory Processing (CHIME), which strategically incorporates heterogeneous compute units across multiple levels of the memory hierarchy. This design targets the efficient execution of diverse, domain-specific workloads by placing computations closest to the data where it optimizes performance, energy consumption, data movement costs, and area. CHIME employs STT-RAM due to its various advantages in PiC/PiM computing, such as high density, low leakage, and better resiliency to data corruption from activating multiple word lines. We demonstrate that CHIME enhances concurrency and improves compute unit utilization at each level of the memory hierarchy. We present strategies for exploring the design space, grouping, and placing the compute units across the memory hierarchy. Experiments reveal that, compared to the state-of-the-art bit-line computing approaches, CHIME achieves significant speedup and energy savings of 57.95% and 78.23% for various domain-specific workloads, while reducing the overheads associated with single-level compute designs. ",Kein DOI-Link verfügbar,2407.19627v1,Yes,"potent(1), strategically(1)"
0000-0001-6944-1988,Vinit Hegiste,Technische Universität Kaiserslautern,Federated Object Detection for Quality Inspection in Shared Production,1970,"  Federated learning (FL) has emerged as a promising approach for training machine learning models on decentralized data without compromising data privacy. In this paper, we propose a FL algorithm for object detection in quality inspection tasks using YOLOv5 as the object detection algorithm and Federated Averaging (FedAvg) as the FL algorithm. We apply this approach to a manufacturing use-case where multiple factories/clients contribute data for training a global object detection model while preserving data privacy on a non-IID dataset. Our experiments demonstrate that our FL approach achieves better generalization performance on the overall clients' test dataset and generates improved bounding boxes around the objects compared to models trained using local clients' datasets. This work showcases the potential of FL for quality inspection tasks in the manufacturing industry and provides valuable insights into the performance and feasibility of utilizing YOLOv5 and FedAvg for federated object detection. ",Kein DOI-Link verfügbar,2306.17645v2,Yes,potent(1)
0000-0001-6944-1988,Vinit Hegiste,Technische Universität Kaiserslautern,Towards Robust Federated Image Classification: An Empirical Study of   Weight Selection Strategies in Manufacturing,1970,"  In the realm of Federated Learning (FL), particularly within the manufacturing sector, the strategy for selecting client weights for server aggregation is pivotal for model performance. This study investigates the comparative effectiveness of two weight selection strategies: Final Epoch Weight Selection (FEWS) and Optimal Epoch Weight Selection (OEWS). Designed for manufacturing contexts where collaboration typically involves a limited number of partners (two to four clients), our research focuses on federated image classification tasks. We employ various neural network architectures, including EfficientNet, ResNet, and VGG, to assess the impact of these weight selection strategies on model convergence and robustness. Our research aims to determine whether FEWS or OEWS enhances the global FL model's performance across communication rounds (CRs). Through empirical analysis and rigorous experimentation, we seek to provide valuable insights for optimizing FL implementations in manufacturing, ensuring that collaborative efforts yield the most effective and reliable models with a limited number of participating clients. The findings from this study are expected to refine FL practices significantly in manufacturing, thereby enhancing the efficiency and performance of collaborative machine learning endeavors in this vital sector. ",Kein DOI-Link verfügbar,2408.10024v2,Yes,pivotal(1)
0000-0001-6944-1988,Vinit Hegiste,Technische Universität Kaiserslautern,Seamless Integration: Sampling Strategies in Federated Learning Systems,1970,"  Federated Learning (FL) represents a paradigm shift in the field of machine learning, offering an approach for a decentralized training of models across a multitude of devices while maintaining the privacy of local data. However, the dynamic nature of FL systems, characterized by the ongoing incorporation of new clients with potentially diverse data distributions and computational capabilities, poses a significant challenge to the stability and efficiency of these distributed learning networks. The seamless integration of new clients is imperative to sustain and enhance the performance and robustness of FL systems. This paper looks into the complexities of integrating new clients into existing FL systems and explores how data heterogeneity and varying data distribution (not independent and identically distributed) among them can affect model training, system efficiency, scalability and stability. Despite these challenges, the integration of new clients into FL systems presents opportunities to enhance data diversity, improve learning performance, and leverage distributed computational power. In contrast to other fields of application such as the distributed optimization of word predictions on Gboard (where federated learning once originated), there are usually only a few clients in the production environment, which is why information from each new client becomes all the more valuable. This paper outlines strategies for effective client selection strategies and solutions for ensuring system scalability and stability. Using the example of images from optical quality inspection, it offers insights into practical approaches. In conclusion, this paper proposes that addressing the challenges presented by new client integration is crucial to the advancement and efficiency of distributed learning networks, thus paving the way for the adoption of Federated Learning in production environments. ",Kein DOI-Link verfügbar,2408.09545v2,Yes,potent(1)
0000-0001-6944-1988,Vinit Hegiste,Technische Universität Kaiserslautern,Enhancing Object Detection with Hybrid dataset in Manufacturing   Environments: Comparing Federated Learning to Conventional Techniques,1970,"  Federated Learning (FL) has garnered significant attention in manufacturing for its robust model development and privacy-preserving capabilities. This paper contributes to research focused on the robustness of FL models in object detection, hereby presenting a comparative study with conventional techniques using a hybrid dataset for small object detection. Our findings demonstrate the superior performance of FL over centralized training models and different deep learning techniques when tested on test data recorded in a different environment with a variety of object viewpoints, lighting conditions, cluttered backgrounds, etc. These results highlight the potential of FL in achieving robust global models that perform efficiently even in unseen environments. The study provides valuable insights for deploying resilient object detection models in manufacturing environments. ",Kein DOI-Link verfügbar,2408.08974v1,Yes,potent(1)
0000-0001-6999-3862,Andreas Walther,Goethe Universität Frankfurt,Experimental superradiance and slow light effects for quantum memories,1970,"  The effects of high optical depth phenomena, such as superradiance, are investigated in potential quantum memory materials. The results may have relevance for several schemes, including CRIB, AFC and EIT-based quantum memories, which are based on using ensembles as storage media. It is shown that strong superradiant effects, manifested as decay rates larger than 1/T2*, are present even for moderate values of alphaL < 5, and increases as a function of alphaL. For even higher alphaL, effects like off-resonant slow light is demonstrated and discussed, and finally, the efficiency of time-reversed optimized input pulses are tested. A maximum retrieval efficiency of ~20% is reached, and agreement with the theoretically expected result is discussed. ",Kein DOI-Link verfügbar,0904.4621v1,Yes,potent(1)
0000-0001-6999-3862,Andreas Walther,Goethe Universität Frankfurt,Fast all-optical nuclear spin echo technique based on EIT,1970,"  We demonstrate an all-optical Raman spin echo technique, using Electromagnetically Induced Transparency (EIT) to create the different pulses of the spin echo sequence: initialization, pi-rotation, and readout. The first pulse of the sequence induces coherence directly from a mixed state, and the technique is used to measure the nuclear spin coherence of an inhomogeneously broadened ensemble of rare-earth ions (Pr$^{3+}$). In contrast to previous experiments it does not require any preparatory hole burning pulse sequences, which greatly shortens the total duration of the sequence. The effect of the different pulses is characterized by quantum state tomography and is compared with simulations. We demonstrate two applications of the technique by using the spin echo sequence to accurately compensate a magnetic field across our sample, and to measure the coherence time at high temperatures up to 11 K, where standard preparation techniques are difficult to implement. We explore the potential of the technique and possible applications. ",https://doi.org/10.1140/epjd/e2016-60716-6,1512.06015v1,Yes,potent(1)
0000-0001-6999-3862,Andreas Walther,Goethe Universität Frankfurt,High connectivity quantum processor nodes using single-ion-qubits in   rare-earth-ion-doped crystals,1970,"  We present two protocols for constructing quantum processor nodes in randomly doped rare-earth-ion crystals and analyze their properties. By varying the doping concentration and the accessible laser tunability, the processor nodes can contain anywhere from only a few tens to almost $1000$ qubits. Furthermore, the average number of qubits each qubit can interact with, denoted by the connectivity, can be partly tailored to lie between just a few and roughly one hundred. We also study how a limited tunability of the laser affects the results, and conclude that a tuning range of $100$ GHz limits the results to roughly $100$ qubits with around $50$ connections per qubit on average. In order to construct an even larger processor, the vision is that several of these quantum processor nodes should be connected to each other in a multi-node architecture via, e.g., optical interfaces or flying qubits in the form of light. Our results are encouraging for establishing the rare-earth-ion-based systems as a quantum computing platform with strong potential and can serve to focus the efforts within the field. ",https://doi.org/10.1103/PhysRevA.105.032603,2111.09016v1,Yes,potent(1)
0000-0001-6999-3862,Andreas Walther,Goethe Universität Frankfurt,Experimental implementation of precisely tailored light-matter   interaction via inverse engineering,1970,"  Accurate and efficient quantum control in the presence of constraints and decoherence is a requirement and a challenge in quantum information processing. Shortcuts to adiabaticity, originally proposed to speed up slow adiabatic process, have nowadays become versatile toolboxes for preparing states or controlling the quantum dynamics. Unique shortcut designs are required for each quantum system with intrinsic physical constraints, imperfections, and noises. Here, we implement fast and robust control for the state preparation and state engineering in a rare-earth ions system. Specifically, the interacting pulses are inversely engineered and further optimized with respect to inhomogeneities of the ensemble and the unwanted interaction with other qubits. We demonstrate that our protocols surpass the conventional adiabatic schemes, by reducing the decoherence from the excited state decay and inhomogeneous broadening. The results presented here are applicable to other noisy intermediate scale quantum systems. ",https://doi.org/10.1038/s41534-021-00473-4,2101.12461v3,Yes,versatile(1)
0000-0001-6999-3862,Andreas Walther,Goethe Universität Frankfurt,Roadmap for Rare-earth Quantum Computing,1970,"  Several platforms are being considered as hardware for quantum technologies. For quantum computing (QC), superconducting qubits and artificially trapped ions are among the leading platforms, but many others also show promise, e.g. photons, cold atoms, defect centers including Rare-Earth (RE) ions. So far, results are limited to the regime of noisy intermediate scale qubits (NISQ), with a small number of qubits and a limited connectivity, and it is likely that future QC hardware will utilize several existing platforms in different ways. Thus, it currently makes sense to invest resources broadly and explore the full range of promising routes to quantum technology. Rare-earth ions in solids constitute one of the most versatile platforms for future quantum technology. One advantage is good coherence properties even when confined in strong natural traps inside a solid-state matrix. This confinement allows very high qubit densities and correspondingly strong ion-ion couplings. In addition, although their fluorescence is generally weak, cavity integration can enhance the emission greatly and enable very good connections to photonic circuits, including at the telecom wavelengths, making them promising systems for long-term scalability. The primary aim of this roadmap is to provide a complete picture of what components a RE quantum computer would consist of, to describe the details of all parts required to achieve a scalable system, and to discuss the most promising paths to reach it. In brief, we find that clusters of 50-100 single RE ions can act as high fidelity qubits in small processors, occupying only about (10 nm)^3. Due to the high capacity for integration of the RE systems, they be optically read out and connected to other such clusters for larger scalability. We make suggestions for future improvements, which could allow the REQC platform to be a leading one. ",Kein DOI-Link verfügbar,2103.15743v1,Yes,versatile(1)
0000-0001-6999-3862,Andreas Walther,Goethe Universität Frankfurt,Demonstration of atomic frequency comb memory for light with spin-wave   storage,1970,"  We present a light-storage experiment in a praseodymium-doped crystal where the light is mapped onto an inhomogeneously broadened optical transition shaped into an atomic frequency comb. After absorption of the light the optical excitation is converted into a spin-wave excitation by a control pulse. A second control pulse reads the memory (on-demand) by reconverting the spin-wave excitation to an optical one, where the comb structure causes a photon-echo type rephasing of the dipole moments and directional retrieval of the light. This combination of photon echo and spin-wave storage allows us to store sub-microsecond (450ns) pulses for up to 20 microseconds. The scheme has a high potential for storing multiple temporal modes in the single photon regime, which is an important resource for future long-distance quantum communication based on quantum repeaters. ",https://doi.org/10.1103/PhysRevLett.104.040503,0908.2309v2,Yes,potent(1)
0000-0001-7051-8030,Richard Blender,Universität Hamburg,Madden-Julian Oscillation described as a Nonlinear Burgers Kink in the   Meridional Vorticity Equation,1970,"  A dynamic equation for a large scale convective event in the tropical atmosphere similar to the Madden--Julian Oscillation (MJO) is suggested based on the meridional vorticity equation with buoyancy parametrized by Convective Available Potential Energy (CAPE). The propagation is determined by the nonlinear Burgers equation with a stationary solution describing a kink moving towards the moisture source. In this conceptual model, the propagation speed depends on the asymmetry in the zonal surface winds which is observed in the boundary layer in the vicinity of an MJO event and attributed to Rossby and Kelvin waves. Furthermore, the model predicts convection at the equator in the east of the MJO which is not correlated with Kelvin and Rossby waves. ",Kein DOI-Link verfügbar,2304.07020v1,Yes,potent(1)
0000-0001-7051-8030,Richard Blender,Universität Hamburg,Fluctuation Analysis of the Atmospheric Energy Cycle,1970,"  The atmosphere gains available potential energy by solar radiation and dissipates kinetic energy mainly in the atmospheric boundary layer. We analyze the fluctuations of the global mean energy cycle defined by Lorenz (1955) in a simulation with a simplified hydrostatic model. The energy current densities are well approximated by the generalized Gumbel distribution (Bramwell, Holdsworth and Pinton, 1998) and the Generalized Extreme Value (GEV) distribution. In an attempt to assess the fluctuation relation of Evans, Cohen, and Morriss (1993) we define entropy production by the injected power and use the GEV location parameter as a reference state. The fluctuation ratio reveals a linear behavior in a finite range. ",https://doi.org/10.1103/PhysRevE.98.023101,1802.07565v1,Yes,potent(1)
0000-0001-7051-8030,Richard Blender,Universität Hamburg,Nambu representation of an extended Lorenz model with viscous heating,1970,"  We consider the Nambu and Hamiltonian representations of Rayleigh-Benard convection with a nonlinear thermal heating effect proportional to the Eckert number (Ec). The model we use is an extension of the classical Lorenz-63 model with 4 kinematic and 6 thermal degrees of freedom. The conservative parts of the dynamical equations which include all nonlinearities satisfy Liouville's theorem and permit a conserved Hamiltonian H for arbitrary Ec. For Ec=0 two independent conserved Casimir functions exist, one of these is associated with unavailable potential energy and is also present in the Lorenz-63 truncation. This Casimir C is used to construct a Nambu representation of the conserved part of the dynamical system. The thermal heating effect can be represented either by a second canonical Hamiltonian or as a gradient (metric) system using the time derivative of the Casimir. The results demonstrate the impact of viscous heating in the total energy budget and in the Lorenz energy cycle for kinetic and available potential energy. ",https://doi.org/10.1016/j.physd.2012.09.007,1202.2210v1,Yes,potent(2)
0000-0001-7051-8030,Richard Blender,Universität Hamburg,Construction of Hamiltonian and Nambu forms for the shallow water   equations,1970,"  A systematic method to derive the Hamiltonian and Nambu form for the shallow water equations, using the conservation for energy and potential enstrophy, is presented. Different mechanisms, such as vortical flows and emission of gravity waves, emerge from different conservation laws (CLs) for total energy and potential enstrophy. The equations are constructed using exterior differential forms and self-adjoint operators and result in the sum of two Nambu brackets, one for the vortical flow and one for the wave-mean flow interaction, and a Poisson bracket representing the interaction between divergence and geostrophic imbalance. The advantage of this approach is that the Hamiltonian and Nambu forms can be here written in a coordinate independent form. ",Kein DOI-Link verfügbar,1606.03355v4,Yes,potent(2)
0000-0001-7051-8030,Richard Blender,Universität Hamburg,Mathematical and Physical Ideas for Climate Science,1970,"  The climate is a forced and dissipative nonlinear system featuring non-trivial dynamics of a vast range of spatial and temporal scales. The understanding of the climate's structural and multiscale properties is crucial for the provision of a unifying picture of its dynamics and for the implementation of accurate and efficient numerical models. We present some recent developments at the intersection between climate science, mathematics, and physics, which may prove fruitful in the direction of constructing a more comprehensive account of climate dynamics. We describe the Nambu formulation of fluid dynamics, and the potential of such a theory for constructing sophisticated numerical models of geophysical fluids. Then, we focus on the statistical mechanics of quasi-equilibrium flows in a rotating environment, which seems crucial for constructing a robust theory of geophysical turbulence. We then discuss ideas and methods suited for approaching directly the non-equilibrium nature of the climate system. First, we describe some recent findings on the thermodynamics of climate and characterize its energy and entropy budgets, and discuss related methods for intercomparing climate models and for studying tipping points. These ideas can also create a common ground between geophysics and astrophysics by suggesting general tools for studying exoplanetary atmospheres. We conclude by focusing on non-equilibrium statistical mechanics, which allows for a unified framing of problems as different as the climate response to forcings, the effect of altering the boundary conditions or the coupling between geophysical flows, and the derivation of parametrizations for numerical models. ",https://doi.org/10.1002/2013RG000446,1311.1190v3,Yes,potent(1)
0000-0001-7123-8567,Ming Cheng,Universität Bayreuth,"Multi-Input Multi-Output Target-Speaker Voice Activity Detection For   Unified, Flexible, and Robust Audio-Visual Speaker Diarization",1970,"  Audio-visual learning has demonstrated promising results in many classical speech tasks (e.g., speech separation, automatic speech recognition, wake-word spotting). We believe that introducing visual modality will also benefit speaker diarization. To date, Target-Speaker Voice Activity Detection (TS-VAD) plays an important role in highly accurate speaker diarization. However, previous TS-VAD models take audio features and utilize the speaker's acoustic footprint to distinguish his or her personal speech activities, which is easily affected by overlapped speech in multi-speaker scenarios. Although visual information naturally tolerates overlapped speech, it suffers from spatial occlusion, low resolution, etc. The potential modality-missing problem blocks TS-VAD towards an audio-visual approach.   This paper proposes a novel Multi-Input Multi-Output Target-Speaker Voice Activity Detection (MIMO-TSVAD) framework for speaker diarization. The proposed method can take audio-visual input and leverage the speaker's acoustic footprint or lip track to flexibly conduct audio-based, video-based, and audio-visual speaker diarization in a unified sequence-to-sequence framework. Experimental results show that the MIMO-TSVAD framework demonstrates state-of-the-art performance on the VoxConverse, DIHARD-III, and MISP 2022 datasets under corresponding evaluation metrics, obtaining the Diarization Error Rates (DERs) of 4.18%, 10.10%, and 8.15%, respectively. In addition, it can perform robustly in heavy lip-missing scenarios. ",Kein DOI-Link verfügbar,2401.08052v2,Yes,potent(1)
0000-0001-7123-8567,Ming Cheng,Universität Bayreuth,SAIC: Integration of Speech Anonymization and Identity Classification,1970,"  Speech anonymization and de-identification have garnered significant attention recently, especially in the healthcare area including telehealth consultations, patient voiceprint matching, and patient real-time monitoring. Speaker identity classification tasks, which involve recognizing specific speakers from audio to learn identity features, are crucial for de-identification. Since rare studies have effectively combined speech anonymization with identity classification, we propose SAIC - an innovative pipeline for integrating Speech Anonymization and Identity Classification. SAIC demonstrates remarkable performance and reaches state-of-the-art in the speaker identity classification task on the Voxceleb1 dataset, with a top-1 accuracy of 96.1%. Although SAIC is not trained or evaluated specifically on clinical data, the result strongly proves the model's effectiveness and the possibility to generalize into the healthcare area, providing insightful guidance for future work. ",Kein DOI-Link verfügbar,2312.15190v1,Yes,innovative(1)
0000-0001-7123-8567,Ming Cheng,Universität Bayreuth,VoxBlink: A Large Scale Speaker Verification Dataset on Camera,1970,"  In this paper, we introduce a large-scale and high-quality audio-visual speaker verification dataset, named VoxBlink. We propose an innovative and robust automatic audio-visual data mining pipeline to curate this dataset, which contains 1.45M utterances from 38K speakers. Due to the inherent nature of automated data collection, introducing noisy data is inevitable. Therefore, we also utilize a multi-modal purification step to generate a cleaner version of the VoxBlink, named VoxBlink-clean, comprising 18K identities and 1.02M utterances. In contrast to the VoxCeleb, the VoxBlink sources from short videos of ordinary users, and the covered scenarios can better align with real-life situations. To our best knowledge, the VoxBlink dataset is one of the largest publicly available speaker verification datasets. Leveraging the VoxCeleb and VoxBlink-clean datasets together, we employ diverse speaker verification models with multiple architectural backbones to conduct comprehensive evaluations on the VoxCeleb test sets. Experimental results indicate a substantial enhancement in performance,ranging from 12% to 30% relatively, across various backbone architectures upon incorporating the VoxBlink-clean into the training process. The details of the dataset can be found on http://voxblink.github.io ",Kein DOI-Link verfügbar,2308.07056v7,Yes,innovative(1)
0000-0001-7123-8567,Ming Cheng,Universität Bayreuth,CrossGP: Cross-Day Glucose Prediction Excluding Physiological   Information,1970,"  The increasing number of diabetic patients is a serious issue in society today, which has significant negative impacts on people's health and the country's financial expenditures. Because diabetes may develop into potential serious complications, early glucose prediction for diabetic patients is necessary for timely medical treatment. Existing glucose prediction methods typically utilize patients' private data (e.g. age, gender, ethnicity) and physiological parameters (e.g. blood pressure, heart rate) as reference features for glucose prediction, which inevitably leads to privacy protection concerns. Moreover, these models generally focus on either long-term (monthly-based) or short-term (minute-based) predictions. Long-term prediction methods are generally inaccurate because of the external uncertainties that can greatly affect the glucose values, while short-term ones fail to provide timely medical guidance. Based on the above issues, we propose CrossGP, a novel machine-learning framework for cross-day glucose prediction solely based on the patient's external activities without involving any physiological parameters. Meanwhile, we implement three baseline models for comparison. Extensive experiments on Anderson's dataset strongly demonstrate the superior performance of CrossGP and prove its potential for future real-life applications. ",Kein DOI-Link verfügbar,2404.10901v1,Yes,potent(2)
0000-0001-7123-8567,Ming Cheng,Universität Bayreuth,A material decomposition method for dual-energy CT via dual interactive   Wasserstein generative adversarial networks,1970,"  Dual-energy computed tomography has great potential in material characterization and identification, whereas the reconstructed material-specific images always suffer from magnified noise and beam hardening artifacts. In this study, a data-driven approach using dual interactive Wasserstein generative adversarial networks is proposed to improve the material decomposition accuracy. Specifically, two interactive generators are used to synthesize the corresponding material images and different loss functions for training the decomposition model are incorporated to preserve texture and edges in the generated images. Besides, a selector is employed to ensure the modelling ability of two generators. The results from both the simulation phantoms and real data demonstrate the advantages of this method in suppressing the noise and beam hardening artifacts. ",https://doi.org/10.1002/mp.14828,2007.11247v1,Yes,potent(1)
0000-0001-7123-8567,Ming Cheng,Universität Bayreuth,VeTraSS: Vehicle Trajectory Similarity Search Through Graph Modeling and   Representation Learning,1970,"  Trajectory similarity search plays an essential role in autonomous driving, as it enables vehicles to analyze the information and characteristics of different trajectories to make informed decisions and navigate safely in dynamic environments. Existing work on the trajectory similarity search task primarily utilizes sequence-processing algorithms or Recurrent Neural Networks (RNNs), which suffer from the inevitable issues of complicated architecture and heavy training costs. Considering the intricate connections between trajectories, using Graph Neural Networks (GNNs) for data modeling is feasible. However, most methods directly use existing mathematical graph structures as the input instead of constructing specific graphs from certain vehicle trajectory data. This ignores such data's unique and dynamic characteristics. To bridge such a research gap, we propose VeTraSS -- an end-to-end pipeline for Vehicle Trajectory Similarity Search. Specifically, VeTraSS models the original trajectory data into multi-scale graphs, and generates comprehensive embeddings through a novel multi-layer attention-based GNN. The learned embeddings can be used for searching similar vehicle trajectories. Extensive experiments on the Porto and Geolife datasets demonstrate the effectiveness of VeTraSS, where our model outperforms existing work and reaches the state-of-the-art. This demonstrates the potential of VeTraSS for trajectory analysis and safe navigation in self-driving vehicles in the real world. ",Kein DOI-Link verfügbar,2404.08021v1,Yes,"intricate(1), potent(1)"
0000-0001-7123-8567,Ming Cheng,Universität Bayreuth,Efflex: Efficient and Flexible Pipeline for Spatio-Temporal Trajectory   Graph Modeling and Representation Learning,1970,"  In the landscape of spatio-temporal data analytics, effective trajectory representation learning is paramount. To bridge the gap of learning accurate representations with efficient and flexible mechanisms, we introduce Efflex, a comprehensive pipeline for transformative graph modeling and representation learning of the large-volume spatio-temporal trajectories. Efflex pioneers the incorporation of a multi-scale k-nearest neighbors (KNN) algorithm with feature fusion for graph construction, marking a leap in dimensionality reduction techniques by preserving essential data features. Moreover, the groundbreaking graph construction mechanism and the high-performance lightweight GCN increase embedding extraction speed by up to 36 times faster. We further offer Efflex in two versions, Efflex-L for scenarios demanding high accuracy, and Efflex-B for environments requiring swift data processing. Comprehensive experimentation with the Porto and Geolife datasets validates our approach, positioning Efflex as the state-of-the-art in the domain. Such enhancements in speed and accuracy highlight the versatility of Efflex, underscoring its wide-ranging potential for deployment in time-sensitive and computationally constrained applications. ",Kein DOI-Link verfügbar,2404.12400v1,Yes,potent(1)
0000-0001-7123-8567,Ming Cheng,Universität Bayreuth,A Dual Camera System for High Spatiotemporal Resolution Video   Acquisition,1970,"  This paper presents a dual camera system for high spatiotemporal resolution (HSTR) video acquisition, where one camera shoots a video with high spatial resolution and low frame rate (HSR-LFR) and another one captures a low spatial resolution and high frame rate (LSR-HFR) video. Our main goal is to combine videos from LSR-HFR and HSR-LFR cameras to create an HSTR video. We propose an end-to-end learning framework, AWnet, mainly consisting of a FlowNet and a FusionNet that learn an adaptive weighting function in pixel domain to combine inputs in a frame recurrent fashion. To improve the reconstruction quality for cameras used in reality, we also introduce noise regularization under the same framework. Our method has demonstrated noticeable performance gains in terms of both objective PSNR measurement in simulation with different publicly available video and light-field datasets and subjective evaluation with real data captured by dual iPhone 7 and Grasshopper3 cameras. Ablation studies are further conducted to investigate and explore various aspects (such as reference structure, camera parallax, exposure time, etc) of our system to fully understand its capability for potential applications. ",Kein DOI-Link verfügbar,1909.13051v2,Yes,potent(1)
0000-0001-7123-8567,Ming Cheng,Universität Bayreuth,"H2-Stereo: High-Speed, High-Resolution Stereoscopic Video System",1970,"  High-speed, high-resolution stereoscopic (H2-Stereo) video allows us to perceive dynamic 3D content at fine granularity. The acquisition of H2-Stereo video, however, remains challenging with commodity cameras. Existing spatial super-resolution or temporal frame interpolation methods provide compromised solutions that lack temporal or spatial details, respectively. To alleviate this problem, we propose a dual camera system, in which one camera captures high-spatial-resolution low-frame-rate (HSR-LFR) videos with rich spatial details, and the other captures low-spatial-resolution high-frame-rate (LSR-HFR) videos with smooth temporal details. We then devise a Learned Information Fusion network (LIFnet) that exploits the cross-camera redundancies to enhance both camera views to high spatiotemporal resolution (HSTR) for reconstructing the H2-Stereo video effectively. We utilize a disparity network to transfer spatiotemporal information across views even in large disparity scenes, based on which, we propose disparity-guided flow-based warping for LSR-HFR view and complementary warping for HSR-LFR view. A multi-scale fusion method in feature domain is proposed to minimize occlusion-induced warping ghosts and holes in HSR-LFR view. The LIFnet is trained in an end-to-end manner using our collected high-quality Stereo Video dataset from YouTube. Extensive experiments demonstrate that our model outperforms existing state-of-the-art methods for both views on synthetic data and camera-captured real data with large disparity. Ablation studies explore various aspects, including spatiotemporal resolution, camera baseline, camera desynchronization, long/short exposures and applications, of our system to fully understand its capability for potential applications. ",Kein DOI-Link verfügbar,2208.02436v1,Yes,potent(1)
0000-0001-7133-046X,Hartmut Kaiser,Christian-Albrechts-Universität zu Kiel,Redesigning OP2 Compiler to Use HPX Runtime Asynchronous Techniques,1970,"  Maximizing parallelism level in applications can be achieved by minimizing overheads due to load imbalances and waiting time due to memory latencies. Compiler optimization is one of the most effective solutions to tackle this problem. The compiler is able to detect the data dependencies in an application and is able to analyze the specific sections of code for parallelization potential. However, all of these techniques provided with a compiler are usually applied at compile time, so they rely on static analysis, which is insufficient for achieving maximum parallelism and producing desired application scalability. One solution to address this challenge is the use of runtime methods. This strategy can be implemented by delaying certain amount of code analysis to be done at runtime. In this research, we improve the parallel application performance generated by the OP2 compiler by leveraging HPX, a C++ runtime system, to provide runtime optimizations. These optimizations include asynchronous tasking, loop interleaving, dynamic chunk sizing, and data prefetching. The results of the research were evaluated using an Airfoil application which showed a 40-50% improvement in parallel performance. ",Kein DOI-Link verfügbar,1703.09264v1,Yes,potent(1)
0000-0001-7133-046X,Hartmut Kaiser,Christian-Albrechts-Universität zu Kiel,Towards a Scalable and Distributed Infrastructure for Deep Learning   Applications,1970,"  Although recent scaling up approaches to training deep neural networks have proven to be effective, the computational intensity of large and complex models, as well as the availability of large-scale datasets, require deep learning frameworks to utilize scaling out techniques. Parallelization approaches and distribution requirements are not considered in the preliminary designs of most available distributed deep learning frameworks, and most of them still are not able to perform effective and efficient fine-grained inter-node communication. We present Phylanx that has the potential to alleviate these shortcomings. Phylanx offers a productivity-oriented frontend where user Python code is translated to a futurized execution tree that can be executed efficiently on multiple nodes using the C++ standard library for parallelism and concurrency (HPX), leveraging fine-grained threading and an active messaging task-based runtime system. ",https://doi.org/10.1109/DLS51937.2020.00008,2010.03012v2,Yes,potent(1)
0000-0001-7133-046X,Hartmut Kaiser,Christian-Albrechts-Universität zu Kiel,Quantifying Overheads in Charm++ and HPX using Task Bench,1970,"  Asynchronous Many-Task (AMT) runtime systems take advantage of multi-core architectures with light-weight threads, asynchronous executions, and smart scheduling. In this paper, we present the comparison of the AMT systems Charm++ and HPX with the main stream MPI, OpenMP, and MPI+OpenMP libraries using the Task Bench benchmarks. Charm++ is a parallel programming language based on C++, supporting stackless tasks as well as light-weight threads asynchronously along with an adaptive runtime system. HPX is a C++ library for concurrency and parallelism, exposing C++ standards conforming API. First, we analyze the commonalities, differences, and advantageous scenarios of Charm++ and HPX in detail. Further, to investigate the potential overheads introduced by the tasking systems of Charm++ and HPX, we utilize an existing parameterized benchmark, Task Bench, wherein 15 different programming systems were implemented, e.g., MPI, OpenMP, MPI + OpenMP, and extend Task Bench by adding HPX implementations. We quantify the overheads of Charm++, HPX, and the main stream libraries in different scenarios where a single task and multi-task are assigned to each core, respectively. We also investigate each system's scalability and the ability to hide the communication latency. ",https://doi.org/10.1007/978-3-031-31209-0_1,2207.12127v1,Yes,potent(1)
0000-0001-7242-5719,Michael Hansen,Johannes Gutenberg-Universität Mainz,Energy harvesting via co-locating horizontal- and vertical-axis wind   turbines,1970,"  Co-locating horizontal- and vertical-axis wind turbines has been recently proposed as a possible approach to enhance the land-area power density of wind farms. In this work, we aim to study the benefits associated with such a co-location using large-eddy simulation (LES) and analytical wake models. In this regard, small-scale vertical-axis wind turbines (VAWTs) in triangular clusters are deployed within a finite-size wind farm consisting of horizontal-axis wind turbines (HAWTs). Wake flow within the wind farm and the effect of VAWTs on the overall wind-farm efficiency are investigated and quantified. The results show that the optimal deployment of small-scale VAWTs has a negligible impact on the performance of HAWT arrays while increasing the total power production. For the particular cases considered here, the power output of the co-located wind farm increases up to 21% compared to the baseline case in which only the HAWTs are present. Also, by comparing to the LES results, it is shown that the analytical framework proposed here is able to accurately predict the power production of wind farms including both HAWTs and VAWTs. Next, as a real-world application, potential benefits of deploying small-scale VAWTs inside the Horns Rev 1 wind farm are explored for various wind directions using the calibrated wake model. The results show potential for about an 18% increase in the wind-farm power production, averaged over all wind directions, for a particular VAWT layout investigated in this study. The levelized cost of energy (LCoE) for the co-located wind farm is also assessed. The simulations finds that meanwhile the installation of VAWTs increases the annual energy production of the wind farm, it also increases the LCoE, which is caused by a) lack of operational data, and b) a low technology readiness level for VAWTs and floating foundations. ",https://doi.org/10.1088/1742-6596/1618/3/032004,2002.10447v2,Yes,potent(2)
0000-0001-7305-3793,Shuo Chen,Ludwig-Maximilians-Universität München,Social Networks are Divulging Your Identity behind Crypto Addresses,1970,"  Cryptocurrencies, such as Bitcoin and Ethereum, are becoming increasingly prevalent mainly due to their anonymity, decentralization, transparency, and security. However, the completely public ledger makes the trace and analysis of each account possible as long as the identity behind the public address is revealed. Theoretically, social networks could make that happen when addresses are posted on social network platforms using accounts containing personal information. To verify such a possibility, we have collected public data from two major platforms, i.e. Twitter and Reddit, aiming to find potential privacy leakage behind the ETH public address. In the end, an easy-to-use retrieval application is also built for a better illustration. ",Kein DOI-Link verfügbar,2211.09656v1,Yes,potent(1)
0000-0001-7305-3793,Shuo Chen,Ludwig-Maximilians-Universität München,Covariance Matrix Estimation for High-Throughput Biomedical Data with   Interconnected Communities,1970,"  Estimating a covariance matrix is central to high-dimensional data analysis. Empirical analyses of high-dimensional biomedical data, including genomics, proteomics, microbiome, and neuroimaging, among others, consistently reveal strong modularity in the dependence patterns. In these analyses, intercorrelated high-dimensional biomedical features often form communities or modules that can be interconnected with others. While the interconnected community structure has been extensively studied in biomedical research (e.g., gene co-expression networks), its potential to assist in the estimation of covariance matrices remains largely unexplored. To address this gap, we propose a procedure that leverages the commonly observed interconnected community structure in high-dimensional biomedical data to estimate large covariance and precision matrices. We derive the uniformly minimum variance unbiased estimators for covariance and precision matrices in closed forms and provide theoretical results on their asymptotic properties. Our proposed method enhances the accuracy of covariance- and precision-matrix estimation and demonstrates superior performance compared to the competing methods in both simulations and real data analyses. ",Kein DOI-Link verfügbar,2302.01861v2,Yes,potent(1)
0000-0001-7305-3793,Shuo Chen,Ludwig-Maximilians-Universität München,Minimizing Age of Information for Mobile Edge Computing Systems: A   Nested Index Approach,1970,"  Exploiting the computational heterogeneity of mobile devices and edge nodes, mobile edge computation (MEC) provides an efficient approach to achieving real-time applications that are sensitive to information freshness, by offloading tasks from mobile devices to edge nodes. We use the metric Age-of-Information (AoI) to evaluate information freshness. An efficient solution to minimize the AoI for the MEC system with multiple users is non-trivial to obtain due to the random computing time. In this paper, we consider multiple users offloading tasks to heterogeneous edge servers in a MEC system. We first reformulate the problem as a Restless Multi-Arm-Bandit (RMAB) problem and establish a hierarchical Markov Decision Process (MDP) to characterize the updating of AoI for the MEC system. Based on the hierarchical MDP, we propose a nested index framework and design a nested index policy with provably asymptotic optimality. Finally, the closed form of the nested index is obtained, which enables the performance tradeoffs between computation complexity and accuracy. Our algorithm leads to an optimality gap reduction of up to 40%, compared to benchmarks. Our algorithm asymptotically approximates the lower bound as the system scalar gets large enough. ",Kein DOI-Link verfügbar,2307.01366v1,Yes,fresh(2)
0000-0001-7305-3793,Shuo Chen,Ludwig-Maximilians-Universität München,Criticality-Guided Efficient Pruning in Spiking Neural Networks Inspired   by Critical Brain Hypothesis,1970,"  Spiking Neural Networks (SNNs) have gained considerable attention due to the energy-efficient and multiplication-free characteristics. The continuous growth in scale of deep SNNs poses challenges for model deployment. Network pruning reduces hardware resource requirements of model deployment by compressing the network scale. However, existing SNN pruning methods cause high pruning costs and performance loss because the pruning iterations amplify the training difficulty of SNNs. In this paper, inspired by the critical brain hypothesis in neuroscience, we propose a regeneration mechanism based on the neuron criticality for SNN pruning to enhance feature extraction and accelerate the pruning process. Firstly, we propose a low-cost metric for the criticality in SNNs. Then, we re-rank the pruned structures after pruning and regenerate those with higher criticality to obtain the critical network. Our method achieves higher performance than the current state-of-the-art (SOTA) method with up to 95.26% reduction of pruning cost. Moreover, we investigate the underlying mechanism of our method and find that it efficiently selects potential structures and learns the consistent feature representation. ",Kein DOI-Link verfügbar,2311.16141v2,Yes,potent(1)
0000-0001-7305-637X,Florian Wendler,Technische Universität Berlin,Carrier multiplication in graphene under Landau quantization,1970,"  Carrier multiplication is a many-particle process giving rise to the generation of multiple electron-hole pairs. This process holds the potential to increase the power conversion efficiency of photovoltaic devices. In graphene, carrier multiplication has been theoretically predicted and recently experimentally observed. However, due to the absence of a bandgap and competing phonon-induced electron-hole recombination, the extraction of charge carriers remains a substantial challenge. Here we present a new strategy to benefit from the gained charge carriers by introducing a Landau quantization that offers a tunable bandgap. Based on microscopic calculations within the framework of the density matrix formalism, we report a significant carrier multiplication in graphene under Landau quantization. Our calculations reveal a high tunability of the effect via externally accessible pump fluence, temperature, and the strength of the magnetic field. ",https://doi.org/10.1038/ncomms4703,1410.6670v1,Yes,potent(1)
0000-0001-7305-637X,Florian Wendler,Technische Universität Berlin,Dark excitons in transition metal dichalcogenides,1970,"  Monolayer transition metal dichalcogenides (TMDs) exhibit a remarkably strong Coulomb interaction that manifests in tightly bound excitons. Due to the complex electronic band structure exhibiting several spin-split valleys in the conduction and valence band, dark excitonic states can be formed. They are inaccessibly by light due to the required spin-flip and/or momentum transfer. The relative position of these dark states with respect to the optically accessible bright excitons has a crucial impact on the emission efficiency of these materials and thus on their technological potential. Based on the solution of the Wannier equation, we present the excitonic landscape of the most studied TMD materials including the spectral position of momentum- and spin-forbidden excitonic states. We show that the knowledge of the electronic dispersion does not allow to conclude about the nature of the material's band gap, since excitonic effects can give rise to significant changes. Furthermore, we reveal that an exponentially reduced photoluminescence yield does not necessarily reflect a transition from a direct to a non-direct gap material, but can be ascribed in most cases to a change of the relative spectral distance between bright and dark excitonic states. ",https://doi.org/10.1103/PhysRevMaterials.2.014002,1709.00941v1,Yes,potent(1)
0000-0001-7484-2049,Simone Paolo Ponzetto,"Universität Mannheim, Universität Mannheim",Fair and Argumentative Language Modeling for Computational Argumentation,1970,"  Although much work in NLP has focused on measuring and mitigating stereotypical bias in semantic spaces, research addressing bias in computational argumentation is still in its infancy. In this paper, we address this research gap and conduct a thorough investigation of bias in argumentative language models. To this end, we introduce ABBA, a novel resource for bias measurement specifically tailored to argumentation. We employ our resource to assess the effect of argumentative fine-tuning and debiasing on the intrinsic bias found in transformer-based language models using a lightweight adapter-based approach that is more sustainable and parameter-efficient than full fine-tuning. Finally, we analyze the potential impact of language model debiasing on the performance in argument quality prediction, a downstream task of computational argumentation. Our results show that we are able to successfully and sustainably remove bias in general and argumentative language models while preserving (and sometimes improving) model performance in downstream tasks. We make all experimental code and data available at https://github.com/umanlp/FairArgumentativeLM. ",Kein DOI-Link verfügbar,2204.04026v1,Yes,potent(1)
0000-0001-7484-2049,Simone Paolo Ponzetto,"Universität Mannheim, Universität Mannheim",X-SCITLDR: Cross-Lingual Extreme Summarization of Scholarly Documents,1970,"  The number of scientific publications nowadays is rapidly increasing, causing information overload for researchers and making it hard for scholars to keep up to date with current trends and lines of work. Consequently, recent work on applying text mining technologies for scholarly publications has investigated the application of automatic text summarization technologies, including extreme summarization, for this domain. However, previous work has concentrated only on monolingual settings, primarily in English. In this paper, we fill this research gap and present an abstractive cross-lingual summarization dataset for four different languages in the scholarly domain, which enables us to train and evaluate models that process English papers and generate summaries in German, Italian, Chinese and Japanese. We present our new X-SCITLDR dataset for multilingual summarization and thoroughly benchmark different models based on a state-of-the-art multilingual pre-trained model, including a two-stage `summarize and translate' approach and a direct cross-lingual model. We additionally explore the benefits of intermediate-stage training using English monolingual summarization and machine translation as intermediate tasks and analyze performance in zero- and few-shot scenarios. ",https://doi.org/10.1145/3529372.3530938,2205.15051v1,Yes,scholarly(2)
0000-0001-7484-2049,Simone Paolo Ponzetto,"Universität Mannheim, Universität Mannheim",ACLSum: A New Dataset for Aspect-based Summarization of Scientific   Publications,1970,"  Extensive efforts in the past have been directed toward the development of summarization datasets. However, a predominant number of these resources have been (semi)-automatically generated, typically through web data crawling, resulting in subpar resources for training and evaluating summarization systems, a quality compromise that is arguably due to the substantial costs associated with generating ground-truth summaries, particularly for diverse languages and specialized domains. To address this issue, we present ACLSum, a novel summarization dataset carefully crafted and evaluated by domain experts. In contrast to previous datasets, ACLSum facilitates multi-aspect summarization of scientific papers, covering challenges, approaches, and outcomes in depth. Through extensive experiments, we evaluate the quality of our resource and the performance of models based on pretrained language models and state-of-the-art large language models (LLMs). Additionally, we explore the effectiveness of extractive versus abstractive summarization within the scholarly domain on the basis of automatically discovered aspects. Our results corroborate previous findings in the general domain and indicate the general superiority of end-to-end aspect-based summarization. Our data is released at https://github.com/sobamchan/aclsum. ",Kein DOI-Link verfügbar,2403.05303v1,Yes,scholarly(1)
0000-0001-7484-2049,Simone Paolo Ponzetto,"Universität Mannheim, Universität Mannheim",Overview of the SV-Ident 2022 Shared Task on Survey Variable   Identification in Social Science Publications,1970,"  In this paper, we provide an overview of the SV-Ident shared task as part of the 3rd Workshop on Scholarly Document Processing (SDP) at COLING 2022. In the shared task, participants were provided with a sentence and a vocabulary of variables, and asked to identify which variables, if any, are mentioned in individual sentences from scholarly documents in full text. Two teams made a total of 9 submissions to the shared task leaderboard. While none of the teams improve on the baseline systems, we still draw insights from their submissions. Furthermore, we provide a detailed evaluation. Data and baselines for our shared task are freely available at https://github.com/vadis-project/sv-ident ",Kein DOI-Link verfügbar,2209.09062v1,Yes,scholarly(2)
0000-0001-7526-0665,David Green,Friedrich-Schiller-Universität Jena,The Maintenance of Sex: Ronald Fisher meets the Red Queen,1970,"  Sex in higher diploids carries a two-fold cost of males that should reduce its fitness relative to cloning and result in its extinction. Instead, sex is widespread and it is clonal species that face early obsolescence. One possible reason is that sex is an adaptation to resist ubiquitous parasites, which evolve rapidly and potentially antagonistically. We use a heuristic approach to model mutation-selection in finite populations where a parasitic haploid mounts a negative frequency-dependent attack on a diploid host. The host evolves reflexively to reduce parasitic load. Both host and parasite populations generate novel alleles by mutation and have access to large allele spaces. Sex outcompetes cloning by two overlapping mechanisms. First, sexual diploids adopt advantageous homozygous mutations more rapidly than clonal diploids under conditions of lag load. This rate advantage can offset the lesser fecundity of sex. Second, a relative advantage to sex emerges under host mutation rates that are fast enough to retain fitness in a rapidly mutating parasite environment and increase host polymorphism. Clonal polymorphic populations disproportionately experience interference with selection at high mutation rates, both between and within loci. This slows clonal population adaptation to a changing parasite environment and reduces clonal population fitness relative to sex. The interference increases markedly with the number of loci under independent selection. Rates of parasite mutation exist that not only allow sex to survive despite the two-fold cost of males but which enable sexual and clonal populations to have equal fitness and co-exist. Since all higher organisms carry parasitic loads, the model is of general applicability. ",Kein DOI-Link verfügbar,1304.2823v2,Yes,potent(1)
0000-0001-7637-0700,Timo Osterburg,TU Dortmund Universität,Energy-based Potential Games for Joint Motion Forecasting and Control,1970,"  This work uses game theory as a mathematical framework to address interaction modeling in multi-agent motion forecasting and control. Despite its interpretability, applying game theory to real-world robotics, like automated driving, faces challenges such as unknown game parameters. To tackle these, we establish a connection between differential games, optimal control, and energy-based models, demonstrating how existing approaches can be unified under our proposed Energy-based Potential Game formulation. Building upon this, we introduce a new end-to-end learning application that combines neural networks for game-parameter inference with a differentiable game-theoretic optimization layer, acting as an inductive bias. The analysis provides empirical evidence that the game-theoretic layer adds interpretability and improves the predictive performance of various neural network backbones using two simulations and two real-world driving datasets. ",Kein DOI-Link verfügbar,2312.01811v1,Yes,potent(1)
0000-0001-7693-318X,Sebastian Braun,Leipzig Universität,CMMD: Contrastive Multi-Modal Diffusion for Video-Audio Conditional   Modeling,1970,"  We introduce a multi-modal diffusion model tailored for the bi-directional conditional generation of video and audio. Recognizing the importance of accurate alignment between video and audio events in multi-modal generation tasks, we propose a joint contrastive training loss to enhance the synchronization between visual and auditory occurrences. Our research methodology involves conducting comprehensive experiments on multiple datasets to thoroughly evaluate the efficacy of our proposed model. The assessment of generation quality and alignment performance is carried out from various angles, encompassing both objective and subjective metrics. Our findings demonstrate that the proposed model outperforms the baseline, substantiating its effectiveness and efficiency. Notably, the incorporation of the contrastive loss results in improvements in audio-visual alignment, particularly in the high-correlation video-to-audio generation task. These results indicate the potential of our proposed model as a robust solution for improving the quality and alignment of multi-modal generation, thereby contributing to the advancement of video and audio conditional generation systems. ",Kein DOI-Link verfügbar,2312.05412v1,Yes,potent(1)
0000-0001-7693-318X,Sebastian Braun,Leipzig Universität,Gaussian Flow Bridges for Audio Domain Transfer with Unpaired Data,1970,"  Audio domain transfer is the process of modifying audio signals to match characteristics of a different domain, while retaining the original content. This paper investigates the potential of Gaussian Flow Bridges, an emerging approach in generative modeling, for this problem. The presented framework addresses the transport problem across different distributions of audio signals through the implementation of a series of two deterministic probability flows. The proposed framework facilitates manipulation of the target distribution properties through a continuous control variable, which defines a certain aspect of the target domain. Notably, this approach does not rely on paired examples for training. To address identified challenges on maintaining the speech content consistent, we recommend a training strategy that incorporates chunk-based minibatch Optimal Transport couplings of data samples and noise. Comparing our unsupervised method with established baselines, we find competitive performance in tasks of reverberation and distortion manipulation. Despite encoutering limitations, the intriguing results obtained in this study underscore potential for further exploration. ",Kein DOI-Link verfügbar,2405.19497v1,Yes,potent(2)
0000-0001-7703-1655,Andreas Fischer,Technische Universität Dresden,DLL: A Blazing Fast Deep Neural Network Library,1970,"  Deep Learning Library (DLL) is a new library for machine learning with deep neural networks that focuses on speed. It supports feed-forward neural networks such as fully-connected Artificial Neural Networks (ANNs) and Convolutional Neural Networks (CNNs). It also has very comprehensive support for Restricted Boltzmann Machines (RBMs) and Convolutional RBMs. Our main motivation for this work was to propose and evaluate novel software engineering strategies with potential to accelerate runtime for training and inference. Such strategies are mostly independent of the underlying deep learning algorithms. On three different datasets and for four different neural network models, we compared DLL to five popular deep learning frameworks. Experimentally, it is shown that the proposed framework is systematically and significantly faster on CPU and GPU. In terms of classification performance, similar accuracies as the other frameworks are reported. ",Kein DOI-Link verfügbar,1804.04512v1,Yes,potent(1)
0000-0001-7703-1655,Andreas Fischer,Technische Universität Dresden,From scalar to polar active matter: Connecting simulations with   mean-field theory,1970,"  We study numerically the phase behavior of self-propelled elliptical particles interacting through the ""hard"" repulsive Gay-Berne potential at infinite P\'eclet number. Changing a single parameter, the aspect ratio, allows to continuously go from discoid active Brownian particles to elongated polar rods. Discoids show phase separation, which changes to a cluster state of polar domains, which then form polar bands as the aspect ratio is increased. From the simulations, we identify and extract the two effective parameters entering the mean-field description: the force imbalance coefficient and the effective coupling to the local polarization. These two coefficients are sufficient to obtain a complete and consistent picture, unifying the paradigms of scalar and polar active matter. ",https://doi.org/10.1103/PhysRevE.101.022602,1910.06547v1,Yes,potent(1)
0000-0001-7703-1655,Andreas Fischer,Technische Universität Dresden,Influence of barrier form on Fowler-Nordheim plot analysis,1970,"  Recent research has described an improved method of Fowler-Nordheim plot analysis, based on the definition and evaluation of a slope correction factor and a new form of intercept correction factor. In this improved approach there exists a basic approximation that neglects certain terms in the general theory, and focuses on the influence of the form of the tunneling barrier on the values of basic slope ({\sigma}B) and intercept ({\rho}B) correction factors. Simple formulae exist that allow these to be evaluated numerically for a barrier of arbitrary well-behaved form. This paper makes an initial exploration of the effects of barrier form on FN plot analysis. For a planar emitter, two models for the correlation-and-exchange (C and E) potential energy (PE) are used. For the Schottky-Nordheim barrier, it is shown that numerical and analytical approaches generate equivalent results. This agreement supports the validity of the numerical methods used. Comparisons with results for the Cutler-Gibbons barrier show that small differences in the assumed C and E PE make little difference to values of {\sigma}B and {\rho}B. Schottky's planar image PE has then been used, in conjunction with the electrostatic PE variation associated with a spherical emitter model, to explore the influence of apex radius r_a on correction-factor values, for values of r_a greater than 20 nm. Both {\sigma}B and {\rho}B increase significantly as r_a decreases, especially {\rho}B. At low values of barrier field F, {\sigma}B depends approximately linearly on 1/F, with a slope that depends on r_a. Suggestions are made for how the exploratory work described in this paper might be extended. ",https://doi.org/10.1116/1.4795822,1210.5768v1,Yes,potent(1)
0000-0001-7703-1655,Andreas Fischer,Technische Universität Dresden,Graph-Based Offline Signature Verification,1970,"  Graphs provide a powerful representation formalism that offers great promise to benefit tasks like handwritten signature verification. While most state-of-the-art approaches to signature verification rely on fixed-size representations, graphs are flexible in size and allow modeling local features as well as the global structure of the handwriting. In this article, we present two recent graph-based approaches to offline signature verification: keypoint graphs with approximated graph edit distance and inkball models. We provide a comprehensive description of the methods, propose improvements both in terms of computational time and accuracy, and report experimental results for four benchmark datasets. The proposed methods achieve top results for several benchmarks, highlighting the potential of graph-based signature verification. ",Kein DOI-Link verfügbar,1906.10401v1,Yes,potent(1)
0000-0001-7703-1655,Andreas Fischer,Technische Universität Dresden,Impact of Ground Truth Quality on Handwriting Recognition,1970,"  Handwriting recognition is a key technology for accessing the content of old manuscripts, helping to preserve cultural heritage. Deep learning shows an impressive performance in solving this task. However, to achieve its full potential, it requires a large amount of labeled data, which is difficult to obtain for ancient languages and scripts. Often, a trade-off has to be made between ground truth quantity and quality, as is the case for the recently introduced Bullinger database. It contains an impressive amount of over a hundred thousand labeled text line images of mostly premodern German and Latin texts that were obtained by automatically aligning existing page-level transcriptions with text line images. However, the alignment process introduces systematic errors, such as wrongly hyphenated words. In this paper, we investigate the impact of such errors on training and evaluation and suggest means to detect and correct typical alignment errors. ",https://doi.org/10.1145/3628797.3628976,2312.09037v1,Yes,potent(1)
0000-0001-7703-1655,Andreas Fischer,Technische Universität Dresden,Character Queries: A Transformer-based Approach to On-Line Handwritten   Character Segmentation,1970,"  On-line handwritten character segmentation is often associated with handwriting recognition and even though recognition models include mechanisms to locate relevant positions during the recognition process, it is typically insufficient to produce a precise segmentation. Decoupling the segmentation from the recognition unlocks the potential to further utilize the result of the recognition. We specifically focus on the scenario where the transcription is known beforehand, in which case the character segmentation becomes an assignment problem between sampling points of the stylus trajectory and characters in the text. Inspired by the $k$-means clustering algorithm, we view it from the perspective of cluster assignment and present a Transformer-based architecture where each cluster is formed based on a learned character query in the Transformer decoder block. In order to assess the quality of our approach, we create character segmentation ground truths for two popular on-line handwriting datasets, IAM-OnDB and HANDS-VNOnDB, and evaluate multiple methods on them, demonstrating that our approach achieves the overall best results. ",https://doi.org/10.1007/978-3-031-41676-7_6,2309.03072v1,Yes,potent(1)
0000-0001-7703-1655,Andreas Fischer,Technische Universität Dresden,Molecular wave-packet dynamics on laser-controlled transition states,1970,"  Understanding and controlling the electronic as well as ro-vibrational motion and, thus, the entire chemical dynamics in molecules is the ultimate goal of ultrafast laser and imaging science. In photochemistry, laser-induced dissociation has become a valuable tool for modification and control of reaction pathways and kinetics. Here, we present a pump-probe study of the dissociation dynamics of H$_2^+$ using ultrashort extreme-ultraviolet (XUV) and near-infrared (IR) laser pulses. The reaction kinematics can be controlled by varying the pump-probe delay. We demonstrate that the nuclear motion through the transition state can be reduced to isolated pairs of initial vibrational states. The dynamics is well reproduced by intuitive semi-classical trajectories on a time-dependent potential curve. From this most fundamental scenario we gain insight in the underlying mechanisms which can be applied as design principles for molecular quantum control, particularly for ultrafast reactions involving protons. ",https://doi.org/10.1103/PhysRevA.93.012507,1410.8032v1,Yes,potent(1)
0000-0001-7703-1655,Andreas Fischer,Technische Universität Dresden,Illustrating field emission theory by using Lauritsen plots of   transmission probability and barrier strength,1970,"  This technical note relates to the theory of cold field electron emission (CFE). It starts by suggesting that, to emphasize common properties in relation to CFE theory, the term 'Lauritsen plot' could be used to describe all graphical plots made with the reciprocal of barrier field (or the reciprocal of a quantity proportional to barrier field) on the horizontal axis. It then argues that Lauritsen plots related to barrier strength (G) and transmission probability (D) could play a useful role in discussion of CFE theory. Such plots would supplement conventional Fowler-Nordheim (FN) plots. All these plots would be regarded as particular types of Lauritsen plot. The Lauritsen plots of -G and lnD can be used to illustrate how basic aspects of FN tunnelling theory are influenced by the mathematical form of the tunnelling barrier. These, in turn, influence local emission current density and emission current. Illustrative applications used in this note relate to the well-known exact triangular and Schottky-Nordheim barriers, and to the Coulomb barrier (i.e., the electrostatic component of the electron potential energy barrier outside a model spherical emitter). For the Coulomb barrier, a good analytical series approximation has been found for the barrier-form correction factor; this can be used to predict the existence (and to some extent the properties) of related curvature in FN plots. ",https://doi.org/10.1116/1.4765096,1208.4735v3,Yes,potent(1)
0000-0001-7703-1655,Andreas Fischer,Technische Universität Dresden,Non-equilibrium nuclear spin distribution function in quantum dots   subject to periodic pulses,1970,"  Electron spin dephasing in a singly charged semiconductor quantum dot can partially be suppressed by periodic laser pulsing. We propose a semi-classical approach describing the decoherence of the electron spin polarization governed by the hyperfine interaction with the nuclear spins as well as the probabilistic nature of the photon absorption. We use the steady-state Floquet condition to analytically derive two subclasses of resonance conditions excellently predicting the peak locations in the part of the Overhauser field distribution which is projected in the direction of the external magnetic field. As a consequence of the periodic pulsing, a non-equilibrium distribution develops as a function of time. The numerical simulation of the coupled dynamics reveals the influence of the hyperfine coupling constant distribution onto the evolution of the electron spin polarisation before the next laser pulse. Experimental indications are provided for both subclasses of resonance conditions. ",https://doi.org/10.1103/PhysRevB.96.205419,1707.07841v1,Yes,excellently(1)
0000-0001-7739-3541,Benedikt Eggert,Universität Duisburg-Essen,"Local magnetic and geometric structure in Mn-doped La(Fe,Si)13",1970,"  Magnetic cooling has the potential to replace conventional gas compression refrigeration. Materials such as La(Fe,Si)$_{13}$ exhibit a sizeable first-order magnetocaloric effect, and it is possible to tailor the phase transition towards room temperature by Mn-H-doping, resulting in a large temperature range for operation. Within this work, we discuss variations of the electronic and lattice structure in La(Fe,Si)$_{13}$ with increasing Mn content utilizing X-ray magnetic circular dichroism (XMCD) and extended X-ray absorption fine structure spectroscopy (EXAFS). While XMCD shows a decrease of the magnetic polarization at the Fe K edge, low-temperature EXAFS measurements indicate increased positional disorder in the La environment that is otherwise absent for Fe and Mn. First-principles calculations link the positional disorder to an enlarged Mn-Si distance -- explaining the increased positional disorder in the La surrounding. ",Kein DOI-Link verfügbar,2304.03065v1,Yes,potent(1)
0000-0001-7739-3541,Benedikt Eggert,Universität Duisburg-Essen,High entropy oxides: An emerging prospect for magnetic rare earth -   transition metal perovskites,1970,"  It has been shown that oxide ceramics containing multiple transition and/or rare-earth elements in equimolar ratios have a strong tendency to crystallize in simple single phase structures, stabilized by the high configurational entropy. In analogy to the metallic alloy systems, these oxides are denoted high entropy oxides (HEOs). The HEO concept allows to access hitherto uncharted areas in the multi-element phase diagram. Among the already realized structures there is the highly complex class of rare earth - transition element perovskites. This fascinating class of materials generated by applying the innovative concept of high entropy stabilization provides a new and manyfold research space with promise of discoveries of unprecedented properties and phenomena. The present study provides a first investigation of the magnetic properties of selected compounds of this novel class of materials. Comprehensive studies by DC and AC magnetometry are combined with element specific spectroscopy in order to understand the interplay between magnetic exchange and the high degree of chemical disorder in the systems. We observe a predominant antiferromagnetic behavior in the single phase materials, combined with a small ferromagnetic contribution possibly stemming from small ferromagnetic clusters or configurations in the antiferromagnetic matrix. In the long term perspective it is proposed to screen the properties of this family of compounds with high throughput methods, including combined experimental and theoretical approaches. ",https://doi.org/10.1103/PhysRevMaterials.3.034406,1901.02395v2,Yes,innovative(1)
0000-0001-7765-6874,Benedikt Wimmer,Universität Tübingen,Quantum Optimization for the Future Energy Grid: Summary and Quantum   Utility Prospects,1970,"  In this project summary paper, we summarize the key results and use-cases explored in the German Federal Ministry of Education and Research (BMBF) funded project ""Q-GRID"" which aims to assess potential quantum utility optimization applications in the electrical grid. The project focuses on two layers of optimization problems relevant to decentralized energy generation and transmission as well as novel energy transportation/exchange methods such as Peer-2-Peer energy trading and microgrid formation. For select energy grid optimization problems, we demonstrate exponential classical optimizer runtime scaling even for small problem instances, and present initial findings that variational quantum algorithms such as QAOA and hybrid quantum annealing solvers may provide more favourable runtime scaling to obtain similar solution quality. These initial results suggest that quantum computing may be a key enabling technology in the future energy transition insofar that they may be able to solve business problems which are already challenging at small problem instance sizes. ",Kein DOI-Link verfügbar,2403.17495v1,Yes,potent(1)
0000-0001-7787-8098,Tien Quang Nguyen,Technische Universität Dresden,Low-temperature acanthite-like phase of Cu$_{2}$S: A first-principles   study on electronic and transport properties,1970,"  The mobility and disorder in the lattice of Cu atoms as liquid-like behavior is an important characteristic affecting the thermoelectric properties of Cu$_{2}$S. In this study, using a theoretical model called acanthite-like structure for Cu$_{2}$S at a low-temperature range, we systematically investigate the electronic structure, intrinsic defect formation, and transport properties by first-principles calculations. Thereby, previous experimental reports on the indirect bandgap nature of Cu$_{2}$S were confirmed in this work with an energy gap of about 0.9-0.95 eV. As a result, the optical absorption coefficient estimated from this model also gives a potential value of $\alpha > 10^{4}$ cm$^{-1}$ in the visible spectrum range. According to the bonding analysis and formation energy aspect, Cu vacancy is the most preferred defect to form in Cu$_{2}$S, which primarily affects the conductive behavior as a $p$-type, as experimentally observed. Finally, the transport properties of Cu$_{2}$S system were successfully reproduced using an electron-phonon scattering method, highlighting the important role of relaxation time prediction in conductivity estimation instead of regarding it as a constant. ",https://doi.org/10.1103/PhysRevB.105.075205,2110.09117v1,Yes,potent(1)
0000-0001-7800-515X,Richard Nelz,Universität des Saarlandes,Plasma treatments and photonic nanostructures for shallow nitrogen   vacancy centers in diamond,1970,"  We investigate the influence of plasma treatments, especially a 0V-bias, potentially low damage O$_2$ plasma as well as a biased Ar/SF$_6$/O$_2$ plasma on shallow, negative nitrogen vacancy (NV$^-$) centers. We ignite and sustain using our 0V-bias plasma using purely inductive coupling. To this end, we pre-treat surfaces of high purity chemical vapor deposited single-crystal diamond (SCD). Subsequently, we create $\sim$10 nm deep NV$^-$ centers via implantation and annealing. Onto the annealed SCD surface, we fabricate nanopillar structures that efficiently waveguide the photoluminescence (PL) of shallow NV$^-$. Characterizing single NV$^-$ inside these nanopillars, we find that the Ar/SF$_6$/O$_2$ plasma treatment quenches NV$^-$ PL even considering that the annealing and cleaning steps following ion implantation remove any surface termination. In contrast, for our 0V-bias as well as biased O$_2$ plasma, we observe stable NV$^-$ PL and low background fluorescence from the photonic nanostructures. ",Kein DOI-Link verfügbar,1909.13496v2,Yes,potent(1)
0000-0001-7800-515X,Richard Nelz,Universität des Saarlandes,Optimized Planar Microwave Antenna for Nitrogen Vacancy Center based   Sensing Applications,1970,"  Individual nitrogen vacancy (NV) color centers in diamond are versatile, spin-based quantum sensors. Coherently controlling the spin of NV centers using microwaves in a typical frequency range between 2.5 and 3.5 GHz is necessary for sensing applications. In this work, we present a stripline-based, planar, {\Omega}-shaped microwave antenna that enables to reliably manipulate NV spins. We find an optimal antenna design using finite integral simulations. We fabricate our antennas on low-cost, transparent glass substrate. We demonstrate highly uniform microwave fields in areas of roughly 400 x 400 {\mu}m^2 while realizing high Rabi frequencies of up to 10 MHz in an ensemble of NV centers. ",https://doi.org/10.3390/nano11082108,2108.09122v1,Yes,versatile(1)
0000-0001-7970-7129,Sebastian Werner,Universität Bonn,Synthesizing Configuration Tactics for Exercising Hidden Options in   Serverless Systems,1970,"  A proper configuration of an information system can ensure accuracy and efficiency, among other system objectives. Conversely, a poor configuration can have a significant negative impact on the system's performance, reliability, and cost. Serverless systems, which are comprised of many functions and managed services, especially risk exposure to misconfigurations, with many provider- and platform-specific, often intransparent and 'hidden' settings. In this paper, we argue to pay close attention to the configuration of serverless systems to exercise options with known accuracy, cost and time. Based on a literature study and long-term serverless systems development experience, we present nine tactics to unlock potentially neglected and unknown options in serverless systems. ",https://doi.org/10.1007/978-3-031-07481-3_5,2205.15904v2,Yes,potent(1)
0000-0001-8001-5832,Lukas Pflug,Friedrich-Alexander-Universität Erlangen-Nürnberg,Topology Optimization of Broadband Acoustic Transition Section: A   Comparison between Deterministic and Stochastic Approaches,1970,"  This paper focuses on the topology optimization of a broadband acoustic transition section that connects two cylindrical waveguides with different radii. The primary objective is to design a transition section such that it maximizes the transmission of a planar acoustic wave while ensuring the planarity of the transmitted wave. Helmholtz equation is used to model linear wave propagation in the device.We utilize the finite element method to solve the state equation on a structured mesh of square elements. Subsequently, a material distribution topology optimization problem is formulated to optimize the distribution of sound-hard material in the transition section. We employ two different gradient-based approaches to solve the optimization problem: namely, a deterministic approach using the method of moving asymptotes (MMA), and a stochastic approach utilizing both stochastic gradient (SG) and continuous stochastic gradient (CSG) methods. A comparative analysis is provided among these methodologies concerning the design feasibility and the transmission performance of the optimized designs, and the computational efficiency. The outcomes highlight the effectiveness of stochastic techniques in achieving enhanced broadband acoustic performance with reduced computational demands and improved design practicality. The insights from this investigation demonstrate the potential of stochastic approaches in acoustic applications, especially when broadband acoustic performance is desired. ",Kein DOI-Link verfügbar,2310.04783v1,Yes,potent(1)
0000-0001-8001-5832,Lukas Pflug,Friedrich-Alexander-Universität Erlangen-Nürnberg,Robust design optimization for enhancing delamination resistance of   composites,1970,"  Recent developments in the field of computational modeling of fracture have opened up possibilities for designing structures against failure. A special case, called interfacial fracture or delamination, can occur in loaded composite structures where two or more materials are bonded together at comparatively weak interfaces. Due to the potential crack growth along these interfaces, the structural problem suffers from snap-back/snap-through instabilities and bifurcations with respect to the model parameters, leading to noisy and discontinuous responses. For such a case, the design optimization problem for a selected quantity of interest is ill-posed, since small variations in the design parameters can lead to large jumps in the structural response. To this end, this paper presents a stochastic optimization approach to maximize delamination resistance that is less sensitive to small perturbations of the design and thereby leads to a robust solution. To overcome the intractability of Monte Carlo methods for estimating the expected value of the expensive-to-evaluate response function, a global, piecewise-constant surrogate is constructed based on nearest-neighbor interpolation that is iteratively refined during the optimization run. We found that by taking a large stochastic region at the beginning of the optimization and gradually reducing it to the desired one can help overcome poor local optima. Our results demonstrate the effectiveness of the proposed framework using an example of shape optimization of hard inclusions embedded in a double-cantilever beam, which significantly enhances delamination resistance. ",Kein DOI-Link verfügbar,2209.05241v1,Yes,potent(1)
0000-0001-8001-5832,Lukas Pflug,Friedrich-Alexander-Universität Erlangen-Nürnberg,T-matrix representation of optical scattering response: Suggestion for a   data format,1970,"  The transition matrix, frequently abbreviated as T-matrix, contains the complete information in a linear approximation of how a spatially localized object scatters an incident field. The T-matrix is used to study the scattering response of an isolated object and describes the optical response of complex photonic materials made from ensembles of individual objects. T-matrices of certain common structures, potentially, have been repeatedly calculated all over the world again and again. This is not necessary and constitutes a major challenge for various reasons. First, the resources spent on their computation represent an unsustainable financial and ecological burden. Second, with the onset of machine learning, data is the gold of our era, and it should be freely available to everybody to address novel scientific challenges. Finally, the possibility of reproducing simulations could tremendously improve if the considered T-matrices could be shared. To address these challenges, we found it important to agree on a common data format for T-matrices and to enable their collection from different sources and distribution. This document aims to develop the specifications for storing T-matrices and associated metadata. The specifications should allow maximum freedom to accommodate as many use cases as possible without introducing any ambiguity in the stored data. The common format will assist in setting up a public database of T-matrices. ",Kein DOI-Link verfügbar,2408.10727v1,Yes,potent(1)
0000-0001-8152-9739,Antje Rogalla,Technische Universität Hamburg,Modeling R$^3$ Needle Steering in Uppaal,1970,"  Medical cyber-physical systems are safety-critical, and as such, require ongoing verification of their correct behavior, as system failure during run time may cause severe (or even fatal) personal damage. However, creating a verifiable model often conflicts with other application requirements, most notably regarding data precision and model accuracy, as efficient model checking promotes discrete data (over continuous) and abstract models to reduce the state space. In this paper, we approach the task of medical needle steering in soft tissue around potential obstacles. We design a verifiable model of needle motion (implemented in Uppaal Stratego) and a framework embedding the model for online needle steering. We mitigate the conflict by imposing boundedness on both the data types, reducing from R^3 to Z^3 when needed, and the motion and environment models, reducing the set of allowed local actions and global paths. In experiments, we successfully apply the static model alone, as well as the dynamic framework in scenarios with varying environment complexity and both a virtual and real needle setting, where up to 100% of targets were reached depending on the scenario and needle. ",https://doi.org/10.4204/EPTCS.355.4,2203.09884v1,Yes,potent(1)
0000-0001-8190-9213,Deep Chatterjee,Goethe-Universität Frankfurt am Main,Neural Post-Einsteinian Framework for Efficient Theory-Agnostic Tests of   General Relativity with Gravitational Waves,1970,"  The parametrized post-Einsteinian (ppE) framework and its variants are widely used to probe gravity through gravitational-wave tests that apply to a large class of theories beyond general relativity. However, the ppE framework is not truly theory-agnostic as it only captures certain types of deviations from general relativity: those that admit a post-Newtonian series representation in the inspiral of coalescencing compact objects. Moreover, each type of deviation in the ppE framework has to be tested separately, making the whole process computationally inefficient and expensive, possibly obscuring the theoretical interpretation of potential deviations that could be detected in the future. We here present the neural post-Einsteinian (npE) framework, an extension of the ppE formalism that overcomes the above weaknesses using deep-learning neural networks. The core of the npE framework is a variantional autoencoder that maps the discrete ppE theories into a continuous latent space in a well-organized manner. This design enables the npE framework to test many theories simultaneously and to select the theory that best describes the observation in a single parameter estimation run. The smooth extension of the ppE parametrization also allows for more general types of deviations to be searched for with the npE model. We showcase the application of the new npE framework to future tests of general relativity with the fifth observing run of the LIGO-Virgo-KAGRA collaboration. In particular, the npE framework is demonstrated to efficiently explore modifications to general relativity beyond what can be mapped by the ppE framework, including modifications coming from higher-order curvature corrections to the Einstein-Hilbert action at high post-Newtonian order, and dark-photon interactions in possibly hidden sectors of matter that do not admit a post-Newtonian representation. ",Kein DOI-Link verfügbar,2403.18936v1,Yes,potent(1)
0000-0001-8190-9213,Deep Chatterjee,Goethe-Universität Frankfurt am Main,A Machine Learning Based Source Property Inference for Compact Binary   Mergers,1970,"  The detection of the binary neutron star (BNS) merger, GW170817, was the first success story of multi-messenger observations of compact binary mergers. The inferred merger rate along with the increased sensitivity of the ground-based gravitational-wave (GW) network in the present LIGO/Virgo, and future LIGO/Virgo/KAGRA observing runs, strongly hints at detection of binaries which could potentially have an electromagnetic (EM) counterpart. A rapid assessment of properties that could lead to a counterpart is essential to aid time-sensitive follow-up operations, especially robotic telescopes. At minimum, the possibility of counterparts require a neutron star (NS). Also, the tidal disruption physics is important to determine the remnant matter post merger, the dynamics of which could result in the counterparts. The main challenge, however, is that the binary system parameters such as masses and spins estimated from the real time, GW template-based searches are often dominated by statistical and systematic errors. Here, we present an approach that uses supervised machine-learning to mitigate such selection effects to report possibility of counterparts based on presence of a NS component, and presence of remnant matter post merger in real time. ",https://doi.org/10.3847/1538-4357/ab8dbe,1911.00116v2,Yes,potent(1)
0000-0001-8190-9213,Deep Chatterjee,Goethe-Universität Frankfurt am Main,Improved early warning of compact binary mergers using higher modes of   gravitational radiation: A population study,1970,"  A gravitational-wave (GW) early-warning of a compact-binary coalescence event, with a sufficiently tight localisation skymap, would allow telescopes to point in the direction of the potential electromagnetic counterpart before its onset. This will enable astronomers to extract valuable information of the complex astrophysical phenomena triggered around the time of the merger. Use of higher-modes of gravitational radiation, in addition to the dominant mode typically used in templated real-time searches, was recently shown to produce significant improvements in early-warning times and skyarea localisations for a range of asymmetric-mass binaries. In this work, we perform a large-scale study to assess the benefits of this method for a population of compact binary merger observations. In particular, we inject 100,000 such signals in Gaussian noise, with component masses $m_1 \in \left[1, 60 \right] M_{\odot}$ and $m_2 \in \left [1, 3 \right] M_{\odot}$. We consider three scenarios involving ground-based detectors: the fifth (O5) observing run of the Advanced LIGO-Virgo-KAGRA network, its projected Voyager upgrade, as well as a proposed third generation (3G) network. We find that for fixed early warning times of $20-60$ seconds, the inclusion of the higher modes can provide localisation improvements of a factor of $\gtrsim 2$ for up to $\sim 60\%$ ($70 \%$) of the neutron star-black hole systems in the O5 (Voyager) scenario. Considering only those neutron star-black hole systems which can produce potential electromagnetic counterparts, such improvements in the localisation can be expected for $\sim 5-35\%$ $(20-50\%)$ binaries in O5 (Voyager), although the localisation areas themselves depend on the distances. For the 3G scenario, a significant fraction of the events have time gains of a minute to several minutes, assuming fiducial target localisation areas of 100 to 1000 sq. deg. ",https://doi.org/10.1093/mnras/stab125,2010.12407v2,Yes,potent(2)
0000-0001-8190-9213,Deep Chatterjee,Goethe-Universität Frankfurt am Main,Demonstration of Machine Learning-assisted real-time noise regression in   gravitational wave detectors,1970,"  Real-time noise regression algorithms are crucial for maximizing the science outcomes of the LIGO, Virgo, and KAGRA gravitational-wave detectors. This includes improvements in the detectability, source localization and pre-merger detectability of signals thereby enabling rapid multi-messenger follow-up. In this paper, we demonstrate the effectiveness of \textit{DeepClean}, a convolutional neural network architecture that uses witness sensors to estimate and subtract non-linear and non-stationary noise from gravitational-wave strain data. Our study uses LIGO data from the third observing run with injected compact binary signals. As a demonstration, we use \textit{DeepClean} to subtract the noise at 60 Hz due to the power mains and their sidebands arising from non-linear coupling with other instrumental noise sources. Our parameter estimation study on the injected signals shows that \textit{DeepClean} does not do any harm to the underlying astrophysical signals in the data while it can enhances the signal-to-noise ratio of potential signals. We show that \textit{DeepClean} can be used for low-latency noise regression to produce cleaned output data at latencies $\sim 1-2$\, s. We also discuss various considerations that may be made while training \textit{DeepClean} for low latency applications. ",Kein DOI-Link verfügbar,2306.11366v1,Yes,potent(1)
0000-0001-8206-9738,Florentin Woergoetter,Georg-August-Universität Göttingen,Self-organized adaptation of a simple neural circuit enables complex   robot behaviour,1970,"  Controlling sensori-motor systems in higher animals or complex robots is a challenging combinatorial problem, because many sensory signals need to be simultaneously coordinated into a broad behavioural spectrum. To rapidly interact with the environment, this control needs to be fast and adaptive. Current robotic solutions operate with limited autonomy and are mostly restricted to few behavioural patterns. Here we introduce chaos control as a new strategy to generate complex behaviour of an autonomous robot. In the presented system, 18 sensors drive 18 motors via a simple neural control circuit, thereby generating 11 basic behavioural patterns (e.g., orienting, taxis, self-protection, various gaits) and their combinations. The control signal quickly and reversibly adapts to new situations and additionally enables learning and synaptic long-term storage of behaviourally useful motor responses. Thus, such neural control provides a powerful yet simple way to self-organize versatile behaviours in autonomous agents with many degrees of freedom. ",https://doi.org/10.1038/nphys1860,1105.1386v1,Yes,versatile(1)
0000-0001-8211-7971,Thomas Lorenz,Universität Konstanz,Single-crystal study of the honeycomb XXZ magnet BaCo$_2$(PO$_4$)$_2$ in   magnetic fields,1970,"  We present a study of high-quality BaCo$_2$(PO$_4$)$_2$ single crystals via magnetization, heat-capacity, thermal-expansion and magnetostriction measurements. Sharp anomalies in the thermodynamic properties at $T_N=3.4\,$K reveal a long-range antiferromagnetic order in these single-crystalline samples, which is absent in polycrystalline BaCo$_2$(PO$_4$)$_2$. The temperature dependent magnetic susceptibilities for in-plane and out-of-plane magnetic fields are strongly anisotropic and reveal a pronounced easy-plane anisotropy. A Curie-Weiss analysis implies strong orbital magnetism, as it is known from the sister compound BaCo$_2$(AsO$_4$)$_2$ that is discussed as a potential Kitaev spin-liquid material. When applying in-plane magnetic fields at low temperature, BaCo$_2$(PO$_4$)$_2$ is driven to another ordered phase at a critical field $H_{C1}\approx 0.11\,$T and then undergoes a further field-induced transition to a highly polarized paramagnetic phase at $H_{C2}\approx 0.3\,$T, which is again similar to the case of BaCo$_2$(AsO$_4$)$_2$. In addition, our lowest-temperature data reveal that the field-induced transitions in BaCo$_2$(PO$_4$)$_2$ become dominated by thermally assisted domain-wall motion. ",https://doi.org/10.1103/PhysRevMaterials.7.024402,2209.15510v2,Yes,potent(1)
0000-0001-8223-1707,Ann-Kathrin Seifert,Technische Universität Darmstadt,Doppler Radar for the Extraction of Biomechanical Parameters in Gait   Analysis,1970,"  The applicability of Doppler radar for gait analysis is investigated by quantitatively comparing the measured biomechanical parameters to those obtained using motion capturing and ground reaction forces. Nineteen individuals walked on a treadmill at two different speeds, where a radar system was positioned in front of or behind the subject. The right knee angle was confined by an adjustable orthosis in five different degrees. Eleven gait parameters are extracted from radar micro-Doppler signatures. Here, new methods for obtaining the velocities of individual lower limb joints are proposed. Further, a new method to extract individual leg flight times from radar data is introduced. Based on radar data, five spatiotemporal parameters related to rhythm and pace could reliably be extracted. Further, for most of the considered conditions, three kinematic parameters could accurately be measured. The radar-based stance and flight time measurements rely on the correct detection of the time instant of maximal knee velocity during the gait cycle. This time instant is reliably detected when the radar has a back view, but is underestimated when the radar is positioned in front of the subject. The results validate the applicability of Doppler radar to accurately measure a variety of medically relevant gait parameters. Radar has the potential to unobtrusively diagnose changes in gait, e.g., to design training in prevention and rehabilitation. As contact-less and privacy-preserving sensor, radar presents a viable technology to supplement existing gait analysis tools for long-term in-home examinations. ",Kein DOI-Link verfügbar,2005.05280v1,Yes,potent(1)
0000-0001-8275-353X,Lukas Martinetz,Universität Duisburg-Essen,Electric trapping and circuit cooling of charged nanorotors,1970,"  The motion of charged particles can be interfaced with electric circuitry via the current induced in nearby pick-up electrodes. Here we show how the rotational and translational dynamics of levitated objects with arbitrary charge distributions can be coupled to a circuit and how the latter acts back on the particle motion. The ensuing cooling rates in series and parallel RLC circuits are determined, demonstrating that quadrupole ion traps are well suited for implementing all-electric cooling. We derive the effective macromotion potential for general trap geometries and demonstrate numerically how consecutive rotational and translational resistive cooling of a microscale particle can be achieved in linear Paul traps. ",https://doi.org/10.1088/1367-2630/ac1c82,2105.00264v2,Yes,potent(1)
0000-0001-8275-353X,Lukas Martinetz,Universität Duisburg-Essen,Surface-induced decoherence and heating of charged particles,1970,"  Levitating charged particles in ultra-high vacuum provides a preeminent platform for quantum information processing, for quantum-enhanced force and torque sensing, for probing physics beyond the standard model, and for high-mass tests of the quantum superposition principle. Existing setups range from single atomic ions, to ion chains and crystals, to charged molecules and nanoparticles. Future technological applications of such quantum systems will be crucially affected by fluctuating electric fields emanating from nearby electrodes, which interact with the levitated particles' monopole and higher charge moments. In this article, we provide a theoretical toolbox for describing how the rotational and translational quantum dynamics of charged nano- to microscale objects is affected by near metallic and dielectric surfaces, as characterized by their macroscopic dielectric response. The resulting quantum master equations describe the coherent surface-particle interaction, due to image charges and Casimir-Polder potentials, as well as surface-induced decoherence and heating, with the experimentally observed frequency and distance scaling. We explicitly evaluate the master equations for typical charge distributions and types of motion, thereby providing the tools required for describing and mitigating surface-induced decoherence in a variety of experiments with charged objects. ",https://doi.org/10.1103/PRXQuantum.3.030327,2203.15088v1,Yes,potent(1)
0000-0001-8275-353X,Lukas Martinetz,Universität Duisburg-Essen,Diffracting molecular matter-waves at deep-ultraviolet standing-light   waves,1970,"  Matter-wave interferometry with molecules is intriguing both because it demonstrates a fundamental quantum phenomenon and because it opens avenues to quantum-enhanced measurements in physical chemistry. One great challenge in such experiments is to establish matter-wave beam splitting mechanisms that are efficient and applicable to a wide range of particles. In the past, continuous standing light waves in the visible spectral range were used predominantly as phase gratings, while pulsed vacuum ultraviolet light found applications in photo-ionisation gratings. Here, we explore the regime of continuous, intense deep-ultraviolet ($\rm >1 MW/cm^2$, $\rm 266\,nm$) light masks, where a rich variety of photo-physical and photo-chemical phenomena and relaxation pathways must be considered. The improved understanding of the mechanisms in this interaction opens new potential pathways to protein interferometry and to matter-wave enhanced sensing of molecular properties. ",Kein DOI-Link verfügbar,2408.00461v1,Yes,potent(1)
0000-0001-8507-927X,Jenny Schmalfuss,Universität Stuttgart,Detection Defenses: An Empty Promise against Adversarial Patch Attacks   on Optical Flow,1970,"  Adversarial patches undermine the reliability of optical flow predictions when placed in arbitrary scene locations. Therefore, they pose a realistic threat to real-world motion detection and its downstream applications. Potential remedies are defense strategies that detect and remove adversarial patches, but their influence on the underlying motion prediction has not been investigated. In this paper, we thoroughly examine the currently available detect-and-remove defenses ILP and LGS for a wide selection of state-of-the-art optical flow methods, and illuminate their side effects on the quality and robustness of the final flow predictions. In particular, we implement defense-aware attacks to investigate whether current defenses are able to withstand attacks that take the defense mechanism into account. Our experiments yield two surprising results: Detect-and-remove defenses do not only lower the optical flow quality on benign scenes, in doing so, they also harm the robustness under patch attacks for all tested optical flow methods except FlowNetC. As currently employed detect-and-remove defenses fail to deliver the promised adversarial robustness for optical flow, they evoke a false sense of security. The code is available at https://github.com/cv-stuttgart/DetectionDefenses. ",Kein DOI-Link verfügbar,2310.17403v2,Yes,potent(1)
0000-0001-8534-0466,Yao Feng,TU Darmstadt,"Physics-Informed Machine Learning: A Survey on Problems, Methods and   Applications",1970,"  Recent advances of data-driven machine learning have revolutionized fields like computer vision, reinforcement learning, and many scientific and engineering domains. In many real-world and scientific problems, systems that generate data are governed by physical laws. Recent work shows that it provides potential benefits for machine learning models by incorporating the physical prior and collected data, which makes the intersection of machine learning and physics become a prevailing paradigm. By integrating the data and mathematical physics models seamlessly, it can guide the machine learning model towards solutions that are physically plausible, improving accuracy and efficiency even in uncertain and high-dimensional contexts. In this survey, we present this learning paradigm called Physics-Informed Machine Learning (PIML) which is to build a model that leverages empirical data and available physical prior knowledge to improve performance on a set of tasks that involve a physical mechanism. We systematically review the recent development of physics-informed machine learning from three perspectives of machine learning tasks, representation of physical prior, and methods for incorporating physical prior. We also propose several important open research problems based on the current trends in the field. We argue that encoding different forms of physical prior into model architectures, optimizers, inference algorithms, and significant domain-specific applications like inverse engineering design and robotic control is far from being fully explored in the field of physics-informed machine learning. We believe that the interdisciplinary research of physics-informed machine learning will significantly propel research progress, foster the creation of more effective machine learning models, and also offer invaluable assistance in addressing long-standing problems in related disciplines. ",Kein DOI-Link verfügbar,2211.08064v2,Yes,"invaluable(1), potent(1)"
0000-0001-8534-0466,Yao Feng,TU Darmstadt,MonoHair: High-Fidelity Hair Modeling from a Monocular Video,1970,"  Undoubtedly, high-fidelity 3D hair is crucial for achieving realism, artistic expression, and immersion in computer graphics. While existing 3D hair modeling methods have achieved impressive performance, the challenge of achieving high-quality hair reconstruction persists: they either require strict capture conditions, making practical applications difficult, or heavily rely on learned prior data, obscuring fine-grained details in images. To address these challenges, we propose MonoHair,a generic framework to achieve high-fidelity hair reconstruction from a monocular video, without specific requirements for environments. Our approach bifurcates the hair modeling process into two main stages: precise exterior reconstruction and interior structure inference. The exterior is meticulously crafted using our Patch-based Multi-View Optimization (PMVO). This method strategically collects and integrates hair information from multiple views, independent of prior data, to produce a high-fidelity exterior 3D line map. This map not only captures intricate details but also facilitates the inference of the hair's inner structure. For the interior, we employ a data-driven, multi-view 3D hair reconstruction method. This method utilizes 2D structural renderings derived from the reconstructed exterior, mirroring the synthetic 2D inputs used during training. This alignment effectively bridges the domain gap between our training data and real-world data, thereby enhancing the accuracy and reliability of our interior structure inference. Lastly, we generate a strand model and resolve the directional ambiguity by our hair growth algorithm. Our experiments demonstrate that our method exhibits robustness across diverse hairstyles and achieves state-of-the-art performance. For more results, please refer to our project page https://keyuwu-cs.github.io/MonoHair/. ",Kein DOI-Link verfügbar,2403.18356v1,Yes,"meticulous(1), intricate(1), meticulously(1), undoubtedly(1), strategically(1)"
0000-0001-8558-6554,Clemens Meiser,Universität des Saarlandes,Generative AI Models: Opportunities and Risks for Industry and   Authorities,1970,"  Generative AI models are capable of performing a wide range of tasks that traditionally require creativity and human understanding. They learn patterns from existing data during training and can subsequently generate new content such as texts, images, and music that follow these patterns. Due to their versatility and generally high-quality results, they, on the one hand, represent an opportunity for digitalization. On the other hand, the use of generative AI models introduces novel IT security risks that need to be considered for a comprehensive analysis of the threat landscape in relation to IT security. In response to this risk potential, companies or authorities using them should conduct an individual risk analysis before integrating generative AI into their workflows. The same applies to developers and operators, as many risks in the context of generative AI have to be taken into account at the time of development or can only be influenced by the operating company. Based on this, existing security measures can be adjusted, and additional measures can be taken. ",Kein DOI-Link verfügbar,2406.04734v1,Yes,potent(1)
0000-0001-8604-4685,Daniel Vogt,Technische Universität Bergakademie Freiberg,Triaxial Analytical Potential-Density Pairs for Galaxies,1970,"  We present two triaxial analytical potential-density pairs that can be viewed as generalized versions of the axisymmetric Miyamoto and Nagai and Satoh galactic models. These potential-density pairs may be useful models for galaxies with box-shaped bulges. The resulting mass density distributions are everywhere non-negative and free from singularities. Also, a few numerically calculated orbits for the Miyamoto and Nagai-like triaxial potential are presented. ",https://doi.org/10.1093/pasj/59.2.319,0705.1622v1,Yes,potent(3)
0000-0001-8653-1168,Max Ehrhardt,Universität Rostock,Exploring complex graphs using three-dimensional quantum walks of   correlated photons,1970,"  Graph representations are a powerful concept for solving complex problems across natural science, as patterns of connectivity can give rise to a multitude of emergent phenomena. Graph-based approaches have proven particularly fruitful in quantum communication and quantum search algorithms in highly branched quantum networks. Here we introduce a new paradigm for the direct experimental realization of excitation dynamics associated with three-dimensional networks by exploiting the hybrid action of spatial and polarization degrees of freedom of photon pairs in complex waveguide circuits with tailored birefringence. This novel testbed for the experimental exploration of multi-particle quantum walks on complex, highly connected graphs paves the way towards exploiting the applicative potential of fermionic dynamics in integrated quantum photonics. ",Kein DOI-Link verfügbar,2007.05262v1,Yes,potent(1)
0000-0001-8653-1168,Max Ehrhardt,Universität Rostock,Populating and probing protected edge states through topology-entailed   trivial states,1970,"  Topological insulators enable non-reciprocal light propagation that is insensitive to disorder and imperfections. Yet, despite considerable attention from the photonics community and beyond, the very feature that has inspired numerous proposals for applications of topological transport also turns out to be one of the main stumbling blocks for practical implementations: Accessing topologically protected states is generally assumed to require their protection to be lifted. We overcome this limitation by topology-entailed trivial (TET) states that arise from the hybridization of counter-propagating interface states. We demonstrate selective injection and extraction of light into topological states as well as long-range coherent light exchange between spatially separated topological channels. Our results highlight the potential of TET states as protection-preserving paradigm to manipulate the flow of light in topological platforms. ",Kein DOI-Link verfügbar,2202.03252v1,Yes,potent(1)
0000-0001-8653-1168,Max Ehrhardt,Universität Rostock,Extreme defect sensitivity from large synthetic dimensionality,1970,"  The geometric dimensionality of a physical system significantly impacts its fundamental characteristics. While experiments are fundamentally limited to the maximum of three spatial dimensions, there is a growing interest in harnessing additional synthetic dimensions. In our work, we introduce a new paradigm for the experimental realization of excitation dynamics associated with many-dimensional systems. Crucially, it relies solely on static one-dimensional equivalent structures with judiciously tailored parameters to faithfully reproduce the same optical spectrum and density of states of the high-dimensional system to be represented. In order to showcase the capabilities of our approach, we fabricate 1D photonic lattices that exhibit the characteristic non-monotonic excitation decays associated with quantum walks in up to 7D square lattices. Furthermore, we find that a new type of bound state at the edge of the continuum emerges in higher-than-three dimensions and gives rise to a sharp localisation transition at defect sites. In a series of experiments, we implement the mapped equivalent lattices of up to 5D systems and observe an extreme increase of sensitivity with respect to the detuning of the respective anchor sites. Our findings demonstrate the feasibility and applicative potential of harnessing high-dimensional effects in planar photonics for ultra-sensitive switching or sensing. Notably, our general approach is by no means limited to optics, and can readily be adapted to a variety of other physical contexts, including cold atoms and superconducting qubits with exclusively nearest-neighbour interactions, promising to drive significant advances in different fields including quantum simulations and information processing. ",https://doi.org/10.1038/s41566-019-0562-8,1903.07883v1,Yes,potent(1)
0000-0001-8653-7439,Arno Pfitzner,Universität Regensburg,Possible Experimental Realization of a Basic Z2 Topological Semimetal,1970,"  We report experimental and theoretical evidence that GaGeTe is a basic $Z_2$ topological semimetal with three types of charge carriers: bulk-originated electrons and holes as well as surface state electrons. This electronic situation is qualitatively similar to the primer 3D topological insulator Bi2Se3, but important differences account for an unprecedented transport scenario in GaGeTe. High-resolution angle-resolved photoemission spectroscopy combined with advanced band structure calculations show a small indirect energy gap caused by a peculiar band inversion in the \textit{T}-point of the Brillouin zone in GaGeTe. An energy overlap of the valence and conduction bands brings both electron- and hole-like carriers to the Fermi level, while the momentum gap between the corresponding dispersions remains finite. We argue that peculiarities of the electronic spectrum of GaGeTe have a fundamental importance for the physics of topological matter and may boost the material's application potential. ",https://doi.org/10.1063/1.5124563,1812.01668v1,Yes,potent(1)
0000-0001-8653-9581,David Hunger,Universität Stuttgart,Scaling laws of the cavity enhancement for nitrogen-vacancy centers in   diamond,1970,"  We employ a fiber-based optical microcavity with high finesse to study the enhancement of phonon sideband fluorescence of nitrogen-vacancy centers in nanodiamonds. Harnessing the full tunability and open access of the resonator, we explicitly demonstrate the scaling laws of the Purcell enhancement by varying both the mode volume and the quality factor over a large range. While changes in the emission lifetime remain small in the regime of a broadband emitter, we observe an increase of the emission spectral density by up to a factor of 300. This gives a direct measure of the Purcell factor that could be achieved with this resonator and an emitter whose linewidth is narrower than the cavity linewidth. Our results show a method for the realization of wavelength-tunable narrow-band single-photon sources and demonstrate a system that has the potential to reach the strong-coupling regime. ",https://doi.org/10.1103/PhysRevA.88.053812,1304.0948v2,Yes,potent(1)
0000-0001-8653-9581,David Hunger,Universität Stuttgart,A Scanning Cavity Microscope,1970,"  Imaging of the optical properties of individual nanosystems beyond fluorescence can provide a wealth of information. However, the minute signals for absorption and dispersion are challenging to observe, and only specialized techniques requiring sophisticated noise rejection are available. Here we use signal enhancement in a scanning optical microcavity to demonstrate ultra-sensitive imaging. Harnessing multiple interactions of probe light with a sample within an optical resonator, we achieve a 1700-fold signal enhancement compared to diffraction-limited microscopy. We demonstrate quantitative imaging of the extinction cross section of gold nanoparticles with a sensitivity below 1 nm2, we show a method to improve spatial resolution potentially below the diffraction limit by using higher order cavity modes, and we present measurements of the birefringence and extinction contrast of gold nanorods. The demonstrated simultaneous enhancement of absorptive and dispersive signals promises intriguing potential for optical studies of nanomaterials, molecules, and biological nanosystems. ",https://doi.org/10.1038/ncomms8249,1411.7180v2,Yes,potent(2)
0000-0001-8653-9581,David Hunger,Universität Stuttgart,Music Generation Using an LSTM,1970,"  Over the past several years, deep learning for sequence modeling has grown in popularity. To achieve this goal, LSTM network structures have proven to be very useful for making predictions for the next output in a series. For instance, a smartphone predicting the next word of a text message could use an LSTM. We sought to demonstrate an approach of music generation using Recurrent Neural Networks (RNN). More specifically, a Long Short-Term Memory (LSTM) neural network. Generating music is a notoriously complicated task, whether handmade or generated, as there are a myriad of components involved. Taking this into account, we provide a brief synopsis of the intuition, theory, and application of LSTMs in music generation, develop and present the network we found to best achieve this goal, identify and address issues and challenges faced, and include potential future improvements for our network. ",Kein DOI-Link verfügbar,2203.12105v1,Yes,potent(1)
0000-0001-8653-9581,David Hunger,Universität Stuttgart,Cavity-enhanced Raman Microscopy of Individual Carbon Nanotubes,1970,"  Raman spectroscopy reveals chemically specific information and provides label-free insight into the molecular world. However, the signals are intrinsically weak and call for enhancement techniques. Here, we demonstrate Purcell enhancement of Raman scattering in a tunable high-finesse microcavity, and utilize it for molecular diagnostics by combined Raman and absorption imaging. Studying individual single-wall carbon nanotubes, we identify crucial structural parameters such as nanotube radius, electronic structure and extinction cross-section. We observe a 320-times enhanced Raman scattering spectral density and an effective Purcell factor of 6.2, together with a collection efficiency of 60%. Potential for significantly higher enhancement, quantitative signals, inherent spectral filtering and absence of intrinsic background in cavity-vacuum stimulated Raman scattering render the technique a promising tool for molecular imaging. Furthermore, cavity-enhanced Raman transitions involving localized excitons could potentially be used for gaining quantum control over nanomechanical motion and open a route for molecular cavity optomechanics. ",https://doi.org/10.1038/ncomms12155,1508.06810v2,Yes,potent(2)
0000-0001-8653-9581,David Hunger,Universität Stuttgart,A Diamond-Photonics Platform Based on Silicon-Vacancy Centers in a   Single Crystal Diamond Membrane and a Fiber-Cavity,1970,"  We realize a potential platform for an efficient spin-photon interface, namely negatively-charged silicon-vacancy centers in a diamond membrane coupled to the mode of a fully-tunable, fiber-based, optical resonator. We demonstrate that introducing the thin ($\sim 200 \, \text{nm}$), single crystal diamond membrane into the mode of the resonator does not change the cavity properties, which is one of the crucial points for an efficient spin-photon interface. In particular, we observe constantly high Finesse values of up to $3000$ and a linear dispersion in the presence of the membrane. We observe cavity-coupled fluorescence froman ensemble of SiV$^{-}$ centers with an enhancement factor of $\sim 1.9$. Furthermore from our investigations we extract the ensemble absorption and extrapolate an absorption cross section of $(2.9 \, \pm \, 2) \, \cdot \, 10^{-12} \, \text{cm}^{2}$ for a single SiV$^{-}$ center, much higher than previously reported. ",https://doi.org/10.1103/PhysRevB.99.165310,1812.02426v3,Yes,potent(1)
0000-0001-8653-9581,David Hunger,Universität Stuttgart,Rare-Earth Molecular Crystals with Ultra-narrow Optical Linewidths for   Photonic Quantum Technologies,1970,"  Rare-earth ions are promising solid state systems to build light-matter interfaces at the quantum level. This relies on their potential to show narrow optical homogeneous linewidths or, equivalently, long-lived optical quantum states. In this letter, we report on europium molecular crystals that exhibit linewidths in the 10s of kHz range, orders of magnitude narrower than other molecular centers. We harness this property to demonstrate efficient optical spin initialization, coherent storage of light using an atomic frequency comb, and optical control of ion-ion interactions towards implementation of quantum gates. These results illustrate the utility of rare-earth molecular crystals as a new platform for photonic quantum technologies that combines highly coherent emitters with the unmatched versatility in composition, structure, and integration capability of molecular materials. ",https://doi.org/10.1038/s41586-021-04316-2,2105.07081v1,Yes,potent(1)
0000-0001-8653-9581,David Hunger,Universität Stuttgart,Open-cavity in closed-cycle cryostat as a quantum optics platform,1970,"  The introduction of an optical resonator can enable efficient and precise interaction between a photon and a solid-state emitter. It facilitates the study of strong light-matter interaction, polaritonic physics and presents a powerful interface for quantum communication and computing. A pivotal aspect in the progress of light-matter interaction with solid-state systems is the challenge of combining the requirements of cryogenic temperature and high mechanical stability against vibrations while maintaining sufficient degrees of freedom for in-situ tunability. Here, we present a fiber-based open Fabry-P\'{e}rot cavity in a closed-cycle cryostat exhibiting ultra-high mechanical stability while providing wide-range tunability in all three spatial directions. We characterize the setup and demonstrate the operation with the root-mean-square cavity length fluctuation of less than $90$ pm at temperature of $6.5$ K and integration bandwidth of $100$ kHz. Finally, we benchmark the cavity performance by demonstrating the strong-coupling formation of exciton-polaritons in monolayer WSe$_2$ with a cooperativity of $1.6$. This set of results manifests the open-cavity in a closed-cycle cryostat as a versatile and powerful platform for low-temperature cavity QED experiments. ",https://doi.org/10.1103/PRXQuantum.2.040318,2103.05619v2,Yes,"versatile(1), pivotal(1)"
0000-0001-8653-9581,David Hunger,Universität Stuttgart,Microwave Control of the Tin-Vacancy Spin Qubit in Diamond with a   Superconducting Waveguide,1970,"  Group-IV color centers in diamond are promising candidates for quantum networks due to their dominant zero-phonon line and symmetry-protected optical transitions that connect to coherent spin levels. The negatively charged tin-vacancy (SnV) center possesses long electron spin lifetimes due to its large spin-orbit splitting. However, the magnetic dipole transitions required for microwave spin control are suppressed, and strain is necessary to enable these transitions. Recent work has shown spin control of strained emitters using microwave lines that suffer from Ohmic losses, restricting coherence through heating. We utilize a superconducting coplanar waveguide to measure SnV centers subjected to strain, observing substantial improvement. A detailed analysis of the SnV center electron spin Hamiltonian based on the angle-dependent splitting of the ground and excited states is performed. We demonstrate coherent spin manipulation and obtain a Hahn echo coherence time of up to $T_2 = 430\,\mu$s. With dynamical decoupling, we can prolong coherence to $T_2 = 10\,$ms, about six-fold improved compared to earlier works. We also observe a nearby coupling $^{13}\mathrm{C}$ spin which may serve as a quantum memory. This substantiates the potential of SnV centers in diamond and demonstrates the benefit of superconducting microwave structures. ",Kein DOI-Link verfügbar,2403.00521v1,Yes,potent(1)
0000-0001-8653-9581,David Hunger,Universität Stuttgart,Roadmap for Rare-earth Quantum Computing,1970,"  Several platforms are being considered as hardware for quantum technologies. For quantum computing (QC), superconducting qubits and artificially trapped ions are among the leading platforms, but many others also show promise, e.g. photons, cold atoms, defect centers including Rare-Earth (RE) ions. So far, results are limited to the regime of noisy intermediate scale qubits (NISQ), with a small number of qubits and a limited connectivity, and it is likely that future QC hardware will utilize several existing platforms in different ways. Thus, it currently makes sense to invest resources broadly and explore the full range of promising routes to quantum technology. Rare-earth ions in solids constitute one of the most versatile platforms for future quantum technology. One advantage is good coherence properties even when confined in strong natural traps inside a solid-state matrix. This confinement allows very high qubit densities and correspondingly strong ion-ion couplings. In addition, although their fluorescence is generally weak, cavity integration can enhance the emission greatly and enable very good connections to photonic circuits, including at the telecom wavelengths, making them promising systems for long-term scalability. The primary aim of this roadmap is to provide a complete picture of what components a RE quantum computer would consist of, to describe the details of all parts required to achieve a scalable system, and to discuss the most promising paths to reach it. In brief, we find that clusters of 50-100 single RE ions can act as high fidelity qubits in small processors, occupying only about (10 nm)^3. Due to the high capacity for integration of the RE systems, they be optically read out and connected to other such clusters for larger scalability. We make suggestions for future improvements, which could allow the REQC platform to be a leading one. ",Kein DOI-Link verfügbar,2103.15743v1,Yes,versatile(1)
0000-0001-8699-4306,Lukas Schmid,Universität Würzburg,3D VSG: Long-term Semantic Scene Change Prediction through 3D Variable   Scene Graphs,1970,"  Numerous applications require robots to operate in environments shared with other agents, such as humans or other robots. However, such shared scenes are typically subject to different kinds of long-term semantic scene changes. The ability to model and predict such changes is thus crucial for robot autonomy. In this work, we formalize the task of semantic scene variability estimation and identify three main varieties of semantic scene change: changes in the position of an object, its semantic state, or the composition of a scene as a whole. To represent this variability, we propose the Variable Scene Graph (VSG), which augments existing 3D Scene Graph (SG) representations with the variability attribute, representing the likelihood of discrete long-term change events. We present a novel method, DeltaVSG, to estimate the variability of VSGs in a supervised fashion. We evaluate our method on the 3RScan long-term dataset, showing notable improvements in this novel task over existing approaches. Our method DeltaVSG achieves an accuracy of 77.1% and a recall of 72.3%, often mimicking human intuition about how indoor scenes change over time. We further show the utility of VSG prediction in the task of active robotic change detection, speeding up task completion by 66.0% compared to a scene-change-unaware planner. We make our code available as open-source. ",https://doi.org/10.1109/ICRA48891.2023.10161212,2209.07896v2,Yes,notable(1)
0000-0001-8699-4306,Lukas Schmid,Universität Würzburg,Traversing Mars: Cooperative Informative Path Planning to Efficiently   Navigate Unknown Scenes,1970,"  The ability to traverse an unknown environment is crucial for autonomous robot operations. However, due to the limited sensing capabilities and system constraints, approaching this problem with a single robot agent can be slow, costly, and unsafe. For example, in planetary exploration missions, the wear on the wheels of a rover from abrasive terrain should be minimized at all costs as reparations are infeasible. On the other hand, utilizing a scouting robot such as a micro aerial vehicle (MAV) has the potential to reduce wear and time costs and increasing safety of a follower robot. This work proposes a novel cooperative IPP framework that allows a scout (e.g., an MAV) to efficiently explore the minimum-cost-path for a follower (e.g., a rover) to reach the goal. We derive theoretic guarantees for our algorithm, and prove that the algorithm always terminates, always finds the optimal path if it exists, and terminates early when the found path is shown to be optimal or infeasible. We show in thorough experimental evaluation that the guarantees hold in practice, and that our algorithm is 22.5% quicker to find the optimal path and 15% quicker to terminate compared to existing methods. ",Kein DOI-Link verfügbar,2406.05313v2,Yes,potent(1)
0000-0001-8767-4101,Joachim Schaeffer,TU Darmstadt,Interpretation of High-Dimensional Linear Regression: Effects of   Nullspace and Regularization Demonstrated on Battery Data,1970,"  High-dimensional linear regression is important in many scientific fields. This article considers discrete measured data of underlying smooth latent processes, as is often obtained from chemical or biological systems. Interpretation in high dimensions is challenging because the nullspace and its interplay with regularization shapes regression coefficients. The data's nullspace contains all coefficients that satisfy $\mathbf{Xw}=\mathbf{0}$, thus allowing very different coefficients to yield identical predictions. We developed an optimization formulation to compare regression coefficients and coefficients obtained by physical engineering knowledge to understand which part of the coefficient differences are close to the nullspace. This nullspace method is tested on a synthetic example and lithium-ion battery data. The case studies show that regularization and z-scoring are design choices that, if chosen corresponding to prior physical knowledge, lead to interpretable regression results. Otherwise, the combination of the nullspace and regularization hinders interpretability and can make it impossible to obtain regression coefficients close to the true coefficients when there is a true underlying linear model. Furthermore, we demonstrate that regression methods that do not produce coefficients orthogonal to the nullspace, such as fused lasso, can improve interpretability. In conclusion, the insights gained from the nullspace perspective help to make informed design choices for building regression models on high-dimensional data and reasoning about potential underlying linear models, which are important for system optimization and improving scientific understanding. ",https://doi.org/10.1016/j.compchemeng.2023.108471,2309.00564v2,Yes,potent(1)
0000-0001-8767-4101,Joachim Schaeffer,TU Darmstadt,Lithium-Ion Battery System Health Monitoring and Fault Analysis from   Field Data Using Gaussian Processes,1970,"  Health monitoring, fault analysis, and detection are critical for the safe and sustainable operation of battery systems. We apply Gaussian process resistance models on lithium iron phosphate battery field data to effectively separate the time-dependent and operating point-dependent resistance. The data set contains 29 battery systems returned to the manufacturer for warranty, each with eight cells in series, totaling 232 cells and 131 million data rows. We develop probabilistic fault detection rules using recursive spatiotemporal Gaussian processes. These processes allow the quick processing of over a million data points, enabling advanced online monitoring and furthering the understanding of battery pack failure in the field. The analysis underlines that often, only a single cell shows abnormal behavior or a knee point, consistent with weakest-link failure for cells connected in series, amplified by local resistive heating. The results further the understanding of how batteries degrade and fail in the field and demonstrate the potential of efficient online monitoring based on data. We open-source the code and publish the large data set upon completion of the review of this article. ",Kein DOI-Link verfügbar,2406.19015v2,Yes,potent(1)
0000-0001-8767-4101,Joachim Schaeffer,TU Darmstadt,Learning Model Predictive Control Parameters via Bayesian Optimization   for Battery Fast Charging,1970,"  Tuning parameters in model predictive control (MPC) presents significant challenges, particularly when there is a notable discrepancy between the controller's predictions and the actual behavior of the closed-loop plant. This mismatch may stem from factors like substantial model-plant differences, limited prediction horizons that do not cover the entire time of interest, or unforeseen system disturbances. Such mismatches can jeopardize both performance and safety, including constraint satisfaction. Traditional methods address this issue by modifying the finite horizon cost function to better reflect the overall operational cost, learning parts of the prediction model from data, or implementing robust MPC strategies, which might be either computationally intensive or overly cautious. As an alternative, directly optimizing or learning the controller parameters to enhance closed-loop performance has been proposed. We apply Bayesian optimization for efficient learning of unknown model parameters and parameterized constraint backoff terms, aiming to improve closed-loop performance of battery fast charging. This approach establishes a hierarchical control framework where Bayesian optimization directly fine-tunes closed-loop behavior towards a global and long-term objective, while MPC handles lower-level, short-term control tasks. For lithium-ion battery fast charging, we show that the learning approach not only ensures safe operation but also maximizes closed-loop performance. This includes maintaining the battery's operation below its maximum terminal voltage and reducing charging times, all achieved using a standard nominal MPC model with a short horizon and notable initial model-plant mismatch. ",Kein DOI-Link verfügbar,2404.06125v1,Yes,notable(2)
0000-0001-8767-4101,Joachim Schaeffer,TU Darmstadt,Accounting for the Effects of Probabilistic Uncertainty During Fast   Charging of Lithium-ion Batteries,1970,"  Batteries are nonlinear dynamical systems that can be modeled by Porous Electrode Theory models. The aim of optimal fast charging is to reduce the charging time while keeping battery degradation low. Most past studies assume that model parameters and ambient temperature are a fixed known value and that all PET model parameters are perfectly known. In real battery operation, however, the ambient temperature and the model parameters are uncertain. To ensure that operational constraints are satisfied at all times in the context of model-based optimal control, uncertainty quantification is required. Here, we analyze optimal fast charging for modest uncertainty in the ambient temperature and 23 model parameters. Uncertainty quantification of the battery model is carried out using non-intrusive polynomial chaos expansion and the results are verified with Monte Carlo simulations. The method is investigated for a constant current--constant voltage charging strategy for a battery for which the strategy is known to be standard for fast charging subject to operating below maximum current and charging constraints. Our results demonstrate that uncertainty in ambient temperature results in violations of constraints on the voltage and temperature. Our results identify a subset of key parameters that contribute to fast charging among the overall uncertain parameters. Additionally, it is shown that the constraints represented by voltage, temperature, and lithium-plating overpotential are violated due to uncertainties in the ambient temperature and parameters. The C-rate and charge constraints are then adjusted so that the probability of violating the degradation acceleration condition is below a pre-specified value. This approach demonstrates a computationally efficient approach for determining fast-charging protocols that take probabilistic uncertainties into account. ",Kein DOI-Link verfügbar,2405.01681v1,Yes,potent(1)
0000-0001-8810-6675,Martin Schubert,Friedrich Schiller Universität Jena,Uplink Grant-Free Random Access Solutions for URLLC services in 5G New   Radio,1970,"  The newly introduced ultra-reliable low latency communication service class in 5G New Radio depends on innovative low latency radio resource management solutions that can guarantee high reliability. Grant-free random access, where channel resources are accessed without undergoing assignment through a handshake process, is proposed in 5G New Radio as an important latency reducing solution. However, this comes at an increased likelihood of collisions resulting from uncontrolled channel access, when the same resources are preallocated to a group of users. Novel reliability enhancement techniques are therefore needed. This article provides an overview of grant-free random access in 5G New Radio focusing on the ultra-reliable low latency communication service class, and presents two reliability-enhancing solutions. The first proposes retransmissions over shared resources, whereas the second proposal incorporates grant-free transmission with non-orthogonal multiple access with overlapping transmissions being resolved through the use of advanced receivers. Both proposed solutions result in significant performance gains, in terms of reliability as well as resource efficiency. For example, the proposed non-orthogonal multiple access scheme can support a normalized load of more than 1.5 users/slot at packet loss rates of ~10^{-5} - a significant improvement over the maximum supported load with conventional grant-free schemes like slotted-ALOHA. ",Kein DOI-Link verfügbar,1904.05593v1,Yes,innovative(1)
0000-0001-8947-0911,Thomas Schneider,Friedrich Schiller Universität Jena,The agnostic sampling transceiver,1970,"  Increasing capacity demands in the access networks require inventive concepts for the transmission and distribution of digital as well as analog signals over the same network. Here a new transceiver system, which is completely agnostic for the signals to be transmitted is presented. Nyquist sampling and time multiplexing of N phase and intensity modulated digital and analog channels with one single modulator, as well as the transmission and demultiplexing with another modulator have been demonstrated. The aggregate symbol rate corresponds to the modulator bandwidth and can be further increased by a modification of the setup. No high-speed electronic signal processing or high bandwidth photonics is required. Apart from its simplicity and the possibility to process high bandwidth signals with low bandwidth electronics and photonics, the method has the potential to be easily integrated into any platform and thus, might be a solution for the increasing data rates in future access networks. ",https://doi.org/10.1364/OE.425548,2008.08040v1,Yes,potent(1)
0000-0001-8947-0911,Thomas Schneider,Friedrich Schiller Universität Jena,Visual-Inertial Teach and Repeat for Aerial Inspection,1970,"  Industrial facilities often require periodic visual inspections of key installations. Examining these points of interest is time consuming, potentially hazardous or require special equipment to reach. MAVs are ideal platforms to automate this expensive and tedious task. In this work we present a novel system that enables a human operator to teach a visual inspection task to an autonomous aerial vehicle by simply demonstrating the task using a handheld device. To enable robust operation in confined, GPS-denied environments, the system employs the Google Tango visual-inertial mapping framework as the only source of pose estimates. In a first step the operator records the desired inspection path and defines the inspection points. The mapping framework then computes a feature-based localization map, which is shared with the robot. After take-off, the robot estimates its pose based on this map and plans a smooth trajectory through the way points defined by the operator. Furthermore, the system is able to track the poses of other robots or the operator, localized in the same map, and follow them in real-time while keeping a safe distance. ",Kein DOI-Link verfügbar,1803.09650v1,Yes,potent(1)
0000-0001-8947-0911,Thomas Schneider,Friedrich Schiller Universität Jena,WW-FL: Secure and Private Large-Scale Federated Learning,1970,"  Federated learning (FL) is an efficient approach for large-scale distributed machine learning that promises data privacy by keeping training data on client devices. However, recent research has uncovered vulnerabilities in FL, impacting both security and privacy through poisoning attacks and the potential disclosure of sensitive information in individual model updates as well as the aggregated global model. This paper explores the inadequacies of existing FL protection measures when applied independently, and the challenges of creating effective compositions.   Addressing these issues, we propose WW-FL, an innovative framework that combines secure multi-party computation (MPC) with hierarchical FL to guarantee data and global model privacy. One notable feature of WW-FL is its capability to prevent malicious clients from directly poisoning model parameters, confining them to less destructive data poisoning attacks. We furthermore provide a PyTorch-based FL implementation integrated with Meta's CrypTen MPC framework to systematically measure the performance and robustness of WW-FL. Our extensive evaluation demonstrates that WW-FL is a promising solution for secure and private large-scale federated learning. ",Kein DOI-Link verfügbar,2302.09904v3,Yes,"innovative(1), notable(1), potent(1)"
0000-0001-8947-0911,Thomas Schneider,Friedrich Schiller Universität Jena,Experimental Comparison of Visual-Aided Odometry Methods for Rail   Vehicles,1970,"  Today, rail vehicle localization is based on infrastructure-side Balises (beacons) together with on-board odometry to determine whether a rail segment is occupied. Such a coarse locking leads to a sub-optimal usage of the rail networks. New railway standards propose the use of moving blocks centered around the rail vehicles to increase the capacity of the network. However, this approach requires accurate and robust position and velocity estimation of all vehicles. In this work, we investigate the applicability, challenges and limitations of current visual and visual-inertial motion estimation frameworks for rail applications. An evaluation against RTK-GPS ground truth is performed on multiple datasets recorded in industrial, sub-urban, and forest environments. Our results show that stereo visual-inertial odometry has a great potential to provide a precise motion estimation because of its complementing sensor modalities and shows superior performance in challenging situations compared to other frameworks. ",https://doi.org/10.1109/LRA.2019.2897169,1904.00936v1,Yes,potent(1)
0000-0001-8947-0911,Thomas Schneider,Friedrich Schiller Universität Jena,Privacy-Preserving Speaker Recognition with Cohort Score Normalisation,1970,"  In many voice biometrics applications there is a requirement to preserve privacy, not least because of the recently enforced General Data Protection Regulation (GDPR). Though progress in bringing privacy preservation to voice biometrics is lagging behind developments in other biometrics communities, recent years have seen rapid progress, with secure computation mechanisms such as homomorphic encryption being applied successfully to speaker recognition. Even so, the computational overhead incurred by processing speech data in the encrypted domain is substantial. While still tolerable for single biometric comparisons, most state-of-the-art systems perform some form of cohort-based score normalisation, requiring many thousands of biometric comparisons. The computational overhead is then prohibitive, meaning that one must accept either degraded performance (no score normalisation) or potential for privacy violations. This paper proposes the first computationally feasible approach to privacy-preserving cohort score normalisation. Our solution is a cohort pruning scheme based on secure multi-party computation which enables privacy-preserving score normalisation using probabilistic linear discriminant analysis (PLDA) comparisons. The solution operates upon binary voice representations. While the binarisation is lossy in biometric rank-1 performance, it supports computationally-feasible biometric rank-n comparisons in the encrypted domain. ",Kein DOI-Link verfügbar,1907.03454v1,Yes,potent(1)
0000-0001-8981-0496,Moritz Drupp,Universität Hamburg,Testing the free-rider hypothesis in climate policy,1970,"  Free-riding is widely perceived as a key obstacle for effective climate policy. In the game-theoretic literature on non-cooperative climate policy and on climate cooperation, the free-rider hypothesis is ubiquitous. Yet, the free-rider hypothesis has not been tested empirically in the climate policy context. With the help of a theoretical model, we demonstrate that if free-riding were the main driver of lax climate policies around the globe, then there should be a pronounced country-size effect: Countries with a larger share of the world's population should, all else equal, internalize more climate damages and thus set higher carbon prices. We use this theoretical prediction for testing the free-rider hypothesis empirically. Drawing on data on emission-weighted carbon prices from 2020, while controlling for a host of other potential explanatory variables of carbon pricing, we find that the free-rider hypothesis cannot be supported empirically, based on the criterion that we propose. Hence, other issues may be more important for explaining climate policy stringency or the lack thereof in many countries. ",Kein DOI-Link verfügbar,2211.06209v1,Yes,potent(1)
0000-0001-9002-5129,Tim Schmitz,Heinrich Heine Universität Düsseldorf,Dependence of the affine coherent states quantization on the   parametrization of the affine group,1970,"  The affine coherent states quantization is a promising integral quantization of Hamiltonian systems when the phase space includes at least one conjugate pair of variables which takes values from a half-plane. Such a situation is common for gravitational systems which include singularities. The construction of the quantization map includes a one-to-one mapping of the half-plane onto the affine group. Particular cases of this mapping define specific parametrizations of the group. Our aim is showing that different such parametrizations lead to unitarily inequivalent quantum theories. Depending on the Hamiltonian system under consideration, this dependence could potentially be used constructively. ",Kein DOI-Link verfügbar,1908.10039v3,Yes,potent(1)
0000-0001-9013-435X,Martin Schulz,Technische Universität München,Quantum Algorithms for Solving Ordinary Differential Equations via   Classical Integration Methods,1970,"  Identifying computational tasks suitable for (future) quantum computers is an active field of research. Here we explore utilizing quantum computers for the purpose of solving differential equations. We consider two approaches: (i) basis encoding and fixed-point arithmetic on a digital quantum computer, and (ii) representing and solving high-order Runge-Kutta methods as optimization problems on quantum annealers. As realizations applied to two-dimensional linear ordinary differential equations, we devise and simulate corresponding digital quantum circuits, and implement and run a 6$^{\mathrm{th}}$ order Gauss-Legendre collocation method on a D-Wave 2000Q system, showing good agreement with the reference solution. We find that the quantum annealing approach exhibits the largest potential for high-order implicit integration methods. As promising future scenario, the digital arithmetic method could be employed as an ""oracle"" within quantum search algorithms for inverse problems. ",https://doi.org/10.22331/q-2021-07-13-502,2012.09469v2,Yes,potent(1)
0000-0001-9013-435X,Martin Schulz,Technische Universität München,Design Principles of Dynamic Resource Management for High-Performance   Parallel Programming Models,1970,"  With Dynamic Resource Management (DRM) the resources assigned to a job can be changed dynamically during its execution. From the system's perspective, DRM opens a new level of flexibility in resource allocation and job scheduling and therefore has the potential to improve system efficiency metrics such as the utilization rate, job throughput, energy efficiency, and responsiveness. From the application perspective, users can tailor the resources they request to their needs offering potential optimizations in queuing time or charged costs. Despite these obvious advantages and many attempts over the last decade to establish DRM in HPC, it remains a concept discussed in academia rather than being successfully deployed on production systems. This stems from the fact that support for DRM requires changes in all the layers of the HPC system software stack including applications, programming models, process managers, and resource management software, as well as an extensive and holistic co-design process to establish new techniques and policies for scheduling and resource optimization. In this work, we therefore start with the assumption that resources are accessible by processes executed either on them (e.g., on CPU) or controlling them (e.g., GPU-offloading). Then, the overall DRM problem can be decomposed into dynamic process management (DPM) and dynamic resource mapping or allocation (DRA). The former determines which processes (or which change in processes) must be managed and the latter identifies the resources where they will be executed. The interfaces for such \mbox{DPM/DPA} in these layers need to be standardized, which requires a careful design to be interoperable while providing high flexibility. Based on a survey of existing approaches we propose design principles, that form the basis of a holistic approach to DMR in HPC and provide a prototype implementation using MPI. ",Kein DOI-Link verfügbar,2403.17107v1,Yes,potent(2)
0000-0001-9013-435X,Martin Schulz,Technische Universität München,On the Convergence of Malleability and the HPC PowerStack: Exploiting   Dynamism in Over-Provisioned and Power-Constrained HPC Systems,1970,"  Recent High-Performance Computing (HPC) systems are facing important challenges, such as massive power consumption, while at the same time significantly under-utilized system resources. Given the power consumption trends, future systems will be deployed in an over-provisioned manner where more resources are installed than they can afford to power simultaneously. In such a scenario, maximizing resource utilization and energy efficiency, while keeping a given power constraint, is pivotal. Driven by this observation, in this position paper we first highlight the recent trends of resource management techniques, with a particular focus on malleability support (i.e., dynamically scaling resource allocations/requirements for a job), co-scheduling (i.e., co-locating multiple jobs within a node), and power management. Second, we consider putting them together, assess their relationships/synergies, and discuss the functionality requirements in each software component for future over-provisioned and power-constrained HPC systems. Third, we briefly introduce our ongoing efforts on the integration of software tools, which will ultimately lead to the convergence of malleability and power management, as it is designed in the HPC PowerStack initiative. ",https://doi.org/10.1007/978-3-031-23220-6_14,2405.03847v1,Yes,pivotal(1)
0000-0001-9021-3197,Dominik Brilhaus,Heinrich Heine Universität Düsseldorf,Ontologies for increasing the FAIRness of plant research data,1970,"  The importance of improving the FAIRness (findability, accessibility, interoperability, reusability) of research data is undeniable, especially in the face of large, complex datasets currently being produced by omics technologies. Facilitating the integration of a dataset with other types of data increases the likelihood of reuse, and the potential of answering novel research questions. Ontologies are a useful tool for semantically tagging datasets as adding relevant metadata increases the understanding of how data was produced and increases its interoperability. Ontologies provide concepts for a particular domain as well as the relationships between concepts. By tagging data with ontology terms, data becomes both human and machine interpretable, allowing for increased reuse and interoperability. However, the task of identifying ontologies relevant to a particular research domain or technology is challenging, especially within the diverse realm of fundamental plant research. In this review, we outline the ontologies most relevant to the fundamental plant sciences and how they can be used to annotate data related to plant-specific experiments within metadata frameworks, such as Investigation-Study-Assay (ISA). We also outline repositories and platforms most useful for identifying applicable ontologies or finding ontology terms. ",Kein DOI-Link verfügbar,2309.07129v1,Yes,potent(1)
0000-0001-9038-3196,Tim Rolff,Universität Hamburg,Immersive Neural Graphics Primitives,1970,"  Neural radiance field (NeRF), in particular its extension by instant neural graphics primitives, is a novel rendering method for view synthesis that uses real-world images to build photo-realistic immersive virtual scenes. Despite its potential, research on the combination of NeRF and virtual reality (VR) remains sparse. Currently, there is no integration into typical VR systems available, and the performance and suitability of NeRF implementations for VR have not been evaluated, for instance, for different scene complexities or screen resolutions. In this paper, we present and evaluate a NeRF-based framework that is capable of rendering scenes in immersive VR allowing users to freely move their heads to explore complex real-world scenes. We evaluate our framework by benchmarking three different NeRF scenes concerning their rendering performance at different scene complexities and resolutions. Utilizing super-resolution, our approach can yield a frame rate of 30 frames per second with a resolution of 1280x720 pixels per eye. We discuss potential applications of our framework and provide an open source implementation online. ",Kein DOI-Link verfügbar,2211.13494v1,Yes,potent(2)
0000-0001-9038-3196,Tim Rolff,Universität Hamburg,Select High-Level Features: Efficient Experts from a Hierarchical   Classification Network,1970,"  This study introduces a novel expert generation method that dynamically reduces task and computational complexity without compromising predictive performance. It is based on a new hierarchical classification network topology that combines sequential processing of generic low-level features with parallelism and nesting of high-level features. This structure allows for the innovative extraction technique: the ability to select only high-level features of task-relevant categories. In certain cases, it is possible to skip almost all unneeded high-level features, which can significantly reduce the inference cost and is highly beneficial in resource-constrained conditions. We believe this method paves the way for future network designs that are lightweight and adaptable, making them suitable for a wide range of applications, from compact edge devices to large-scale clouds. In terms of dynamic inference our methodology can achieve an exclusion of up to 88.7\,\% of parameters and 73.4\,\% fewer giga-multiply accumulate (GMAC) operations, analysis against comparative baselines showing an average reduction of 47.6\,\% in parameters and 5.8\,\% in GMACs across the cases we evaluated. ",Kein DOI-Link verfügbar,2403.05601v1,Yes,innovative(1)
0000-0001-9042-1076,Nils Kreher,Universität Siegen,Gauge anomalies in the Standard-Model Effective Field Theory,1970,"  If the Standard Model is understood as the first term of an effective field theory, the anomaly-cancellation conditions have to be worked out and fulfilled order by order in the effective field-theory expansion. We bring attention to this issue and study in detail a subset of the anomalies of the effective field theories at the electroweak scale. The end result is a set of sum rules for the operator coefficients. These conditions, which are necessary for the internal consistency of the theory, lead to a number of phenomenological consequences when implemented in analyses of experimental data. In particular, they not only decrease the number of free parameters in different physical processes but have the potential to relate processes with different flavor content. Conversely, a violation of these conditions would necessarily imply the existence of undetected non-decoupling new physics associated with the electroweak energy scale. ",Kein DOI-Link verfügbar,2011.09976v1,Yes,potent(1)
0000-0001-9042-1076,Nils Kreher,Universität Siegen,Precision Test of the Muon-Higgs Coupling at a High-energy Muon Collider,1970,"  We explore the sensitivity of directly testing the muon-Higgs coupling at a high-energy muon collider. This is strongly motivated if there exists new physics that is not aligned with the Standard Model Yukawa interactions which are responsible for the fermion mass generation. We illustrate a few such examples for physics beyond the Standard Model. With the accidentally small value of the muon Yukawa coupling and its subtle role in the high-energy production of multiple (vector and Higgs) bosons, we show that it is possible to measure the muon-Higgs coupling to an accuracy of ten percent for a 10 TeV muon collider and a few percent for a 30 TeV machine by utilizing the three boson production, potentially sensitive to a new physics scale about $\Lambda \sim 30-100$ TeV. ",https://doi.org/10.1007/JHEP12(2021)162,2108.05362v3,Yes,potent(1)
0000-0001-9042-1076,Nils Kreher,Universität Siegen,Precision test of the muon-Higgs coupling at a high-energy muon collider,1970,"  We explore the sensitivity of directly testing the muon-Higgs coupling at a high-energy muon collider. This is strongly motivated if there exists new physics that is not aligned with the Standard Model Yukawa interactions which are responsible for the fermion mass generation. We illustrate a few such examples for physics beyond the Standard Model. With the accidentally small value of the muon Yukawa coupling and its subtle role in the high-energy production of multiple (vector and Higgs) bosons, we show that it is possible to measure the muon-Higgs coupling to an accuracy of ten percent for a 10 TeV muon collider and a few percent for a 30 TeV machine by utilizing the three boson production, potentially sensitive to a new physics scale about $\Lambda \sim$ 30-100 TeV. ",Kein DOI-Link verfügbar,2212.01323v1,Yes,potent(1)
0000-0001-9064-6865,Matthias Klein,Ludwig-Maximilians-Universität München,More Confining N=1 SUSY Gauge Theories From Non-Abelian Duality,1970,  We expand on an idea of Seiberg that an N=1 supersymmetric gauge theory shows confinement without breaking of chiral symmetry when the gauge symmetry of its magnetic dual is completely broken by the Higgs effect. This has recently been applied to some models involving tensor fields and an appropriate tree-level superpotential. We show how the confining spectrum of a supersymmetric gauge theory can easily be derived when a magnetic dual is known and we determine it explicitly for many models containing fields in second rank tensor representations. We also give the form of the confining superpotential for most of these models. ,https://doi.org/10.1016/S0550-3213(99)00229-1,hep-th/9812155v1,Yes,potent(2)
0000-0001-9064-6865,Matthias Klein,Ludwig-Maximilians-Universität München,Confining N=1 SUSY gauge theories from Seiberg duality,1970,  In this talk I review and generalize an idea of Seiberg that an N=1 supersymmetric gauge theory shows confinement without breaking of chiral symmetry when the gauge symmetry of its magnetic dual is completely broken by the Higgs effect. It is shown how the confining spectrum of a supersymmetric gauge theory can easily be derived when a magnetic dual is known and this method is applied to many models containing fields in second rank tensor representations and an appropriate tree-level superpotential. ,Kein DOI-Link verfügbar,hep-th/9904210v1,Yes,potent(1)
0000-0001-9064-6865,Matthias Klein,Ludwig-Maximilians-Universität München,Quantum modified moduli spaces and field dependent gauge couplings,1970,"  In this paper we discuss quantum modified moduli spaces in supergravity. We examine a model suggested by Izawa and Yanagida and by Intriligator and Thomas that breaks global supersymmetry by a quantum deformation of the classical moduli space. We determine the minimum of the supergravity potential when the gauge coupling is taken to depend on a dynamical field, typically a modulus of string theory. We find that the only minimum is at the trivial configuration of vanishing coupling constant and unbroken supersymmetry. We also discuss models involving more complicated superpotentials and find that the gauge coupling is only stabilized in a supersymmetric ground state. ",https://doi.org/10.1016/S0550-3213(98)00498-2,hep-th/9803143v1,Yes,potent(2)
0000-0001-9064-6865,Matthias Klein,Ludwig-Maximilians-Universität München,On effective superpotentials and Kutasov duality,1970,"  We derive the effective superpotential for an N=1 SU(N_c) gauge theory with one massless adjoint field and N_f massless fundamental flavors and cubic tree-level superpotential for the adjoint field. This is a generalization of the Affleck-Dine-Seiberg superpotential to gauge theories with one massless adjoint matter field. Using Kutasov's generalization of Seiberg duality, we then find the effective superpotential for a related theory with massive fundamental flavors. ",https://doi.org/10.1088/1126-6708/2003/10/050,hep-th/0309044v1,Yes,potent(4)
0000-0001-9064-6865,Matthias Klein,Ludwig-Maximilians-Universität München,"Matrix model, Kutasov duality and Factorization of Seiberg-Witten Curves",1970,  We study the duality of $\mathcal{N}=1$ gauge theories in the presence of a massless adjoint field and massive quarks by calculating the superpotential using the Dighkgraaf-Vafa matrix model and by comparing with the previous result coming from Kutasov duality. The Kutasov duality method gives a result in which one instanton term is absent. The matrix model method confirms it and also show that the absence of the one instanton term is related to the masslessness of the adjoint field. ,Kein DOI-Link verfügbar,hep-th/0310078v2,Yes,potent(1)
0000-0001-9064-6865,Matthias Klein,Ludwig-Maximilians-Universität München,The Dilaton Potential from N= 1*,1970,"  Recent understanding of {\cal N}=1* supersymmetric theory (mass deformed {\cal N}=4) has made it possible to find an exact superpotential which encodes the properties of the different phases of the theory. We consider this superpotential as an illustrative example for the source of a nontrivial scalar potential for the string theory dilaton and study its properties. The superpotential is characterized by the rank of the corresponding gauge group (N) and integers p,q,k labelling the different massive phases of the theory. For generic values of these parameters, we find the expected runaway behaviour of the potential to vanishing string coupling. But there are also supersymmetric minima at weak coupling stabilizing the dilaton field. An interesting property of this potential is that there is a proliferation of supersymmetric vacua in the confining phases, with the number of vacua increasing with N and leading to a kind of staircase potential. For a range of parameters, it is possible to obtain realistic values for the gauge coupling. ",https://doi.org/10.1016/S0550-3213(01)00202-4,hep-th/0101186v3,Yes,potent(7)
0000-0001-9103-086X,Alexander Bartl,Technische Universität Darmstadt,Charged-current reactions in the supernova neutrino-sphere,1970,"  We calculate neutrino absorption rates due to charged-current reactions $\nu_e+n \rightarrow e^- + p $ and $\bar{\nu}_e+p \rightarrow e^+ + n $ in the outer regions of a newly born neutron star called the neutrino-sphere. To improve on recent work which has shown that nuclear mean fields enhance the $\nu_e$ cross-section and suppress the $\bar{\nu}_e$ cross-section, we employ realistic nucleon-nucleon interactions that fit measured scattering phase shifts. Using these interactions we calculate the momentum-, density-, and temperature-dependent nucleon self-energies in the Hartree-Fock approximation. A potential derived from chiral effective field theory and a pseudo-potential constructed to reproduce nucleon-nucleon phase shifts at the mean-field level are used to study the equilibrium proton fraction and the charged-current rates are studied in detail. We compare our results to earlier calculations obtained using phenomenological mean-field models and to those obtained in the virial expansion valid at low density. We find that for typical ambient conditions in the neutrino-sphere, $T=5-10$ MeV and $\rho =10^{11}-10^{13}$ g/cm$^3$, the difference between the $\nu_{e}$ and $\bar{\nu}_e$ absorption rates is much larger than predicted earlier. Our results have important implications for heavy-element nucleosynthesis in supernovae and for supernova neutrino detection. ",https://doi.org/10.1103/PhysRevC.91.035806,1408.3368v3,Yes,potent(2)
0000-0001-9289-4467,Tobias Frank,Leibniz Universität Hannover,Femtosecond photo-switching of interface polaritons in black phosphorus   heterostructures,1970,"  The possibility of hybridizing collective electronic motion with mid-infrared (mid-IR) light to form surface polaritons has made van der Waals layered materials a versatile platform for extreme light confinement and tailored nanophotonics. Graphene and its heterostructures have attracted particular attention because the absence of an energy gap allows for plasmon polaritons to be continuously tuned. Here, we introduce black phosphorus (BP) as a promising new material in surface polaritonics that features key advantages for ultrafast switching. Unlike graphene, BP is a van der Waals bonded semiconductor, which enables high-contrast interband excitation of electron-hole pairs by ultrashort near-infrared (near-IR) pulses. We design a SiO$_2$/BP/SiO$_2$ heterostructure in which the surface phonon modes of the SiO$_2$ layers hybridize with surface plasmon modes in BP that can be activated by photo-induced interband excitation. Within the Reststrahlen band of SiO$_2$, the hybrid interface polariton assumes surface-phonon-like properties, with a well-defined frequency and momentum and excellent coherence. During the lifetime of the photogenerated electron-hole plasma, coherent polariton waves can be launched by a broadband mid-IR pulse coupled to the tip of a scattering-type scanning near-field optical microscopy (s-SNOM) setup. The scattered radiation allows us to trace the new hybrid mode in time, energy, and space. We find that the surface mode can be activated within ~50 fs and disappears within 5 ps, as the electron-hole pairs in BP recombine. The excellent switching contrast and switching speed, the coherence properties, and the constant wavelength of this transient mode make it a promising candidate for ultrafast nanophotonic devices. ",https://doi.org/10.1038/nnano.2016.261,1709.09846v1,Yes,versatile(1)
0000-0001-9300-9626,Matthias Uhl,Universität Stuttgart,Propagator for a driven Brownian particle in step potentials,1970,"  Although driven Brownian particles are ubiquitous in stochastic dynamics and often serve as paradigmatic model systems for many aspects of stochastic thermodynamics, fully analytically solvable models are few and far between. In this paper, we introduce an iterative calculation scheme, similar to the method of images in electrostatics, that enables one to obtain the propagator if the potential consists of a finite number of steps. For the special case of a single potential step, this method converges after one iteration, thus providing an expression for the propagator in closed form. In all other cases, the iteration results in an approximation that holds for times smaller than some characteristic timescale that depends on the number of iterations performed. This method can also be applied to a related class of systems like Brownian ratchets, which do not formally contain step potentials in their definition, but impose the same kind of boundary conditions that are caused by potential steps. ",https://doi.org/10.1088/1751-8121/abc21f,2009.03201v1,Yes,potent(4)
0000-0001-9300-9626,Matthias Uhl,Universität Stuttgart,Zombies in the Loop? Humans Trust Untrustworthy AI-Advisors for Ethical   Decisions,1970,"  Departing from the claim that AI needs to be trustworthy, we find that ethical advice from an AI-powered algorithm is trusted even when its users know nothing about its training data and when they learn information about it that warrants distrust. We conducted online experiments where the subjects took the role of decision-makers who received advice from an algorithm on how to deal with an ethical dilemma. We manipulated the information about the algorithm and studied its influence. Our findings suggest that AI is overtrusted rather than distrusted. We suggest digital literacy as a potential remedy to ensure the responsible use of AI. ",Kein DOI-Link verfügbar,2106.16122v2,Yes,potent(1)
0000-0001-9371-1087,Christoph Niemann,Universität Rostock,On the background-gyroresonant character of the Bell instability,1970,"  We show that the Bell instability, which is widely considered potentially important for cosmic-ray acceleration, is the low-frequency limit of a gyroresonant interaction between the protons of the interstellar medium and shear-Alfv\'en waves. At large cosmic-ray current densities, its growth rate is therefore limited by the proton gyrofrequency, and two modes emerge from the cold-beam dispersion relation. A third mode driven by electron gyroresonance is only weakly unstable at low current densities. We discuss implications for magnetic-field amplification and its saturation in the vicinity of supernova remnants. ",https://doi.org/10.3847/1538-4357/aafad0,1811.05666v1,Yes,potent(1)
0000-0001-9371-1087,Christoph Niemann,Universität Rostock,Optimal Opinion Control: The Campaign Problem,1970,"  Opinion dynamics is nowadays a very common field of research. In this article we formulate and then study a novel, namely strategic perspective on such dynamics: There are the usual normal agents that update their opinions, for instance according the well-known bounded confidence mechanism. But, additionally, there is at least one strategic agent. That agent uses opinions as freely selectable strategies to get control on the dynamics: The strategic agent of our benchmark problem tries, during a campaign of a certain length, to influence the ongoing dynamics among normal agents with strategically placed opinions (one per period) in such a way, that, by the end of the campaign, as much as possible normals end up with opinions in a certain interval of the opinion space. Structurally, such a problem is an optimal control problem. That type of problem is ubiquitous. Resorting to advanced and partly non-standard methods for computing optimal controls, we solve some instances of the campaign problem. But even for a very small number of normal agents, just one strategic agent, and a ten-period campaign length, the problem turns out to be extremely difficult. Explicitly we discuss moral and political concerns that immediately arise, if someone starts to analyze the possibilities of an optimal opinion control. ",Kein DOI-Link verfügbar,1410.8419v2,Yes,strategically(1)
0000-0001-9439-8686,Christoph Hauser,Martin-Luther-Universität Halle-Wittenberg,Enhancement of spin mixing conductance in   La$_{0.7}$Sr$_{0.3}$MnO$_{3}$/LaNiO$_{3}$/SrRuO$_{3}$ heterostructures,1970,"  We investigate spin pumping and the effective spin mixing conductance in heterostructures based on magnetic oxide trilayers composed of La$_{0.7}$Sr$_{0.3}$MnO$_3$ (LSMO), LaNiO$_3$ (LNO), and SrRuO$_3$ (SRO). The heterostructures serve as a model system for an estimation of the effective spin mixing conductance at the different interfaces. Our results show that by introducing a LNO interlayer between LSMO and SRO, the total effective spin mixing conductance increases due to the much more favourable interface of LSMO/LNO with respect to the LSMO/SRO interface. Neverheless, the spin current into the SRO does not decrease because of the spin diffusion length of $\lambda_\text{LNO}\approx$3.3 nm in the LNO. This value is two times higher than that of SRO. Our results show the potential of using oxide interfaces to tune the effective spin mixing conductance in heterostructures and to bring novel functionalities into spintronics by implementing complex oxides. ",https://doi.org/10.1002/pssb.201900606,1909.12766v1,Yes,potent(1)
0000-0001-9497-6378,Weiqiang Chen,Technische Universität Berlin,Electron Tunneling in Monolayer and Bilayer Graphene,1970,"  Electron's tunneling through potential barrier in monolayer and bilayer graphene lattices is investigated by using full tight-binding model. Emphasis is placed on the resonance tunneling feature and inter-valley scattering probability. It is shown that normal incidence transmission probabilities for monolayer and bilayer graphene exhibit different properties. Our calculation indicates that valleytronics in graphene systems may be detected, generated and controlled by changing the structure parameters of the external electric potential. ",Kein DOI-Link verfügbar,0808.3032v1,Yes,potent(2)
0000-0001-9497-6378,Weiqiang Chen,Technische Universität Berlin,Global phase diagram of three-dimensional extended Boson Hubbard model -   a continuous time Quantum Monte Carlo study,1970,"  We present the global phase diagram of the extended boson Hubbard model on a simple cubic lattice by quantum Monte Carlo simulation with worm update algorithm. Four kinds of phases are supported by this model, including superfluid, supersolid, Mott, and charge density wave (CDW) states, which are identified in the phase diagram of chemical potential $\mu$ versus nearest neighbor interaction V . By changing the chemical potential, a continuous transition is found from the Mott phase to a superfluid phase without breaking the translational symmetry. For an insulating CDW state, adding particles to it gives rise to a continuous transition to a supersolid phase, while removing particles usually leads to a first-order one to either supersolid or superfluid phase. By tuning the nearest neighbor interaction, one can realize the transition between two insulating phases, Mott and CDW with the same particle density, which turns out to be of the first-order. We also demonstrate that a supersolid phase with average particle density less than 1/2 can exist in a small region of $\mu$ - V phase diagram. ",https://doi.org/10.1103/PhysRevB.84.054512,1104.4678v1,Yes,potent(2)
0000-0001-9497-6378,Weiqiang Chen,Technische Universität Berlin,Trapped Ultracold Bosons in Periodically Modulated Lattices,1970,"  Motivated by the recent rapid development of the field of quantum gases in optical lattices, we present a comprehensive study of the spectrum of ultracold atoms in a one-dimensional optical lattice subjected to a periodic lattice modulation. Using the time-dependent density-matrix renormalization group method, we study the dynamical response due to lattice modulations in different quantum phases of the system with varying density. For the Mott insulating state, we identify several excitation processes, which provide important information about the density profile of the gases. For the superfluid, the dynamical response can be well described in a local density approximation. This simplification can be valuable in understanding the strong-correlated superfluid in a slow-varying harmonic potential. All these spectroscopic features of an inhomogeneous system can be used as a test for the validity of the Bose-Hubbard model in a parabolic trapping potential. ",https://doi.org/10.1103/PhysRevA.84.043608,1108.4574v2,Yes,potent(2)
0000-0001-9497-6378,Weiqiang Chen,Technische Universität Berlin,Population-Based Evolutionary Gaming for Unsupervised Person   Re-identification,1970,"  Unsupervised person re-identification has achieved great success through the self-improvement of individual neural networks. However, limited by the lack of diversity of discriminant information, a single network has difficulty learning sufficient discrimination ability by itself under unsupervised conditions. To address this limit, we develop a population-based evolutionary gaming (PEG) framework in which a population of diverse neural networks is trained concurrently through selection, reproduction, mutation, and population mutual learning iteratively. Specifically, the selection of networks to preserve is modeled as a cooperative game and solved by the best-response dynamics, then the reproduction and mutation are implemented by cloning and fluctuating hyper-parameters of networks to learn more diversity, and population mutual learning improves the discrimination of networks by knowledge distillation from each other within the population. In addition, we propose a cross-reference scatter (CRS) to approximately evaluate re-ID models without labeled samples and adopt it as the criterion of network selection in PEG. CRS measures a model's performance by indirectly estimating the accuracy of its predicted pseudo-labels according to the cohesion and separation of the feature space. Extensive experiments demonstrate that (1) CRS approximately measures the performance of models without labeled samples; (2) and PEG produces new state-of-the-art accuracy for person re-identification, indicating the great potential of population-based network cooperative training for unsupervised learning. ",Kein DOI-Link verfügbar,2306.05236v1,Yes,potent(1)
0000-0001-9497-6378,Weiqiang Chen,Technische Universität Berlin,Cherenkov Radiation Induced by Megavolt X-Ray Beams in the Second   Near-Infrared Window,1970,"  Although the Cherenkov light contains mostly short-wavelength components, it is beneficial in the aspect of imaging to visualize it in the second near-infrared (NIR-II) window. In this study, Cherenkov imaging was performed within the NIR-II range on megavolt X-ray beams delivered by a medical linear accelerator. A shielding system was used to reduce the noises of the NIR-II image, enabling high quality signal acquisition. It was demonstrated that the NIR-II Cherenkov imaging is potentially a tool for radiotherapy dosimetry, and correlates well with different parameters. The NIR-II Cherenkov imaging is less susceptible to scattering, while more susceptible to absorption, compared with the visible-near-infrared imaging. Finally, a mouse was used to demonstrate this technology on animals. These results indicate the potentials to apply NIR-II Cherenkov imaging in the practice of radiotherapy. ",https://doi.org/10.1016/j.optcom.2019.05.017,1901.00422v2,Yes,potent(2)
0000-0001-9497-6378,Weiqiang Chen,Technische Universität Berlin,Edelstein effect induced superconducting diode effect in inversion   symmetry breaking MoTe$_2$ Josephson junctions,1970,"  Superconducting diode effect (SDE) with nonreciprocal supercurrent transport has attracted intense attention recently, not only for its intriguing physics, but also for its great application potential in superconducting circuits. It is revealed in this work that planar Josephson junctions (JJs) based on type-II Weyl semimetal (WSM) MoTe$_2$ can exhibit a prominent SDE due to the emergence of asymmetric Josephson effect (AJE) in perpendicular magnetic fields. The AJE manifests itself in a very large asymmetry in the critical supercurrents with respect to the current direction. The sign of this asymmetry can also be effectively modulated by the external magnetic field. Considering the special noncentrosymmetric crystal symmetry of MoTe$_2$, this AJE is understood in terms of the Edelstein effect, which induces a nontrivial phase shift in the current phase relation of the junctions. Besides these, it is further demonstrated that the rectification of supercurrent in such MoTe$_2$ JJs with the rectification efficiency up to 50.4%, unveiling the great application potential of WSMs in superconducting electronics. ",https://doi.org/10.1002/adfm.202311229,2303.07701v2,Yes,potent(2)
0000-0001-9513-2468,Nicole Jung,Karlsruhe Institut für Technologie,What is missing in autonomous discovery: Open challenges for the   community,1970,"  Self-driving labs (SDLs) leverage combinations of artificial intelligence, automation, and advanced computing to accelerate scientific discovery. The promise of this field has given rise to a rich community of passionate scientists, engineers, and social scientists, as evidenced by the development of the Acceleration Consortium and recent Accelerate Conference. Despite its strengths, this rapidly developing field presents numerous opportunities for growth, challenges to overcome, and potential risks of which to remain aware. This community perspective builds on a discourse instantiated during the first Accelerate Conference, and looks to the future of self-driving labs with a tempered optimism. Incorporating input from academia, government, and industry, we briefly describe the current status of self-driving labs, then turn our attention to barriers, opportunities, and a vision for what is possible. Our field is delivering solutions in technology and infrastructure, artificial intelligence and knowledge generation, and education and workforce development. In the spirit of community, we intend for this work to foster discussion and drive best practices as our field grows. ",Kein DOI-Link verfügbar,2304.11120v2,Yes,potent(1)
0000-0001-9536-7873,Alexander Winkler,"RWTH Aachen Universität, Rheinisch-Westfälische Technische Hochschule Aachen",Simulation of fluid-solid coexistence in finite volumes: A method to   study the properties of wall-attached crystalline nuclei,1970,"  The Asakura-Oosawa model for colloid-polymer mixtures is studied by Monte Carlo simulations at densities inside the two-phase coexistence region of fluid and solid. Choosing a geometry where the system is confined between two flat walls, and a wall-colloid potential that leads to incomplete wetting of the crystal at the wall, conditions can be created where a single nanoscopic wall-attached crystalline cluster coexists with fluid in the remainder of the simulation box. Following related ideas that have been useful to study heterogeneous nucleation of liquid droplets at the vapor-liquid coexistence, we estimate the contact angles from observations of the crystalline clusters in thermal equilibrium. We find fair agreement with a prediction based on Young's equation, using estimates of interface and wall tension from the study of flat surfaces. It is shown that the pressure versus density curve of the finite system exhibits a loop, but the pressure maximum signifies the ""droplet evaporation-condensation"" transition and thus has nothing in common with a van der Waals-like loop. Preparing systems where the packing fraction is deep inside the two-phase coexistence region, the system spontaneously forms a ""slab state"", with two wall-attached crystalline domains separated by (flat) interfaces from liquid in full equilibrium with the crystal in between; analysis of such states allows a precise estimation of the bulk equilibrium properties at phase coexistence. ",https://doi.org/10.1063/1.3699981,1203.3716v1,Yes,potent(1)
0000-0001-9536-7873,Alexander Winkler,"RWTH Aachen Universität, Rheinisch-Westfälische Technische Hochschule Aachen",Capillary Condensation in Cylindrical Pores: Monte Carlo Study of the   Interplay of Surface and Finite Size Effects,1970,"  When a fluid that undergoes a vapor to liquid transition in the bulk is confined to a long cylindrical pore, the phase transition is shifted (mostly due to surface effects at the walls of the pore) and rounded (due to finite size effects). The nature of the phase coexistence at the transition depends on the length of the pore: For very long pores the system is axially homogeneous at low temperatures. At the chemical potential where the transition takes place fluctuations occur between vapor-like and liquid-like states of the cylinder as a whole. At somewhat higher temperatures (but still far below bulk criticality) the system at phase coexistence is in an axially inhomogeneous multi-domain state, where long cylindrical liquid-like and vapor-like domains alternate. Using Monte Carlo simulations for the Ising/lattice gas model and the Asakura-Oosawa model of colloid-polymer mixtures the transition between these two different scenarios is characterized. It is shown that the density distribution changes gradually from a double-peak structure to a triple-peak shape, and the correlation length in axial direction (measuring the equilibrium domain length) becomes much smaller than the cylinder length. The (rounded) transition to the disordered phase of the fluid occurs when the axial correlation length has decreased to a value comparable to the cylinder diameter. It is also suggested that adsorption hysteresis vanishes when the transition from the simple domain state to the multi-domain state of the cylindrical pore occurs. We predict that the difference between the pore critical temperature and the hysteresis critical emperature should increase logarithmically with the length of the pore. ",https://doi.org/10.1063/1.3502684,1006.5843v1,Yes,potent(1)
0000-0001-9536-7873,Alexander Winkler,"RWTH Aachen Universität, Rheinisch-Westfälische Technische Hochschule Aachen",Methods to Compute Pressure and Wall Tension in Fluids containing Hard   Particles,1970,"  Colloidal systems are often modelled as fluids of hard particles (possibly with an additional soft attraction, e.g. caused by polymers also contained in the suspension). in simulations of such systems, the virial theorem cannot be straightforwardly applied to obtain the components of the pressure tensor. In systems confined by walls, it is hence also not straightforward to extract the excess energy due to the wall (the ""wall tension"") from the pressure tensor anisotropy. A comparative evaluation of several methods to circumvent this problem is presented, using as examples fluids of hard spheres and the Asakura-Oosawa model of colloid-polymer mixtures with a size ratio $q=0.15$ (for which the effect of the polymers can be integrated out to yield an effective attractive potential between the colloids). Factors limiting the accuracy of the various methods are carefully discussed, and controlling these factors very good mutual agreement between the various methods is found. ",https://doi.org/10.1142/S0129183112400116,1110.1483v1,Yes,potent(1)
0000-0001-9536-7873,Alexander Winkler,"RWTH Aachen Universität, Rheinisch-Westfälische Technische Hochschule Aachen",Hard sphere fluids confined between soft repulsive walls: A comparative   study using Monte Carlo and density functional methods,1970,"  Hard-sphere fluids confined between parallel plates a distance $D$ apart are studied for a wide range of packing fractions, including also the onset of crystallization, applying Monte Carlo simulation techniques and density functional theory. The walls repel the hard spheres (of diameter $\sigma$) with a Weeks-Chandler-Andersen (WCA) potential $V_{WCA}(z) = 4 \epsilon [(\sigma_w/z)^{12}-(\sigma_w/z)^6 + 1/4]$, with range $\sigma_w = \sigma/2$. We vary the strength $\epsilon$ over a wide range and the case of simple hard walls is also treated for comparison. By the variation of $\epsilon$ one can change both the surface excess packing fraction and the wall-fluid $(\gamma_{wf})$ and wall-crystal $(\gamma_{wc})$ surface free energies. Several different methods to extract $\gamma_{wf}$ and $\gamma_{wc}$ from Monte Carlo (MC) simulations are implemented, and their accuracy and efficiency is comparatively discussed. The density functional theory (DFT) using Fundamental Measure functionals is found to be quantitatively accurate over a wide range of packing fractions; small deviations between DFT and MC near the fluid to crystal transition need to be studied further. Our results on density profiles near soft walls could be useful to interpret corresponding experiments with suitable colloidal dispersions. ",https://doi.org/10.1063/1.3593197,1103.4069v2,Yes,potent(1)
0000-0001-9563-2147,Lars Meckbach,Philipps-Universität Marburg,Influence of the effective layer thickness on the groundstate and   excitonic properties of transition-metal dichalcogenide systems,1970,"  A self-consistent scheme for the calculations of the interacting groundstate and the near bandgap optical spectra of mono- and multilayer transition-metal-dichalcogenide systems is presented. The approach combines a dielectric model for the Coulomb interaction potential in a multilayer environment, gap equations for the renormalized groundstate, and the Dirac-Wannier-equation to determine the excitonic properties. To account for the extension of the individual monolayers perpendicular to their basic plane, an effective thickness parameter in the Coulomb interaction potential is introduced. Numerical evaluations for the example of MoS$_2$ show that the resulting finite size effects lead to significant modifications in the optical spectra, reproducing the experimentally observed non hydrogenic features of the excitonic resonance series. Applying the theory for multi-layer configurations, a consistent description of the near bandgap optical properties is obtained all the way from monolayer to bulk. In addition to the well-known in-plane excitons, also interlayer excitons occur in multilayer systems suggesting a reinterpretation of experimental results obtained for bulk material. ",https://doi.org/10.1103/PhysRevB.97.035425,1709.09056v1,Yes,potent(2)
0000-0001-9600-9170,Michael Fischer,Albert-Ludwigs-Universität Freiburg,Plateau-reduced Differentiable Path Tracing,1970,"  Current differentiable renderers provide light transport gradients with respect to arbitrary scene parameters. However, the mere existence of these gradients does not guarantee useful update steps in an optimization. Instead, inverse rendering might not converge due to inherent plateaus, i.e., regions of zero gradient, in the objective function. We propose to alleviate this by convolving the high-dimensional rendering function that maps scene parameters to images with an additional kernel that blurs the parameter space. We describe two Monte Carlo estimators to compute plateau-free gradients efficiently, i.e., with low variance, and show that these translate into net-gains in optimization error and runtime performance. Our approach is a straightforward extension to both black-box and differentiable renderers and enables optimization of problems with intricate light transport, such as caustics or global illumination, that existing differentiable renderers do not converge on. ",Kein DOI-Link verfügbar,2211.17263v2,Yes,intricate(1)
0000-0001-9600-9170,Michael Fischer,Albert-Ludwigs-Universität Freiburg,Quantum behavior of a superconducting Duffing oscillator at the   dissipative phase transition,1970,"  Understanding the non-deterministic behavior of deterministic nonlinear systems has been an implicit dream since Lorenz named it the ""butterfly effect"". A prominent example is the hysteresis and bistability of the Duffing oscillator, which in the classical description is attributed to the coexistence of two steady states in a double-well potential. However, this interpretation fails in the quantum-mechanical perspective, where a single unique steady state is allowed in the whole parameter space. Here, we measure the non-equilibrium dynamics of a superconducting Duffing oscillator and reconcile the classical and quantum descriptions in a unified picture of quantum metastability. We demonstrate that the two classically regarded steady states are in fact metastable states. They have a remarkably long lifetime in the classical hysteresis regime but must eventually relax into a single unique steady state allowed by quantum mechanics. By engineering the lifetime of the metastable states sufficiently large, we observe a first-order dissipative phase transition, which mimics a sudden change of the mean field in a 11-site Bose-Hubbard lattice. We also reveal the two distinct phases of the transition by quantum state tomography, namely a coherent-state phase and a squeezed-state phase separated by a critical point. Our results reveal a smooth quantum state evolution behind a sudden dissipative phase transition, and they form an essential step towards understanding hysteresis and instability in non-equilibrium systems. ",https://doi.org/10.1038/s41467-023-38217-x,2206.06338v1,Yes,potent(1)
0000-0001-9600-9170,Michael Fischer,Albert-Ludwigs-Universität Freiburg,Flux-driven Josephson parametric amplifiers: Hysteretic flux response   and nondegenerate gain measurements,1970,"  Josephson parametric amplifiers (JPA) have become key devices in quantum science and technology with superconducting circuits. In particular, they can be utilized as quantum-limited amplifiers or as a source of squeezed microwave fields. Here, we report on the detailed measurements of five flux-driven JPAs, three of them exhibiting a hysteretic dependence of the resonant frequency versus the applied magnetic flux. We model the measured characteristics by numerical simulations based on the two-dimensional potential landscape of the dc superconducting quantum interference devices (dc-SQUID), which provide the JPA nonlinearity, for a finite screening parameter $\beta_\mathrm{L}\,{>}\,0$ and demonstrate excellent agreement between the numerical results and the experimental data. Furthermore, we study the nondegenerate response of different JPAs and accurately describe the experimental results with our theory. ",https://doi.org/10.1103/PhysRevApplied.8.024012,1609.09041v1,Yes,potent(1)
0000-0001-9646-9679,Andreas Schmidbauer,Universität Regensburg,Tailoring potentials by simulation-aided design of gate layouts for spin   qubit applications,1970,"  Gate-layouts of spin qubit devices are commonly adapted from previous successful devices. As qubit numbers and the device complexity increase, modelling new device layouts and optimizing for yield and performance becomes necessary. Simulation tools from advanced semiconductor industry need to be adapted for smaller structure sizes and electron numbers. Here, we present a general approach for electrostatically modelling new spin qubit device layouts, considering gate voltages, heterostructures, reservoirs and an applied source-drain bias. Exemplified by a specific potential, we study the influence of each parameter. We verify our model by indirectly probing the potential landscape of two design implementations through transport measurements. We use the simulations to identify critical design areas and optimize for robustness with regard to influence and resolution limits of the fabrication process. ",https://doi.org/10.1103/PhysRevApplied.20.044058,2303.13358v1,Yes,potent(2)
0000-0001-9646-9679,Andreas Schmidbauer,Universität Regensburg,"Large, tunable valley splitting and single-spin relaxation mechanisms in   a Si/Si$_x$Ge$_{1-x}$ quantum dot",1970,"  Valley splitting is a key figure of silicon-based spin qubits. Quantum dots in Si/SiGe heterostructures reportedly suffer from a relatively low valley splitting, limiting the operation temperature and the scalability of such qubit devices. Here, we demonstrate a robust and large valley splitting exceeding 200 $\mu$eV in a gate-defined single quantum dot, hosted in molecular-beam epitaxy-grown $^{28}$Si/SiGe. The valley splitting is monotonically and reproducibly tunable up to 15 % by gate voltages, originating from a 6 nm lateral displacement of the quantum dot. We observe static spin relaxation times $T_1>1$ s at low magnetic fields in our device containing an integrated nanomagnet. At higher magnetic fields, $T_1$ is limited by the valley hotspot and by phonon noise coupling to intrinsic and artificial spin-orbit coupling, including phonon bottlenecking. ",https://doi.org/10.1103/PhysRevApplied.13.034068,1907.04146v2,Yes,reportedly(1)
0000-0001-9660-8683,Markus Risse,Universität Siegen,An upper limit to photons from first data taken by the Pierre Auger   Observatory,1970,  Many models for ultra-high energy cosmic rays postulate exotic scenarios to explain the sources or the nature of these particles. A characteristic feature of these models is the prediction of a significant flux of photons at ultra-high energy. The Pierre Auger Observatory offers a great potential to search for such photons. We present shower observables with sensitivity to photons and the search strategy employed. An upper limit to photon primaries is derived from first Auger data. Prospects for constraining theoretical source models are discussed. ,Kein DOI-Link verfügbar,astro-ph/0701065v1,Yes,potent(1)
0000-0001-9751-4291,Benjamin Geiger,Universität Regensburg,Semiclassics in a system without classical limit: The few-body spectrum   of two interacting bosons in one dimension,1970,"  We present a semiclassical study of the spectrum of a few-body system consisting of two short-range interacting bosonic particles in one dimension, a particular case of a general class of integrable many-body systems where the energy spectrum is given by the solution of algebraic transcendental equations. By an exact mapping between $\delta$-potentials and boundary conditions on the few-body wave functions, we are able to extend previous semiclassical results for single-particle systems with mixed boundary conditions to the two-body problem. The semiclassical approach allows us to derive explicit analytical results for the smooth part of the two-body density of states that are in excellent agreement with numerical calculations. It further enables us to include the effect of bound states in the attractive case. Remarkably, for the particular case of two particles in one dimension, the discrete energy levels obtained through a requantization condition of the smooth density of states are essentially in perfect agreement with the exact ones. ",https://doi.org/10.1103/PhysRevE.96.022204,1705.09637v2,Yes,potent(1)
0000-0001-9811-1005,Sebastian Weissenseel,Julius-Maximilians-Universität Würzburg,Long-Lived Spin-Polarized Intermolecular Exciplex States in Thermally   Activated Delayed Fluorescence-Based Organic Light-Emitting Diodes,1970,"  Spin-spin interactions in organic light-emitting diodes (OLEDs) based on thermally activated delayed fluorescence (TADF) are pivotal because radiative recombination is largely determined by triplet-to-singlet conversion, also called reverse intersystem crossing (RISC). To explore the underlying process, we apply a spin-resonance spectral hole-burning technique to probe electroluminescence. We find that the triplet exciplex states in OLEDs are highly spin-polarized and show that these states can be decoupled from the heterogeneous nuclear environment as a source of spin dephasing and can even be coherently manipulated on a spin-spin relaxation time scale T2* of 30 ns. Crucially, we obtain the characteristic triplet exciplex spin-lattice relaxation time T1 in the range of 50 us, which far exceeds the RISC time. We conclude that slow spin relaxation rather than RISC is an efficiency-limiting step for intermolecular donor:acceptor systems. Finding TADF emitters with faster spin relaxation will benefit this type of TADF OLEDs. ",https://doi.org/10.1126/sciadv.abj9961,2108.06323v2,Yes,pivotal(1)
0000-0001-9811-1005,Sebastian Weissenseel,Julius-Maximilians-Universität Würzburg,Optically and electrically excited intermediate electronic states in   donor:acceptor based OLEDs,1970,"  Thermally activated delayed fluorescence (TADF) emitters consisting of donor and acceptor molecules are potentially highly interesting for electroluminescence (EL) applications. Their strong fluorescence emission is considered to be due to reverse intersystem crossing (RISC), in which energetically close triplet and singlet charge transfer (CT) states, also called exciplex states, are involved. In order to distinguish between different mechanisms and excited states involved, temperature-dependent spin-sensitive measurements on organic light-emitting diodes (OLEDs) and thin films are essential. In our work we apply continuous wave (cw) and time-resolved (tr) photoluminescence (PL) spectroscopy as well as spin-sensitive EL and PL detected magnetic resonance to films and OLED devices made of three different donor:acceptor combinations. Our results clearly show that triplet exciplex states are formed and contribute to delayed fluorescence (DF) via RISC in both electrically driven OLEDs and optically excited films. In the same sample set we also found molecular triplet excitons, which occurred only in PL experiments under optical excitation and for some material systems only at low temperatures. We conclude that in all investigated molecular systems exciplex states formed at the donor:acceptor interface are responsible for TADF in OLEDs with distinct activation energies. Molecular (local) triplet exciton states are also detectable, but only under optical excitation, while they are not found in OLEDs when excited states are generated electrically. We believe that the weakly bound emissive exciplex states and the strongly bound non-emissive molecular triplet excited states coexist in the TADF emitters, and it is imperative to distinguish between optical and electrical generation paths as they may involve different intermediate excited states. ",https://doi.org/10.1039/C9MH01475F,1906.06073v3,Yes,potent(1)
0000-0001-9854-0635,Jiang Liu,Universität Rostock,GlanceSeg: Real-time microaneurysm lesion segmentation with   gaze-map-guided foundation model for early detection of diabetic retinopathy,1970,"  Early-stage diabetic retinopathy (DR) presents challenges in clinical diagnosis due to inconspicuous and minute microangioma lesions, resulting in limited research in this area. Additionally, the potential of emerging foundation models, such as the segment anything model (SAM), in medical scenarios remains rarely explored. In this work, we propose a human-in-the-loop, label-free early DR diagnosis framework called GlanceSeg, based on SAM. GlanceSeg enables real-time segmentation of microangioma lesions as ophthalmologists review fundus images. Our human-in-the-loop framework integrates the ophthalmologist's gaze map, allowing for rough localization of minute lesions in fundus images. Subsequently, a saliency map is generated based on the located region of interest, which provides prompt points to assist the foundation model in efficiently segmenting microangioma lesions. Finally, a domain knowledge filter refines the segmentation of minute lesions. We conducted experiments on two newly-built public datasets, i.e., IDRiD and Retinal-Lesions, and validated the feasibility and superiority of GlanceSeg through visualized illustrations and quantitative measures. Additionally, we demonstrated that GlanceSeg improves annotation efficiency for clinicians and enhances segmentation performance through fine-tuning using annotations. This study highlights the potential of GlanceSeg-based annotations for self-model optimization, leading to enduring performance advancements through continual learning. ",Kein DOI-Link verfügbar,2311.08075v1,Yes,potent(2)
0000-0001-9854-0635,Jiang Liu,Universität Rostock,Deep Learning for Computational Cytology: A Survey,1970,"  Computational cytology is a critical, rapid-developing, yet challenging topic in the field of medical image computing which analyzes the digitized cytology image by computer-aided technologies for cancer screening. Recently, an increasing number of deep learning (DL) algorithms have made significant progress in medical image analysis, leading to the boosting publications of cytological studies. To investigate the advanced methods and comprehensive applications, we survey more than 120 publications of DL-based cytology image analysis in this article. We first introduce various deep learning methods, including fully supervised, weakly supervised, unsupervised, and transfer learning. Then, we systematically summarize the public datasets, evaluation metrics, versatile cytology image analysis applications including classification, detection, segmentation, and other related tasks. Finally, we discuss current challenges and potential research directions of computational cytology. ",https://doi.org/10.1016/j.media.2022.102691,2202.05126v2,Yes,"versatile(1), potent(1)"
0000-0001-9854-0635,Jiang Liu,Universität Rostock,Eye tracking guided deep multiple instance learning with dual   cross-attention for fundus disease detection,1970,"  Deep neural networks (DNNs) have promoted the development of computer aided diagnosis (CAD) systems for fundus diseases, helping ophthalmologists reduce missed diagnosis and misdiagnosis rate. However, the majority of CAD systems are data-driven but lack of medical prior knowledge which can be performance-friendly. In this regard, we innovatively proposed a human-in-the-loop (HITL) CAD system by leveraging ophthalmologists' eye-tracking information, which is more efficient and accurate. Concretely, the HITL CAD system was implemented on the multiple instance learning (MIL), where eye-tracking gaze maps were beneficial to cherry-pick diagnosis-related instances. Furthermore, the dual-cross-attention MIL (DCAMIL) network was utilized to curb the adverse effects of noisy instances. Meanwhile, both sequence augmentation module and domain adversarial module were introduced to enrich and standardize instances in the training bag, respectively, thereby enhancing the robustness of our method. We conduct comparative experiments on our newly constructed datasets (namely, AMD-Gaze and DR-Gaze), respectively for the AMD and early DR detection. Rigorous experiments demonstrate the feasibility of our HITL CAD system and the superiority of the proposed DCAMIL, fully exploring the ophthalmologists' eye-tracking information. These investigations indicate that physicians' gaze maps, as medical prior knowledge, is potential to contribute to the CAD systems of clinical diseases. ",Kein DOI-Link verfügbar,2304.12719v1,Yes,"innovative(1), potent(1), innovatively(1)"
0000-0001-9854-0635,Jiang Liu,Universität Rostock,Label-noise-tolerant medical image classification via self-attention and   self-supervised learning,1970,"  Deep neural networks (DNNs) have been widely applied in medical image classification and achieve remarkable classification performance. These achievements heavily depend on large-scale accurately annotated training data. However, label noise is inevitably introduced in the medical image annotation, as the labeling process heavily relies on the expertise and experience of annotators. Meanwhile, DNNs suffer from overfitting noisy labels, degrading the performance of models. Therefore, in this work, we innovatively devise noise-robust training approach to mitigate the adverse effects of noisy labels in medical image classification. Specifically, we incorporate contrastive learning and intra-group attention mixup strategies into the vanilla supervised learning. The contrastive learning for feature extractor helps to enhance visual representation of DNNs. The intra-group attention mixup module constructs groups and assigns self-attention weights for group-wise samples, and subsequently interpolates massive noisy-suppressed samples through weighted mixup operation. We conduct comparative experiments on both synthetic and real-world noisy medical datasets under various noise levels. Rigorous experiments validate that our noise-robust method with contrastive learning and attention mixup can effectively handle with label noise, and is superior to state-of-the-art methods. An ablation study also shows that both components contribute to boost model performance. The proposed method demonstrates its capability of curb label noise and has certain potential toward real-world clinic applications. ",Kein DOI-Link verfügbar,2306.09718v1,Yes,"innovative(1), potent(1), innovatively(1)"
0000-0001-9854-0635,Jiang Liu,Universität Rostock,A Two-Stream Meticulous Processing Network for Retinal Vessel   Segmentation,1970,"  Vessel segmentation in fundus is a key diagnostic capability in ophthalmology, and there are various challenges remained in this essential task. Early approaches indicate that it is often difficult to obtain desirable segmentation performance on thin vessels and boundary areas due to the imbalance of vessel pixels with different thickness levels. In this paper, we propose a novel two-stream Meticulous-Processing Network (MP-Net) for tackling this problem. To pay more attention to the thin vessels and boundary areas, we firstly propose an efficient hierarchical model automatically stratifies the ground-truth masks into different thickness levels. Then a novel two-stream adversarial network is introduced to use the stratification results with a balanced loss function and an integration operation to achieve a better performance, especially in thin vessels and boundary areas detecting. Our model is proved to outperform state-of-the-art methods on DRIVE, STARE, and CHASE_DB1 datasets. ",Kein DOI-Link verfügbar,2001.05829v1,Yes,meticulous(1)
0000-0001-9854-0635,Jiang Liu,Universität Rostock,SuperVessel: Segmenting High-resolution Vessel from Low-resolution   Retinal Image,1970,"  Vascular segmentation extracts blood vessels from images and serves as the basis for diagnosing various diseases, like ophthalmic diseases. Ophthalmologists often require high-resolution segmentation results for analysis, which leads to super-computational load by most existing methods. If based on low-resolution input, they easily ignore tiny vessels or cause discontinuity of segmented vessels. To solve these problems, the paper proposes an algorithm named SuperVessel, which gives out high-resolution and accurate vessel segmentation using low-resolution images as input. We first take super-resolution as our auxiliary branch to provide potential high-resolution detail features, which can be deleted in the test phase. Secondly, we propose two modules to enhance the features of the interested segmentation region, including an upsampling with feature decomposition (UFD) module and a feature interaction module (FIM) with a constraining loss to focus on the interested features. Extensive experiments on three publicly available datasets demonstrate that our proposed SuperVessel can segment more tiny vessels with higher segmentation accuracy IoU over 6%, compared with other state-of-the-art algorithms. Besides, the stability of SuperVessel is also stronger than other algorithms. We will release the code after the paper is published. ",Kein DOI-Link verfügbar,2207.13882v1,Yes,potent(1)
0000-0001-9904-5417,Tom Schmit,Universität des Saarlandes,Stability and decay of subradiant patterns in a quantum gas with   photon-mediated interactions,1970,"  The phenomenon of subradiance, marked by its surprising suppression of spontaneous emission, challenges conventional expectations of the collective behavior of scatterers. We study subradiance in the experimental setting of a Bose-Einstein condensate positioned at the mode crossing of two optical cavities. In this setup, subradiance manifests in the form of metastable density structures that suppress emission into one cavity mode, thereby preventing relaxation to the stationary, superradiant grating that minimizes the system's energy. We observe lifetimes of the subradiant states exceeding hundred milliseconds, far surpassing any characteristic dynamic time scale of the system. Eventually, an instability triggers a rapid transition to the superradiant stationary pattern. We reproduce these dynamics by a quantum mean field model, suggesting that subradiance shares characteristics with quasi-stationary states predicted in other long-range interacting systems such as astrophysical clusters and plasmas. This behavior highlights the potential of photon-mediated long-range forces as controllable and exploitable quantum cooperative phenomenon. ",Kein DOI-Link verfügbar,2407.09227v1,Yes,potent(1)
0000-0001-9924-3261,Peter Kroll,TU Dortmund Universität,Exclusive production of quarkonia as a probe of the GPD E for gluons,1970,  Exclusive quarkonium photo- and electro-production off the nucleon is studied in the framework of generalized parton distributions (GPDs). The short distance part of the process is treated at leading order in perturbative Quantum Chromodynamics. The main focus is on the GPD E for gluons. On the basis of different models for E we estimate the transverse target spin asymmetry for typical kinematics of a future Electron Ion Collider. We also explore the potential of measuring the polarization of the recoil nucleon. ,https://doi.org/10.1103/PhysRevD.85.051502,1112.1334v1,Yes,potent(1)
0000-0001-9960-2084,Lothar Ratschbacher,Technische Universität Bergakademie Freiberg,State-dependent fluorescence of neutral atoms in optical potentials,1970,"  Recently we have demonstrated scalable, non-destructive, and high-fidelity detection of the internal state of $^{87}$Rb neutral atoms in optical dipole traps using state-dependent fluorescence imaging [M. Martinez-Dorantes et al., PRL, 2017]. In this article we provide experimental procedures and interpretations to overcome the detrimental effects of heating-induced trap losses and state leakage. We present models for the dynamics of optically trapped atoms during state-dependent fluorescence imaging and verify our results by comparing Monte Carlo simulations with experimental data. Our systematic study of dipole force fluctuations heating in optical traps during near-resonant illumination shows that off-resonant light is preferable for state detection in tightly confining optical potentials. ",https://doi.org/10.1103/PhysRevA.97.023410,1710.07964v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Lattice QCD at High Temperature and the QGP,1970,"  We review recent progress in studies of bulk thermodynamics of strongly interacting matter, present results on the QCD equation of state and discuss the status of studies of the phase diagram at non-vanishing quark chemical potential. ",https://doi.org/10.1063/1.2220177,hep-lat/0601013v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Properties of the Quark Gluon Plasma: A lattice perspective,1970,  We discuss results from lattice calculations for a few observables that are sensitive to different length scales in the high temperature phase of QCD and can give insight into its non-perturbative structure. We compare lattice results with perturbative calculations at high temperature obtained for vanishing and non-vanishing quark chemical potential. ,https://doi.org/10.1016/j.nuclphysa.2006.11.035,hep-ph/0610024v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,"Recent lattice results on finite temperature and density QCD, part I",1970,"  We discuss recent progress made studies of bulk thermodynamics of strongly interacting matter through lattice simulations of QCD with an almost physical light and strange quark mass spectrum. We present results on the QCD equation of state at vanishing and non-vanishing quark chemical potential and show first results on baryon number and strangeness fluctuations, which might be measured in event-by-event fluctuations in low energy runs at RHIC as well as at FAIR. ",Kein DOI-Link verfügbar,0711.0656v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,O(N) universality and the chiral phase transition in QCD,1970,  We discuss universal scaling properties of (2+1)-flavor QCD in the vicinity of the chiral phase transition at vanishing as well as non-vanishing light quark chemical potential (mu_l). We provide evidence for O(N) scaling of the chiral order parameter in (2+1)-flavor QCD and show that the scaling analysis of its derivative with respect to the light quark chemical potential provides a unique approach to the determination of the curvature of the chiral phase transition line in the vicinity of mu_l/T=0. ,https://doi.org/10.1143/PTPS.186.479,1007.2393v1,Yes,potent(2)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,QCD thermodynamics in the crossover/freeze-out region,1970,  We use results from a 6-th order Taylor expansion of the QCD equation of state to construct expansions for cumulants of conserved charge fluctuations and their correlations. We show that these cumulants strongly constrain the range of applicability of hadron resonance gas model calculations. We point out that the latter is inappropriate to describe equilibrium properties of QCD at zero and non-zero values of the baryon chemical potential already at T~155 MeV. ,Kein DOI-Link verfügbar,1703.06702v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Lattice QCD at non-zero chemical potential and the resonance gas model,1970,"  We present results from lattice calculations on the thermodynamics of QCD at non-zero temperature and baryon chemical potential and discuss the role of resonances for the occurrence of the transition to the quark-gluon plasma in hot and dense matter. Properties of a hadronic resonance gas are compared to lattice results on the equation of state at zero as well as non-zero baryon chemical potential. Furthermore, it is shown that the quark mass dependence of the transition temperature can be understood in terms of lines of constant energy density in a resonance gas. ",https://doi.org/10.1143/PTPS.153.106,hep-lat/0401031v1,Yes,potent(2)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,News from Lattice QCD on Heavy Quark Potentials and Spectral Functions   of Heavy Quark States,1970,"  We discuss recent lattice results on in-medium properties of hadrons and focus on thermal properties of heavy quark bound states. We will clarify the relation between heavy quark free energies and potentials used to analyze the melting of heavy quark bound states. Furthermore, we present calculations of meson spectral functions which indicate that the charmonium ground states, J/psi and eta_c, persist in the quark gluon plasma as well defined resonances with no significant change of their zero temperature masses at least up to T ~ 1.5 T_c. We also briefly comment on the current status of lattice calculations at non-vanishing baryon number density. ",https://doi.org/10.1088/0954-3899/30/8/030,hep-lat/0403016v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Thermodynamic Properties of Strongly Interacting Matter at Non-zero   Baryon Number Density,1970,"  We present recent lattice results on QCD thermodynamics at non-vanishing baryon number density obtained from a 6th order Taylor expansion in the chemical potential. Results for bulk thermodynamic observables, in particular for fluctuations in the baryon number density, are found to be well described by a hadron resonance gas model at low temperature and an ideal quark gluon gas at high temperature. We also analyze the radius of convergence of the Taylor series and discuss the information it provides on the occurrence of a second order phase transition point in the QCD phase diagram. ",https://doi.org/10.1088/0954-3899/31/6/002,hep-lat/0412038v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Lattice QCD results on cumulant ratios at freeze-out,1970,"  Ratios of cumulants of net proton-number fluctuations measured by the STAR Collaboration show strong deviations from a skellam distribution, which should describe thermal properties of cumulant ratios, if proton-number fluctuations are generated in equilibrium and a hadron resonance gas (HRG) model would provide a suitable description of thermodynamics at the freeze-out temperature. We present some results on sixth order cumulants entering the calculation of the QCD equation of state at non-zero values of the baryon chemical potential (mu_B) and discuss limitations on the applicability of HRG thermodynamics deduced from a comparison between QCD and HRG model calculations of cumulants of conserved charge fluctuations. We show that basic features of the $\mu_B$-dependence of skewness and kurtosis ratios of net proton-number fluctuations measured by the STAR Collaboration resemble those expected from a O(mu_B^2) QCD calculation of the corresponding net baryon-number cumulant ratios. ",https://doi.org/10.1088/1742-6596/779/1/012015,1611.01973v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Conserved charge fluctuations at vanishing and non-vanishing chemical   potential,1970,"  Up to 6th order cumulants of fluctuations of net baryon-number, net electric charge and net strangeness as well as correlations among these conserved charge fluctuations are now being calculated in lattice QCD. These cumulants provide a wealth of information on the properties of strong-interaction matter in the transition region from the low temperature hadronic phase to the quark-gluon plasma phase. They can be used to quantify deviations from hadron resonance gas (HRG) model calculations which frequently are used to determine thermal conditions realized in heavy ion collision experiments. Already some second order cumulants like the correlations between net baryon-number and net strangeness or net electric charge differ significantly at temperatures above 155 MeV in QCD and HRG model calculations. We show that these differences increase at non-zero baryon chemical potential constraining the applicability range of HRG model calculations to even smaller values of the temperature. ",https://doi.org/10.1016/j.nuclphysa.2017.06.011,1706.01620v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Critical behavior and net-charge fluctuations from lattice QCD,1970,"  We present recent results on the critical and pseudo-critical temperatures in (2+1)-flavor QCD with a physical strange quark mass and two degenerate light quark masses extrapolated to the chiral limit and tuned to the physical value, respectively. We furthermore discuss implication of the observed low chiral phase transition temperature, Tc0=132_{-6}^{+3} MeV, for the structure of cumulants of conserved charge fluctuations at vanishing baryon chemical potential and consequences for the possible location of the QCD critical endpoint in the QCD phase diagram at non-zero baryon chemical potential. ",Kein DOI-Link verfügbar,1905.03936v1,Yes,potent(2)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Deconfinement and Chiral Symmetry Restoration in an SU(3) Gauge Theory   with Adjoint Fermions,1970,"  We analyze the finite temperature phase diagram of$QC$ with fermions in the adjoint representation. The simulations performed with four dynamical Majorana fermions show that the deconfinement and chiral phase transitions occur at two distinct temperatures. While the deconfinement transition is first order at T_d we find evidence for a continuous chiral transition at a higher temperature $T_c ~ 8 T_d. We observe a rapid change of bulk thermodynamic observables at T_d which reflects the increase in the number of degrees of freedom. However, these show little variation at T_c, where the fermion condensate vanishes. We also analyze the potential between static fundamental and adjoint charges in all three phases and extract the corresponding screening masses above T_d. ",https://doi.org/10.1016/S0550-3213(99)00129-7,hep-lat/9812023v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Probing freeze-out conditions in heavy ion collisions with moments of   charge fluctuations,1970,"  We calculate the first four moments of baryon number, electric charge and strangeness fluctuations within the hadron resonance gas model. Different moments and their ratios as well as skewness and kurtosis are evaluated on the phenomenologically determined freeze-out curve in the temperature, baryon chemical potential plane. The model results and its predictions as well as relations between different moments are compared with the first data on net proton fluctuations in Au-Au collisions obtained at RHIC by the STAR Collaboration. We find good agreement between the model calculations and experimental results. We also point out that higher order moments should be more sensitive to critical behavior and will also distinguish hadron resonance gas model calculations from results obtained from lattice QCD. ",https://doi.org/10.1016/j.physletb.2010.10.046,1007.2581v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Has Tc been measured by heavy ion experiments?,1970,"  We discuss the role of cumulants of net baryon number fluctuations in the analysis of critical behavior in QCD and the study of freeze-out conditions in heavy ion experiments. Through the comparison of the current set of measurements of higher order cumulants of net baryon number fluctuations with lattice QCD calculations and results from hadron resonance gas model we can learn to what extent freeze-out as, determined by such cumulants, occurs close to the QCD transition temperature and thus can probe critical behavior at small values of the baryon chemical potential. Understanding how the relation between freeze-out conditions and the QCD crossover transition is reflected in properties of the experimentally determined cumulants is an important prerequisite to search for the QCD critical point. We point out that even if perfect continuum extrapolated lattice QCD results would be available, it would be inappropriate to use these observables to extract the value of the QCD transition temperature at vanishing baryon chemical potential from experimental data. We furthermore provide indications that a recently performed comparison of lattice QCD results on cumulants with data from heavy ion experiments suffer from systematic as well as statistical uncertainties in the lattice QCD calculations. This makes such comparison of lattice QCD calculations with experimental data at present not useful. ",https://doi.org/10.1103/PhysRevD.84.051504,1107.1412v1,Yes,potent(2)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Higher order cumulants of net baryon-number distributions at non-zero   $μ_B$,1970,"  Using recent results on higher order cumulants of conserved charge fluctuations from lattice QCD, we construct mean, variance, skewness, kurtosis, hyper-skewness and hyper-kurtosis of net-baryon number distributions for small baryon chemical potentials $\mu_B$. For the strangeness neutral case ($\mu_S=0$) at fixed ratio of electric charge to baryon number density ($\frac{n_Q}{n_B}=0.4$), which is appropriate for a comparison with heavy ion collisions, we present results for $\kappa_B \sigma_B^2$, $S_B \sigma_B^3/M_B$, $\kappa^{H}_{B}\sigma_{B}^4$ and $S^{H}_{B}\sigma^5_{B}/M_{B}$ on the crossover line for the chiral transition, $T_{pc}(\mu_B)$. Continuum extrapolations for this pseudo-critical transition line have recently been reported by HotQCD up to baryon chemical potentials $\mu_B\simeq 300$ MeV [arXiv:1812.08235]. These cumulant ratios are of direct relevance for comparisons with corresponding ratios measured by STAR in the BES-I and II runs at beam energies $\sqrt{s_{NN}}\ge 20$ GeV. In particular, we point out that recent high statistics results on skewness and kurtosis of net-baryon number distributions obtained by STAR at $\sqrt{s_{NN}} = 54.4$ GeV put strong constraints on freeze-out parameters and are consistent with predictions from thermal QCD. ",https://doi.org/10.1016/j.nuclphysa.2020.121835,2002.01837v1,Yes,potent(2)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Conserved charge fluctuations in the chiral limit,1970,"  We study the signs of criticality in conserved charge fluctuations and related observables of finite temperature QCD at vanishing chemical potential, as we approach the chiral limit of two light quarks. Our calculations have been performed on gauge ensembles generated using Highly Improved Staggered Quark (HISQ) fermion action, with pion masses ranging from 140 MeV to 55 MeV. ",https://doi.org/10.5506/APHYSPOLBSUPP.14.383,2011.00240v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Heavy Quark Potentials in Quenched QCD at High Temperature,1970,"  Heavy quark potentials are investigated at high temperatures. The temperature range covered by the analysis extends from $T$ values just below the deconfinement temperature up to about $4 T_c$ in the deconfined phase. We simulated the pure gauge sector of QCD on lattices with temporal extents of 4, 6 and 8 with spatial volumes of $32^3$. On the smallest lattice a tree level improved action was employed while in the other two cases the standard Wilson action was used. Below $T_c$ we find a temperature dependent logarithmic term contributing to the confinement potential and observe a string tension which decreases with rising temperature but retains a finite value at the deconfinement transition. Above $T_c$ the potential is Debye-screened, however simple perturbative predictions do not apply. ",https://doi.org/10.1103/PhysRevD.62.034021,hep-lat/9908010v1,Yes,potent(3)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Towards finite density QCD with Taylor expansions,1970,"  Convergence properties of Taylor expansions of observables, which are also used in lattice QCD calculations at non-zero chemical potential, are analyzed in an effective N_f = 2+1 flavor Polyakov-quark-meson model. A recently developed algorithmic technique allows the calculation of higher-order Taylor expansion coefficients in functional approaches. This novel technique is for the first time applied to an effective N_f = 2+1 flavor Polyakov-quark-meson model and the findings are compared with the full model solution at finite densities. The results are used to discuss prospects for locating the QCD phase boundary and a possible critical endpoint in the phase diagram. ",https://doi.org/10.1016/j.physletb.2011.03.013,1009.5211v2,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Searching for the QCD critical point along the   pseudo-critical/freeze-out line using Padé-resummed Taylor expansions of   cumulants of conserved charge fluctuations,1970,"  Using high-statistics datasets generated in (2+1)-flavor QCD calculations at finite temperature we construct estimators for the radius of convergence from an eighth order series expansion of the pressure as well as the number density. We show that the estimator for pressure and number density will be identical in the asymptotic limit. In the vicinity of the pseudo-critical temperature, $T_{pc}\simeq 156.5$~MeV, we find the estimator of the radius of convergence to be $\mu_B/T \gtrsim\ 3$ for strangeness-neutral matter. We also present results for the pole structure of the Pad\'e approximants for the pressure at non-zero values of the baryon chemical potential and show that the pole structure of the [4,4] Pad\'e is consistent with not having a critical point at temperatures larger than $135~$MeV and a baryon chemical potential smaller than $\mu_B/T \sim \ 2.5$. ",https://doi.org/10.5506/APhysPolBSupp.16.1-A76,2206.04504v1,Yes,potent(2)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Imprint of chiral symmetry restoration on the Polyakov loop and the   heavy quark free energy,1970,"  The Polyakov loop expectation value $\langle P\rangle$ is an order parameter of the deconfinement transition in the heavy quark mass regime, whereas its sensitivity to the deconfinement of light, dynamical quarks is not apparent. From the perspective of an effective Lagrangian in the vicinity of the chiral transition, the Polyakov loop, $P$, is an energy-like observable, and $\langle P\rangle$ should hence scale like the energy density. Using $N_f=2+1$ HISQ configurations at finite lattice spacing, we show that near the chiral transition temperature, the scaling behavior of $\langle P\rangle$ and the heavy quark free energy $F_q$ is consistent with energy-like observables in the 3-$d$, O($N$) universality class. We extend this analysis to other Polyakov loop observables, including the response of the heavy quark free energy, $F_q$, to the baryon chemical potential, which is expected to scale like a specific heat. ",https://doi.org/10.22323/1.396.0184,2111.09844v1,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Critical end points in (2+1)-flavor QCD with imaginary chemical   potential,1970,"  We present here the results from an ongoing determination of the critical quark mass in simulations of (2+1)-flavor QCD with an imaginary chemical potential. Studies with unimproved actions found the existence of a critical quark mass value at which the crossover transition ends on a second order phase transition and becomes first order for smaller values of the quark mass for the case of both vanishing and imaginary chemical potential. We use the Highly Improved Staggered Quark (HISQ) action and perform calculations in the Roberge-Weiss (RW) plane, where the value of the critical mass is expected to be largest. The lowest quark mass value used in our simulation corresponds to the pion mass $m_\pi$, down to $40$ MeV. Contrary to calculations performed with unimproved actions we find no evidence for the occurrence of first order transitions at the smallest quark mass values explored so far. Moreover we also show that the chiral observables are sensitive to the RW transition. Our results also indicate that the RW transition and chiral transition could coincide in the chiral limit. ",https://doi.org/10.22323/1.347.0162,1905.03625v1,Yes,potent(2)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Study of QCD thermodynamics at finite density by Taylor expansion,1970,"  We discuss the phase structure and the equation of state for QCD at non-zero temperature and density. Derivatives of $\ln Z$ with respect to quark chemical potential $\mu_q$ up to fourth order are calculated for 2-flavor QCD, enabling estimates of the pressure, quark number density and associated susceptibilities as functions of $\mu_q$ via a Taylor series expansion. Also, the phase transition line for 2 and 3-flavor QCD and the critical endpoint in the $(T, \mu_q)$ plane are investigated in the low density regime. ",https://doi.org/10.1143/PTPS.153.118,hep-lat/0312006v2,Yes,potent(1)
0000-0001-9994-5597,Frithjof Karsch,Bielefeld Universität,Critical behavior towards the chiral limit at vanishing and   non-vanishing chemical potentials,1970,"  We study the scaling behavior of the (2+1)-flavor QCD crossover region towards the chiral limit with smaller-than-physical light quark mass gauge ensembles, generated using the HISQ fermion discretization. At zero chemical potential, we study the fluctuations of conserved charges and their correlations with the chiral condensate, towards the chiral limit. We analyse the role of universal and regular contributions to the above quantities. We find a preliminary estimate of the leading curvature coefficient of the chiral phase transition line using scaling arguments. ",https://doi.org/10.22323/1.396.0429,2112.15398v1,Yes,potent(1)
0000-0002-0041-2430,Irina Heinz,Universität Konstanz,Analysis and mitigation of residual exchange coupling in linear spin   qubit arrays,1970,"  In recent advancements of quantum computing utilizing spin qubits, it has been demonstrated that this platform possesses the potential for implementing two-qubit gates with fidelities exceeding 99.5%. However, as with other qubit platforms, it is not feasible to completely turn qubit couplings off. This study aims to investigate the impact of coherent error matrices in gate set tomography by employing a double quantum dot. We evaluate the infidelity caused by residual exchange between spins and compare various mitigation approaches, including the use of adjusted timing through simple drives, considering different parameter settings in the presence of charge noise. Furthermore, we extend our analysis to larger arrays of exchange-coupled spin qubits to provide an estimation of the expected fidelity. In particular, we demonstrate the influence of residual exchange on a single-qubit $Y$ gate and the native two-qubit SWAP gate in a linear chain. Our findings emphasize the significance of accounting for residual exchange when scaling up spin qubit devices and highlight the tradeoff between the effects of charge noise and residual exchange in mitigation techniques. ",https://doi.org/10.1103/PhysRevResearch.6.013153,2308.11308v2,Yes,potent(1)
0000-0002-0053-6337,André Kubetzka,Universität Hamburg,Electrical detection of magnetic skyrmions by non-collinear   magnetoresistance,1970,"  Magnetic skyrmions are localised non-collinear spin textures with high potential for future spintronic applications. Skyrmion phases have been discovered in a number of materials and a focus of current research is the preparation, detection, and manipulation of individual skyrmions for an implementation in devices. Local experimental characterization of skyrmions has been performed by, e.g., Lorentz microscopy or atomic-scale tunnel magnetoresistance measurements using spin-polarised scanning tunneling microscopy. Here, we report on a drastic change of the differential tunnel conductance for magnetic skyrmions arising from their non-collinearity: mixing between the spin channels locally alters the electronic structure, making a skyrmion electronically distinct from its ferromagnetic environment. We propose this non-collinear magnetoresistance (NCMR) as a reliable all-electrical detection scheme for skyrmions with an easy implementation into device architectures. ",https://doi.org/10.1038/nnano.2015.218,1507.04337v1,Yes,potent(1)
0000-0002-0053-6337,André Kubetzka,Universität Hamburg,Zero-field skyrmionic states and in-field edge-skyrmions induced by   boundary tuning,1970,"  When magnetic skyrmions are moved via currents, they do not strictly travel along the path of the current, instead their motion also gains a transverse component. This so-called skyrmion Hall effect can be detrimental in potential skyrmion devices because it drives skyrmions towards the edge of their hosting material where they face potential annihilation. Here we experimentally modify a skyrmion model system - an atomic Pd/Fe bilayer on Ir(111) - by decorating the film edge with ferromagnetic Co/Fe patches. Employing spin-polarized scanning tunneling microscopy, we demonstrate that this ferromagnetic rim prevents skyrmion annihilation at the film edge and stabilizes skyrmions and target states in zero field. Furthermore, in an external magnetic field the Co/Fe rim can give rise to skyrmions pinned to the film edge. Spin dynamics simulations reveal how a combination of different attractive and repulsive skyrmion-edge interactions can induce such an edge-pinning effect for skyrmions. ",https://doi.org/10.1038/s42005-021-00796-w,2108.06223v1,Yes,potent(2)
0000-0002-0132-0650,Alexander Schindler,Universität Potsdam,Multi-Modal Video Forensic Platform for Investigating Post-Terrorist   Attack Scenarios,1970,"  The forensic investigation of a terrorist attack poses a significant challenge to the investigative authorities, as often several thousand hours of video footage must be viewed. Large scale Video Analytic Platforms (VAP) assist law enforcement agencies (LEA) in identifying suspects and securing evidence. Current platforms focus primarily on the integration of different computer vision methods and thus are restricted to a single modality. We present a video analytic platform that integrates visual and audio analytic modules and fuses information from surveillance cameras and video uploads from eyewitnesses. Videos are analyzed according their acoustic and visual content. Specifically, Audio Event Detection is applied to index the content according to attack-specific acoustic concepts. Audio similarity search is utilized to identify similar video sequences recorded from different perspectives. Visual object detection and tracking are used to index the content according to relevant concepts. Innovative user-interface concepts are introduced to harness the full potential of the heterogeneous results of the analytical modules, allowing investigators to more quickly follow-up on leads and eyewitness reports. ",Kein DOI-Link verfügbar,2004.01023v1,Yes,"innovative(1), potent(1)"
0000-0002-0132-0650,Alexander Schindler,Universität Potsdam,Wider or Deeper Neural Network Architecture for Acoustic Scene   Classification with Mismatched Recording Devices,1970,"  In this paper, we present a robust and low complexity system for Acoustic Scene Classification (ASC), the task of identifying the scene of an audio recording. We first construct an ASC baseline system in which a novel inception-residual-based network architecture is proposed to deal with the mismatched recording device issue. To further improve the performance but still satisfy the low complexity model, we apply two techniques: ensemble of multiple spectrograms and channel reduction on the ASC baseline system. By conducting extensive experiments on the benchmark DCASE 2020 Task 1A Development dataset, we achieve the best model performing an accuracy of 69.9% and a low complexity of 2.4M trainable parameters, which is competitive to the state-of-the-art ASC systems and potential for real-life applications on edge devices. ",Kein DOI-Link verfügbar,2203.12314v1,Yes,potent(1)
0000-0002-0132-0650,Alexander Schindler,Universität Potsdam,Remote Sensing Image Classification using Transfer Learning and   Attention Based Deep Neural Network,1970,"  The task of remote sensing image scene classification (RSISC), which aims at classifying remote sensing images into groups of semantic categories based on their contents, has taken the important role in a wide range of applications such as urban planning, natural hazards detection, environment monitoring,vegetation mapping, or geospatial object detection. During the past years, research community focusing on RSISC task has shown significant effort to publish diverse datasets as well as propose different approaches to deal with the RSISC challenges. Recently, almost proposed RSISC systems base on deep learning models which prove powerful and outperform traditional approaches using image processing and machine learning. In this paper, we also leverage the power of deep learning technology, evaluate a variety of deep neural network architectures, indicate main factors affecting the performance of a RSISC system. Given the comprehensive analysis, we propose a deep learning based framework for RSISC, which makes use of the transfer learning technique and multihead attention scheme. The proposed deep learning framework is evaluated on the benchmark NWPU-RESISC45 dataset and achieves the best classification accuracy of 94.7% which shows competitive to the state-of-the-art systems and potential for real-life applications. ",Kein DOI-Link verfügbar,2206.13392v1,Yes,potent(1)
0000-0002-0132-0650,Alexander Schindler,Universität Potsdam,Deepfake Audio Detection Using Spectrogram-based Feature and Ensemble of   Deep Learning Models,1970,"  In this paper, we propose a deep learning based system for the task of deepfake audio detection. In particular, the draw input audio is first transformed into various spectrograms using three transformation methods of Short-time Fourier Transform (STFT), Constant-Q Transform (CQT), Wavelet Transform (WT) combined with different auditory-based filters of Mel, Gammatone, linear filters (LF), and discrete cosine transform (DCT). Given the spectrograms, we evaluate a wide range of classification models based on three deep learning approaches. The first approach is to train directly the spectrograms using our proposed baseline models of CNN-based model (CNN-baseline), RNN-based model (RNN-baseline), C-RNN model (C-RNN baseline). Meanwhile, the second approach is transfer learning from computer vision models such as ResNet-18, MobileNet-V3, EfficientNet-B0, DenseNet-121, SuffleNet-V2, Swint, Convnext-Tiny, GoogLeNet, MNASsnet, RegNet. In the third approach, we leverage the state-of-the-art audio pre-trained models of Whisper, Seamless, Speechbrain, and Pyannote to extract audio embeddings from the input spectrograms. Then, the audio embeddings are explored by a Multilayer perceptron (MLP) model to detect the fake or real audio samples. Finally, high-performance deep learning models from these approaches are fused to achieve the best performance. We evaluated our proposed models on ASVspoof 2019 benchmark dataset. Our best ensemble model achieved an Equal Error Rate (EER) of 0.03, which is highly competitive to top-performing systems in the ASVspoofing 2019 challenge. Experimental results also highlight the potential of selective spectrograms and deep learning approaches to enhance the task of audio deepfake detection. ",Kein DOI-Link verfügbar,2407.01777v1,Yes,potent(1)
0000-0002-0132-0650,Alexander Schindler,Universität Potsdam,A Light-weight Deep Learning Model for Remote Sensing Image   Classification,1970,"  In this paper, we present a high-performance and light-weight deep learning model for Remote Sensing Image Classification (RSIC), the task of identifying the aerial scene of a remote sensing image. To this end, we first valuate various benchmark convolutional neural network (CNN) architectures: MobileNet V1/V2, ResNet 50/151V2, InceptionV3/InceptionResNetV2, EfficientNet B0/B7, DenseNet 121/201, ConNeXt Tiny/Large. Then, the best performing models are selected to train a compact model in a teacher-student arrangement. The knowledge distillation from the teacher aims to achieve high performance with significantly reduced complexity. By conducting extensive experiments on the NWPU-RESISC45 benchmark, our proposed teacher-student models outperforms the state-of-the-art systems, and has potential to be applied on a wide rage of edge devices. ",Kein DOI-Link verfügbar,2302.13028v1,Yes,potent(1)
0000-0002-0132-0650,Alexander Schindler,Universität Potsdam,Towards Unsupervised Speaker Diarization System for Multilingual   Telephone Calls Using Pre-trained Whisper Model and Mixture of Sparse   Autoencoders,1970,"  Existing speaker diarization systems heavily rely on large amounts of manually annotated data, which is labor-intensive and challenging to collect in real-world scenarios. Additionally, the language-specific constraint in speaker diarization systems significantly hinders their applicability and scalability in multilingual settings. In this paper, we therefore propose a cluster-based speaker diarization system for multilingual telephone call applications. The proposed system supports multiple languages and does not require large-scale annotated data for the training process as leveraging the multilingual Whisper model to extract speaker embeddings and proposing a novel Mixture of Sparse Autoencoders (Mix-SAE) network architecture for unsupervised speaker clustering. Experimental results on the evaluating dataset derived from two-speaker subsets of CALLHOME and CALLFRIEND telephonic speech corpora demonstrate superior efficiency of the proposed Mix-SAE network to other autoencoder-based clustering methods. The overall performance of our proposed system also indicates the promising potential of our approach in developing unsupervised multilingual speaker diarization applications within the context of limited annotated data and enhancing the integration ability into comprehensive multi-task speech analysis systems (i.e. multiple tasks of speech-to-text, language detection, speaker diarization integrated in a low-complexity system). ",Kein DOI-Link verfügbar,2407.01963v2,Yes,potent(1)
0000-0002-0132-4934,Stefan Schneegass,Universität Duisburg-Essen,Maneuver-based Driving for Intervention in Autonomous Cars,1970,"  The way we communicate with autonomous cars will fundamentally change as soon as manual input is no longer required as back-up for the autonomous system. Maneuver-based driving is a potential way to allow still the user to intervene with the autonomous car to communicate requests such as stopping at the next parking lot. In this work, we highlight different research questions that still need to be explored to gain insights into how such control can be realized in the future. ",Kein DOI-Link verfügbar,2003.12496v1,Yes,potent(1)
0000-0002-0162-1007,Björn Heinz,Technische Universität Kaiserslautern,Temperature dependence of spin pinning and spin-wave dispersion in   nanoscopic ferromagnetic waveguides,1970,"  The field of magnonics attracts significant attention due to the possibility of utilizing information coded into the spin-wave phase or amplitude to perform computation operations on the nanoscale. Recently, spin waves were investigated in Yttrium Iron Garnet (YIG) waveguides with widths ranging down to 50 nm and aspect ratios thickness over width approaching unity. A critical width was found, below which the exchange interaction suppresses the dipolar pinning phenomenon and the system becomes unpinned. Here we continue these investigations and analyse the pinning phenomenon and spin-wave dispersions as a function of temperature, thickness and material of choice. Higher order modes, the influence of a finite wavevector along the waveguide and the impact of the pinning phenomenon on the spin-wave lifetime are discussed as well as the influence of a trapezoidal cross section and edge roughness of the waveguides. The presented results are of particular interest for potential applications in magnonic devices and the incipient field of quantum magnonics at cryogenic temperatures. ",https://doi.org/10.15407/ujpe65.12.1094,2002.00003v1,Yes,potent(1)
0000-0002-0162-1007,Björn Heinz,Technische Universität Kaiserslautern,Parametric generation of spin waves in nano-scaled magnonic conduits,1970,"  The research feld of magnonics proposes a low-energy wave-logic computation technology based on spin waves to complement the established CMOS technology and provide a basis for emerging unconventional computation architectures. However, magnetic damping is a limiting factor for all-magnonic logic circuits and multi-device networks, ultimately rendering mechanisms to effciently manipulate and amplify spin waves a necessity. In this regard, parallel pumping is a versatile tool since it allows to selectively generate and amplify spin waves. While extensively studied in microscopic systems, nano-scaled systems are lacking investigation to assess the feasibility and potential future use of parallel pumping in magnonics. Here, we investigate a longitudinally magnetized 100 nm-wide magnonic nano-conduit using space and time-resolved micro-focused Brillouin-light-scattering spectroscopy. Employing parallel pumping to generate spin waves, we observe that the non-resonant excitation of dipolar spin waves is favored over the resonant excitation of short wavelength exchange spin waves. In addition, we utilize this technique to access the effective spin-wave relaxation time of an individual nano-conduit, observing a large relaxation time up to (115.0 +- 7.6) ns. Despite the significant decrease of the pumping effciency in the investigated nano-conduit, a reasonably small threshold is found rendering parallel pumping feasible on the nano-scale. ",https://doi.org/10.1103/PhysRevB.105.144424,2106.10727v2,Yes,"versatile(1), potent(1)"
0000-0002-0162-1007,Björn Heinz,Technische Universität Kaiserslautern,Long-range spin-wave propagation in transversely magnetized nano-scaled   conduits,1970,"  Magnonics attracts increasing attention in the view of novel low-energy computation technologies based on spin waves. Recently, spin-wave propagation in longitudinally magnetized nano-scaled spin-wave conduits was demonstrated, proving the fundamental feasibility of magnonics at the sub-100 nm scale. Transversely magnetized nano-conduits, which are of great interest in this regard as they offer a large group velocity and a potentially chirality-based protected transport of energy, have not yet been investigated due to their complex internal magnetic field distribution. Here, we present a study of propagating spin waves in a transversely magnetized nanoscopic yttrium iron garnet conduit of 50 nm width. Space and time-resolved micro-focused Brillouin-light-scattering spectroscopy is employed to measure the spin-wave group velocity and decay length. A long-range spin-wave propagation is observed with a decay length of up to (8.0+-1.5) {\mu}m and a large spin-wave lifetime of up to (44.7+-9.1) ns. The results are supported with micromagnetic simulations, revealing a single-mode dispersion relation in contrast to the common formation of localized edge modes for microscopic systems. Furthermore, a frequency non-reciprocity for counter-propagating spin waves is observed in the simulations and the experiment, caused by the trapezoidal cross-section of the structure. The revealed long-distance spin-wave propagation on the nanoscale is particularly interesting for an application in spin-wave devices, allowing for long-distance transport of information in magnonic circuits, as well as novel low-energy device architectures. ",https://doi.org/10.1063/5.0045570,2101.10192v1,Yes,potent(1)
0000-0002-0216-213X,Frieder Ladisch,Universität Rostock,Groups with anticentral elements,1970,"  We study finite groups $G$ with elements $g$ such that $\lvert \mathbf{C}_G(g)\rvert = \lvert G:G' \rvert$. (Such elements generalize fixed-point-free automorphisms of finite groups.) We show that these groups have a unique conjugacy class of nilpotent supplements for the commutator subgroup and, using the classification of finite simple groups, that these groups are solvable. ",https://doi.org/10.1080/00927870802108106,2305.06184v1,Yes,potent(1)
0000-0002-0235-0931,Sebastian Bauer,Kiel Universität,Weck's Selection Theorem: The Maxwell Compactness Property for Bounded   Weak Lipschitz Domains with Mixed Boundary Conditions in Arbitrary Dimensions,1970,"  It is proved that the space of differential forms with weak exterior and co-derivative, is compactly embedded into the space of square integrable differential forms. Mixed boundary conditions on weak Lipschitz domains are considered. Furthermore, canonical applications such as Maxwell estimates, Helmholtz decompositions and a static solution theory are proved. As a side product and crucial tool for our proofs we show the existence of regular potentials and regular decompositions as well. ",Kein DOI-Link verfügbar,1809.01192v4,Yes,potent(1)
0000-0002-0235-0931,Sebastian Bauer,Kiel Universität,Staging Epileptogenesis with Deep Neural Networks,1970,"  Epilepsy is a common neurological disorder characterized by recurrent seizures accompanied by excessive synchronous brain activity. The process of structural and functional brain alterations leading to increased seizure susceptibility and eventually spontaneous seizures is called epileptogenesis (EPG) and can span months or even years. Detecting and monitoring the progression of EPG could allow for targeted early interventions that could slow down disease progression or even halt its development. Here, we propose an approach for staging EPG using deep neural networks and identify potential electroencephalography (EEG) biomarkers to distinguish different phases of EPG. Specifically, continuous intracranial EEG recordings were collected from a rodent model where epilepsy is induced by electrical perforant pathway stimulation (PPS). A deep neural network (DNN) is trained to distinguish EEG signals from before stimulation (baseline), shortly after the PPS and long after the PPS but before the first spontaneous seizure (FSS). Experimental results show that our proposed method can classify EEG signals from the three phases with an average area under the curve (AUC) of 0.93, 0.89, and 0.86. To the best of our knowledge, this represents the first successful attempt to stage EPG prior to the FSS using DNNs. ",Kein DOI-Link verfügbar,2006.09885v1,Yes,potent(1)
0000-0002-0235-0931,Sebastian Bauer,Kiel Universität,Towards Early Diagnosis of Epilepsy from EEG Data,1970,"  Epilepsy is one of the most common neurological disorders, affecting about 1% of the population at all ages. Detecting the development of epilepsy, i.e., epileptogenesis (EPG), before any seizures occur could allow for early interventions and potentially more effective treatments. Here, we investigate if modern machine learning (ML) techniques can detect EPG from intra-cranial electroencephalography (EEG) recordings prior to the occurrence of any seizures. For this we use a rodent model of epilepsy where EPG is triggered by electrical stimulation of the brain. We propose a ML framework for EPG identification, which combines a deep convolutional neural network (CNN) with a prediction aggregation method to obtain the final classification decision. Specifically, the neural network is trained to distinguish five second segments of EEG recordings taken from either the pre-stimulation period or the post-stimulation period. Due to the gradual development of epilepsy, there is enormous overlap of the EEG patterns before and after the stimulation. Hence, a prediction aggregation process is introduced, which pools predictions over a longer period. By aggregating predictions over one hour, our approach achieves an area under the curve (AUC) of 0.99 on the EPG detection task. This demonstrates the feasibility of EPG prediction from EEG recordings. ",Kein DOI-Link verfügbar,2006.06675v2,Yes,potent(1)
0000-0002-0269-2763,Felix Jungmann,Universität Duisburg-Essen,Observation of bottom-up formation for charged grain aggregates related   to pre-planetary evolution beyond the bouncing barrier,1970,"  Context. Particles in protoplanetary disks go through a number of phases that are dominated by collisions. In each of these events, grains exchange electrical charge via triboelectric effects. This enhances the stability of particle aggregates. Aim. Dielectric grains are easily charged by collisions. Here, we investigate whether a charge is capable of inducing an aggregation of particles and we consider how collision properties, such as ticking velocities and collisional cross-sections, are altered. Methods. We explored aggregation in microgravity experiments based on the observation of the motion of submillimeter (submm) grains following many collisions. In the process, grains attract each other, collide, stick, and ultimately form small aggregates. Results. We observed a bottom-up formation of irregular aggregates from submm grains. While some of the observed trajectories during the approach of grains reflect the presence of a pure Coulomb potential, the motion is not always in agreement with pure Kepler motion. Higher-order potentials of multipole charge distributions stand as a plausible explanation for this behavior. An immediate consequence of charging is that the particles continue to stick to each other at velocities of $\sim 10 \, \rm cm/s,$ while surface forces of neutral grains are only expected to allow sticking below $\sim 1 \, \rm mm/s$. No bouncing collision was observed among hundreds of collisions in the given parameter range. Applied to early phases of planet formation, the forming aggregates are therefore the first steps in a new growth phase beyond the traditional bouncing barrier in planet formation. ",https://doi.org/10.1051/0004-6361/202039430,2106.01081v1,Yes,potent(2)
0000-0002-0286-8183,Robin Leister,Karlsruhe Institut für Technologie,Investigating the shortcomings of the Flow Convergence Method for   quantification of Mitral Regurgitation in a pulsatile in-vitro environment   and with Computational Fluid Dynamics,1970,"  The flow convergence method includes calculation of the proximal isovelocity surface area (PISA) and is widely used to classify mitral regurgitation (MR) with echocardiography. It constitutes a primary decision factor for determination of treatment and should therefore be a robust quantification method. However, it is known for its tendency to underestimate MR and its dependence on user expertise. The present work systematically compares different pulsatile flow profiles arising from different regurgitation orifices using transesophageal echocardiographic (TEE) probe and particle image velocimetry (PIV) as a reference in an in-vitro environment. It is found that the inter-observer variability using echocardiography is small compared to the systematic underestimation of the regurgitation volume for large orifice areas (up to 52%) where a violation of the flow convergence method assumptions occurs. From a flow perspective, a starting vortex was found as a dominant flow pattern in the regurgant jet for all orifice shapes and sizes. A series of simplified computational fluid dynamics (CFD) simulations indicate that selecting a suboptimal aliasing velocity during echocardiography measurements might be a primary source of potential underestimation in MR characterization via the PISA-based method, reaching up to 40%. In this study, it has been noted in clinical observations that physicians often select an aliasing velocity higher than necessary for optimal estimation in diagnostic procedures. ",Kein DOI-Link verfügbar,2403.05224v3,Yes,potent(1)
0000-0002-0342-324X,Dietmar Paschek,Universität Rostock,Temperature Dependence of the Hydrophobic Hydration and Interaction of   Simple Solutes: An Examination of Five Popular Water Models,1970,"  We examine five different popular rigid water models (SPC, SPCE, TIP3P, TIP4P and TIP5P) using MD simulations in order to investigate the hydrophobic hydration and interaction of apolar Lennard-Jones solutes as a function of temperature in the range between $275 {K}$ and $375 {K}$. For all investigated models and state points we calculate the excess chemical potential for the noble gases and Methane.All water models exhibit too small hydration entropies, but show a clear hierarchy. TIP3P shows poorest agreement with experiment whereas TIP5P is closest to the experimental data at lower temperatures and SPCE is closest at higher temperatures. A rescaling procedure inspired by information theory model of Hummer et al. ({\em Chem.Phys.}258, 349-370 (2000)) suggests that the differences between the different models and real water can be explained on the basis of the density curves at constant pressure. In addition, the models that give a good representation of the water structure at ambient conditions (TIP5P, SPCE and TIP4P) show considerably better agreement with the experimental data than SPC and TIP3P. We calculate the hydrophobic interaction between Xenon particles directly from a series of 60 ns simulation runs.We find that the temperature dependence of the association is related to the strength of the solvation entropy. Nevertheless, differences between the models seem to require a more detailed molecular picture.The TIP5P model shows by far the strongest temperature dependence.The suggested density-rescaling is also applied to the Xenon-Xenon contact-pair configuration, indicating the presence of a temperature where the hydrophobic interaction turns into purely repulsive.The predicted association for Xenon in real water suggest the presence a strong variation with temperature. ",https://doi.org/10.1063/1.1652015,cond-mat/0312252v3,Yes,potent(1)
0000-0002-0342-324X,Dietmar Paschek,Universität Rostock,Heat Capacity Effects Associated with the Hydrophobic Hydration and   Interaction of Simple Solutes: A Detailed Structural and Energetical Analysis   Based on MD Simulations,1970,"  We examine the SPCE and TIP5P water models to study heat capacity effects associated with the hydrophobic hydration and interaction of Xenon particles. We calculate the excess chemical potential for Xenon employing the Widom particle insertion technique. The solvation enthalpy and excess heat capacity is obtained from the temperature dependence of the chemical potentials and, alternatively, directly by Ewald summation, as well as a reaction field based method. All three different approaches provide consistent results. The reaction field method allows a separation of the individual components to the heat capacity of solvation into solute/solvent and solvent/solvent parts, revealing the solvent/solvent part as the dominating contribution. A detailed spacial analysis of the heat capacity of the water molecules around a pair of Xenon particles at different separations reveals that the enhanced heat capacity of the water molecules in the bisector plane between two Xenon atoms is responsible for the maximum of the heat capacity observed at the desolvation barrier, recently reported by Shimizu and Chan ({\em J. Am. Chem. Soc.},{\bf 123}, 2083--2084 (2001)). The about 60% enlarged heat capacity of water in the concave part of the joint Xenon-Xenon hydration shell is the result of a counterplay of strengthened hydrogen bonds and an enhanced breaking of hydrogen bonds with increasing temperature. Differences between the two models concerning the heat capacity in the Xenon-Xenon contact state are attributed to the different water model bulk heat capacities, and to the different spacial extension of the structure effect introduced by the hydrophobic particles. Similarities between the different states of water in the joint Xenon-Xenon hydration shell and the properties of stretched water are discussed. ",https://doi.org/10.1063/1.1737294,cond-mat/0402202v1,Yes,potent(2)
0000-0002-0342-324X,Dietmar Paschek,Universität Rostock,Revisiting Imidazolium Based Ionic Liquids: Effect of the Conformation   Bias of the [NTf$_{2}$] Anion Studied By Molecular Dynamics Simulations,1970,"  We study ionic liquids composed 1-alkyl-3-methylimidazolium cations and bis(trifluoromethyl-sulfonyl)imide anions ([C$_n$MIm][NTf$_2$]) with varying chain-length $n\!=\!2, 4, 6, 8$ by using molecular dynamics simulations. We show that a reparametrization of the dihedral potentials as well as charges of the [NTf$_2$] anion leads to an improvment of the force field model introduced by K\""oddermann {\em et al.} [ChemPhysChem, \textbf{8}, 2464 (2007)] (KPL-force field). A crucial advantage of the new parameter set is that the minimum energy conformations of the anion ({\em trans} and {\em gauche}), as deduced from {\em ab initio} calculations and {\sc Raman} experiments, are now both well represented by our model. In addition, the results for [C$_n$MIm][NTf$_2$] show that this modification leads to an even better agreement between experiment and molecular dynamics simulation as demonstrated for densities, diffusion coefficients, vaporization enthalpies, reorientational correlation times, and viscosities. Even though we focused on a better representation of the anion conformation, also the alkyl chain-length dependence of the cation behaves closer to the experiment. We strongly encourage to use the new NGKPL force field for the [NTf$_2$] anion instead of the earlier KPL parameter set for computer simulations aiming to describe the thermodynamics, dynamics and also structure of imidazolium based ionic liquids. ",Kein DOI-Link verfügbar,1711.03779v1,Yes,potent(1)
0000-0002-0356-6662,Michael Hartelt,Technische Universität Kaiserslautern,Orbital angular momentum multiplication in plasmonic vortex cavities,1970,"  Orbital angular momentum of light is a core feature in photonics. Its confinement to surfaces using plasmonics has unlocked many phenomena and potential applications. Here we introduce the reflection from structural boundaries as a new degree of freedom to generate and control plasmonic orbital angular momentum. We experimentally demonstrate plasmonic vortex cavities, generating a succession of vortex pulses with increasing topological charge as a function of time. We track the spatio-temporal dynamics of these angularly decelerating plasmon pulse train within the cavities for over 300 femtoseconds using time-resolved Photoemission Electron Microscopy, showing that the angular momentum grows by multiples of the chiral order of the cavity. The introduction of this degree of freedom to tame orbital angular momentum delivered by plasmonic vortices, could miniaturize pump-probe-like quantum initialization schemes, increase the torque exerted by plasmonic tweezers and potentially achieve vortex lattice cavities with dynamically evolving topology. ",https://doi.org/10.1126/sciadv.abg5571,2012.05833v1,Yes,potent(2)
0000-0002-0379-5967,Tomas Dohnal,Martin-Luther-Universität Halle-Wittenberg,Traveling Solitary Waves in the Periodic Nonlinear Schrödinger   Equation with Finite Band Potentials,1970,"  The paper studies asymptotics of moving gap solitons in nonlinear periodic structures of finite contrast (""deep grating"") within the one dimensional periodic nonlinear Schr\""odinger equation (PNLS). Periodic structures described by a finite band potential feature transversal crossings of band functions in the linear band structure and a periodic perturbation of the potential yields new small gaps. Novel gap solitons with O(1) velocity despite the deep grating are presented in these gaps. An approximation of gap solitons is given by slowly varying envelopes which satisfy a system of generalized Coupled Mode Equations (gCME) and by Bloch waves at the crossing point. The eigenspace at the crossing point is two dimensional and it is necessary to select Bloch waves belonging to the two band functions. This is achieved by an optimization algorithm. Traveling solitary wave solutions of the gCME then result in nearly solitary wave solutions of PNLS moving at an O(1) velocity across the periodic structure. A number of numerical tests are performed to confirm the asymptotics. ",Kein DOI-Link verfügbar,1305.3504v2,Yes,potent(2)
0000-0002-0379-5967,Tomas Dohnal,Martin-Luther-Universität Halle-Wittenberg,Vortex families near a spectral edge in the Gross-Pitaevskii equation   with a two-dimensional periodic potential,1970,  We examine numerically vortex families near band edges of the Bloch wave spectrum in the Gross--Pitaevskii equation with a two-dimensional periodic potential and in the discrete nonlinear Schroedinger equation. We show that besides vortex families that terminate at a small distance from the band edges via fold bifurcations there exist vortex families that are continued all way to the band edges. ,https://doi.org/10.1103/PhysRevE.85.026605,1110.3780v1,Yes,potent(1)
0000-0002-0379-5967,Tomas Dohnal,Martin-Luther-Universität Halle-Wittenberg,Surface gap solitons at a nonlinearity interface,1970,"  We demonstrate existence of waves localized at the interface of two nonlinear periodic media with different coefficients of the cubic nonlinearity via the one-dimensional Gross--Pitaevsky equation. We call these waves the surface gap solitons (SGS). In the case of smooth symmetric periodic potentials, we study analytically bifurcations of SGS's from standard gap solitons and determine numerically the maximal jump of the nonlinearity coefficient allowing for the SGS existence. We show that the maximal jump vanishes near the thresholds of bifurcations of gap solitons. In the case of continuous potentials with a jump in the first derivative at the interface, we develop a homotopy method of continuation of SGS families from the solution obtained via gluing of parts of the standard gap solitons and study existence of SGS's in the photonic band gaps. We explain the termination of the SGS families in the interior points of the band gaps from the bifurcation of linear bound states in the continuous non-smooth potentials. ",https://doi.org/10.1137/060676751,0704.1742v2,Yes,potent(3)
0000-0002-0379-5967,Tomas Dohnal,Martin-Luther-Universität Halle-Wittenberg,Coupled-mode equations and gap solitons in a two-dimensional nonlinear   elliptic problem with a separable periodic potential,1970,"  We address a two-dimensional nonlinear elliptic problem with a finite-amplitude periodic potential. For a class of separable symmetric potentials, we study the bifurcation of the first band gap in the spectrum of the linear Schr\""{o}dinger operator and the relevant coupled-mode equations to describe this bifurcation. The coupled-mode equations are derived by the rigorous analysis based on the Fourier--Bloch decomposition and the Implicit Function Theorem in the space of bounded continuous functions vanishing at infinity. Persistence of reversible localized solutions, called gap solitons, beyond the coupled-mode equations is proved under a non-degeneracy assumption on the kernel of the linearization operator. Various branches of reversible localized solutions are classified numerically in the framework of the coupled-mode equations and convergence of the approximation error is verified. Error estimates on the time-dependent solutions of the Gross--Pitaevskii equation and the coupled-mode equations are obtained for a finite-time interval. ",https://doi.org/10.1007/s00332-008-9027-9,0707.3731v2,Yes,potent(2)
0000-0002-0379-5967,Tomas Dohnal,Martin-Luther-Universität Halle-Wittenberg,Interfaces Supporting Surface Gap Soliton Ground States in the 1D   Nonlinear Schroedinger Equation,1970,"  We consider the problem of verifying the existence of $H^1$ ground states of the 1D nonlinear Schr\""odinger equation for an interface of two periodic structures: $$-u"" +V(x)u -\lambda u = \Gamma(x) |u|^{p-1}u \ {on} \R$$ with $V(x) = V_1(x), \Gamma(x)=\Gamma_1(x)$ for $x\geq 0$ and $V(x) = V_2(x), \Gamma(x)=\Gamma_2(x)$ for $x<0$. Here $V_1,V_2,\Gamma_1,\Gamma_2$ are periodic, $\lambda <\min\sigma(-\tfrac{d^2}{dx^2}+V)$, and $p>1$. The article [T. Dohnal, M. Plum and W. Reichel, ""Surface Gap Soliton Ground States for the Nonlinear Schr\""odinger Equation,"" \textit{Comm. Math. Phys.} \textbf{308}, 511-542 (2011)] provides in the 1D case an existence criterion in the form of an integral inequality involving the linear potentials $V_{1},V_2$ and the Bloch waves of the operators $-\tfrac{d^2}{dx^2}+V_{1,2}-\lambda$. We choose here the classes of piecewise constant and piecewise linear potentials $V_{1,2}$ and check this criterion for a set of parameter values. In the piecewise constant case the Bloch waves are calculated explicitly and in the piecewise linear case verified enclosures of the Bloch waves are computed numerically. The integrals in the criterion are evaluated via interval arithmetic so that rigorous existence statements are produced. Examples of interfaces supporting ground states are reported including such, for which ground state existence follows for all periodic $\Gamma_ {1,2}$ with $\esssup \Gamma_{1,2}>0$. ",Kein DOI-Link verfügbar,1202.3588v3,Yes,potent(2)
0000-0002-0379-5967,Tomas Dohnal,Martin-Luther-Universität Halle-Wittenberg,Bifurcation of nonlinear bound states in the periodic Gross-Pitaevskii   equation with PT-symmetry,1970,"  The stationary Gross-Pitaevskii equation in one dimension is considered with a complex periodic potential satisfying the conditions of the PT (parity-time reversal) symmetry. Under rather general assumptions on the potentials we prove bifurcations of PT-symmetric nonlinear bound states from the end points of a real interval in the spectrum of the non-selfadjoint linear Schrodinger operator with a complex PT-symmetric periodic potential. The nonlinear bound states are approximated by the effective amplitude equation, which bears the form of the cubic nonlinear Schrodinger equation. In addition we provide sufficient conditions for the appearance of complex spectral bands when the complex $\PT$-symmetric potential has an asymptotically small imaginary part. ",Kein DOI-Link verfügbar,1702.03469v2,Yes,potent(4)
0000-0002-0379-7719,Stefan Martin,Technische Universität Bergakademie Freiberg,Nulling at short wavelengths: theoretical performance constraints and a   demonstration of faint companion detection inside the diffraction limit with   a rotating-baseline interferometer,1970,"  The Palomar Fiber Nuller (PFN) is a rotating-baseline nulling interferometer that enables high-accuracy near-infrared (NIR) nulling observations with full azimuth coverage. To achieve NIR null-depth accuracies of several x 10-4, the PFN uses a common-mode optical system to provide a high degree of symmetry, single-mode-fiber beam combination to reduce sensitivity to pointing and wavefront errors, extreme adaptive optics to stabilize the fiber coupling and the cross-aperture fringe phase, rapid signal calibration and camera readout to minimize temporal effects, and a statistical null-depth fluctuation analysis to relax the phase stabilization requirement. Here we describe the PFN final design and performance, and provide a demonstration of faint-companion detection by means of nulling-baseline rotation, as originally envisioned for space-based nulling interferometry. Specifically, the Ks-band null-depth rotation curve measured on the spectroscopic binary eta Peg reflects both a secondary star 1.08 +/- 0.06 x 10-2 as bright as the primary, and a null-depth contribution of 4.8 +/- 1.6 x 10-4 due to the size of the primary star. With a 30 mas separation at the time, eta Peg B was well inside both the telescope diffraction-limited beam diameter (88 mas) and typical coronagraphic inner working angles. Finally, we discuss potential improvements that can enable a number of small-angle nulling observations on larger telescopes. ",https://doi.org/10.1093/mnras/stz2163,1908.05977v1,Yes,potent(1)
0000-0002-0379-7903,Dominik Hartmann,Ruhr Universität Bochum,"The Research Space: using the career paths of scholars to predict the   evolution of the research output of individuals, institutions, and nations",1970,"  In recent years scholars have built maps of science by connecting the academic fields that cite each other, are cited together, or that cite a similar literature. But since scholars cannot always publish in the fields they cite, or that cite them, these science maps are only rough proxies for the potential of a scholar, organization, or country, to enter a new academic field. Here we use a large dataset of scholarly publications disambiguated at the individual level to create a map of science-or research space-where links connect pairs of fields based on the probability that an individual has published in both of them. We find that the research space is a significantly more accurate predictor of the fields that individuals and organizations will enter in the future than citation based science maps. At the country level, however, the research space and citations based science maps are equally accurate. These findings show that data on career trajectories-the set of fields that individuals have previously published in-provide more accurate predictors of future research output for more focalized units-such as individuals or organizations-than citation based science maps. ",Kein DOI-Link verfügbar,1602.08409v3,Yes,"potent(1), scholarly(1)"
0000-0002-0383-7709,Fabian Müller,Universität Konstanz,Phononic heat conductance of gold atomic contacts: Coherent versus   incoherent transport,1970,"  We present here a theoretical method to determine the phononic contribution to the thermal conductance of nanoscale systems in the phase-coherent regime. Our approach makes use of classical molecular dynamics (MD) simulations to calculate the temperature-dependent dynamical matrix, and the phononic heat conductance is subsequently computed within the Landauer-B\""uttiker formalism with the help of nonequilibrium Green's function techniques. Tailored to nanostructures, crucial steps of force constant and heat transport calculations are performed directly in real space. As compared to conventional density functional theory (DFT) approaches, the advantage of our method is two-fold. First, interatomic interactions can be described with the method of choice. Semiempirical potentials may lead to large computational speedups, enabling the study of much larger systems. Second, the method naturally takes into account the temperature dependence of atomic force constants, an aspect that is ignored in typical static DFT-based calculations. We illustrate our method by analyzing the temperature dependence of the phononic thermal conductance of gold (Au) chains with lengths ranging from 1 to 12 atoms. Moreover, in order to evaluate the importance of anharmonic effects in these atomic-scale wires, we compare the phase-coherent approach with nonequilibrium MD (NEMD) simulations. We find that the predictions of the phase-coherent method and the classical NEMD approach largely agree above the Debye temperature for all studied chain lengths, which shows that heat transport is coherent and that our phase-coherent approach is well suited for such nanostructures. ",https://doi.org/10.1103/PhysRevB.106.195401,2208.09171v2,Yes,potent(1)
0000-0002-0395-5115,Stefan Meyer,Christian-Albrechts-Universität zu Kiel,Correlations and pair emission in the escape dynamics of ions from   one-dimensional traps,1970,  We explore the non-equilibrium escape dynamics of long-range interacting ions in one-dimensional traps. The phase space of the few ion setup and its impact on the escape properties are studied. As a main result we show that an instantaneous reduction of the trap's potential depth leads to the synchronized emission of a sequence of ion pairs if the initial configurations are close to the crystalline ionic configuration. The corresponding time-intervals of the consecutive pair emission as well as the number of emitted pairs can be tuned by changing the final trap depth. Correlations between the escape times and kinetic energies of the ions are observed and analyzed. ,https://doi.org/10.1088/1367-2630/13/2/023006,1012.2711v1,Yes,potent(1)
0000-0002-0395-5115,Stefan Meyer,Christian-Albrechts-Universität zu Kiel,Bid-Centric Cloud Service Provisioning,1970,"  Bid-centric service descriptions have the potential to offer a new cloud service provisioning model that promotes portability, diversity of choice and differentiation between providers. A bid matching model based on requirements and capabilities is presented that provides the basis for such an approach. In order to facilitate the bidding process, tenders should be specified as abstractly as possible so that the solution space is not needlessly restricted. To this end, we describe how partial TOSCA service descriptions allow for a range of diverse solutions to be proposed by multiple providers in response to tenders. Rather than adopting a lowest common denominator approach, true portability should allow for the relative strengths and differentiating features of cloud service providers to be applied to bids. With this in mind, we describe how TOSCA service descriptions could be augmented with additional information in order to facilitate heterogeneity in proposed solutions, such as the use of coprocessors and provider-specific services. ",Kein DOI-Link verfügbar,1312.4853v1,Yes,potent(1)
0000-0002-0407-0597,Michael Figelius,Universität Siegen,The complexity of knapsack problems in wreath products,1970,"  We prove new complexity results for computational problems in certain wreath products of groups and (as an application) for free solvable group. For a finitely generated group we study the so-called power word problem (does a given expression $u_1^{k_1} \ldots u_d^{k_d}$, where $u_1, \ldots, u_d$ are words over the group generators and $k_1, \ldots, k_d$ are binary encoded integers, evaluate to the group identity?) and knapsack problem (does a given equation $u_1^{x_1} \ldots u_d^{x_d} = v$, where $u_1, \ldots, u_d,v$ are words over the group generators and $x_1,\ldots,x_d$ are variables, has a solution in the natural numbers). We prove that the power word problem for wreath products of the form $G \wr \mathbb{Z}$ with $G$ nilpotent and iterated wreath products of free abelian groups belongs to $\mathsf{TC}^0$. As an application of the latter, the power word problem for free solvable groups is in $\mathsf{TC}^0$. On the other hand we show that for wreath products $G \wr \mathbb{Z}$, where $G$ is a so called uniformly strongly efficiently non-solvable group (which form a large subclass of non-solvable groups), the power word problem is $\mathsf{coNP}$-hard. For the knapsack problem we show $\mathsf{NP}$-completeness for iterated wreath products of free abelian groups and hence free solvable groups. Moreover, the knapsack problem for every wreath product $G \wr \mathbb{Z}$, where $G$ is uniformly efficiently non-solvable, is $\Sigma^2_p$-hard. ",Kein DOI-Link verfügbar,2002.08086v1,Yes,potent(1)
0000-0002-0465-1068,Christopher Morris,Technische Universität Dortmund,Probabilistically Rewired Message-Passing Neural Networks,1970,"  Message-passing graph neural networks (MPNNs) emerged as powerful tools for processing graph-structured input. However, they operate on a fixed input graph structure, ignoring potential noise and missing information. Furthermore, their local aggregation mechanism can lead to problems such as over-squashing and limited expressive power in capturing relevant graph structures. Existing solutions to these challenges have primarily relied on heuristic methods, often disregarding the underlying data distribution. Hence, devising principled approaches for learning to infer graph structures relevant to the given prediction task remains an open challenge. In this work, leveraging recent progress in exact and differentiable $k$-subset sampling, we devise probabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edges while omitting less beneficial ones. For the first time, our theoretical analysis explores how PR-MPNNs enhance expressive power, and we identify precise conditions under which they outperform purely randomized approaches. Empirically, we demonstrate that our approach effectively mitigates issues like over-squashing and under-reaching. In addition, on established real-world datasets, our method exhibits competitive or superior predictive performance compared to traditional MPNN models and recent graph transformer architectures. ",Kein DOI-Link verfügbar,2310.02156v4,Yes,potent(1)
0000-0002-0492-6527,Michael Moeller,Universität Siegen,Color Bregman TV,1970,"  In this paper we present a novel iterative procedure for multichannel image and data reconstruction using Bregman distances. With the motivation that multiple channels sharing a common subgradient with respect to a suitable regularization implies desirable properties such as a common edge set (and a common direction of the normals to the level lines) in the case of the total variation (TV), we propose to determine each iterate by regularizing each channel with a weighted linear combination of Bregman distances to all other image channels from the previous iteration. In this sense we generalize the Bregman iteration proposed by Osher et al. to multichannel images. We prove the convergence of the proposed scheme, analyze stationary points and present numerical experiments on color image denoising, which show the superior behavior of our approach in comparison to TV, TV with Bregman iterations on each channel separately, and vectorial TV. Additionally, we propose to use the infimal convolution of Bregman distances to different channels from the previous iteration to obtain the independence of the sign and hence the independence of the direction of the edge. While this work focuses on TV regularization, the proposed scheme can potentially improve any variational multichannel reconstruction method with a 1-homogeneous regularization. ",Kein DOI-Link verfügbar,1310.3146v3,Yes,potent(1)
0000-0002-0492-6527,Michael Moeller,Universität Siegen,Collaborative Total Variation: A General Framework for Vectorial TV   Models,1970,"  Even after over two decades, the total variation (TV) remains one of the most popular regularizations for image processing problems and has sparked a tremendous amount of research, particularly to move from scalar to vector-valued functions. In this paper, we consider the gradient of a color image as a three dimensional matrix or tensor with dimensions corresponding to the spatial extend, the differences to other pixels, and the spectral channels. The smoothness of this tensor is then measured by taking different norms along the different dimensions. Depending on the type of these norms one obtains very different properties of the regularization, leading to novel models for color images. We call this class of regularizations collaborative total variation (CTV). On the theoretical side, we characterize the dual norm, the subdifferential and the proximal mapping of the proposed regularizers. We further prove, with the help of the generalized concept of singular vectors, that an $\ell^{\infty}$ channel coupling makes the most prior assumptions and has the greatest potential to reduce color artifacts. Our practical contributions consist of an extensive experimental section where we compare the performance of a large number of collaborative TV methods for inverse problems like denoising, deblurring and inpainting. ",https://doi.org/10.1137/15M102873X,1508.01308v1,Yes,potent(1)
0000-0002-0492-6527,Michael Moeller,Universität Siegen,"Locally Sparse Reconstruction Using the $\ell^{1,\infty}$-Norm",1970,"  This paper discusses the incorporation of local sparsity information, e.g. in each pixel of an image, via minimization of the $\ell^{1,\infty}$-norm. We discuss the basic properties of this norm when used as a regularization functional and associated optimization problems, for which we derive equivalent reformulations either more amenable to theory or to numerical computation. Further focus of the analysis is put on the locally 1-sparse case, which is well motivated by some biomedical imaging applications. Our computational approaches are based on alternating direction methods of multipliers (ADMM) and appropriate splittings with augmented Lagrangians. Those are tested for a model scenario related to dynamic positron emission tomography (PET), which is a functional imaging technique in nuclear medicine. The results of this paper provide insight into the potential impact of regularization with the $\ell^{1,\infty}$-norm for local sparsity in appropriate settings. However, it also indicates several shortcomings, possibly related to the non-tightness of the functional as a relaxation of the $\ell^{0,\infty}$-norm. ",Kein DOI-Link verfügbar,1405.5908v3,Yes,potent(1)
0000-0002-0492-6527,Michael Moeller,Universität Siegen,Is Differentiable Architecture Search truly a One-Shot Method?,1970,"  Differentiable architecture search (DAS) is a widely researched tool for the discovery of novel architectures, due to its promising results for image classification. The main benefit of DAS is the effectiveness achieved through the weight-sharing one-shot paradigm, which allows efficient architecture search. In this work, we investigate DAS in a systematic case study of inverse problems, which allows us to analyze these potential benefits in a controlled manner. We demonstrate that the success of DAS can be extended from image classification to signal reconstruction, in principle. However, our experiments also expose three fundamental difficulties in the evaluation of DAS-based methods in inverse problems: First, the results show a large variance in all test cases. Second, the final performance is strongly dependent on the hyperparameters of the optimizer. And third, the performance of the weight-sharing architecture used during training does not reflect the final performance of the found architecture well. While the results on image reconstruction confirm the potential of the DAS paradigm, they challenge the common understanding of DAS as a one-shot method. ",Kein DOI-Link verfügbar,2108.05647v3,Yes,potent(2)
0000-0002-0492-6527,Michael Moeller,Universität Siegen,Adiabatic Quantum Graph Matching with Permutation Matrix Constraints,1970,"  Matching problems on 3D shapes and images are challenging as they are frequently formulated as combinatorial quadratic assignment problems (QAPs) with permutation matrix constraints, which are NP-hard. In this work, we address such problems with emerging quantum computing technology and propose several reformulations of QAPs as unconstrained problems suitable for efficient execution on quantum hardware. We investigate several ways to inject permutation matrix constraints in a quadratic unconstrained binary optimization problem which can be mapped to quantum hardware. We focus on obtaining a sufficient spectral gap, which further increases the probability to measure optimal solutions and valid permutation matrices in a single run. We perform our experiments on the quantum computer D-Wave 2000Q (2^11 qubits, adiabatic). Despite the observed discrepancy between simulated adiabatic quantum computing and execution on real quantum hardware, our reformulation of permutation matrix constraints increases the robustness of the numerical computations over other penalty approaches in our experiments. The proposed algorithm has the potential to scale to higher dimensions on future quantum computing architectures, which opens up multiple new directions for solving matching problems in 3D computer vision and graphics. ",Kein DOI-Link verfügbar,2107.04032v1,Yes,potent(1)
0000-0002-0492-6527,Michael Moeller,Universität Siegen,Intrinsic Neural Fields: Learning Functions on Manifolds,1970,"  Neural fields have gained significant attention in the computer vision community due to their excellent performance in novel view synthesis, geometry reconstruction, and generative modeling. Some of their advantages are a sound theoretic foundation and an easy implementation in current deep learning frameworks. While neural fields have been applied to signals on manifolds, e.g., for texture reconstruction, their representation has been limited to extrinsically embedding the shape into Euclidean space. The extrinsic embedding ignores known intrinsic manifold properties and is inflexible wrt. transfer of the learned function. To overcome these limitations, this work introduces intrinsic neural fields, a novel and versatile representation for neural fields on manifolds. Intrinsic neural fields combine the advantages of neural fields with the spectral properties of the Laplace-Beltrami operator. We show theoretically that intrinsic neural fields inherit many desirable properties of the extrinsic neural field framework but exhibit additional intrinsic qualities, like isometry invariance. In experiments, we show intrinsic neural fields can reconstruct high-fidelity textures from images with state-of-the-art quality and are robust to the discretization of the underlying manifold. We demonstrate the versatility of intrinsic neural fields by tackling various applications: texture transfer between deformed shapes & different shapes, texture reconstruction from real-world images with view dependence, and discretization-agnostic learning on meshes and point clouds. ",Kein DOI-Link verfügbar,2203.07967v3,Yes,versatile(1)
0000-0002-0493-0876,Thomas Engel,Friedrich-Schiller-Universität Jena,Software-Defined Location Privacy Protection for Vehicular Networks,1970,"  While the adoption of connected vehicles is growing, security and privacy concerns are still the key barriers raised by society. These concerns mandate automakers and standardization groups to propose convenient solutions for privacy preservation. One of the main proposed solutions is the use of Pseudonym-Changing Strategies (PCSs). However, ETSI has recently published a technical report which highlights the absence of standardized and efficient PCSs [1]. This alarming situation mandates an innovative shift in the way that the privacy of end-users is protected during their journey. Software-Defined Networking (SDN) is emerging as a key 5G enabler to manage the network in a dynamic manner. SDN-enabled wireless networks are opening up new programmable and highly-flexible privacy-aware solutions. We exploit this paradigm to propose an innovative software-defined location privacy architecture for vehicular networks. The proposed architecture is context-aware, programmable, extensible, and able to encompass all existing and future pseudonym-changing strategies. To demonstrate the merit of our architecture, we consider a case study that involves four pseudonym-changing strategies, which we deploy over our architecture and compare with their static implementations. We also detail how the SDN controller dynamically switches between the strategies according to the context. ",Kein DOI-Link verfügbar,2001.09170v1,Yes,innovative(2)
0000-0002-0493-0876,Thomas Engel,Friedrich-Schiller-Universität Jena,Mitigating Collisions in Sidelink NR V2X: A Study on Cooperative   Resource Allocation,1970,"  New Radio (NR) Vehicle-to-Everything (V2X) Sidelink (SL), an integral part of the 5G NR standard, is expected to revolutionize the automotive and rail industries by enabling direct and low-latency exchange of critical information between traffic participants independently of cellular networks. However, this advancement depends primarily on efficient SL resource allocation. Mode 2(a) is a well-known method for this purpose, where each node autonomously selects resources. However, this method is prone to packet collisions due to the hidden-node problem. In this paper, we propose a cooperative scheduling method that could potentially address this issue. We describe an extension of Mode 2(a) that allows nodes to share resource allocation information at two hops. Initial simulation results show a promising improvement over Mode 2(a). ",Kein DOI-Link verfügbar,2404.17532v1,Yes,potent(1)
0000-0002-0615-8082,Felix Yu,Johannes Gutenberg Universität Mainz,Di-jet resonances at future hadron colliders: A Snowmass whitepaper,1970,"  I investigate the sensitivity of future hadron colliders to di-jet resonances arising from Z' or coloron models. The projected discovery potential and exclusion limits for these resonances is presented in the coupling vs. mass plane, which highlights both the increased mass reach from higher energy machines as well as the improved coupling sensivity from larger luminosity. ",Kein DOI-Link verfügbar,1308.1077v1,Yes,potent(1)
0000-0002-0615-8082,Felix Yu,Johannes Gutenberg Universität Mainz,Primer on Axion Physics,1970,"  I review the canonical axion potential, with an emphasis on the field theory underlying radial and angular modes of complex scalar fields. I present the explicit calculation of the instanton-induced breaking of the Goldstone field direction necessary to derive the canonical axion mass and decay constant relation. The primer is intended to serve an audience with elementary quantum field theory expertise. ",https://doi.org/10.1002/andp.202300106,2308.08612v1,Yes,potent(1)
0000-0002-0615-8082,Felix Yu,Johannes Gutenberg Universität Mainz,Discovery potential of Kaluza-Klein gluons at hadron colliders: A   Snowmass whitepaper,1970,"  We investigate the discovery potential of Kaluza-Klein gluons as a dijet resonance at hadron colliders with different center-of-mass energies, from 14 TeV to 33 TeV to 100 TeV. We also present the current bounds from dijet searches at UA2, Tevatron, and LHC. ",Kein DOI-Link verfügbar,1308.1078v2,Yes,potent(1)
0000-0002-0615-8082,Felix Yu,Johannes Gutenberg Universität Mainz,Collider Signals of Maximal Flavor Violation: Same-Sign Leptons from   Same-Sign Tops at the Tevatron,1970,"  In models of maximal flavor violation (MxFV) there is at least one new scalar $\Phi_{FV}$ which couples to the quarks via $\Phi_{FV} q_i q_j \propto \xi_{ij}$ where $\xi_{i3},\xi_{3i} \sim V_{tb}$ for $i = 1,2$ and $\xi_{33} \sim V_{td}$ and $V$ is the CKM matrix. In this article, we explore the potential phenomenological implications of MxFV for collider experiments. We study MxFV signals of same-sign leptons from same-sign top-quark pair production at the Tevatron and at the LHC. We show that the current Tevatron dataset has strong sensitivity to this signature, for which there are no current limits. For example, if $m_{\Phi_{FV}} \sim 200$ GeV and the MxFV coupling $\xi$ has a natural value of $\sim 1$, we expect $\sim 12$ MxFV events to survive a selection requiring a pair of same-sign leptons, a tagged $b$-jet and missing transverse energy, over a background of approximately 4-5 events. ",https://doi.org/10.1103/PhysRevD.78.033003,0803.3795v1,Yes,potent(1)
0000-0002-0615-8082,Felix Yu,Johannes Gutenberg Universität Mainz,Sensitivity of potential future $pp$ colliders to quark compositeness,1970,  A study is presented of the sensitivity of potential future $pp$ colliders to quark compositeness. The analysis uses normalized dijet angular distributions compared to expectations from leading-order contact interaction models. ,Kein DOI-Link verfügbar,1307.7149v2,Yes,potent(1)
0000-0002-0615-8082,Felix Yu,Johannes Gutenberg Universität Mainz,Constraining RS Models by Future Flavor and Collider Measurements: A   Snowmass Whitepaper,1970,"  Randall-Sundrum models are models of quark flavor, because they explain the hierarchies in the quark masses and mixings in terms of order one localization parameters of extra dimensional wavefunctions. The same small numbers which generate the light quark masses suppress contributions to flavor violating tree level amplitudes. In this note we update universal constraints from electroweak precision parameters and demonstrate how future measurements of flavor violation in ultra rare decay channels of Kaons and B mesons will constrain the parameter space of this type of models. We show how collider signatures are correlated with these flavor measurements and compute projected limits for direct searches at the 14 TeV LHC run, a 14 TeV LHC luminosity upgrade, a 33 TeV LHC energy upgrade, and a potential 100 TeV machine. We further discuss the effects of a warped model of leptons in future measurements of lepton flavor violation. ",Kein DOI-Link verfügbar,1310.1070v1,Yes,potent(1)
0000-0002-0615-8082,Felix Yu,Johannes Gutenberg Universität Mainz,Doubly-stochastic mining for heterogeneous retrieval,1970,"  Modern retrieval problems are characterised by training sets with potentially billions of labels, and heterogeneous data distributions across subpopulations (e.g., users of a retrieval system may be from different countries), each of which poses a challenge. The first challenge concerns scalability: with a large number of labels, standard losses are difficult to optimise even on a single example. The second challenge concerns uniformity: one ideally wants good performance on each subpopulation. While several solutions have been proposed to address the first challenge, the second challenge has received relatively less attention. In this paper, we propose doubly-stochastic mining (S2M ), a stochastic optimization technique that addresses both challenges. In each iteration of S2M, we compute a per-example loss based on a subset of hardest labels, and then compute the minibatch loss based on the hardest examples. We show theoretically and empirically that by focusing on the hardest examples, S2M ensures that all data subpopulations are modelled well. ",Kein DOI-Link verfügbar,2004.10915v1,Yes,potent(1)
0000-0002-0615-8082,Felix Yu,Johannes Gutenberg Universität Mainz,Compatibility of theta13 and the Type I Seesaw Model with A4 Symmetry,1970,"  We derive formulae for neutrino masses and mixing angles in a type I seesaw framework with an underlying A4 flavor symmetry. In particular, the Majorana neutrino mass matrix includes contributions from an A4 triplet, 1, 1', and 1"" flavon fields. Using these formulae, we constrain the general A4 parameter space using the updated global fits on neutrino mixing angles and mass squared differences, including results from the Daya Bay and RENO experiments, and we find predictive relations among the mixing parameters for certain choices of the triplet vacuum expectation value. In the normal hierarchy case, sizable deviation from maximal atmospheric mixing is predicted, and such deviation is strongly correlated with the value of theta13 in the range of ~ (8-10) degrees. On the other hand, such deviation is negligible and insensitive to theta13 in the inverted mass hierarchy case. We also show expectations for the Dirac CP phase resulting from the parameter scan. Future refined measurements of neutrino mixing angles will test these predicted correlations and potentially show evidence for particular triplet vev patterns. ",https://doi.org/10.1007/JHEP02(2013)021,1210.6982v2,Yes,potent(1)
0000-0002-0646-6050,Juliane Doster,Universität Konstanz,Strong Strain-Induced Coupling between Nanomechanical Pillar Resonators,1970,"  Networks of coupled resonators are an ubiquitous concept in physics, forming the basis of synchronization phenomena, metamaterial formation, nonreciprocal behavior and topological effects. Such systems are typically explored using optical or microwave resonators. In recent years, mechanical resonators have entered the stage as universal building block for resonator networks, both for their well-controlled mechanical properties and for their eigenfrequencies conveniently located in the radio-frequency regime. Vertically oriented nanomechanical pillar resonators are ideally suited for the dense integration into large resonator networks. However, to realize the potential of these promising systems, an intrinsic coupling mechanism needs to be established. Here, we demonstrate strain-induced, strong coupling between two adjacent nanomechanical pillar resonators. The coupling is mediated through the strain distribution in the joint substrate caused by the flexural vibration of the pillars, such that the coupling strength can be controlled by the geometric properties of the nanopillars as well as their separation. Both, mode hybridization and the formation of an avoided level crossing in the response of the nanopillar pair are experimentally observed. The coupling mechanism is readily scalable to large arrays of nanopillars, enabling all-mechanical resonator networks for the investigation of a broad range of collective dynamical phenomena. ",https://doi.org/10.1038/s41467-019-13309-9,1812.08614v1,Yes,potent(1)
0000-0002-0708-3035,Xiaochen Zhang,Freie Universität Berlin,Scalable Power Control/Beamforming in Heterogeneous Wireless Networks   with Graph Neural Networks,1970,"  Machine learning (ML) has been widely used for efficient resource allocation (RA) in wireless networks. Although superb performance is achieved on small and simple networks, most existing ML-based approaches are confronted with difficulties when heterogeneity occurs and network size expands. In this paper, specifically focusing on power control/beamforming (PC/BF) in heterogeneous device-to-device (D2D) networks, we propose a novel unsupervised learning-based framework named heterogeneous interference graph neural network (HIGNN) to handle these challenges. First, we characterize diversified link features and interference relations with heterogeneous graphs. Then, HIGNN is proposed to empower each link to obtain its individual transmission scheme after limited information exchange with neighboring links. It is noteworthy that HIGNN is scalable to wireless networks of growing sizes with robust performance after trained on small-sized networks. Numerical results show that compared with state-of-the-art benchmarks, HIGNN achieves much higher execution efficiency while providing strong performance. ",Kein DOI-Link verfügbar,2104.05463v2,Yes,noteworthy(1)
0000-0002-0748-1025,Lin Zhu,Universität Hamburg,Cross-domain Chinese Sentence Pattern Parsing,1970,"  Sentence Pattern Structure (SPS) parsing is a syntactic analysis method primarily employed in language teaching.Existing SPS parsers rely heavily on textbook corpora for training, lacking cross-domain capability.To overcome this constraint, this paper proposes an innovative approach leveraging large language models (LLMs) within a self-training framework. Partial syntactic rules from a source domain are combined with target domain sentences to dynamically generate training data, enhancing the adaptability of the parser to diverse domains.Experiments conducted on textbook and news domains demonstrate the effectiveness of the proposed method, outperforming rule-based baselines by 1.68 points on F1 metrics. ",Kein DOI-Link verfügbar,2402.16311v3,Yes,innovative(1)
0000-0002-0748-1025,Lin Zhu,Universität Hamburg,Exploiting Frequency Correlation for Hyperspectral Image Reconstruction,1970,"  Deep priors have emerged as potent methods in hyperspectral image (HSI) reconstruction. While most methods emphasize space-domain learning using image space priors like non-local similarity, frequency-domain learning using image frequency priors remains neglected, limiting the reconstruction capability of networks. In this paper, we first propose a Hyperspectral Frequency Correlation (HFC) prior rooted in in-depth statistical frequency analyses of existent HSI datasets. Leveraging the HFC prior, we subsequently establish the frequency domain learning composed of a Spectral-wise self-Attention of Frequency (SAF) and a Spectral-spatial Interaction of Frequency (SIF) targeting low-frequency and high-frequency components, respectively. The outputs of SAF and SIF are adaptively merged by a learnable gating filter, thus achieving a thorough exploitation of image frequency priors. Integrating the frequency domain learning and the existing space domain learning, we finally develop the Correlation-driven Mixing Domains Transformer (CMDT) for HSI reconstruction. Extensive experiments highlight that our method surpasses various state-of-the-art (SOTA) methods in reconstruction quality and computational efficiency. ",Kein DOI-Link verfügbar,2406.00683v1,Yes,potent(1)
0000-0002-0748-1025,Lin Zhu,Universität Hamburg,Event-based Video Reconstruction via Potential-assisted Spiking Neural   Network,1970,"  Neuromorphic vision sensor is a new bio-inspired imaging paradigm that reports asynchronous, continuously per-pixel brightness changes called `events' with high temporal resolution and high dynamic range. So far, the event-based image reconstruction methods are based on artificial neural networks (ANN) or hand-crafted spatiotemporal smoothing techniques. In this paper, we first implement the image reconstruction work via fully spiking neural network (SNN) architecture. As the bio-inspired neural networks, SNNs operating with asynchronous binary spikes distributed over time, can potentially lead to greater computational efficiency on event-driven hardware. We propose a novel Event-based Video reconstruction framework based on a fully Spiking Neural Network (EVSNN), which utilizes Leaky-Integrate-and-Fire (LIF) neuron and Membrane Potential (MP) neuron. We find that the spiking neurons have the potential to store useful temporal information (memory) to complete such time-dependent tasks. Furthermore, to better utilize the temporal information, we propose a hybrid potential-assisted framework (PA-EVSNN) using the membrane potential of spiking neuron. The proposed neuron is referred as Adaptive Membrane Potential (AMP) neuron, which adaptively updates the membrane potential according to the input spikes. The experimental results demonstrate that our models achieve comparable performance to ANN-based models on IJRR, MVSEC, and HQF datasets. The energy consumptions of EVSNN and PA-EVSNN are 19.36$\times$ and 7.75$\times$ more computationally efficient than their ANN architectures, respectively. ",Kein DOI-Link verfügbar,2201.10943v3,Yes,potent(7)
0000-0002-0748-1025,Lin Zhu,Universität Hamburg,LED: A Large-scale Real-world Paired Dataset for Event Camera Denoising,1970,"  Event camera has significant advantages in capturing dynamic scene information while being prone to noise interference, particularly in challenging conditions like low threshold and low illumination. However, most existing research focuses on gentle situations, hindering event camera applications in realistic complex scenarios. To tackle this limitation and advance the field, we construct a new paired real-world event denoising dataset (LED), including 3K sequences with 18K seconds of high-resolution (1200*680) event streams and showing three notable distinctions compared to others: diverse noise levels and scenes, larger-scale with high-resolution, and high-quality GT. Specifically, it contains stepped parameters and varying illumination with diverse scenarios. Moreover, based on the property of noise events inconsistency and signal events consistency, we propose a novel effective denoising framework(DED) using homogeneous dual events to generate the GT with better separating noise from the raw. Furthermore, we design a bio-inspired baseline leveraging Leaky-Integrate-and-Fire (LIF) neurons with dynamic thresholds to realize accurate denoising. The experimental results demonstrate that the remarkable performance of the proposed approach on different datasets.The dataset and code are at https://github.com/Yee-Sing/led. ",Kein DOI-Link verfügbar,2405.19718v1,Yes,notable(1)
0000-0002-0750-3482,Ziqian Chen,Saarland Universität,Studying the Impact of Data Disclosure Mechanism in Recommender Systems   via Simulation,1970,"  Recently, privacy issues in web services that rely on users' personal data have raised great attention. Unlike existing privacy-preserving technologies such as federated learning and differential privacy, we explore another way to mitigate users' privacy concerns, giving them control over their own data. For this goal, we propose a privacy aware recommendation framework that gives users delicate control over their personal data, including implicit behaviors, e.g., clicks and watches. In this new framework, users can proactively control which data to disclose based on the trade-off between anticipated privacy risks and potential utilities. Then we study users' privacy decision making under different data disclosure mechanisms and recommendation models, and how their data disclosure decisions affect the recommender system's performance.   To avoid the high cost of real-world experiments, we apply simulations to study the effects of our proposed framework. Specifically, we propose a reinforcement learning algorithm to simulate users' decisions (with various sensitivities) under three proposed platform mechanisms on two datasets with three representative recommendation models. The simulation results show that the platform mechanisms with finer split granularity and more unrestrained disclosure strategy can bring better results for both end users and platforms than the ""all or nothing"" binary mechanism adopted by most real-world applications. It also shows that our proposed framework can effectively protect users' privacy since they can obtain comparable or even better results with much less disclosed data. ",Kein DOI-Link verfügbar,2204.00279v2,Yes,potent(1)
0000-0002-0819-196X,Michael Schneider,Heinrich-Heine-Universität Düsseldorf,The Impact of Intrinsic Alignments: Cosmological Constraints from a   Joint Analysis of Cosmic Shear and Galaxy Survey Data,1970,"  Constraints on cosmology from recent cosmic shear observations are becoming increasingly sophisticated in their treatment of potential systematic effects. Here we present cosmological constraints which include modelling of intrinsic alignments. We demonstrate how the results are changed for three different intrinsic alignment models, and for two different models of the cosmic shear galaxy population. We find that intrinsic alignments can either reduce or increase measurements of the fluctuation amplitude parameter sigma_8 depending on these decisions, and depending on the cosmic shear survey properties. This is due to the interplay between the two types of intrinsic alignment, II and GI. It has been shown that future surveys must make a careful treatment of intrinsic alignments to avoid significant biases, and that simultaneous constraints from shear-shear and shear-position correlation functions can mitigate the effects. For the first time we here combine constraints from cosmic shear surveys (shear-shear correlations) with those from ""GI"" intrinsic alignment data sets (shear-position correlations). We produce updated constraints on cosmology marginalised over two free parameters in the halo model for intrinsic alignments. We find that the additional freedom is well compensated by the additional information, in that the constraints are very similar indeed to those obtained when intrinsic alignments are ignored, both in terms of best fit values and uncertainties. ",https://doi.org/10.1111/j.1365-2966.2010.17213.x,1001.3787v1,Yes,potent(1)
0000-0002-0859-2042,Gloria Feher,TU Dortmund Universität,Retrieving Multi-Entity Associations: An Evaluation of Combination Modes   for Word Embeddings,1970,"  Word embeddings have gained significant attention as learnable representations of semantic relations between words, and have been shown to improve upon the results of traditional word representations. However, little effort has been devoted to using embeddings for the retrieval of entity associations beyond pairwise relations. In this paper, we use popular embedding methods to train vector representations of an entity-annotated news corpus, and evaluate their performance for the task of predicting entity participation in news events versus a traditional word cooccurrence network as a baseline. To support queries for events with multiple participating entities, we test a number of combination modes for the embedding vectors. While we find that even the best combination modes for word embeddings do not quite reach the performance of the full cooccurrence network, especially for rare entities, we observe that different embedding methods model different types of relations, thereby indicating the potential for ensemble methods. ",https://doi.org/10.1145/3331184.3331366,1905.09052v1,Yes,potent(1)
0000-0002-0926-9212,Felix Wolf,Technische Universität Darmstadt,A Fast Isogeometric BEM for the Three Dimensional Laplace- and Helmholtz   Problems,1970,"  We present an indirect higher order boundary element method utilising NURBS mappings for exact geometry representation and an interpolation-based fast multipole method for compression and reduction of computational complexity, to counteract the problems arising due to the dense matrices produced by boundary element methods. By solving Laplace and Helmholtz problems via a single layer approach we show, through a series of numerical examples suitable for easy comparison with other numerical schemes, that one can indeed achieve extremely high rates of convergence of the pointwise potential through the utilisation of higher order B-spline-based ansatz functions. ",https://doi.org/10.1016/j.cma.2017.10.020,1708.09162v2,Yes,potent(1)
0000-0002-0959-8550,Xing Li,Technische Universität Darmstadt,Propagation of non-WKB Alfven waves in a multicomponent solar wind with   differential ion flow,1970,"  The propagation of dissipationless, hydromagnetic, non-WKB, purely toroidal Alfv\'en waves in a realistic background three-fluid solar wind with axial symmetry and differential proton-alpha flow is investigated. The wave equations are derived from standard multi-fluid 5-moment equations. The Alfv\'enic point, where the combined poloidal Alfv\'en Mach number $M_T=1$, is found to be a singular point for the wave equation, which is then numerically solved for three representative angular frequencies $\omega=10^{-3}$, $10^{-4}$ and $10^{-5}$ rad s$^{-1}$ with a fixed wave amplitude of 10 km s$^{-1}$ imposed at the coronal base (1 $R_\odot$). Between 1 $R_\odot$ and 1 AU, the numerical solutions show substantial deviation from the WKB expectations. Even for the relatively high frequency $\omega=10^{-3}$ rad s$^{-1}$, a WKB-like behavior can be seen only in regions $r\gtrsim 10$ $R_\odot$. In the low-frequency case $\omega=10^{-5}$ rad s$^{-1}$, the computed profiles of wave-related parameters show a spatial dependence distinct from the WKB one, the deviation being particularly pronounced in interplanetary space. In the inner corona $r\lesssim 4$ $R_\odot$, the computed ion velocity fluctuations are considerably smaller than the WKB expectations in all cases, as is the computed wave-induced acceleration exerted on protons or alpha particles. With the chosen base wave amplitude, the wave acceleration has negligible effect on the ion force balance in the corona. Hence processes other than the non-WKB wave acceleration are needed to accelerate the ions out of the gravitational potential well of the Sun. However, at large distances beyond the Alfv\'enic point, the low-frequency waves can play an important role in the ion dynamics, with the net effect being to equalize the speeds of the two ion species considered. ",https://doi.org/10.1086/514324,astro-ph/0702383v2,Yes,potent(1)
0000-0002-0959-8550,Xing Li,Technische Universität Darmstadt,Circuit Transformer: End-to-end Circuit Design by Predicting the Next   Gate,1970,"  Language, a prominent human ability to express through sequential symbols, has been computationally mastered by recent advances of large language models (LLMs). By predicting the next word recurrently with huge neural models, LLMs have shown unprecedented capabilities in understanding and reasoning. Circuit, as the ""language"" of electronic design, specifies the functionality of an electronic device by cascade connections of logic gates. Then, can circuits also be mastered by a a sufficiently large ""circuit model"", which can conquer electronic design tasks by simply predicting the next logic gate? In this work, we take the first step to explore such possibilities. Two primary barriers impede the straightforward application of LLMs to circuits: their complex, non-sequential structure, and the intolerance of hallucination due to strict constraints (e.g., equivalence). For the first barrier, we encode a circuit as a memory-less, depth-first traversal trajectory, which allows Transformer-based neural models to better leverage its structural information, and predict the next gate on the trajectory as a circuit model. For the second barrier, we introduce an equivalence-preserving decoding process, which ensures that every token in the generated trajectory adheres to the specified equivalence constraints. Moreover, the circuit model can also be regarded as a stochastic policy to tackle optimization-oriented circuit design tasks. Experimentally, we trained a Transformer-based model of 88M parameters, named ""Circuit Transformer"", which demonstrates impressive performance in end-to-end logic synthesis. With Monte-Carlo tree search, Circuit Transformer significantly improves over resyn2 while retaining strict equivalence, showcasing the potential of generative AI in conquering electronic design challenges. ",Kein DOI-Link verfügbar,2403.13838v1,Yes,potent(1)
0000-0002-0959-8550,Xing Li,Technische Universität Darmstadt,Representation Learning of Reconstructed Graphs Using Random Walk Graph   Convolutional Network,1970,"  Graphs are often used to organize data because of their simple topological structure, and therefore play a key role in machine learning. And it turns out that the low-dimensional embedded representation obtained by graph representation learning are extremely useful in various typical tasks, such as node classification, content recommendation and link prediction. However, the existing methods mostly start from the microstructure (i.e., the edges) in the graph, ignoring the mesoscopic structure (high-order local structure). Here, we propose wGCN -- a novel framework that utilizes random walk to obtain the node-specific mesoscopic structures of the graph, and utilizes these mesoscopic structures to reconstruct the graph And organize the characteristic information of the nodes. Our method can effectively generate node embeddings for previously unseen data, which has been proven in a series of experiments conducted on citation networks and social networks (our method has advantages over baseline methods). We believe that combining high-order local structural information can more efficiently explore the potential of the network, which will greatly improve the learning efficiency of graph neural network and promote the establishment of new learning models. ",Kein DOI-Link verfügbar,2101.00417v1,Yes,potent(1)
0000-0002-0959-8550,Xing Li,Technische Universität Darmstadt,"Securing Serverless Computing: Challenges, Solutions, and Opportunities",1970,"  Serverless computing is a new cloud service model that reduces both cloud providers' and consumers' costs through extremely agile development, operation, and charging mechanisms and has been widely applied since its emergence. Nevertheless, some characteristics of serverless computing, such as fragmented application boundaries, have raised new security challenges. Considerable literature work has been committed to addressing these challenges. Commercial and open-source serverless platforms implement many security measures to enhance serverless environments. This paper presents the first survey of serverless security that considers both literature work and industrial security measures. We summarize the primary security challenges, analyze corresponding solutions from the literature and industry, and identify potential research opportunities. Then, we conduct a gap analysis of the academic and industrial solutions as well as commercial and open-source serverless platforms' security capabilities, and finally, we present a complete picture of current serverless security research. ",Kein DOI-Link verfügbar,2105.12581v1,Yes,potent(1)
0000-0002-0959-8550,Xing Li,Technische Universität Darmstadt,The Lamé functions and elliptic soliton solutions: Bilinear approach,1970,"  The Lam\'e function can be used to construct plane wave factors and solutions to the Korteweg-de Vries (KdV) and Kadomtsev-Petviashvili (KP) hierarchy. The solutions are usually called elliptic solitons. In this chapter, first, we review recent development in the Hirota bilinear method on elliptic solitons of the KdV equation and KP equation, including bilinear calculations involved with the Lam\'e type plane wave factors, expressions of $\tau$ functions and the generating vertex operators. Then, for the discrete potential KdV and KP equations, we give their bilinear forms, derive $\tau$ functions of elliptic solitons, and show that they share the same vertex operators with the KdV hierarchy and the KP hierarchy, respectively. ",Kein DOI-Link verfügbar,2307.02312v2,Yes,potent(1)
0000-0002-0959-8550,Xing Li,Technische Universität Darmstadt,On the classification and false alarm of invalid prefixes in RPKI based   BGP route origin validation,1970,"  BGP is the default inter-domain routing protocol in today's Internet, but has serious security vulnerabilities\cite{murphy2005bgp}. One of them is (sub)prefix hijacking. IETF standardizes RPKI to validate the AS origin but RPKI has a lot of problems\cite{heilman2014consent}\cite{cooper2013risk}\cite{gilad2017we}\cite{gilad2017maxlength}, among which is potential false alarm. Although some previous work\cite{gilad2017we}\cite{heilman2014consent} points it out explicitly or implicitly, further measurement and analysis remain to be done. Our work measures and analyzes the invalid prefixes systematically. We first classify the invalid prefixes into six different types and then analyze their stability. We show that a large proportion of the invalid prefixes very likely result from traffic engineering, IP address transfer and failing to aggregate rather than real hijackings. ",Kein DOI-Link verfügbar,1903.06860v1,Yes,potent(1)
0000-0002-0959-8550,Xing Li,Technische Universität Darmstadt,Roles of Fast-Cyclotron and Alfven-Cyclotron Waves for the Multi-Ion   Solar Wind,1970,"  Using linear Vlasov theory of plasma waves and quasi-linear theory of resonant wave-particle interaction, the dispersion relations and the electromagnetic field fluctuations of fast and Alfven waves are studied for a low-beta multi-ion plasma in the inner corona. Their probable roles in heating and accelerating the solar wind via Landau and cyclotron resonances are quantified. We assume that (1) low-frequency Alfven and fast waves have the same spectral shape and the same amplitude of power spectral density; (2) these waves eventually reach ion cyclotron frequencies due to a turbulence cascade; (3) kinetic wave-particle interaction powers the solar wind. The existence of alpha particles in a dominant proton/electron plasma can trigger linear mode conversion between oblique fast-whistler and hybrid alpha-proton cyclotron waves. The fast-cyclotron waves undergo both alpha and proton cyclotron resonances. The alpha cyclotron resonance in fast-cyclotron waves is much stronger than that in Alfven-cyclotron waves. For alpha cyclotron resonance, an oblique fast-cyclotron wave has a larger left-handed electric field fluctuation, a smaller wave number, a larger local wave amplitude, and a greater energization capability than a corresponding Alfven-cyclotron wave at the same wave propagation angle \theta, particularly at $80^\circ$ < \theta < $90^\circ$. When Alfven-cyclotron or fast-cyclotron waves are present, alpha particles are the chief energy recipient. The transition of preferential energization from alpha particles to protons may be self-modulated by differential speed and temperature anisotropy of alpha particles via the self-consistently evolving wave-particle interaction. Therefore, fast-cyclotron waves as a result of linear mode coupling is a potentially important mechanism for preferential energization of minor ions in the main acceleration region of the solar wind. ",https://doi.org/10.1007/s11207-012-9973-0,1203.2353v1,Yes,potent(1)
0000-0002-0959-8550,Xing Li,Technische Universität Darmstadt,Representation Learning of Graphs Using Graph Convolutional Multilayer   Networks Based on Motifs,1970,"  The graph structure is a commonly used data storage mode, and it turns out that the low-dimensional embedded representation of nodes in the graph is extremely useful in various typical tasks, such as node classification, link prediction , etc. However, most of the existing approaches start from the binary relationship (i.e., edges) in the graph and have not leveraged the higher order local structure (i.e., motifs) of the graph. Here, we propose mGCMN -- a novel framework which utilizes node feature information and the higher order local structure of the graph to effectively generate node embeddings for previously unseen data. Through research we have found that different types of networks have different key motifs. And the advantages of our method over the baseline methods have been demonstrated in a large number of experiments on citation network and social network datasets. At the same time, a positive correlation between increase of the classification accuracy and the clustering coefficient is revealed. It is believed that using high order structural information can truly manifest the potential of the network, which will greatly improve the learning efficiency of the graph neural network and promote a brand-new learning mode establishment. ",Kein DOI-Link verfügbar,2007.15838v1,Yes,potent(1)
0000-0002-0959-8550,Xing Li,Technische Universität Darmstadt,Optimal preselection and postselection in weak measurements for   observing photonic spin Hall effect,1970,"  Photonic spin Hall effect (SHE) holds great potential applications in precision metrology. How to obtain a high measurement precision is an important issue to detect the photonic SHE. In this letter, we propose using optimal preselection and postselection in weak measurements to enhance the measurement precision. We find that the maximum weak value and pointer shift can be obtained with an optimal overlap of preselection and postselection states. These findings offer the possibility for improving the precision of weak measurements and thereby have possible applications for accurately characterizing the parameters of nanostructures. ",https://doi.org/10.1063/1.4864782,1404.2721v1,Yes,potent(1)
0000-0002-0959-8550,Xing Li,Technische Universität Darmstadt,WS2 as a saturable absorber for ultrafast photonic applications of   mode-locked and Q-switched lasers,1970,"  Two-dimensional (2D) nanomaterials, especially the transition metal sulfide semiconductors, have drawn great interests due to their potential applications in viable photonic and optoelectronic devices, such as saturable absorbers (SAs) and optical switches, etc. In this work, tungsten disulfide (WS2) based SA for ultrafast photonic applications was demonstrated. WS2 nanosheets were prepared using liquid-phase exfoliation method and embedded in polyvinyl alcohol (PVA) thin film for the practical usage. Saturable absorption was observed in the WS2-PVA SA at the telecommunication waveband near 1550 nm. By incorporating WS2-PVA SA into a fiber laser cavity, both stable mode locking operation and Q-switching operation were achieved. In the mode locking operation, the laser obtained femtosecond output pulse width and high spectral purity in the radio frequency spectrum. In the Q-switching operation, the laser had tunable repetition rate and output pulse energy of a few tens of nano joule. Our findings suggest that few-layer WS2 nanosheets embedded in PVA thin film are promising nonlinear optical materials for ultrafast photonic applications as a mode locker or Q-switcher. ",https://doi.org/10.1364/OE.23.011453,1411.5777v1,Yes,potent(1)
0000-0002-1102-7263,Hartmut Buhmann,Universität Würzburg,Microwave studies of the fractional Josephson effect in HgTe-based   Josephson junctions,1970,"  The rise of topological phases of matter is strongly connected to their potential to host Majorana bound states, a powerful ingredient in the search for a robust, topologically protected, quantum information processing. In order to produce such states, a method of choice is to induce superconductivity in topological insulators. The engineering of the interplay between superconductivity and the electronic properties of a topological insulator is a challenging task and it is consequently very important to understand the physics of simple superconducting devices such as Josephson junctions, in which new topological properties are expected to emerge. In this article, we review recent experiments investigating topological superconductivity in topological insulators, using microwave excitation and detection techniques. More precisely, we have fabricated and studied topological Josephson junctions made of HgTe weak links in contact with two Al or Nb contacts. In such devices, we have observed two signatures of the fractional Josephson effect, which is expected to emerge from topologically-protected gapless Andreev bound states. We first recall the theoretical background on topological Josephson junctions, then move to the experimental observations. Then, we assess the topological origin of the observed features and conclude with an outlook towards more advanced microwave spectroscopy experiments, currently under development. ",https://doi.org/10.1007/978-3-319-76388-0_5,1810.03862v1,Yes,potent(1)
0000-0002-1102-7263,Hartmut Buhmann,Universität Würzburg,Spatially resolved study of backscattering in the quantum spin Hall   state,1970,"  The discovery of the Quantum Spin Hall state, and topological insulators in general, has sparked strong experimental efforts. Transport studies of the Quantum Spin Hall state confirmed the presence of edge states, showed ballistic edge transport in micron-sized samples and demonstrated the spin polarization of the helical edge states. While these experiments have confirmed the broad theoretical model, the properties of the QSH edge states have not yet been investigated on a local scale.   Using Scanning Gate Microscopy to perturb the QSH edge states on a sub-micron scale, we identify well-localized scattering sites which likely limit the expected non-dissipative transport in the helical edge channels. In the micron-sized regions between the scattering sites, the edge states appear to propagate unperturbed as expected for an ideal QSH system and are found to be robust against weak induced potential fluctuations. ",https://doi.org/10.1103/PhysRevX.3.021003,1211.3917v1,Yes,potent(1)
0000-0002-1102-7263,Hartmut Buhmann,Universität Würzburg,Dirac-screening stabilized surface-state transport in a topological   insulator,1970,"  We report magnetotransport studies on a gated strained HgTe device. This material is a threedimensional topological insulator and exclusively shows surface state transport. Remarkably, the Landau level dispersion and the accuracy of the Hall quantization remain unchanged over a wide density range ($3 \times 10^{11} cm^{-2} < n < 1 \times 10^{12} cm^{-2}$). This implies that even at large carrier densities the transport is surface state dominated, where bulk transport would have been expected to coexist already. Moreover, the density dependence of the Dirac-type quantum Hall effect allows to identify the contributions from the individual surfaces. A $k \cdot p$ model can describe the experiments, but only when assuming a steep band bending across the regions where the topological surface states are contained. This steep potential originates from the specific screening properties of Dirac systems and causes the gate voltage to influence the position of the Dirac points rather than that of the Fermi level. ",Kein DOI-Link verfügbar,1407.6537v1,Yes,potent(1)
0000-0002-1102-7263,Hartmut Buhmann,Universität Würzburg,Phase-sensitive SQUIDs based on the 3D topological insulator HgTe,1970,"  Three-dimensional topological insulators represent a new class of materials in which transport is governed by Dirac surface states while the bulk remains insulating. Due to helical spin polarization of the surface states, the coupling of a 3D topological insulator to a nearby superconductor is expected to generate unconventional proximity induced $p$-wave superconductivity. We report here on the development and measurements of SQUIDs on the surface of strained HgTe, a 3D topological insulator, as a potential tool to investigate this effect. ",https://doi.org/10.1088/0031-8949/2015/T164/014002,1510.04426v1,Yes,potent(1)
0000-0002-1102-7263,Hartmut Buhmann,Universität Würzburg,Interacting topological edge channels,1970,"  Electrical currents in a quantum spin Hall insulator are confined to the boundary of the system. The charge carriers can be described as massless relativistic particles, whose spin and momentum are coupled to each other. While the helical character of those states is by now well established experimentally, it is a fundamental open question how those edge states interact with each other when brought in spatial proximity. We employ a topological quantum point contact to guide edge channels from opposite sides into a quasi-one-dimensional constriction, based on inverted HgTe quantum wells. Apart from the expected quantization in integer steps of $2 e^2/h$, we find a surprising additional plateau at $e^2/h$. We explain our observation by combining band structure calculations and repulsive electron-electron interaction effects captured within the Tomonaga-Luttinger liquid model. The present results may have direct implications for the study of one-dimensional helical electron quantum optics, Majorana- and potentially para-fermions. ",https://doi.org/10.1038/s41567-019-0692-4,1905.08175v1,Yes,potent(1)
0000-0002-1102-7263,Hartmut Buhmann,Universität Würzburg,Interplay of Dirac nodes and Volkov-Pankratov surface states in   compressively strained HgTe,1970,"  Preceded by the discovery of topological insulators, Dirac and Weyl semimetals have become a pivotal direction of research in contemporary condensed matter physics. While easily accessible from a theoretical viewpoint, these topological semimetals pose a serious challenge in terms of experimental synthesis and analysis to allow for their unambiguous identification. In this work, we report on detailed transport experiments on compressively strained HgTe. Due to the superior sample quality in comparison to other topological semimetallic materials, this enables us to resolve the interplay of topological surface states and semimetallic bulk states to an unprecedented degree of precision and complexity. As our gate design allows us to precisely tune the Fermi level at the Weyl and Dirac points, we identify a magnetotransport regime dominated by Weyl/Dirac bulk state conduction for small carrier densities and by topological surface state conduction for larger carrier densities. As such, similar to topological insulators, HgTe provides the archetypical reference for the experimental investigation of topological semimetals. ",https://doi.org/10.1103/PhysRevX.9.031034,1907.11148v2,Yes,pivotal(1)
0000-0002-1102-7263,Hartmut Buhmann,Universität Würzburg,Period-doubling in the phase dynamics of a shunted HgTe quantum well   Josephson junction,1970,"  The fractional AC Josephson effect is a discerning property of topological superconductivity in hybrid Josephson junctions. Recent experimental observations of missing odd Shapiro steps and half Josephson frequency emission in various materials have sparked significant debate regarding their potential origin in the effect. In this study, we present microwave emission measurements on a resistively shunted Josephson junction based on a HgTe quantum well. We demonstrate that, with significant spurious inductance in the shunt wiring, the experiment operates in a nonlinear dynamic regime characterized by period-doubling. This leads to additional microwave emission peaks at half of the Josephson frequency, $f_J/2$, which can mimic the $4\pi$-periodicity of topological Andreev states. The observed current-voltage characteristics and emission spectra are well-described by a simple RCLSJ model. Furthermore, we show that the nonlinear dynamics of the junction can be controlled using gate voltage, magnetic field, and temperature, with our model accurately reproducing these effects without incorporating any topological attributes. Our observations urge caution in interpreting emission at $f_J/2$ as evidence for gapless Andreev bound states in topological junctions and suggest the appropriate parameter range for future experiments. ",Kein DOI-Link verfügbar,2408.06119v1,Yes,potent(1)
0000-0002-1102-7263,Hartmut Buhmann,Universität Würzburg,Topological band inversion in HgTe(001): surface and bulk signatures   from photoemission,1970,"  HgTe is a versatile topological material and has enabled the realization of a variety of topological states, including two- and three-dimensional (3D) topological insulators and topological semimetals. Nevertheless, a quantitative understanding of its electronic structure remains challenging, in particular due to coupling of the Te 5p-derived valence electrons to Hg 5d core states at shallow binding energy. We present a joint experimental and theoretical study of the electronic structure in strained HgTe(001) films in the 3D topological-insulator regime, based on angle-resolved photoelectron spectroscopy and density functional theory. The results establish detailed agreement in terms of (i) electronic band dispersions and orbital symmetries, (ii) surface and bulk contributions to the electronic structure, and (iii) the importance of Hg 5d states in the valence-band formation. Supported by theory, our experiments directly image the paradigmatic band inversion in HgTe, underlying its non-trivial band topology. ",https://doi.org/10.1103/PhysRevB.107.L121102,2212.05425v1,Yes,versatile(1)
0000-0002-1102-7263,Hartmut Buhmann,Universität Würzburg,Imaging currents in HgTe quantum wells in the quantum spin Hall regime,1970,"  The quantum spin Hall (QSH) state is a genuinely new state of matter characterized by a non-trivial topology of its band structure. Its key feature is conducting edge channels whose spin polarization has potential for spintronic and quantum information applications. The QSH state was predicted and experimentally demonstrated to exist in HgTe quantum wells. The existence of the edge channels has been inferred from the fact that local and non-local conductance values in sufficiently small devices are close to the quantized values expected for ideal edge channels and from signatures of the spin polarization. The robustness of the edge channels in larger devices and the interplay between the edge channels and a conducting bulk are relatively unexplored experimentally, and are difficult to assess via transport measurements. Here we image the current in large Hallbars made from HgTe quantum wells by probing the magnetic field generated by the current using a scanning superconducting quantum interference device (SQUID). We observe that the current flows along the edge of the device in the QSH regime, and furthermore that an identifiable edge channel exists even in the presence of disorder and considerable bulk conduction as the device is gated or its temperature is raised. Our results represent a versatile method for the characterization of new quantum spin Hall materials systems, and confirm both the existence and the robustness of the predicted edge channels. ",https://doi.org/10.1038/nmat3682,1212.2203v2,Yes,"versatile(1), potent(1)"
0000-0002-1103-6792,Stephan Fischer,Universität Konstanz,Modelling Erythroblastic Islands: Using a Hybrid Model to Assess the   Function of Central Macrophage,1970,"  The production and regulation of red blood cells, erythropoiesis, occurs in the bone marrow where erythroid cells proliferate and differentiate within particular structures, called erythroblastic islands. A typical structure of these islands consists in a macrophage (white cell) surrounded by immature erythroid cells (progenitors), with more mature cells on the periphery of the island, ready to leave the bone marrow and enter the bloodstream. A hybrid model, coupling a continuous model (ordinary differential equations) describing intracellular regulation through competition of two key proteins, to a discrete spatial model describing cell-cell interactions, with growth factor diffusion in the medium described by a continuous model (partial differential equations), is proposed to investigate the role of the central macrophage in normal erythropoiesis. Intracellular competition of the two proteins leads the erythroid cell to either proliferation, differentiation, or death by apoptosis. This approach allows considering spatial aspects of erythropoiesis, involved for instance in the occurrence of cellular interactions or the access to external factors, as well as dynamics of intracellular and extracellular scales of this complex cellular process, accounting for stochasticity in cell cycle durations and orientation of the mitotic spindle. The analysis of the model shows a strong effect of the central macrophage on the stability of an erythroblastic island, when assuming the macrophage releases pro-survival cytokines. Even though it is not clear whether or not erythroblastic island stability must be required, investigation of the model concludes that stability improves responsiveness of the model, hence stressing out the potential relevance of the central macrophage in normal erythropoiesis. ",Kein DOI-Link verfügbar,1105.5816v1,Yes,potent(1)
0000-0002-1115-3286,Thomas Vogt,TU Bergakademie Freiberg,"Secure Integration of 5G in Industrial Networks: State of the Art,   Challenges and Opportunities",1970,"  The industrial landscape is undergoing a significant transformation, moving away from traditional wired fieldbus networks to cutting-edge 5G mobile networks. This transition, extending from local applications to company-wide use and spanning multiple factories, is driven by the promise of low-latency communication and seamless connectivity for various devices in industrial settings. However, besides these tremendous benefits, the integration of 5G as the communication infrastructure in industrial networks introduces a new set of risks and threats to the security of industrial systems. The inherent complexity of 5G systems poses unique challenges for ensuring a secure integration, surpassing those encountered with any technology previously utilized in industrial networks. Most importantly, the distinct characteristics of industrial networks, such as real-time operation, required safety guarantees, and high availability requirements, further complicate this task. As the industrial transition from wired to wireless networks is a relatively new concept, a lack of guidance and recommendations on securely integrating 5G renders many industrial systems vulnerable and exposed to threats associated with 5G. To address this situation, in this paper, we summarize the state-of-the-art and derive a set of recommendations for the secure integration of 5G into industrial networks based on a thorough analysis of the research landscape. Furthermore, we identify opportunities to utilize 5G to further enhance security and indicate remaining challenges, potentially identifying future academic potential ",Kein DOI-Link verfügbar,2408.16833v1,Yes,potent(2)
0000-0002-1115-3286,Thomas Vogt,TU Bergakademie Freiberg,Assessment of the regionalised demand response potential in Germany   using an open source tool and dataset,1970,"  With the expansion of renewable energies in Germany, imminent grid congestion events occur more often. One approach for avoiding curtailment of renewable energies is to cover excess feed-in by demand response. As curtailment is often a local phenomenon, in this work we determine the regional demand response potential for the 401 German administrative districts. The load regionalisation is based on weighting factors derived from population and employment statistics, locations of industrial facilities, etc. Using periodic and temperature-dependent load profiles and technology specific parameters, load shifting potentials were determined with a temporal resolution of 15 minutes. Our analysis yields that power-to-heat technologies provide the highest potentials, followed by residential appliances, commercial and industrial loads. For the considered 2030 scenario, power-to-gas and e-mobility also contribute a significant potential. The cumulated load increase potential of all technologies ranges from $5 - 470~MW$ per administrative district. The median value is $25~MW$, which would suffice to avoid the curtailment of 8 classical wind turbines. Further, we calculated load shifting cost-potential curves for each district. Industrial processes and power-to-heat in district heating have the lowest load shifting investment cost, due to the largest installed capacities per facility. We distinguished between different size classes of the installed capacity of heat pumps, yielding $23\%$ lower average investment cost for heat pump flexibilisation in the city of Berlin compared to a rural district. The variable costs of most considered load shifting technologies remain under the average compensation costs for curtailment of renewable energies of $110~\text{\euro{}}/MWh$. As all results and the developed code are published under open source licenses, they can be integrated into energy system models. ",Kein DOI-Link verfügbar,2009.05122v1,Yes,potent(6)
0000-0002-1161-2059,Paulo E. Faria Junior,Universität Regensburg,Exciton g-factors of van der Waals heterostructures from first   principles calculations,1970,"  External fields are a powerful tool to probe optical excitations in a material. The linear energy shift of an excitation in a magnetic field is quantified by its effective g-factor. Here we show how exciton g-factors and their sign can be determined by converged first principles calculations. We apply the method to monolayer excitons in semiconducting transition metal dichalcogenides and to interlayer excitons in MoSe$_2$/WSe$_2$ heterobilayers and obtain good agreement with recent experimental data. The precision of our method allows to assign measured g-factors of optical peaks to specific transitions in the band structure and also to specific regions of the samples. This revealed the nature of various, previously measured interlayer exciton peaks. We further show that, due to specific optical selection rules, g-factors in van der Waals heterostructures are strongly spin- and stacking-dependent. The calculation of orbital angular momenta requires the summation over hundreds of bands, indicating that for the considered two-dimensional materials the basis set size is a critical numerical issue. The presented approach can potentially be applied to a wide variety of semiconductors. ",https://doi.org/10.1103/PhysRevB.101.235408,2002.02542v3,Yes,potent(1)
0000-0002-1161-2059,Paulo E. Faria Junior,Universität Regensburg,Magneto-optical anisotropies of 2D antiferromagnetic MPX$_3$ from first   principles,1970,"  Here we systematically investigate the impact of the spin direction on the electronic and optical properties of transition metal phosphorus trichalcogenides (MPX$_3$, M=Mn, Ni, Fe; X=S, Se) exhibiting various antiferromagnetic arrangement within the 2D limit. Our analysis based on the density functional theory and versatile formalism of Bethe-Salpeter equation reveals larger exciton binding energies for MPS$_3$ (up to 1.1 eV in air) than MPSe$_3$(up to 0.8 eV in air), exceeding the values of transition metal dichalcogenides (TMDs). For the (Mn,Fe)PX$_3$ we determine the optically active band edge transitions, revealing that they are sensitive to in-plane magnetic order, irrespective of the type of chalcogen atom. We predict the anistropic effective masses and the type of linear polarization as an important fingerprints for sensing the type of magnetic AFM arrangements. Furthermore, we identify the spin-orientation-dependent features such as the valley splitting, the effective mass of holes, and the exciton binding energy. In particular, we demonstrate that for MnPX$_3$ (X=S, Se) a pair of non equivalent K+ and K- points exists yielding the valley splittings that strongly depend on the direction of AFM aligned spins. Notably, for the out-of-plane direction of spins, two distinct peaks are expected to be visible below the absorption onset, whereas one peak should emerge for the in-plane configuration of spins. These spin-dependent features provide an insight into spin flop transitions of 2D materials. Finally, we propose a strategy how the spin valley polarization can be realized in 2D AFM within honeycomb lattice. ",Kein DOI-Link verfügbar,2308.13109v1,Yes,versatile(1)
0000-0002-1161-2059,Paulo E. Faria Junior,Universität Regensburg,Ultralong spin lifetimes in one-dimensional semiconductor nanowires,1970,"  We experimentally demonstrate ultralong spin lifetimes of electrons in the one-dimensional (1D) quantum limit of semiconductor nanowires. Optically probing single wires of different diameters reveals an increase in the spin relaxation time by orders of magnitude as the electrons become increasingly confined until only a single 1D subband is populated. We find the observed spin lifetimes of more than $200\,\textrm{ns}$ to result from the robustness of 1D electrons against major spin relaxation mechanisms, highlighting the promising potential of these wires for long-range transport of coherent spin information. ",https://doi.org/10.1063/1.5096970,1809.08009v2,Yes,potent(1)
0000-0002-1161-2059,Paulo E. Faria Junior,Universität Regensburg,A Josephson junction supercurrent diode,1970,"  Transport is called nonreciprocal when not only the sign, but also the absolute value of the current, depends on the polarity of the applied voltage. It requires simultaneously broken inversion and time-reversal symmetries, e.g., by the interplay of spin-orbit coupling and magnetic field. So far, observation of nonreciprocity was always tied to resistivity, and dissipationless nonreciprocal circuit elements were elusive. Here, we engineer fully superconducting nonreciprocal devices based on highly-transparent Josephson junctions fabricated on InAs quantum wells. We demonstrate supercurrent rectification far below the transition temperature. By measuring Josephson inductance, we can link nonreciprocal supercurrent to the asymmetry of the current-phase relation, and directly derive the supercurrent magnetochiral anisotropy coefficient for the first time. A semi-quantitative model well explains the main features of our experimental data. Nonreciprocal Josephson junctions have the potential to become for superconducting circuits what $pn$-junctions are for traditional electronics, opening the way to novel nondissipative circuit elements. ",https://doi.org/10.1038/s41565-021-01009-9,2103.06984v1,Yes,potent(1)
0000-0002-1161-2059,Paulo E. Faria Junior,Universität Regensburg,Amplification of interlayer exciton emission in twisted   WSe$_2$/WSe$_2$/MoSe$_2$ heterotrilayers,1970,"  Transition metal dichalcogenide (TMDC) heterostructures have unique properties that depend on the twisting angle and stacking order of two or more monolayers. However, their practical applications are limited by the low photoluminescence yield of interlayer excitons. This limits the use of layered 2D materials as a versatile platform for developing innovative optoelectronic and spintronic devices. In this study, we report on the emission enhancement of interlayer excitons in multilayered-stacked monolayers through the fabrication of heterotrilayers consisting of WSe$_2$/WSe$_2$/MoSe$_2$ with differing twist angles. Our results show that an additional WSe$_2$ monolayer introduces new absorption pathways, leading to an improvement in the emission of interlayer excitons by more than an order of magnitude. The emission boost is affected by the twist angle, and we observe a tenfold increase in the heterotrilayer area when there is a 44$^\circ$ angle between the WSe$_2$ and MoSe$_2$ materials, as opposed to their heterobilayer counterparts. Furthermore, using density functional theory, we identify the emergence of new carrier transfer pathways in the three-layer sample which extends the current understanding of 2D semiconducting heterostructures. In addition, our research provides a viable way to significantly enhance the emission of interlayer excitons. The emission enhancement of interlayer excitons is significant not only for studying the fundamental properties of interlayer excitons, but also for enabling optoelectronic applications that utilize engineered 2D quantum materials with high luminescence yield. ",Kein DOI-Link verfügbar,2311.02509v1,Yes,"innovative(1), versatile(1)"
0000-0002-1161-2059,Paulo E. Faria Junior,Universität Regensburg,Dual topological insulator with mirror-symmetry-protected helical edge   states,1970,"  Dual topological insulators (DTIs) are simultaneously protected by time-reversal and crystal symmetries, representing advantageous alternatives to conventional topological insulators. By combining ab initio calculations and the $\mathbf{k}\cdot\mathbf{p}$ approach, here we investigate the electronic band structure of a Na$_2$CdSn tri-atomic layer and derive a low-energy $4\times 4$ effective model consistent with all the symmetries of this material class. We obtain the effective Hamiltonian using the L\""owdin perturbation theory, the folding down technique, and the theory of invariants, and determine its parameters by fitting our analytical dispersion relations to those of ab initio calculations. We then calculate the bulk topological invariants of the system and show that the Na$_2$CdSn tri-atomic layer is a giant-gap (hundreds of meV) quasi-2D DTI characterized by both spin and mirror Chern numbers $-2$. In agreement with the bulk-boundary correspondence theorem, we find that a finite-width strip of Na$_2$CdSn possesses two pairs of counter-propagating helical edge states per interface. We obtain analytical expressions for the edge states energy dispersions and wave functions, which are shown to agree with our numerical calculations. Our work opens a new avenue for further studies of Na$_2$CdSn as a potential DTI candidate with room-temperature applications in areas of technological interest, such as nanoelectronics and spintronics. ",Kein DOI-Link verfügbar,2405.15869v1,Yes,potent(1)
0000-0002-1459-6023,Dietrich Bodeker,Universität Bielefeld,Remark on the QCD-electroweak phase transition in a supercooled Universe,1970,"  In extensions of the Standard Model with no dimensionful parameters the electroweak phase transition can be delayed to temperatures of order 100 MeV. Then the chiral phase transition of QCD can proceed with 6 massless quarks. The top-quark condensate destabilizes the Higgs potential through the Yukawa interaction, triggering the electroweak transition. Based on the symmetries of massless QCD, it has been argued that the chiral phase transition is first order. We point out that the top-Higgs Yukawa interaction is nonperturbatively large at the QCD scale, and that its effect on the chiral phase transition may not be negligible, violating some of the symmetries of massless QCD. The remaining symmetries indicate that top quarks condense in a second-order phase transition, but top condensation might also be triggered by a first-order symmetry-breaking transition in the light-quark sector. ",https://doi.org/10.1103/PhysRevD.104.L111501,2108.11966v2,Yes,potent(1)
0000-0002-1459-6023,Dietrich Bodeker,Universität Bielefeld,The Baryon asymmetry in the Standard Model with a low cut-off,1970,"  We study the generation of the baryon asymmetry in a variant of the standard model, where the Higgs field is stabilized by a dimension-six interaction. Analyzing the one-loop potential, we find a strong first order electroweak phase transition for Higgs masses up to at least 170 GeV. Dimension-six operators induce also new sources of CP violation. We compute the baryon asymmetry in the WKB approximation. Novel source terms in the transport equations enhance the generated baryon asymmetry. For a wide range of parameters the model predicts a baryon asymmetry close to the observed value. ",https://doi.org/10.1088/1126-6708/2005/02/026,hep-ph/0412366v1,Yes,potent(1)
0000-0002-1459-6023,Dietrich Bodeker,Universität Bielefeld,Cosmic QCD Epoch at Nonvanishing Lepton Asymmetry,1970,"  We investigate how a lepton asymmetry impacts the cosmic trajectory in the QCD phase diagram. We study the evolution of chemical potentials during the QCD epoch of the early Universe using susceptibilities from lattice QCD to interpolate between an ideal quark gas and an ideal hadron resonance gas. The lepton asymmetry affects the evolution of all chemical potentials. The standard cosmic trajectory is obtained assuming tiny lepton and baryon asymmetries. For larger lepton asymmetry, the charge chemical potential exceeds the baryon chemical potential before pion annihilation. ",https://doi.org/10.1103/PhysRevLett.121.201302,1807.10815v2,Yes,potent(4)
0000-0002-1591-0977,Philipp Gohlke,Universität Bielefeld,Fast dimension spectrum for a potential with a logarithmic singularity,1970,"  We regard the classic Thue--Morse diffraction measure as an equilibrium measure for a potential function with a logarithmic singularity over the doubling map. Our focus is on unusually fast scaling of the Birkhoff sums (superlinear) and of the local measure decay (superpolynomial). For several scaling functions, we show that points with this behavior are abundant in the sense of full Hausdorff dimension. At the fastest possible scaling, the corresponding rates reveal several remarkable phenomena. There is a gap between level sets for dyadic rationals and non-dyadic points, and beyond dyadic rationals, non-zero accumulation points occur only within intervals of positive length. The dependence between the smallest and the largest accumulation point also manifests itself in a non-trivial joint dimension spectrum. ",Kein DOI-Link verfügbar,2306.00515v1,Yes,potent(1)
0000-0002-1591-0977,Philipp Gohlke,Universität Bielefeld,Zero Measure Spectrum for Multi-Frequency Schrödinger Operators,1970,"  Building on works of Berth\'e--Steiner--Thuswaldner and Fogg--Nous we show that on the two-dimensional torus, Lebesgue almost every translation admits a natural coding such that the associated subshift satisfies the Boshernitzan criterion. As a consequence we show that for these torus translations, every quasi-periodic potential can be approximated uniformly by one for which the associated Schr\""odinger operator has Cantor spectrum of zero Lebesgue measure. We also describe a framework that can allow this to be extended to higher-dimensional tori. ",Kein DOI-Link verfügbar,2009.11946v1,Yes,potent(1)
0000-0002-1591-0977,Philipp Gohlke,Universität Bielefeld,Scaling properties of the Thue--Morse measure,1970,"  The classic Thue--Morse measure is a paradigmatic example of a purely singular continuous probability measure on the unit interval. Since it has a representation as an infinite Riesz product, many aspects of this measure have been studied in the past, including various scaling properties and a partly heuristic multifractal analysis. Some of the difficulties emerge from the appearance of an unbounded potential in the thermodynamic formalism. It is the purpose of this article to review and prove some of the observations that were previously established via numerical or scaling arguments. ",https://doi.org/10.3934/dcds.2019168,1810.06949v2,Yes,potent(1)
0000-0002-1591-0977,Philipp Gohlke,Universität Bielefeld,Spectral Characteristics of Schrödinger Operators Generated by Product   Systems,1970,"  We study ergodic Schr\""odinger operators defined over product dynamical systems in which one factor is periodic and the other factor is either a subshift over a finite alphabet or an irrational rotation of the circle. In the case in which one factor is a Boshernitzan subshift, we prove that either the resulting operators are periodic or the resulting spectra must be Cantor sets. The main ingredient is a suitable stability result for Boshernitzan's criterion under taking products. We also discuss the stability of purely singular continuous spectrum, which, given the zero-measure spectrum result, amounts to stability results for eigenvalue exclusion. In particular, we examine situations in which the existing criteria for the exclusion of eigenvalues are stable under periodic perturbations. As a highlight of this, we show that any simple Toeplitz subshift over a binary alphabet exhibits uniform absence of eigenvalues on the hull for any periodic perturbation whose period is commensurate with the coding sequence. In the case of a full shift, we give an effective criterion to compute exactly the spectrum of a random Anderson model perturbed by a potential of period two, and we further show that the naive generalization of this criterion does not hold for period three. Next, we consider quasi-periodic potentials with potentials generated by trigonometric polynomials with periodic background. We show that the quasiperiodic cocycle induced by passing to blocks of period length is subcritical when the coupling constant is small and supercritical when the coupling constant is large. Thus, the spectral type is absolutely continuous for small coupling and pure point (for a.e.\ frequency and phase) when the coupling is large. ",Kein DOI-Link verfügbar,2203.11739v1,Yes,potent(3)
0000-0002-1686-8280,Bertfried Fauser,Universität Tübingen,On the relation of Clifford-Lipschitz groups to q-symmetric groups,1970,"  It can be shown that it is possible to find a representation of Hecke algebras within Clifford algebras of multivectors. These Clifford algebras possess a unique gradation and a possibly non-symmetric bilinear form. Hecke algebra representations can be classified, for non-generic q, by Young tableaux of the symmetric group due to the isomorphy of the group algebras for q ->1. Since spinors can be constructed as elements of minimal left (right) ideals obtained by the left (right) action on primitive idempotents, we are able to construct q-spinors from q-Young operators corresponding to the appropriate symmetry type. It turns out that an anti-symmetric part in the Clifford bilinear form is necessary. q-deformed reflections (Hecke generators) can be obtained only for even multivector aggregates rendering this symmetry a composite one. In this construction one is able to deform spin groups only, though not pin groups. The method is closely related to a projective interpretation. ",Kein DOI-Link verfügbar,math/9807158v1,Yes,potent(1)
0000-0002-1686-8280,Bertfried Fauser,Universität Tübingen,On the transposition anti-involution in real Clifford algebras I: The   transposition map,1970,"  A particular orthogonal map on a finite dimensional real quadratic vector space (V,Q) with a non-degenerate quadratic form Q of any signature (p,q) is considered. It can be viewed as a correlation of the vector space that leads to a dual Clifford algebra CL(V^*,Q) of linear functionals (multiforms) acting on the universal Clifford algebra CL(V,Q). The map results in a unique involutive automorphism and a unique involutive anti-automorphism of CL(V,Q). The anti-involution reduces to reversion (resp. conjugation) for any Euclidean (resp. anti-Euclidean) signature. When applied to a general element of the algebra, it results in transposition of the element matrix in the left regular representation of CL(V,Q). We give also an example for real spinor spaces. The general setting for spinor representations will be treated in part II of this work [...II: Spabilizer groups of primitive idempotents]. ",https://doi.org/10.1080/03081087.2010.517201,1005.3554v1,Yes,potent(1)
0000-0002-1686-8280,Bertfried Fauser,Universität Tübingen,Hecke Algebra Representations in Ideals Generated by q-Young Clifford   Idempotents,1970,"  It is a well known fact from the group theory that irreducible tensor representations of classical groups are suitably characterized by irreducible representations of the symmetric groups. However, due to their different nature, vector and spinor representations are only connected and not united in such description.   Clifford algebras are an ideal tool with which to describe symmetries of multi-particle systems since they contain spinor and vector representations within the same formalism, and, moreover, allow for a complete study of all classical Lie groups. In this work, together with an accompanying work also presented at this conference, an analysis of q-symmetry -- for generic q's -- based on the ordinary symmetric groups is given for the first time. We construct q-Young operators as Clifford idempotents and the Hecke algebra representations in ideals generated by these operators. Various relations as orthogonality of representations and completeness are given explicitly, and the symmetry types of representations is discussed. Appropriate q-Young diagrams and tableaux are given. The ordinary case of the symmetric group is obtained in the limit q \to 1. All in all, a toolkit for Clifford algebraic treatment of multi-particle systems is provided. The distinguishing feature of this paper is that the Young operators of conjugated Young diagrams are related by Clifford reversion, connecting Clifford algebra and Hecke algebra features. This contrasts the purely Hecke algebraic approach of King and Wybourne, who do not embed Hecke algebras into Clifford algebras. ",Kein DOI-Link verfügbar,math/9908062v1,Yes,potent(1)
0000-0002-1686-8280,Bertfried Fauser,Universität Tübingen,On the transposition anti-involution in real Cliffrd algebras II:   Stabilizer groups of primitive idempotents,1970,"  In the first article of this work [... I: The transposition map] we showed that real Clifford algebras CL(V,Q) posses a unique transposition anti-involution \tp. There it was shown that the map reduces to reversion (resp. conjugation) for any Euclidean (resp. anti-Euclidean) signature. When applied to a general element of the algebra, it results in transposition of the associated matrix of that element in the left regular representation of the algebra. In this paper we show that, depending on the value of (p-q) mod 8, where \ve=(p,q) is the signature of Q, the anti-involution gives rise to transposition, Hermitian complex, and Hermitian quaternionic conjugation of representation matrices in spinor representations. We realize spinors in minimal left ideals S=CL_{p,q}f generated by a primitive idempotent f. The map \tp allows us to define a dual spinor space S^\ast, and a new spinor norm on S, which is different, in general, from two spinor norms known to exist. We study a transitive action of generalized Salingaros' multiplicative vee groups G_{p,q} on complete sets of mutually annihilating primitive idempotents. Using the normal stabilizer subgroup G_{p,q}(f) we construct left transversals, spinor bases, and maps between spinor spaces for different orthogonal idempotents f_i summing up to 1. We classify the stabilizer groups according to the signature in simple and semisimple cases. ",https://doi.org/10.1080/03081087.2010.517202,1005.3558v1,Yes,potent(3)
0000-0002-1686-8280,Bertfried Fauser,Universität Tübingen,Transposition anti-involution in Clifford algebras and invariance groups   of scalar products on spinor spaces,1970,"  We introduce on the abstract level in real Clifford algebras \cl_{p,q} of a non-degenerate quadratic space (V,Q), where Q has signature \epsilon=(p,q), a transposition anti-involution \tp. In a spinor representation, the anti-involution \tp gives transposition, complex Hermitian conjugation or quaternionic Hermitian conjugation when the spinor space \check{S} is viewed as a \cl_{p,q}-left and \check{K}-right module with \check{K} isomorphic to R or R^2, C, or, H or H^2.   \tp is a lifting to \cl_{p,q} of an orthogonal involution \tve: V \rightarrow V which depends on the signature of Q. The involution is a symmetric correlatio \tve: V \rightarrow V^{*} \cong V and it allows one to define a reciprocal basis for the dual space (V^{*},Q). The anti-involution \tp acts as reversion on \cl_{p,0} and as conjugation on \cl_{0,q}. Using the concept of a transpose of a linear mapping one can show that if [L_u] is a matrix in the left regular representation of the operator L_u: \cl_{p,q} \rightarrow \cl_{p,q} relative to a Grassmann basis B in \cl_{p,q}, then matrix [L_{\tp(u)}] is the matrix transpose of [L_u].   Of particular importance is the action of \tp on the algebraic spinor space S, generated by a primitive idempotent f, or a sum f+\hat{f} in simple or semisimple algebras. \tp allows us to define a new spinor scalar product S \times S \rightarrow \check{K}, where K=f\cl_{p,q}f and \check{K}=K or K \oplus \hat{K} in the simple or semisimple case. Our scalar product reduces to well known ones in Euclidean and anti-Euclidean signatures. \tp acts as identity, complex conjugation, or quaternionic conjugation on \check{K}. The action of \tp on spinors results in matrix transposition, complex Hermitian conjugation, or quaternionic ermitian conjugation. We classify the automorphism groups of the new product as O(N), U(N), Sp(N), O(N)^2, or Sp(N)^2. ",Kein DOI-Link verfügbar,1112.3047v1,Yes,potent(1)
0000-0002-1686-8280,Bertfried Fauser,Universität Tübingen,Smooth coalgebra: testing vector analysis,1970,"  Processes are often viewed as coalgebras, with the structure maps specifying the state transitions. In the simplest case, the state spaces are discrete, and the structure map simply takes each state to the next states. But the coalgebraic view is also quite effective for studying processes over structured state spaces, e.g. measurable, or continuous. In the present paper we consider coalgebras over manifolds. This means that the captured processes evolve over state spaces that are not just continuous, but also locally homeomorphic to Banach spaces, and thus carry a differential structure. Both dynamical systems and differential forms arise as coalgebras over such state spaces, for two different endofunctors over manifolds. A duality induced by these two endofunctors provides a formal underpinning for the informal geometric intuitions linking differential forms and dynamical systems in the various practical applications, e.g. in physics. This joint functorial reconstruction of tangent bundles and cotangent bundles uncovers the universal properties and a high level view of these fundamental structures, which are implemented rather intricately in their standard form. The succinct coalgebraic presentation provides unexpected insights even about the situations as familiar as Newton's laws. ",https://doi.org/10.1017/S0960129515000511,1402.4414v2,Yes,intricate(1)
0000-0002-1701-528X,Ersoy Sasioglu,Martin-Luther-Universität Halle-Wittenberg,Proposal for semiconductor-free negative differential resistance tunnel   diode with ultra-high peak-to-valley current ratio,1970,"  The negative differential resistance (NDR) tunnel diodes are promising alternative devices for beyond-CMOS computing as they offer several potential applications when integrated with transistors. We propose a novel semiconductor-free NDR tunnel diode concept that exhibits an ultra-high peak-to-valley current ratio (PVCR) value. Our proposed NDR diode consists of two cold metal electrodes separated by a thin insulating tunnel barrier. The NDR effect stems from the unique electronic band structure of the cold metal electrodes, i.e., the width of the isolated metallic bands around the Fermi level as well as the energy gaps separating higher- and lower-lying bands determine the current-voltage ($I$-$V$) characteristics and the PVCR value of the tunnel diode. By proper choice of the cold metal electrode materials, either a conventional N-type or ${\Lambda}$-type NDR effect can be obtained. Two-dimensional (2D) materials offer a unique platform for the realization of proposed NDR tunnel diodes. To demonstrate the proof of concept we employ the nonequilibrium Green function method combined with density functional theory to calculate the $I$-$V$ characteristic of the lateral (AlI$_2$/MgI$_2$/AlI$_2$) and vertical (NbS$_2$/h-BN/NbS$_2$) heterojunction tunnel diodes based on 2D cold metals. For the lateral tunnel diode, we obtain a ${\Lambda}$-type NDR effect with an ultra-high PVCR value of 10$^{16}$ at room temperature, while the vertical tunnel diode exhibits a conventional N-type NDR effect with a smaller PVCR value of about 10$^4$. The proposed concept provides a semiconductor-free solution for NDR devices to achieve desired $I$-$V$ characteristics with ultra-high PVCR values for memory and logic applications. ",Kein DOI-Link verfügbar,2207.02593v2,Yes,potent(1)
0000-0002-1701-528X,Ersoy Sasioglu,Martin-Luther-Universität Halle-Wittenberg,Effective Coulomb interaction in transition metals from constrained   random-phase approximation,1970,"  The effective on-site Coulomb interaction (Hubbard $U$) between localized \textit{d} electrons in 3\textit{d}, 4\textit{d}, and 5\textit{d} transition metals is calculated employing a new parameter-free realization of the constrained random-phase approximation using Wannier functions within the full-potential linearized augmented-plane-wave method. The $U$ values lie between 1.5 and 5.7 eV and depend on the crystal structure, spin polarization, \textit{d} electron number, and \textit{d} orbital filling. On the basis of the calculated $U$ parameters, we discuss the strength of the electronic correlations and the instability of the paramagnetic state towards the ferromagnetic one for 3\textit{d} metals. ",https://doi.org/10.1103/PhysRevB.83.121101,1103.5593v1,Yes,potent(1)
0000-0002-1701-528X,Ersoy Sasioglu,Martin-Luther-Universität Halle-Wittenberg,Ab-initio calculation of the effective on-site Coulomb interaction   parameters for half-metallic magnets,1970,"  Correlation effects play an important role in the electronic structure of half-metallic (HM) magnets. In particular, they give rise to non-quasiparticle states above (or below) the Fermi energy at finite temperatures that reduce the spin polarization and, as a consequence, the efficiency of spintronics devices. Employing the constrained random-phase approximation (cRPA) within the full-potential linearized augmented-plane-wave (FLAPW) method using maximally localized Wannier functions, we calculate the strength of the effective on-site Coulomb interaction (Hubbard $U$ and Hund exchange $J$) between localized electrons in different classes of HM magnets considering: (i) \emph{sp}-electron ferromagnets in rock-salt structure, (ii) zincblende 3\emph{d} binary ferromagnets, as well as (iii) ferromagnetic and ferrimagnetic semi- and full-Heusler compounds. ",https://doi.org/10.1103/PhysRevB.88.134402,1309.6657v1,Yes,potent(1)
0000-0002-1701-528X,Ersoy Sasioglu,Martin-Luther-Universität Halle-Wittenberg,Wannier-function approach to spin excitations in solids,1970,"  We present a computational scheme to study spin excitations in magnetic materials from first principles. The central quantity is the transverse spin susceptibility, from which the complete excitation spectrum, including single-particle spin-flip Stoner excitations and collective spin-wave modes, can be obtained. The susceptibility is derived from many-body perturbation theory and includes dynamic correlation through a summation over ladder diagrams that describe the coupling of electrons and holes with opposite spins. In contrast to earlier studies, we do not use a model potential with adjustable parameters for the electron-hole interaction but employ the random-phase approximation. To reduce the numerical cost for the calculation of the four-point scattering matrix we perform a projection onto maximally localized Wannier functions, which allows us to truncate the matrix efficiently by exploiting the short spatial range of electronic correlation in the partially filled d or f orbitals. Our implementation is based on the FLAPW method. Starting from a ground-state calculation within the LSDA, we first analyze the matrix elements of the screened Coulomb potential in the Wannier basis for the 3d transition-metal series. In particular, we discuss the differences between a constrained nonmagnetic and a proper spin-polarized treatment for the ferromagnets Fe, Co, and Ni. The spectrum of single-particle and collective spin excitations in fcc Ni is then studied in detail. The calculated spin-wave dispersion is in good overall agreement with experimental data and contains both an acoustic and an optical branch for intermediate wave vectors along the [100] direction. In addition, we find evidence for a similar double-peak structure in the spectral function along the [111] direction. ",https://doi.org/10.1103/PhysRevB.81.054434,1002.4897v1,Yes,potent(2)
0000-0002-1701-528X,Ersoy Sasioglu,Martin-Luther-Universität Halle-Wittenberg,First-principles calculation of electronic excitations in solids with   SPEX,1970,"  We describe the software package SPEX, which allows first-principles calculations of quasiparticle and collective electronic excitations in solids using techniques from many-body perturbation theory. The implementation is based on the full-potential linearized augmented-plane-wave (FLAPW) method, which treats core and valence electrons on an equal footing and can be applied to a wide range of materials, including transition metals and rare earths. After a discussion of essential features that contribute to the high numerical efficiency of the code, we present illustrative results for quasiparticle band structures calculated within the GW approximation for the electronic self-energy, electron-energy-loss spectra with inter- and intraband transitions as well as local-field effects, and spin-wave spectra of itinerant ferromagnets. In all cases the inclusion of many-body correlation terms leads to very good quantitative agreement with experimental spectroscopies. ",https://doi.org/10.1524/zpch.2010.6110,1110.1596v1,Yes,potent(1)
0000-0002-1775-4701,Martin Ulrich Schmidt,Universität Mannheim,The space of genus two spectral curves of constant mean curvature tori   in $\mathbb{R}^3$,1970,"  We use Whitham deformations to give a complete account of spectral data of real solutions of the sinh--Gordon equation of spectral genus 2. We parameterise the closure of spectral data of constant mean curvature tori in $\mathbb{R}^3$ by an isosceles right triangle and analyse its boundary. We prove that the Wente family, which is described by spectral data with real coefficients, is parameterised by the bisector of the right angle. Our methods combine blowups of Whitham deformations and spectral data in an innovative way that changes the underlying integrable system. ",Kein DOI-Link verfügbar,2110.00436v2,Yes,innovative(1)
0000-0002-1836-3630,Gernot Münster,Universität Münster,The interfacial profile in two-loop order,1970,"  The profile of interfaces separating different phases of statistical systems is investigated in the framework of renormalized field theory. The profile function is calculated analytically in the local potential approximation, using the effective potential to two loops. It can be interpreted as an intrinsic interfacial profile. The loop corrections to the leading tanh-type term turn out to be small. They yield a broadening of the interface. ",https://doi.org/10.1007/s10955-007-9404-z,cond-mat/0610376v2,Yes,potent(2)
0000-0002-1836-3630,Gernot Münster,Universität Münster,Dynamical suppression of large instantons,1970,"  We investigate the distribution of instanton sizes in the framework of a simplified model for ensembles of instantons. This model takes into account the non-diluteness of instantons. The infrared problem for the integration over instanton sizes is dealt with in a self-consistent manner by approximating instanton interactions by a repulsive hard core potential. This leads to a dynamical suppression of large instantons. The characteristic features of the instanton size distribution are studied by means of analytic and Monte Carlo methods. We find a power law behaviour for small sizes, consistent with the semi-classical results. At large instanton sizes the distribution decays exponentially. The results are compared with those from lattice simulations. ",https://doi.org/10.1016/S0920-5632(01)01785-6,hep-lat/0111017v1,Yes,potent(1)
0000-0002-1836-3630,Gernot Münster,Universität Münster,Distribution of instanton sizes in a simplified instanton gas model,1970,"  We investigate the distribution of instanton sizes in the framework of a simplified model for ensembles of instantons. This model takes into account the non-diluteness of instantons. The infrared problem for the integration over instanton sizes is dealt with in a self-consistent manner by approximating instanton interactions by a repulsive hard core potential. This leads to a dynamical suppression of large instantons. The characteristic features of the instanton size distribution are studied by means of analytic and Monte Carlo methods. In one dimension exact results can be derived. In any dimension we find a power law behaviour for small sizes, consistent with the semi-classical results. At large instanton sizes the distribution decays exponentially. The results are compared with those from lattice simulations. ",https://doi.org/10.1007/s100520000506,hep-th/0005084v2,Yes,potent(1)
0000-0002-1878-5665,Lisa Streit,Universität Ulm,Precision and accuracy of single-molecule FRET measurements - a   worldwide benchmark study,1970,"  Single-molecule F\""orster resonance energy transfer (smFRET) is increasingly being used to determine distances, structures, and dynamics of biomolecules in vitro and in vivo. However, generalized protocols and FRET standards ensuring both the reproducibility and accuracy of measuring FRET efficiencies are currently lacking. Here we report the results of a worldwide, comparative, blind study, in which 20 labs determined the FRET efficiencies of several dye-labeled DNA duplexes. Using a unified and straightforward method, we show that FRET efficiencies can be obtained with a standard deviation between ${\Delta}$E = +-0.02 and +-0.05. We further suggest an experimental and computational procedure for converting FRET efficiencies into accurate distances. We discuss potential uncertainties in the experiment and the modelling. Our extensive quantitative assessment of intensity-based smFRET measurements and correction procedures serve as an essential step towards validation of distance networks with the ultimate aim to archive reliable structural models of biomolecular systems obtained by smFRET-based hybrid methods. ",https://doi.org/10.1038/s41592-018-0085-0,1710.03807v2,Yes,potent(1)
0000-0002-1922-654X,Alexander Fay,"Helmut-Schmidt-Universität Hamburg, Ruhr-Universität Bochum, Technische Universität Braunschweig",Model-Based Engineering of CPPS Functions and Code Generation for Skills,1970,"  Today's production systems are complex networks of cyber-physical systems which combine mechanical and electronic parts with software and networking capabilities. To the inherent complexity of such systems additional complexity arises from the context in which these systems operate. Manufacturing companies need to be able to adapt their production to ever changing customer demands as well as decreasing lot sizes. Engineering such systems, which need to be combined and reconfigured into different networks under changing conditions, requires engineering methods to carefully design them for possible future uses. Such engineering methods need to preserve the flexibility of functions into runtime, so that reconfiguring machines can be done with as little effort as possible. In this paper we present a model-based approach that is focused on machine functions and allows to methodically develop system functionalities for changing system networks. These functions are implemented as so-called skills using automated code-generation. ",https://doi.org/10.1109/ICPS51978.2022.9816919,2201.13290v3,Yes,methodically(1)
0000-0002-1922-654X,Alexander Fay,"Helmut-Schmidt-Universität Hamburg, Ruhr-Universität Bochum, Technische Universität Braunschweig",A Formal Model for Artificial Intelligence Applications in Automation   Systems,1970,"  The integration of Artificial Intelligence (AI) into automation systems has the potential to enhance efficiency and to address currently unsolved existing technical challenges. However, the industry-wide adoption of AI is hindered by the lack of standardized documentation for the complex compositions of automation systems, AI software, production hardware, and their interdependencies. This paper proposes a formal model using standards and ontologies to provide clear and structured documentation of AI applications in automation systems. The proposed information model for artificial intelligence in automation systems (AIAS) utilizes ontology design patterns to map and link various aspects of automation systems and AI software. Validated through a practical example, the model demonstrates its effectiveness in improving documentation practices and aiding the sustainable implementation of AI in industrial settings. ",Kein DOI-Link verfügbar,2407.03183v1,Yes,potent(1)
0000-0002-1922-654X,Alexander Fay,"Helmut-Schmidt-Universität Hamburg, Ruhr-Universität Bochum, Technische Universität Braunschweig",Integration of Domain Expert-Centric Ontology Design into the CRISP-DM   for Cyber-Physical Production Systems,1970,"  In the age of Industry 4.0 and Cyber-Physical Production Systems (CPPSs) vast amounts of potentially valuable data are being generated. Methods from Machine Learning (ML) and Data Mining (DM) have proven to be promising in extracting complex and hidden patterns from the data collected. The knowledge obtained can in turn be used to improve tasks like diagnostics or maintenance planning. However, such data-driven projects, usually performed with the Cross-Industry Standard Process for Data Mining (CRISP-DM), often fail due to the disproportionate amount of time needed for understanding and preparing the data. The application of domain-specific ontologies has demonstrated its advantageousness in a wide variety of Industry 4.0 application scenarios regarding the aforementioned challenges. However, workflows and artifacts from ontology design for CPPSs have not yet been systematically integrated into the CRISP-DM. Accordingly, this contribution intends to present an integrated approach so that data scientists are able to more quickly and reliably gain insights into the CPPS. The result is exemplarily applied to an anomaly detection use case. ",https://doi.org/10.1109/ETFA54631.2023.10275612,2307.11637v2,Yes,potent(1)
0000-0002-1922-654X,Alexander Fay,"Helmut-Schmidt-Universität Hamburg, Ruhr-Universität Bochum, Technische Universität Braunschweig",Coordinating Cooperative Perception in Urban Air Mobility for Enhanced   Environmental Awareness,1970,"  The trend for Urban Air Mobility (UAM) is growing with prospective air taxis, parcel deliverers, and medical and industrial services. Safe and efficient UAM operation relies on timely communication and reliable data exchange. In this paper, we explore Cooperative Perception (CP) for Unmanned Aircraft Systems (UAS), considering the unique communication needs involving high dynamics and a large number of UAS. We propose a hybrid approach combining local broadcast with a central CP service, inspired by centrally managed U-space and broadcast mechanisms from automotive and aviation domains. In a simulation study, we show that our approach significantly enhances the environmental awareness for UAS compared to fully distributed approaches, with an increased communication channel load, which we also evaluate. These findings prompt a discussion on communication strategies for CP in UAM and the potential of a centralized CP service in future research. ",Kein DOI-Link verfügbar,2405.03290v2,Yes,potent(1)
0000-0002-1922-654X,Alexander Fay,"Helmut-Schmidt-Universität Hamburg, Ruhr-Universität Bochum, Technische Universität Braunschweig",Cost Optimized Scheduling in Modular Electrolysis Plants,1970,"  In response to the global shift towards renewable energy resources, the production of green hydrogen through electrolysis is emerging as a promising solution. Modular electrolysis plants, designed for flexibility and scalability, offer a dynamic response to the increasing demand for hydrogen while accommodating the fluctuations inherent in renewable energy sources. However, optimizing their operation is challenging, especially when a large number of electrolysis modules needs to be coordinated, each with potentially different characteristics.   To address these challenges, this paper presents a decentralized scheduling model to optimize the operation of modular electrolysis plants using the Alternating Direction Method of Multipliers. The model aims to balance hydrogen production with fluctuating demand, to minimize the marginal Levelized Cost of Hydrogen (mLCOH), and to ensure adaptability to operational disturbances. A case study validates the accuracy of the model in calculating mLCOH values under nominal load conditions and demonstrates its responsiveness to dynamic changes, such as electrolyzer module malfunctions and scale-up scenarios. ",https://doi.org/10.1109/ICIT58233.2024.10540907,2402.05148v1,Yes,potent(1)
0000-0002-1922-654X,Alexander Fay,"Helmut-Schmidt-Universität Hamburg, Ruhr-Universität Bochum, Technische Universität Braunschweig",Semantic Capability Model for the Simulation of Manufacturing Processes,1970,"  Simulations offer opportunities in the examination of manufacturing processes. They represent various aspects of the production process and the associated production systems. However, often a single simulation does not suffice to provide a comprehensive understanding of specific process settings. Instead, a combination of different simulations is necessary when the outputs of one simulation serve as the input parameters for another, resulting in a sequence of simulations. Manual planning of simulation sequences is a demanding task that requires careful evaluation of factors like time, cost, and result quality to choose the best simulation scenario for a given inquiry. In this paper, an information model is introduced, which represents simulations, their capabilities to generate certain knowledge, and their respective quality criteria. The information model is designed to provide the foundation for automatically generating simulation sequences. The model is implemented as an extendable and adaptable ontology. It utilizes Ontology Design Patterns based on established industrial standards to enhance interoperability and reusability. To demonstrate the practicality of this information model, an application example is provided. This example serves to illustrate the model's capacity in a real-world context, thereby validating its utility and potential for future applications. ",Kein DOI-Link verfügbar,2408.08048v1,Yes,potent(1)
0000-0002-1922-654X,Alexander Fay,"Helmut-Schmidt-Universität Hamburg, Ruhr-Universität Bochum, Technische Universität Braunschweig",Toward a Method to Generate Capability Ontologies from Natural Language   Descriptions,1970,"  To achieve a flexible and adaptable system, capability ontologies are increasingly leveraged to describe functions in a machine-interpretable way. However, modeling such complex ontological descriptions is still a manual and error-prone task that requires a significant amount of effort and ontology expertise. This contribution presents an innovative method to automate capability ontology modeling using Large Language Models (LLMs), which have proven to be well suited for such tasks. Our approach requires only a natural language description of a capability, which is then automatically inserted into a predefined prompt using a few-shot prompting technique. After prompting an LLM, the resulting capability ontology is automatically verified through various steps in a loop with the LLM to check the overall correctness of the capability ontology. First, a syntax check is performed, then a check for contradictions, and finally a check for hallucinations and missing ontology elements. Our method greatly reduces manual effort, as only the initial natural language description and a final human review and possible correction are necessary, thereby streamlining the capability ontology generation process. ",Kein DOI-Link verfügbar,2406.07962v1,Yes,innovative(1)
0000-0002-1922-654X,Alexander Fay,"Helmut-Schmidt-Universität Hamburg, Ruhr-Universität Bochum, Technische Universität Braunschweig",Integrating 2D and 3D Digital Plant Information Towards Automatic   Generation of Digital Twins,1970,"  Ongoing standardization in Industry 4.0 supports tool vendor neutral representations of Piping and Instrumentation diagrams as well as 3D pipe routing. However, a complete digital plant model requires combining these two representations. 3D pipe routing information is essential for building any accurate first-principles process simulation model. Piping and instrumentation diagrams are the primary source for control loops. In order to automatically integrate these information sources to a unified digital plant model, it is necessary to develop algorithms for identifying corresponding elements such as tanks and pumps from piping and instrumentation diagrams and 3D CAD models. One approach is to raise these two information sources to a common level of abstraction and to match them at this level of abstraction. Graph matching is a potential technique for this purpose. This article focuses on automatic generation of the graphs as a prerequisite to graph matching. Algorithms for this purpose are proposed and validated with a case study. The paper concludes with a discussion of further research needed to reprocess the generated graphs in order to enable effective matching. ",https://doi.org/10.1109/ISIE45063.2020.9152371,2104.01854v1,Yes,potent(1)
0000-0002-2040-661X,Harald Baumeister,Universität Ulm,Social Media App Usage in Relation with PHQ-9 Depression Scores during   the COVID-19 Pandemic,1970,"  With about 300 million affected people, major depressive disorder (MDD) is one of the most common diseases worldwide. During the COVID-19 pandemic, the number of cases increased even further, by 28%. Many factors may be correlated with MDD, including the excessive use of social media apps. In this paper, we investigated the relationship between the use of social media and communication apps and depressive symptoms during the COVID-19 pandemic. The pandemic and social distancing like lockdowns probably changed smartphone usage times and usage patterns. While previous studies have shown an association between depression and social media usage, we report about the situation during these special circumstances.We employed a log-linear regression to examine the association of social media and communication app usage and depression. To quantify the usage, we applied the total usage time in hours of social media apps (e.g., WhatsApp, Facebook) as well as communication apps (Phone and Messaging) within one week. To measure depressive symptoms, we used the PHQ-9 score. We discovered a significant association between the usage time and the PHQ-9 score (beta=0.0084, p-value=0.010). We conclude that social media usage is a robust marker for depression severity and future research should focus on a better understanding of the underlying causality and potential counter-measures. ",https://doi.org/10.1145/3544793.3563411,2210.08883v1,Yes,potent(1)
0000-0002-2042-7795,Juliane Mueller,Martin Luther Universität Halle-Wittenberg,A Self-Supervised Approach to Reconstruction in Sparse X-Ray Computed   Tomography,1970,"  Computed tomography has propelled scientific advances in fields from biology to materials science. This technology allows for the elucidation of 3-dimensional internal structure by the attenuation of x-rays through an object at different rotations relative to the beam. By imaging 2-dimensional projections, a 3-dimensional object can be reconstructed through a computational algorithm. Imaging at a greater number of rotation angles allows for improved reconstruction. However, taking more measurements increases the x-ray dose and may cause sample damage. Deep neural networks have been used to transform sparse 2-D projection measurements to a 3-D reconstruction by training on a dataset of known similar objects. However, obtaining high-quality object reconstructions for the training dataset requires high x-ray dose measurements that can destroy or alter the specimen before imaging is complete. This becomes a chicken-and-egg problem: high-quality reconstructions cannot be generated without deep learning, and the deep neural network cannot be learned without the reconstructions. This work develops and validates a self-supervised probabilistic deep learning technique, the physics-informed variational autoencoder, to solve this problem. A dataset consisting solely of sparse projection measurements from each object is used to jointly reconstruct all objects of the set. This approach has the potential to allow visualization of fragile samples with x-ray computed tomography. We release our code for reproducing our results at: https://github.com/vganapati/CT_PVAE . ",Kein DOI-Link verfügbar,2211.00002v1,Yes,potent(1)
0000-0002-2042-7795,Juliane Mueller,Martin Luther Universität Halle-Wittenberg,Adaptive Computing for Scale-up Problems,1970,"  Adaptive Computing is an application-agnostic outer loop framework to strategically deploy simulations and experiments to guide decision making for scale-up analysis. Resources are allocated over successive batches, which makes the allocation adaptive to some objective such as optimization or model training. The framework enables the characterization and management of uncertainties associated with predictive models of complex systems when scale-up questions lead to significant model extrapolation. A key feature of this framework is the ability to explicitly utilize user-specified uncertainty priors, which we call model-specific local trust estimates, that are provided directly together with the problem specification and exploited in adaptive sampling strategies. A multi-fidelity model hierarchy is supported to allow trade-offs in accuracy and data acquisition cost while exploring the search space given a specified budget of potentially distributed, heterogeneous resources. We discuss application of this framework to problems in the renewable energy space, including biofuels production, material synthesis, perovskite crystal growth, and building electrical loads. ",Kein DOI-Link verfügbar,2404.00053v1,Yes,"potent(1), strategically(1)"
0000-0002-2073-1500,Matthew Liew,Universität Mannheim,Convergence towards the Vlasov-Poisson Equation from the $N$-Fermionic   Schrödinger Equation,1970,"  We consider the quantum dynamics of $N$ interacting fermions in the large $N$ limit. The particles in the system interact with each other via repulsive interaction that is regularized Coulomb potential with a polynomial cutoff with respect to $N$.From the quantum system, we derive the Vlasov-Poisson system by simultaneously estimating the semiclassical and mean-field residues in terms of the Husimi measure. ",https://doi.org/10.1007/s00023-021-01103-7,2104.05465v2,Yes,potent(1)
0000-0002-2145-9342,Florian Niederschuh,Technische Universität Darmstadt,Simulating the Photon Statistics of Multimode Gaussian States by   Automatic Differentiation of Generating Functions,1970,"  Advances in photonics require photon-number resolved simulations of quantum optical experiments with Gaussian states. We demonstrate a simple and versatile method to simulate the photon statistics of general multimode Gaussian states. The derived generating functions enable simulations of the photon number distribution, cumulative probabilities, moments, and factorial moments of the photon statistics of Gaussian states as well as of multimode photon-added and photon-subtracted Gaussian states. Numerical results are obtained by automatic differentiation of these generating functions by employing the software framework PyTorch. Our approach is particularly well suited for practical simulations of the photon statistics of quantum optical experiments in realistic scenarios with low photon numbers, in which various sources of imperfections have to be taken into account. As an example, we calculate the detection probabilities for a recent multipartite time-bin coding quantum key distribution setup and compare them with the corresponding experimental values. ",https://doi.org/10.1063/5.0129638,2209.05330v2,Yes,versatile(1)
0000-0002-2174-9681,Daniel Meier,Universität Bielefeld,Thermally driven spin and charge currents in thin NiFe2O4/Pt films,1970,"  We present results on the longitudinal spin Seebeck effect (LSSE) shown by semiconducting ferrimagnetic NiFe2O4/Pt films from room temperature down to 50K base temperature. To the best of our knowledge, this is the first observation of spin caloric effect in NiFe2O4 thin films. The temperature dependence of the conductivity has been studied in parallel to obtain information about the origin of the electric potentials detected at the Pt coverage of the ferrimagnet in order to distinguish the LSSE from the anomalous Nernst effect. Furthermore, the dependence of the LSSE on temperature gradients as well as the influence of an external magnetic field direction is investigated. ",https://doi.org/10.1103/PhysRevB.87.054421,1301.7313v1,Yes,potent(1)
0000-0002-2180-9154,Volkhard Helms,Universität des Saarlandes,Identification of Biomarkers Driving Blood Cell Development,1970,"  A blood cell lineage consists of several consecutive developmental stages from the pluripotent or multipotent stem cell to a particular stage of terminally differentiated cells. There is considerable interest in identifying the key regulatory genes that govern blood cell development from the gene expression data without considering the underlying network between transcription factors (TFs) and their target genes. In this study, we introduce a novel expression pattern that key regulators expose along the differentiation path. We deploy this pattern to identify the cell-specific key regulators responsible for the development. As proof of concept, we consider this approach to data on six developmental stages from mouse embryonic stem cells to terminally differentiated macrophages. ",Kein DOI-Link verfügbar,1912.01890v1,Yes,potent(2)
0000-0002-2180-9154,Volkhard Helms,Universität des Saarlandes,Identification of Biomarkers Controlling Cell Fate In Blood Cell   Development,1970,"  A blood cell lineage consists of several consecutive developmental stages from the pluri- or multipotent stem cell to a state of terminal differentiation. Despite their importance for human biology, the regulatory pathways and gene networks that govern these differentiation processes are not yet fully understood. This is in part due to challenges associated with delineating the interactions between transcription factors (TFs) and their target genes. A possible path forward in this issue is provided by increasingly available expression data as a basis for linking differentiation stages and gene activities. Here, we present a novel hierarchical approach to identify characteristic expression peak patterns that global regulators expose along the differentiation path of cell lineages. Based on such simple patterns, we identify cell state-specific marker genes and extract TFs that likely drive their differentiation. Integration of the mean expression values of stage-specific key player genes yields a distinct peaking pattern for each lineage that is used to identify further genes in the dataset behaving similarly. Incorporating the set of TFs which regulate these genes incurred at a set of stage-specific regulators controlling the biological process of cell fate. As proof of concept, we consider two expression datasets covering key differentiation events in blood cell formation of mice. ",Kein DOI-Link verfügbar,2009.08296v1,Yes,potent(1)
0000-0002-2193-9741,Jorge Leandro,Universität Siegen,GENEVA: GENErating and Visualizing branching narratives using LLMs,1970,"  Dialogue-based Role Playing Games (RPGs) require powerful storytelling. The narratives of these may take years to write and typically involve a large creative team. In this work, we demonstrate the potential of large generative text models to assist this process. \textbf{GENEVA}, a prototype tool, generates a rich narrative graph with branching and reconverging storylines that match a high-level narrative description and constraints provided by the designer. A large language model (LLM), GPT-4, is used to generate the branching narrative and to render it in a graph format in a two-step process. We illustrate the use of GENEVA in generating new branching narratives for four well-known stories under different contextual constraints. This tool has the potential to assist in game development, simulations, and other applications with game-like properties. ",Kein DOI-Link verfügbar,2311.09213v3,Yes,potent(2)
0000-0002-2193-9741,Jorge Leandro,Universität Siegen,Player-Driven Emergence in LLM-Driven Game Narrative,1970,"  We explore how interaction with large language models (LLMs) can give rise to emergent behaviors, empowering players to participate in the evolution of game narratives. Our testbed is a text-adventure game in which players attempt to solve a mystery under a fixed narrative premise, but can freely interact with non-player characters generated by GPT-4, a large language model. We recruit 28 gamers to play the game and use GPT-4 to automatically convert the game logs into a node-graph representing the narrative in the player's gameplay. We find that through their interactions with the non-deterministic behavior of the LLM, players are able to discover interesting new emergent nodes that were not a part of the original narrative but have potential for being fun and engaging. Players that created the most emergent nodes tended to be those that often enjoy games that facilitate discovery, exploration and experimentation. ",Kein DOI-Link verfügbar,2404.17027v3,Yes,potent(1)
0000-0002-2210-1676,Jan Strohbeck,Universität Ulm,Identification of Threat Regions From a Dynamic Occupancy Grid Map for   Situation-Aware Environment Perception,1970,"  The advance towards higher levels of automation within the field of automated driving is accompanied by increasing requirements for the operational safety of vehicles. Induced by the limitation of computational resources, trade-offs between the computational complexity of algorithms and their potential to ensure safe operation of automated vehicles are often encountered. Situation-aware environment perception presents one promising example, where computational resources are distributed to regions within the perception area that are relevant for the task of the automated vehicle. While prior map knowledge is often leveraged to identify relevant regions, in this work, we present a lightweight identification of safety-relevant regions that relies solely on online information. We show that our approach enables safe vehicle operation in critical scenarios, while retaining the benefits of non-uniformly distributed resources within the environment perception. ",https://doi.org/10.1109/ITSC55140.2022.9922163,2207.01902v3,Yes,potent(1)
0000-0002-2210-1676,Jan Strohbeck,Universität Ulm,Fast Long-Term Multi-Scenario Prediction for Maneuver Planning at   Unsignalized Intersections,1970,"  Motion prediction for intelligent vehicles typically focuses on estimating the most probable future evolutions of a traffic scenario. Estimating the gap acceptance, i.e., whether a vehicle merges or crosses before another vehicle with the right of way, is often handled implicitly in the prediction. However, an infrastructure-based maneuver planning can assign artificial priorities between cooperative vehicles, so it needs to evaluate many more potential scenarios. Additionally, the prediction horizon has to be long enough to assess the impact of a maneuver. We, therefore, present a novel long-term prediction approach handling the gap acceptance estimation and the velocity prediction in two separate stages. Thereby, the behavior of regular vehicles as well as priority assignments of cooperative vehicles can be considered. We train both stages on real-world traffic observations to achieve realistic prediction results. Our method has a competitive accuracy and is fast enough to predict a multitude of scenarios in a short time, making it suitable to be used in a maneuver planning framework. ",Kein DOI-Link verfügbar,2401.14879v1,Yes,potent(1)
0000-0002-2210-1676,Jan Strohbeck,Universität Ulm,Enabling automated driving by ICT infrastructure: A reference   architecture,1970,"  Information and communication technology (ICT) is an enabler for establishing automated vehicles (AVs) in today's traffic systems. By providing complementary and/or redundant information via radio communication to the AV's perception by on-board sensors, higher levels of automated driving become more comfortable, safer, or even possible without interaction by the driver, especially in complex scenarios. Additionally, communication between vehicles and/or a central service can improve the efficiency of traffic flow. This paper presents a reference architecture for such an infrastructure-based support of AVs. The architecture combines innovative concepts and technologies from different technological fields like communication, IT environment and data flows, and cyber-security and privacy. Being the basis for the EU-funded project ICT4CART, exemplary implementations of this architecture will show its power for a variety of use cases on highways and in urban areas in test sites in Austria, Germany, and Italy, including cross-border interoperability. ",Kein DOI-Link verfügbar,2003.05229v1,Yes,innovative(1)
0000-0002-2415-2186,Alexander Tornede,Leibniz Universität Hannover,Algorithm Selection on a Meta Level,1970,"  The problem of selecting an algorithm that appears most suitable for a specific instance of an algorithmic problem class, such as the Boolean satisfiability problem, is called instance-specific algorithm selection. Over the past decade, the problem has received considerable attention, resulting in a number of different methods for algorithm selection. Although most of these methods are based on machine learning, surprisingly little work has been done on meta learning, that is, on taking advantage of the complementarity of existing algorithm selection methods in order to combine them into a single superior algorithm selector. In this paper, we introduce the problem of meta algorithm selection, which essentially asks for the best way to combine a given set of algorithm selectors. We present a general methodological framework for meta algorithm selection as well as several concrete learning methods as instantiations of this framework, essentially combining ideas of meta learning and ensemble learning. In an extensive experimental evaluation, we demonstrate that ensembles of algorithm selectors can significantly outperform single algorithm selectors and have the potential to form the new state of the art in algorithm selection. ",Kein DOI-Link verfügbar,2107.09414v1,Yes,potent(1)
0000-0002-2415-2186,Alexander Tornede,Leibniz Universität Hannover,Interactive Hyperparameter Optimization in Multi-Objective Problems via   Preference Learning,1970,"  Hyperparameter optimization (HPO) is important to leverage the full potential of machine learning (ML). In practice, users are often interested in multi-objective (MO) problems, i.e., optimizing potentially conflicting objectives, like accuracy and energy consumption. To tackle this, the vast majority of MO-ML algorithms return a Pareto front of non-dominated machine learning models to the user. Optimizing the hyperparameters of such algorithms is non-trivial as evaluating a hyperparameter configuration entails evaluating the quality of the resulting Pareto front. In literature, there are known indicators that assess the quality of a Pareto front (e.g., hypervolume, R2) by quantifying different properties (e.g., volume, proximity to a reference point). However, choosing the indicator that leads to the desired Pareto front might be a hard task for a user. In this paper, we propose a human-centered interactive HPO approach tailored towards multi-objective ML leveraging preference learning to extract desiderata from users that guide the optimization. Instead of relying on the user guessing the most suitable indicator for their needs, our approach automatically learns an appropriate indicator. Concretely, we leverage pairwise comparisons of distinct Pareto fronts to learn such an appropriate quality indicator. Then, we optimize the hyperparameters of the underlying MO-ML algorithm towards this learned indicator using a state-of-the-art HPO approach. In an experimental study targeting the environmental impact of ML, we demonstrate that our approach leads to substantially better Pareto fronts compared to optimizing based on a wrong indicator pre-selected by the user, and performs comparable in the case of an advanced user knowing which indicator to pick. ",Kein DOI-Link verfügbar,2309.03581v3,Yes,potent(2)
0000-0002-2415-2186,Alexander Tornede,Leibniz Universität Hannover,"AutoML in the Age of Large Language Models: Current Challenges, Future   Opportunities and Risks",1970,"  The fields of both Natural Language Processing (NLP) and Automated Machine Learning (AutoML) have achieved remarkable results over the past years. In NLP, especially Large Language Models (LLMs) have experienced a rapid series of breakthroughs very recently. We envision that the two fields can radically push the boundaries of each other through tight integration. To showcase this vision, we explore the potential of a symbiotic relationship between AutoML and LLMs, shedding light on how they can benefit each other. In particular, we investigate both the opportunities to enhance AutoML approaches with LLMs from different perspectives and the challenges of leveraging AutoML to further improve LLMs. To this end, we survey existing work, and we critically assess risks. We strongly believe that the integration of the two fields has the potential to disrupt both fields, NLP and AutoML. By highlighting conceivable synergies, but also risks, we aim to foster further exploration at the intersection of AutoML and LLMs. ",Kein DOI-Link verfügbar,2306.08107v3,Yes,potent(2)
0000-0002-2415-2186,Alexander Tornede,Leibniz Universität Hannover,Position: A Call to Action for a Human-Centered AutoML Paradigm,1970,"  Automated machine learning (AutoML) was formed around the fundamental objectives of automatically and efficiently configuring machine learning (ML) workflows, aiding the research of new ML algorithms, and contributing to the democratization of ML by making it accessible to a broader audience. Over the past decade, commendable achievements in AutoML have primarily focused on optimizing predictive performance. This focused progress, while substantial, raises questions about how well AutoML has met its broader, original goals. In this position paper, we argue that a key to unlocking AutoML's full potential lies in addressing the currently underexplored aspect of user interaction with AutoML systems, including their diverse roles, expectations, and expertise. We envision a more human-centered approach in future AutoML research, promoting the collaborative design of ML systems that tightly integrates the complementary strengths of human expertise and AutoML methodologies. ",Kein DOI-Link verfügbar,2406.03348v1,Yes,"commendable(1), potent(1)"
0000-0002-2426-3126,André Artelt,Bielefeld Universität,Adversarial attacks hidden in plain sight,1970,"  Convolutional neural networks have been used to achieve a string of successes during recent years, but their lack of interpretability remains a serious issue. Adversarial examples are designed to deliberately fool neural networks into making any desired incorrect classification, potentially with very high certainty. Several defensive approaches increase robustness against adversarial attacks, demanding attacks of greater magnitude, which lead to visible artifacts. By considering human visual perception, we compose a technique that allows to hide such adversarial attacks in regions of high complexity, such that they are imperceptible even to an astute observer. We carry out a user study on classifying adversarially modified images to validate the perceptual quality of our approach and find significant evidence for its concealment with regards to human visual perception. ",https://doi.org/10.1007/978-3-030-44584-3_19,1902.09286v3,Yes,potent(1)
0000-0002-2426-3126,André Artelt,Bielefeld Universität,Explainable Artificial Intelligence for Improved Modeling of Processes,1970,"  In modern business processes, the amount of data collected has increased substantially in recent years. Because this data can potentially yield valuable insights, automated knowledge extraction based on process mining has been proposed, among other techniques, to provide users with intuitive access to the information contained therein. At present, the majority of technologies aim to reconstruct explicit business process models. These are directly interpretable but limited concerning the integration of diverse and real-valued information sources. On the other hand, Machine Learning (ML) benefits from the vast amount of data available and can deal with high-dimensional sources, yet it has rarely been applied to being used in processes. In this contribution, we evaluate the capability of modern Transformer architectures as well as more classical ML technologies of modeling process regularities, as can be quantitatively evaluated by their prediction capability. In addition, we demonstrate the capability of attentional properties and feature relevance determination by highlighting features that are crucial to the processes' predictive abilities. We demonstrate the efficacy of our approach using five benchmark datasets and show that the ML models are capable of predicting critical outcomes and that the attention mechanisms or XAI components offer new insights into the underlying processes. ",https://doi.org/10.1007/978-3-031-21753-1_31,2212.00695v1,Yes,potent(1)
0000-0002-2426-3126,André Artelt,Bielefeld Universität,For Better or Worse: The Impact of Counterfactual Explanations'   Directionality on User Behavior in xAI,1970,"  Counterfactual explanations (CFEs) are a popular approach in explainable artificial intelligence (xAI), highlighting changes to input data necessary for altering a model's output. A CFE can either describe a scenario that is better than the factual state (upward CFE), or a scenario that is worse than the factual state (downward CFE). However, potential benefits and drawbacks of the directionality of CFEs for user behavior in xAI remain unclear. The current user study (N=161) compares the impact of CFE directionality on behavior and experience of participants tasked to extract new knowledge from an automated system based on model predictions and CFEs. Results suggest that upward CFEs provide a significant performance advantage over other forms of counterfactual feedback. Moreover, the study highlights potential benefits of mixed CFEs improving user performance compared to downward CFEs or no explanations. In line with the performance results, users' explicit knowledge of the system is statistically higher after receiving upward CFEs compared to downward comparisons. These findings imply that the alignment between explanation and task at hand, the so-called regulatory fit, may play a crucial role in determining the effectiveness of model explanations, informing future research directions in xAI. To ensure reproducible research, the entire code, underlying models and user data of this study is openly available: https://github.com/ukuhl/DirectionalAlienZoo ",https://doi.org/10.1007/978-3-031-44070-0_14,2306.07637v1,Yes,potent(2)
0000-0002-2533-2189,Harald Rösner,Universität Münster,Unveiling the Asymmetry in Density within the Shear Bands of Metallic   Glasses,1970,"  Plastic deformation in metallic glasses at room temperature leads to the development of shear bands due to shear localization. In many experiments, shear bands have shown local density variations along their path, with a distinct imbalance in magnitude between local densification and dilation. However, a comprehensive mechanistic understanding or theory to explain this asymmetry has been lacking until now. Here, we introduce a new model that consists of a sequential arrangement of alternating topological 'charges', generating a dipolar field. The resulting microscopic displacement field, when integrated into the deformation gradient tensor, provides an accurate analytical solution for the observed imbalances in the density variations. The implications of this method are discussed, highlighting the potential to elucidate a broader range of observations in shear bands. ",https://doi.org/10.1103/PhysRevB.110.014107,2407.07733v1,Yes,potent(1)
0000-0002-2551-0491,Volker Michel,Universität Siegen,A dictionary learning add-on for spherical downward continuation,1970,"  We propose a novel dictionary learning add-on for existing approximation algorithms for spherical inverse problems such as the downward continuation of the gravitational potential. The Inverse Problem Matching Pursuit (IPMP) algorithms iteratively minimize the Tikhonov functional in order to construct a weighted linear combination of so-called dictionary elements as a regularized approximation. A dictionary is a set that contains trial functions such as spherical harmonics (SHs), Slepian functions (SLs) as well as radial basis functions (RBFs) and wavelets (RBWs). Previously, the IPMP algorithms worked with finite dictionaries which are vulnerable regarding a possible biasing of the outcome. Here, we propose an additional learning technique that allows us to work with infinitely many trial functions and provides us with a learnt dictionary for future use in the IPMP algorithms. We explain the general mechanism and provide numerical results that prove its applicability and efficiency. ",https://doi.org/10.1007/s00190-022-01598-w,2012.05560v1,Yes,potent(1)
0000-0002-2551-0491,Volker Michel,Universität Siegen,A first approach to learning a best basis for gravitational field   modelling,1970,"  Gravitational field modelling is an important tool for inferring past and present dynamic processes of the Earth. Functions on the sphere such as the gravitational potential are usually expanded in terms of either spherical harmonics or radial basis functions (RBFs). The (Regularized) Functional Matching Pursuit ((R)FMP) and its variants use an overcomplete dictionary of diverse trial functions to build a best basis as a sparse subset of the dictionary and compute a model, for instance, of the gravity field, in this best basis. Thus, one advantage is that the dictionary may contain spherical harmonics and RBFs. Moreover, these methods represent a possibility to obtain an approximative and stable solution of an ill-posed inverse problem, such as the downward continuation of gravitational data from the satellite orbit to the Earth's surface, but also other inverse problems in geomathematics and medical imaging. A remaining drawback is that in practice, the dictionary has to be finite and, so far, could only be chosen by rule of thumb or trial-and-error. In this paper, we develop a strategy for automatically choosing a dictionary by a novel learning approach. We utilize a non-linear constrained optimization problem to determine best-fitting RBFs (Abel-Poisson kernels). For this, we use the Ipopt software package with an HSL subroutine. Details of the algorithm are explained and first numerical results are shown. ",https://doi.org/10.1007/s13137-020-0143-5,1901.04222v2,Yes,potent(1)
0000-0002-2551-0491,Volker Michel,Universität Siegen,High-dimensional experiments for the downward continuation using the   LRFMP algorithm,1970,"  Time-dependent gravity data from satellite missions like GRACE-FO reveal mass redistribution in the system Earth at various time scales: long-term climate change signals, inter-annual phenomena like El Nino, seasonal mass transports and transients, e. g. due to earthquakes. For this contemporary issue, a classical inverse problem has to be considered: the gravitational potential has to be modelled on the Earth's surface from measurements in space. This is also known as the downward continuation problem. Thus, it is important to further develop current mathematical methods for such inverse problems. For this, the (Learning) Inverse Problem Matching Pursuits ((L)IPMPs) have been developed within the last decade. Their unique feature is the combination of local as well as global trial functions in the approximative solution of an inverse problem such as the downward continuation of the gravitational potential. In this way, they harmonize the ideas of a traditional spherical harmonic ansatz and the radial basis function approach. Previous publications on these methods showed proofs of concept. Here, we consider the methods for high-dimensional experiments settings with more than 500 000 grid points which yields a resolution of 20 km at best on a realistic satellite geometry. We also explain the changes in the methods that had to be done to work with such a large amount of data. The corresponding code (updated for big data use) is available at https://doi.org/10.5281/zenodo.8223771 under the licence CC BY-NC-SA 3.0 Germany. ",Kein DOI-Link verfügbar,2308.04167v1,Yes,potent(2)
0000-0002-2551-0491,Volker Michel,Universität Siegen,Vector-valued Spline Method for the Spherical Multiple-shell   Electro-magnetoencephalography Problem,1970,"  Human brain activity is based on electrochemical processes, which can only be measured invasively. Therefore, quantities such as magnetic flux density (MEG) or electric potential differences (EEG) are measured non-invasively in medicine and research. The reconstruction of the neuronal current from the measurements is a severely ill-posed problem though its visualization is one of the main research tools in cognitive neuroscience. Here, using an isotropic multiple-shell model for the geometry of the head and a quasi-static approach for modeling the electro-magnetic processes, we derive a novel vector-valued spline method based on reproducing kernel Hilbert spaces. The presented vector spline method follows the path of former spline approaches and provides classical minimum norm properties. In addition, it minimizes the (infinite-dimensional) Tikhonov-Philips functional handling the instability of the inverse problem. This optimization problem reduces to solving a finite-dimensional system of linear equations without loss of information. It results in a unique solution which takes into account that only the harmonic and solenoidal component of the current affects the measurements. Besides, we prove a convergence result: the solution achieved by the vector spline method converges to the generator of the data as the number of measurements increases. The vector splines are applied to the inversion of synthetic test cases, where the irregularly distributed data situation could be handled very well. Combined with parameter choice methods, numerical results are shown with and without additional Gaussian white noise. Former approaches based on scalar splines are outperformed by the vector splines results with respect to the normalized root mean square error. Finally, reasonable results with respect to physiological expectations for real data are shown. ",https://doi.org/10.1088/1361-6420/ac62f5,2112.12015v1,Yes,potent(1)
0000-0002-2551-0491,Volker Michel,Universität Siegen,A matching pursuit approach to the geophysical inverse problem of   seismic travel time tomography under the ray theory approximation,1970,"  Seismic travel time tomography is a geophysical imaging method to infer the 3-D interior structure of the solid Earth. Most commonly formulated as a linear(ized) inverse problem, it maps differences between observed and expected wave travel times to interior regions where waves propagate faster or slower than the expected average. The Earth's interior is typically parametrized by a single kind of localized basis function. Here we present an alternative approach that uses matching pursuits on large dictionaries of basis functions.   Within the past decade the (Learning) Inverse Problem Matching Pursuits ((L)IPMPs) have been developed. They combine global and local trial functions. An approximation is built in a so-called best basis, chosen iteratively from an intentionally overcomplete set or dictionary. In each iteration, the choice for the next best basis element reduces the Tikhonov-Phillips functional. This is in contrast to classical methods that use either global or local basis functions. The LIPMPs have proven its applicability in inverse problems like the downward continuation of the gravitational potential as well as the MEG-/EEG-problem from medical imaging.   Here, we remodel the Learning Regularized Functional Matching Pursuit (LRFMP), which is one of the LIPMPs, for travel time tomography in a ray theoretical setting. In particular, we introduce the operator, some possible trial functions and the regularization. We show a numerical proof of concept for artificial travel time delays obtained from a contrived model for velocity differences. The corresponding code is available at https://doi.org/10.5281/zenodo.8227888 under the licence CC-BY-NC-SA 3.0 DE. ",Kein DOI-Link verfügbar,2309.00085v1,Yes,potent(1)
0000-0002-2613-9014,Maximilian Stahlhofen,Albert-Ludwigs-Universität Freiburg,The QCD static potential in 2+1 dimensions at weak coupling,1970,"  Using the effective theory pNRQCD we determine the potential energy of a color singlet quark-antiquark pair with (fixed) distance r in three space-time dimensions at weak coupling (alpha r << 1). The precision of our result reaches O(alpha^3 r^2), i.e. NNLO in the multipole expansion, and NNLL in a alpha/DeltaV expansion, where Delta V ~ alpha ln(alpha r). We even include all logarithmic terms up to N^4LL order and compare the outcome to existing lattice data. ",https://doi.org/10.1016/j.nuclphysbps.2010.10.097,1009.4237v1,Yes,potent(1)
0000-0002-2613-9014,Maximilian Stahlhofen,Albert-Ludwigs-Universität Freiburg,NLL resummation for the static potential in N=4 SYM theory,1970,  We determine the complete NLL running of the static potential associated with the locally 1/2 BPS Wilson loop in N=4 supersymmetric Yang-Mills theory. We present results for the SU(N_c) singlet as well as for the adjoint configuration and arbitrary N_c at weak coupling. In order to derive the respective anomalous dimensions we perform a two-loop calculation in the N=4 supersymmetric version of the effective field theory pNRQCD. In addition we confirm the recently obtained fixed-order result for the singlet static potential generated exclusively by ladder diagrams to the third order in the t`Hooft coupling. We also give an explicit expression for the logarithmic contribution of all non-ladder diagrams at this order. ,https://doi.org/10.1007/JHEP11(2012)155,1209.2122v2,Yes,potent(2)
0000-0002-2613-9014,Maximilian Stahlhofen,Albert-Ludwigs-Universität Freiburg,The QCD static potential in D<4 dimensions at weak coupling,1970,"  We study the static potential of a color singlet quark-antiquark pair with (fixed) distance r in D=3 and D=2 space-time dimensions at weak coupling (alpha r << 1 and g r << 1, respectively). Using the effective theory pNRQCD we determine the ultrasoft contributions, which cannot be computed in conventional perturbative QCD. We show in detail how the ultrasoft renormalization in pNRQCD is carried out. In three dimensions the precision of our results reaches O(alpha^3 r^2), i.e. NNLO in the multipole expansion, and NNLL in a alpha/DeltaV expansion, where DeltaV ~ alpha ln(alpha r). We even present results up to partly N^4LL order and compare them to existing lattice data. Finally we discuss the relevance of the perturbative calculation in two dimensions, where the exact result is known. ",https://doi.org/10.1103/PhysRevD.81.074026,1002.1965v2,Yes,potent(1)
0000-0002-2613-9014,Maximilian Stahlhofen,Albert-Ludwigs-Universität Freiburg,The static hybrid potential in D dimensions at short distances,1970,"  We compute the energy of a static hybrid, i.e. of a hybrid quarkonium with static quark and antiquark, at short distances in D=4,3 dimensions. The soft contribution to this energy is the static potential of a color octet quark-antiquark pair at short distances, which is known at two loops for arbitrary D. We have checked this expression employing thermal field theory methods. Using the effective field theory pNRQCD we calculate the ultrasoft contributions to the hybrid (and singlet) static energy at the two-loop level. We then present new results for the static hybrid energy/potential and the hybrid decay width in three and four dimensions. Finally we comment on the meaning of the perturbative results in two space-time dimensions, where the hybrid does not exist. ",https://doi.org/10.1103/PhysRevD.84.034016,1105.4356v1,Yes,potent(2)
0000-0002-2613-9014,Maximilian Stahlhofen,Albert-Ludwigs-Universität Freiburg,Two-Loop Ultrasoft Running of the O(v^2) QCD Quark Potentials,1970,  The two-loop ultrasoft contributions to the next-to-leading logarithmic (NLL) running of the QCD potentials at order v^2 are determined. The results represent an important step towards the next-to-next-to-leading logarithmic (NNLL) description of heavy quark pair production and annihilation close to threshold. ,https://doi.org/10.1103/PhysRevD.75.054025,hep-ph/0611292v3,Yes,potent(1)
0000-0002-2613-9014,Maximilian Stahlhofen,Albert-Ludwigs-Universität Freiburg,Ultrasoft NLL Running of the Nonrelativistic O(v) QCD Quark Potential,1970,"  Using the nonrelativistic effective field theory vNRQCD, we determine the contribution to the next-to-leading logarithmic (NLL) running of the effective quark-antiquark potential at order v (1/mk) from diagrams with one potential and two ultrasoft loops, v being the velocity of the quarks in the c.m. frame. The results are numerically important and complete the description of ultrasoft next-to-next-to-leading logarithmic (NNLL) order effects in heavy quark pair production and annihilation close to threshold. ",https://doi.org/10.1007/JHEP06(2011)088,1102.0269v2,Yes,potent(2)
0000-0002-2613-9014,Maximilian Stahlhofen,Albert-Ludwigs-Universität Freiburg,Relativistic corrections to the static energy in terms of Wilson loops   at weak coupling,1970,"  We consider the ${\mathcal O}(1/m)$ and the spin-independent momentum-dependent ${\mathcal O}(1/m^2)$ quasi-static energies of heavy quarkonium (with unequal masses). They are defined nonperturbatively in terms of Wilson loops. We determine their short-distance behavior through ${\mathcal O}(\alpha^3)$ and ${\mathcal O}(\alpha^2)$, respectively. In particular, we calculate the ultrasoft contributions to the quasi-static energies, which requires the resummation of potential interactions. Our results can be directly compared to lattice simulations. In addition, we also compare the available lattice data with the expectations from effective string models for the long-distance behavior of the quasi-static energies. ",https://doi.org/10.1140/epjc/s10052-017-5250-6,1706.03971v2,Yes,potent(1)
0000-0002-2613-9014,Maximilian Stahlhofen,Albert-Ludwigs-Universität Freiburg,Integrating out heavy fields in the path integral using the   background-field method: general formalism,1970,"  Building on an older method used to derive non-decoupling effects of a heavy Higgs boson in the Standard Model, we describe a general procedure to integrate out heavy fields in the path integral. The derivation of the corresponding effective Lagrangian including the one-loop contributions of the heavy particle(s) is particularly transparent, flexible, and algorithmic. The background-field formalism allows for a clear separation of tree-level and one-loop effects involving the heavy fields. Using expansion by regions the one-loop effects are further split into contributions from large and small momentum modes. The former are contained in Wilson coefficients of effective operators, the latter are reproduced by one-loop diagrams involving effective tree-level couplings. The method is illustrated by calculating potential non-decoupling effects of a heavy Higgs boson in a singlet Higgs extension of the Standard Model. In particular, we work in a field basis corresponding to mass eigenstates and properly take into account non-vanishing mixing between the two Higgs fields of the model. We also show that a proper choice of renormalization scheme for the non-standard sector of the underlying full theory is crucial for the construction of a consistent effective field theory. ",https://doi.org/10.1140/epjc/s10052-021-09587-7,2102.12020v2,Yes,potent(1)
0000-0002-2613-9014,Maximilian Stahlhofen,Albert-Ludwigs-Universität Freiburg,Potential NRQCD for unequal masses and the $B_c$ spectrum at NNNLO,1970,"  We determine the $1/m$ and $1/m^2$ spin-independent heavy quarkonium potentials in the unequal mass case with $\mathcal O(\alpha^3)$ and $\mathcal O(\alpha^2)$ accuracy, respectively. We discuss in detail different methods to calculate the potentials, and show the equivalence among them. In particular we obtain, for the first time, the manifestly gauge invariant $1/m$ and $1/m^2$ potentials in terms of Wilson loops with next-to-leading order (NLO) precision. As an application of our results we derive the theoretical expression for the $B_c$ spectrum in the weak-coupling limit through next-to-next-to-next-to-leading order (N$^3$LO). ",https://doi.org/10.1007/JHEP05(2016)017,1511.08210v3,Yes,potent(3)
0000-0002-2613-9014,Maximilian Stahlhofen,Albert-Ludwigs-Universität Freiburg,Matter dependence of the four-loop QCD cusp anomalous dimension: from   small angles to all angles,1970,"  We compute the fermionic contributions to the cusp anomalous dimension in QCD at four loops as an expansion for small cusp angle. As a byproduct we also obtain the respective terms of the four-loop HQET wave function anomalous dimension. Our new results at small angles provide stringent tests of a recent conjecture for the exact angle dependence of the matter terms in the four-loop cusp anomalous dimension. We find that the conjecture does not hold for two of the seven fermionic color structures, but passes all tests for the remaining terms. This provides strong support for the validity of the corresponding conjectured expressions with full angle dependence. Taking the limit of large Minkowskian angle, we extract novel analytic results for certain terms of the light-like cusp anomalous dimension. They agree with the known numerical results. Finally, we study the anti-parallel lines limit of the cusp anomalous dimension. In a conformal theory, the latter is proportional to the static quark-antiquark potential. We use the new four-loop results to determine parts of the conformal anomaly term. ",https://doi.org/10.1007/JHEP05(2019)186,1902.05076v1,Yes,potent(1)
0000-0002-2616-8739,Alexander Krause,Technische Universität Dresden,MorphStore: Analytical Query Engine with a Holistic Compression-Enabled   Processing Model,1970,"  In this paper, we present MorphStore, an open-source in-memory columnar analytical query engine with a novel holistic compression-enabled processing model. Basically, compression using lightweight integer compression algorithms already plays an important role in existing in-memory column-store database systems, but mainly for base data. In particular, during query processing, these systems only keep the data compressed until an operator cannot process the compressed data directly, whereupon the data is decompressed, but not recompressed. Thus, the full potential of compression during query processing is not exploited. To overcome that, we developed a novel compression-enabled processing model as presented in this paper. As we are going to show, the continuous usage of compression for all base data and all intermediates is very beneficial to reduce the overall memory footprint as well as to improve the query performance. ",Kein DOI-Link verfügbar,2004.09350v1,Yes,potent(1)
0000-0002-2616-8739,Alexander Krause,Technische Universität Dresden,"""We've Disabled MFA for You"": An Evaluation of the Security and   Usability of Multi-Factor Authentication Recovery Deployments",1970,"  Multi-Factor Authentication is intended to strengthen the security of password-based authentication by adding another factor, such as hardware tokens or one-time passwords using mobile apps. However, this increased authentication security comes with potential drawbacks that can lead to account and asset loss. If users lose access to their additional authentication factors for any reason, they will be locked out of their accounts. Consequently, services that provide Multi-Factor Authentication should deploy procedures to allow their users to recover from losing access to their additional factor that are both secure and easy-to-use. In this work, we investigate the security and user experience of Multi-Factor Authentication recovery procedures, and compare their deployment to descriptions on help and support pages. We first evaluate the official help and support pages of 1,303 websites that provide Multi-Factor Authentication and collect documented information about their recovery procedures. Second, we select a subset of 71 websites, create accounts, set up Multi-Factor Authentication, and perform an in-depth investigation of their recovery procedure security and user experience. We find that many websites deploy insecure Multi-Factor Authentication recovery procedures and allowed us to circumvent and disable Multi-Factor Authentication when having access to the accounts' associated email addresses. Furthermore, we commonly observed discrepancies between our in-depth analysis and the official help and support pages, implying that information meant to aid users is often either incorrect or outdated. Based on our findings, we provide recommendations for best practices regarding Multi-Factor Authentication recovery. ",Kein DOI-Link verfügbar,2306.09708v3,Yes,potent(1)
0000-0002-2629-8672,Matthias Feldmaier,Universität Stuttgart,Binary contraction method for the construction of time-dependent   dividing surfaces in driven chemical reactions,1970,"  Transition state theory formally provides a simplifying approach for determining chemical reaction rates and pathways. Given an underlying potential energy surface for a reactive system, one can determine the dividing surface in phase space which separates reactant and product regions, and thereby also these regions. This is often a difficult task, and it is especially demanding for high-dimensional time-dependent systems or when a non-local dividing surface is required. Recently, approaches relying on Lagrangian descriptors have been successful at resolving the dividing surface in some of these challenging cases, but this method can also be computationally expensive due to the necessity of integrating the corresponding phase space function. In this paper, we present an alternative method by which time-dependent, locally recrossing-free dividing surfaces can be constructed without the calculation of any auxiliary phase space function, but only from simple dynamical properties close to the energy barrier. ",https://doi.org/10.1103/PhysRevE.98.032204,1808.07614v1,Yes,potent(1)
0000-0002-2629-8672,Matthias Feldmaier,Universität Stuttgart,Chemical dynamics between wells across a time-dependent barrier:   Self-similarity in the Lagrangian descriptor and reactive basins,1970,"  In chemical or physical reaction dynamics, it is essential to distinguish precisely between reactants and products for all time. This task is especially demanding in time-dependent or driven systems because therein the dividing surface (DS) between these states often exhibits a nontrivial time-dependence. The so-called transition state (TS) trajectory has been seen to define a DS which is free of recrossings in a large number of one-dimensional reactions across time-dependent barriers, and, thus, allows one to determine exact reaction rates. A fundamental challenge to applying this method is the construction of the TS trajectory itself. The minimization of Lagrangian descriptors (LDs) provides a general and powerful scheme to obtain that trajectory even when perturbation theory fails. Both approaches encounter possible breakdowns when the overall potential is bounded, admitting the possibility of returns to the barrier long after trajectories have reached the product or reactant wells. Such global dynamics cannot be captured by perturbation theory. Meanwhile, in the LD-DS approach, it leads to the emergence of additional local minima which make it difficult to extract the optimal branch associated with the desired TS trajectory. In this work, we illustrate this behavior for a time-dependent double-well potential revealing a self-similar structure of the LD, and we demonstrate how the reflections and side-minima can be addressed by an appropriate modification of the LD associated with the direct rate across the barrier. ",https://doi.org/10.1063/1.4997379,1705.00250v3,Yes,potent(2)
0000-0002-2629-8672,Matthias Feldmaier,Universität Stuttgart,Neural network approach to time-dependent dividing surfaces in classical   reaction dynamics,1970,"  In a dynamical system, the transition between reactants and products is typically mediated by an energy barrier whose properties determine the corresponding pathways and rates. The latter is the flux through a dividing surface (DS) between the two corresponding regions and it is exact only if it is free of recrossings. For time-independent barriers, the DS can be attached to the top of the corresponding saddle point of the potential energy surface, and in time-dependent systems, the DS is a moving object. The precise determination of reaction rates, eg using transition state theory, requires the actual construction of a DS for a given saddle geometry which is in general a demanding methodical and computational task, especially in high-dimensional systems. In this paper, we demonstrate how such time-dependent, global, and recrossing-free DSs can be constructed using neural networks. In our approach, the neural network uses the bath coordinates and time as input and it is trained in a way that its output provides the position of the DS along the reaction coordinate. An advantage of this procedure is that, once the neural network is trained, the complete information about the dynamical phase space separation is stored in the network's parameters, and a precise distinction between reactants and products can be made for all possible system configurations, all times, and with little computational effort. We demonstrate this general method for two- and three-dimensional systems, and explain its straightforward extension to even more degrees of freedom. ",https://doi.org/10.1103/PhysRevE.97.042309,1712.07324v2,Yes,potent(1)
0000-0002-2636-2531,Matthias Vogt,Martin-Luther-Universität Halle-Wittenberg,Glassy behavior in a binary atomic mixture,1970,"  We experimentally study one-dimensional, lattice-modulated Bose gases in the presence of an uncorrelated disorder potential formed by localized impurity atoms, and compare to the case of correlated quasi-disorder formed by an incommensurate lattice. While the effects of the two disorder realizations are comparable deeply in the strongly interacting regime, both showing signatures of Bose glass formation, we find a dramatic difference near the superfluid-to-insulator transition. In this transition region, we observe that random, uncorrelated disorder leads to a shift of the critical lattice depth for the breakdown of transport as opposed to the case of correlated quasi-disorder, where no such shift is seen. Our findings, which are consistent with recent predictions for interacting bosons in one dimension, illustrate the important role of correlations in disordered atomic systems. ",https://doi.org/10.1103/PhysRevLett.107.145306,1107.2428v2,Yes,potent(1)
0000-0002-2636-2531,Matthias Vogt,Martin-Luther-Universität Halle-Wittenberg,Indirect Chiral Magnetic Exchange through   Dzyaloshinskii-Moriya--Enhanced RKKY Interactions in Manganese Oxide Chains   on Ir(100),1970,"  Ruderman-Kittel-Kasuya-Yosida interaction even if their wave functions lack direct overlap. Theory predicts that spin-orbit scattering leads to a Dzyaloshinskii-Moriya type enhancement of this indirect exchange interaction, giving rise to chiral exchange terms. Here we present a combined spin-polarized scanning tunneling microscopy, angle-resolved photoemission, and density functional theory study of MnO$_2$ chains on Ir(100). Whereas we find antiferromagnetic Mn--Mn coupling along the chain, the inter-chain coupling across the non-magnetic Ir substrate turns out to be chiral with a $120^{\circ}$ rotation between adjacent MnO$_2$ chains. Calculations reveal that the Dzyaloshinskii-Moriya interaction results in spin spirals with a periodicity in agreement with experiment. Our findings confirm the existence of indirect chiral magnetic exchange, potentially giving rise to exotic phenomena, such as chiral spin-liquid states in spin ice systems or the emergence of new quasiparticles. ",https://doi.org/10.1038/s41467-019-10515-3,1906.07703v1,Yes,potent(1)
0000-0002-2715-8057,Alexander Kurz,Albert-Ludwigs-Universität Freiburg,Nominal Regular Expressions for Languages over Infinite Alphabets.   Extended Abstract,1970,"  We propose regular expressions to abstractly model and study properties of resource-aware computations. Inspired by nominal techniques -- as those popular in process calculi -- we extend classical regular expressions with names (to model computational resources) and suitable operators (for allocation, deallocation, scoping of, and freshness conditions on resources). We discuss classes of such nominal regular expressions, show how such expressions have natural interpretations in terms of languages over infinite alphabets, and give Kleene theorems to characterise their formal languages in terms of nominal automata. ",Kein DOI-Link verfügbar,1310.7093v1,Yes,fresh(1)
0000-0002-2715-8057,Alexander Kurz,Albert-Ludwigs-Universität Freiburg,Interface Automata for Choreographies,1970,"  Choreographic approaches to message-passing applications can be regarded as an instance of the model-driven development principles. Choreographies specify interactions among distributed participants coordinating among themselves with message-passing at two levels of abstractions. A global view of the application is specified with a model that abstracts away from asynchrony while a local view of the application specifies the communication pattern of each participant. Noteworthy, the latter view can typically be algorithmically obtained by projection of the global view. A crucial element of this approach is to verify the so-called well-formed conditions on global views so that its projections realise a sound communication protocol. We introduce a novel local model, group interface automata, to represent the local view of choreographies and propose a new method to verify the well-formedness of global choreographies. We rely on a recently proposed semantics of global views formalised in terms of pomsets. ",https://doi.org/10.4204/EPTCS.304.1,1909.05967v1,Yes,noteworthy(1)
0000-0002-2715-8057,Alexander Kurz,Albert-Ludwigs-Universität Freiburg,Benchmarking common uncertainty estimation methods with   histopathological images under domain shift and label noise,1970,"  In the past years, deep learning has seen an increase in usage in the domain of histopathological applications. However, while these approaches have shown great potential, in high-risk environments deep learning models need to be able to judge their uncertainty and be able to reject inputs when there is a significant chance of misclassification. In this work, we conduct a rigorous evaluation of the most commonly used uncertainty and robustness methods for the classification of Whole Slide Images, with a focus on the task of selective classification, where the model should reject the classification in situations in which it is uncertain. We conduct our experiments on tile-level under the aspects of domain shift and label noise, as well as on slide-level. In our experiments, we compare Deep Ensembles, Monte-Carlo Dropout, Stochastic Variational Inference, Test-Time Data Augmentation as well as ensembles of the latter approaches. We observe that ensembles of methods generally lead to better uncertainty estimates as well as an increased robustness towards domain shifts and label noise, while contrary to results from classical computer vision benchmarks no systematic gain of the other methods can be shown. Across methods, a rejection of the most uncertain samples reliably leads to a significant increase in classification accuracy on both in-distribution as well as out-of-distribution data. Furthermore, we conduct experiments comparing these methods under varying conditions of label noise. Lastly, we publish our code framework to facilitate further research on uncertainty estimation on histopathological data. ",https://doi.org/10.1016/j.media.2023.102914,2301.01054v2,Yes,potent(1)
0000-0002-2755-9686,Simon Wagner,Universität Potsdam,SAR Image Synthesis with Diffusion Models,1970,"  In recent years, diffusion models (DMs) have become a popular method for generating synthetic data. By achieving samples of higher quality, they quickly became superior to generative adversarial networks (GANs) and the current state-of-the-art method in generative modeling. However, their potential has not yet been exploited in radar, where the lack of available training data is a long-standing problem. In this work, a specific type of DMs, namely denoising diffusion probabilistic model (DDPM) is adapted to the SAR domain. We investigate the network choice and specific diffusion parameters for conditional and unconditional SAR image generation. In our experiments, we show that DDPM qualitatively and quantitatively outperforms state-of-the-art GAN-based methods for SAR image generation. Finally, we show that DDPM profits from pretraining on largescale clutter data, generating SAR images of even higher quality. ",Kein DOI-Link verfügbar,2405.07776v1,Yes,potent(1)
0000-0002-2802-7825,Lukas Barth,Karlsruher Institut für Technologie,Temporal Map Labeling: A New Unified Framework with Experiments,1970,"  The increased availability of interactive maps on the Internet and on personal mobile devices has created new challenges in computational cartography and, in particular, for label placement in maps. Operations like rotation, zoom, and translation dynamically change the map over time and make a consistent adaptation of the map labeling necessary.   In this paper, we consider map labeling for the case that a map undergoes a sequence of operations over a specified time span. We unify and generalize several preceding models for dynamic map labeling into one versatile and flexible model. In contrast to previous research, we completely abstract from the particular operations (e.g., zoom, rotation, etc.) and express the labeling problem as a set of time intervals representing the labels' presences, activities, and conflicts. The model's strength is manifested in its simplicity and broad range of applications. In particular, it supports label selection both for map features with fixed position as well as for moving entities (e.g., for tracking vehicles in logistics or air traffic control).   Through extensive experiments on OpenStreetMap data, we evaluate our model using algorithms of varying complexity as a case study for navigation systems. Our experiments show that even simple (and thus, fast) algorithms achieve near-optimal solutions in our model with respect to an intuitive objective function. ",Kein DOI-Link verfügbar,1609.06327v1,Yes,versatile(1)
0000-0002-2821-4313,Yannik Keller,TU Darmstadt,From Images to Connections: Can DQN with GNNs learn the Strategic Game   of Hex?,1970,"  The gameplay of strategic board games such as chess, Go and Hex is often characterized by combinatorial, relational structures -- capturing distinct interactions and non-local patterns -- and not just images. Nonetheless, most common self-play reinforcement learning (RL) approaches simply approximate policy and value functions using convolutional neural networks (CNN). A key feature of CNNs is their relational inductive bias towards locality and translational invariance. In contrast, graph neural networks (GNN) can encode more complicated and distinct relational structures. Hence, we investigate the crucial question: Can GNNs, with their ability to encode complex connections, replace CNNs in self-play reinforcement learning? To this end, we do a comparison with Hex -- an abstract yet strategically rich board game -- serving as our experimental platform. Our findings reveal that GNNs excel at dealing with long range dependency situations in game states and are less prone to overfitting, but also showing a reduced proficiency in discerning local patterns. This suggests a potential paradigm shift, signaling the use of game-specific structures to reshape self-play reinforcement learning. ",Kein DOI-Link verfügbar,2311.13414v1,Yes,"potent(1), strategically(1)"
0000-0002-2944-8373,Volker Michael Hannen,Universität Münster,Suppression of electrical breakdown phenomena in liquid TriMethyl   Bismuth based ionization detectors,1970,"  Organometallic liquids provide good properties for ionization detectors. TriMethyl Bismuth (TMBi) has been proposed as a detector medium with charge and Cherenkov photon readout for Positron Emission Tomography. In this work, we present studies for the handling of TMBi at different electric fields and under different environmental conditions to find applicable configurations for the suppression of electrical breakdowns in TMBi at room temperature. A simple glass cell with two electrodes filled with TMBi was constructed and tested under different operation conditions. Working at the vapour pressure of TMBi at room temperature of about 40 mbar and electric fields of up to 20 kV/cm in presence of a small oxygen contamination we found the formation of a discharge channel in the liquid and a steady increase in the current. Further reduction of pressure by pumping caused the TMBi to boil and a spontaneous combustion. Eliminating the oxygen contamination led the TMBi under the same condition to only decompose. When operating the setup under an argon atmosphere of 1 bar we did not observe breakdowns of the electrical potential up to field strengths of 20 kV/cm. Still, in presence of a small oxygen contamination fluctuating currents in the nA range were observed, but no decomposition or combustion. We conclude from our experiments that TMBi at room temperature in a pure argon atmosphere of 1 bar remains stable against electrical breakdown at least up to electric field strengths of 20 kV/cm, presumably because the formation of gaseous TMBi was prevented. ",https://doi.org/10.1088/1748-0221/17/09/P09029,2206.13440v1,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Orbital and spin relaxation in single and coupled quantum dots,1970,"  Phonon-induced orbital and spin relaxation rates of single electron states in lateral single and double quantum dots are obtained numerically for realistic materials parameters. The rates are calculated as a function of magnetic field and interdot coupling, at various field and quantum dot orientations. It is found that orbital relaxation is due to deformation potential phonons at low magnetic fields, while piezoelectric phonons dominate the relaxation at high fields. Spin relaxation, which is dominated by piezoelectric phonons, in single quantum dots is highly anisotropic due to the interplay of the Bychkov-Rashba and Dresselhaus spin-orbit couplings. Orbital relaxation in double dots varies strongly with the interdot coupling due to the cyclotron effects on the tunneling energy. Spin relaxation in double dots has an additional anisotropy due to anisotropic spin hot spots which otherwise cause giant enhancement of the rate at useful magnetic fields and interdot couplings. Conditions for the absence of the spin hot spots in in-plane magnetic fields (easy passages) and perpendicular magnetic fields (weak passages) are formulated analytically for different growth directions of the underlying heterostructure. It is shown that easy passages disappear (spin hot spots reappear) if the double dot system loses symmetry by an xy-like perturbation. ",https://doi.org/10.1103/PhysRevB.74.045320,cond-mat/0604633v1,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Graphene on transition-metal dichalcogenides: a platform for proximity   spin-orbit physics and optospintronics,1970,"  Hybrids of graphene and two dimensional transition metal dichalcogenides (TMDC) have the potential to bring graphene spintronics to the next level. As we show here by performing first-principles calculations of graphene on monolayer MoS$_2$, there are several advantages of such hybrids over pristine graphene. First, Dirac electrons in graphene exhibit a giant global proximity spin-orbit coupling, without compromising the semimetallic character of the whole system at zero field. Remarkably, these spin-orbit effects can be very accurately described by a simple effective Hamiltonian. Second, the Fermi level can be tuned by a transverse electric field to cross the MoS$_2$ conduction band, creating a system of coupled massive and massles electron gases. Both charge and spin transport in such systems should be unique. Finally, we propose to use graphene/TMDC structures as a platform for optospintronics, in particular for optical spin injection into graphene and for studying spin transfer between TMDC and graphene. ",https://doi.org/10.1103/PhysRevB.92.155403,1506.08954v1,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,"First-principles studies of orbital and spin-orbit properties of GaAs,   GaSb, InAs, and InSb zinc-blende and wurtzite semiconductors",1970,"  We employ first-principles techniques tailored to properly describe semiconductors (modified Becke-Johnson potential added to the exchange-correlation functional), to obtain the electronic band structures of both the zinc-blende and wurtzite phases of GaAs, GaSb, InAs, and InSb. We extract the spin-orbit fields for the relevant valence and conduction bands at zone center, by fitting the spin-splittings resulting from the lack of space inversion symmetry of these bulk crystal structures, to known functional forms---third-order polynomials. We also determine the orientations of the spin-orbit vector fields (for conduction bands) and the average spins (valence bands) in the momentum space. We describe the dependence of the spin-orbit parameters on the cation and anion atomic weights. These results should be useful for spin transport, spin relaxation, and spin optical orientation modeling of semiconductor heterostructures, as well as for realistic studies of semiconductor-based Majorana nanowires, for which accurate values of spin-orbit couplings are needed. ",https://doi.org/10.1103/PhysRevB.94.165202,1606.00588v1,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,"Proximity effects in bilayer graphene on monolayer WSe$_2$: Field-effect   spin-valley locking, spin-orbit valve, and spin transistor",1970,"  Proximity orbital and spin-orbit effects of bilayer graphene on monolayer WSe$_2$ are investigated from first-principles. We find that the built-in electric field induces an orbital band gap of about 10 meV in bilayer graphene. Remarkably, the proximity spin-orbit splitting for holes is two orders of magnitude---the spin-orbit splitting of the valence band at K is about 2 meV---more than for electrons. Effectively, holes experience spin-valley locking due to the strong proximity of the lower graphene layer to WSe$_2$. However, applying an external transverse electric field of some 1 V/nm, countering the built-in field of the heterostructure, completely reverses this effect and allows, instead for holes, electrons to be spin-valley locked with 2 meV spin-orbit splitting. Such a behavior constitutes a highly efficient field-effect spin-orbit valve, making bilayer graphene on WSe$_2$ a potential platform for a field-effect spin transistor. ",https://doi.org/10.1103/PhysRevLett.119.146401,1706.06149v1,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Engineering Proximity Exchange by Twisting: Reversal of Ferromagnetic   and Emergence of Antiferromagnetic Dirac Bands in Graphene/Cr$_2$Ge$_2$Te$_6$,1970,"  We investigate the twist-angle and gate dependence of the proximity exchange coupling in twisted graphene on monolayer Cr$_2$Ge$_2$Te$_6$ from first principles. The proximitized Dirac band dispersions of graphene are fitted to a model Hamiltonian, yielding effective sublattice-resolved proximity-induced exchange parameters ($\lambda_{\textrm{ex}}^\textrm{A}$ and $\lambda_{\textrm{ex}}^\textrm{B}$) for a series of twist angles between 0$^{\circ}$ and 30$^{\circ}$. For aligned layers (0$^{\circ}$ twist angle), the exchange coupling of graphene is the same on both sublattices, $\lambda_{\textrm{ex}}^\textrm{A} \approx \lambda_{\textrm{ex}}^\textrm{B} \approx 4$ meV, while the coupling is reversed at 30$^{\circ}$ (with $\lambda_{\textrm{ex}}^\textrm{A} \approx \lambda_{\textrm{ex}}^\textrm{B} \approx -4$ meV). Remarkably, at 19.1$^{\circ}$ the induced exchange coupling becomes antiferromagnetic: $\lambda_{\textrm{ex}}^\textrm{A} < 0, \lambda_{\textrm{ex}}^\textrm{B} > 0$. Further tuning is provided by a transverse electric field and the interlayer distance. The predicted proximity magnetization reversal and emergence of an antiferromagnetic Dirac dispersion make twisted graphene/Cr$_2$Ge$_2$Te$_6$ bilayers a versatile platform for realizing topological phases and for spintronics applications. ",https://doi.org/10.1103/PhysRevLett.128.106401,2108.03984v2,Yes,versatile(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Phonon-induced spin relaxation of conduction electrons in aluminum,1970,  Spin-flip Eliashberg function $\alpha_S^2F$ and temperature-dependent spin relaxation time $T_1(T)$ are calculated for aluminum using realistic pseudopotentials. The spin-flip electron-phonon coupling constant $\lambda_S$ is found to be $2.5\times 10^{-5}$. The calculations agree with experiments validating the Elliott-Yafet theory and the spin-hot-spot picture of spin relaxation for polyvalent metals. ,https://doi.org/10.1103/PhysRevLett.83.1211,cond-mat/9904140v1,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Theory of spin-polarized bipolar transport in magnetic p-n junctions,1970,"  The interplay between spin and charge transport in electrically and magnetically inhomogeneous semiconductor systems is investigated theoretically. In particular, the theory of spin-polarized bipolar transport in magnetic p-n junctions is formulated, generalizing the classic Shockley model. The theory assumes that in the depletion layer the nonequilibrium chemical potentials of spin up and spin down carriers are constant and carrier recombination and spin relaxation are inhibited. Under the general conditions of an applied bias and externally injected (source) spin, the model formulates analytically carrier and spin transport in magnetic p-n junctions at low bias. The evaluation of the carrier and spin densities at the depletion layer establishes the necessary boundary conditions for solving the diffusive transport equations in the bulk regions separately, thus greatly simplifying the problem. The carrier and spin density and current profiles in the bulk regions are calculated and the I-V characteristics of the junction are obtained. It is demonstrated that spin injection through the depletion layer of a magnetic p-n junction is not possible unless nonequilibrium spin accumulates in the bulk regions--either by external spin injection or by the application of a large bias. Implications of the theory for majority spin injection across the depletion layer, minority spin pumping and spin amplification, giant magnetoresistance, spin-voltaic effect, biasing electrode spin injection, and magnetic drift in the bulk regions are discussed in details, and illustrated using the example of a GaAs based magnetic p-n junction. ",https://doi.org/10.1103/PhysRevB.66.165301,cond-mat/0205340v1,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Gate-defined coupled quantum dots in topological insulators,1970,"  We consider electrostatically coupled quantum dots in topological insulators, otherwise confined and gapped by a magnetic texture. By numerically solving the (2+1) Dirac equation for the wave packet dynamics, we extract the energy spectrum of the coupled dots as a function of bias-controlled coupling and an external perpendicular magnetic field. We show that the tunneling energy can be controlled to a large extent by the electrostatic barrier potential. Particularly interesting is the coupling via Klein tunneling through a resonant valence state of the barrier. The effective three-level system nicely maps to a model Hamiltonian, from which we extract the Klein coupling between the confined conduction and valence dots levels. For large enough magnetic fields Klein tunneling can be completely blocked due to the enhanced localization of the degenerate Landau levels formed in the quantum dots. ",https://doi.org/10.1103/PhysRevB.89.075432,1310.1463v1,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Skew Andreev reflection in ferromagnet/superconductor junctions,1970,"  Andreev reflection (AR) in ferromagnet/superconductor junctions is an indispensable spectroscopic tool for measuring spin polarization. We study theoretically how the presence of a thin semiconducting interface in such junctions, inducing Rashba and Dresselhaus spin-orbit coupling, modifies AR processes. The interface gives rise to an effective momentum- and spin-dependent scattering potential, making the probability of AR strongly asymmetric with respect to the sign of the incident electrons' transverse momenta. This skew AR creates spatial charge carrier imbalances and transverse Hall currents flow in the ferromagnet. We show that the effect is giant, as compared to the normal regime. We provide a quantitative analysis and a qualitative picture of this phenomenon, and finally show that skew AR also leads to a widely tunable transverse supercurrent response in the superconductor. ",https://doi.org/10.1103/PhysRevB.100.060507,1905.12525v2,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Swapping Exchange and Spin-Orbit Coupling in 2D van der Waals   Heterostructures,1970,"  The concept of swapping the two most important spin interactions -- exchange and spin-orbit coupling -- is proposed based on two-dimensional multilayer van der Waals heterostructures. Specifically, we show by performing realistic ab initio simulations, that a single device consisting of a bilayer graphene sandwiched by a 2D ferromagnet Cr$_2$Ge$_2$Te$_6$ (CGT) and a monolayer WS$_2$, is able not only to generate, but also to swap the two interactions. The highly efficient swapping is enabled by the interplay of gate-dependent layer polarization in bilayer graphene and short-range spin-orbit and exchange proximity effects affecting only the layers in contact with the sandwiching materials. We call these structures ex-so-tic, for supplying either exchange (ex) or spin-orbit (so) coupling in a single device, by gating. Such bifunctional devices demonstrate the potential of van der Waals spintronics engineering using 2D crystal multilayers. ",https://doi.org/10.1103/PhysRevLett.125.196402,2005.11058v2,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Emergent correlated phases in rhombohedral trilayer graphene induced by   proximity spin-orbit and exchange coupling,1970,"  The impact of proximity-induced spin-orbit and exchange coupling on the correlated phase diagram of rhombohedral trilayer graphene (RTG) is investigated theoretically. By employing \emph{ab initio}-fitted effective models of RTG encapsulated by transition metal dichalcogenides (spin-orbit proximity effect) and ferromagnetic Cr$_2$Ge$_2$Te$_6$ (exchange proximity effect), we incorporate the Coulomb interactions within the random-phase approximation to explore potential correlated phases at different displacement field and doping. We find a rich spectrum of spin-valley resolved Stoner and intervalley coherence instabilities induced by the spin-orbit proximity effects, such as the emergence of a \textit{spin-valley-coherent} phase due to the presence of valley-Zeeman coupling. Similarly, proximity exchange removes the phase degeneracies by biasing the spin direction, enabling a magneto-correlation effect -- strong sensitivity of the correlated phases to the relative magnetization orientations (parallel or antiparallel) of the encapsulating ferromagnetic layers. ",https://doi.org/10.1103/PhysRevLett.132.186401,2305.14277v2,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Theory of Single Electron Spin Relaxation in Si/SiGe Lateral Coupled   Quantum Dots,1970,"  We investigate the spin relaxation induced by acoustic phonons in the presence of spin-orbit interactions in single electron Si/SiGe lateral coupled quantum dots. The relaxation rates are computed numerically in single and double quantum dots, in in-plane and perpendicular magnetic fields. The deformation potential of acoustic phonons is taken into account for both transverse and longitudinal polarizations and their contributions to the total relaxation rate are discussed with respect to the dilatation and shear potential constants. We find that in single dots the spin relaxation rate scales approximately with the seventh power of the magnetic field, in line with a recent experiment. In double dots the relaxation rate is much more sensitive to the dot spectrum structure, as it is often dominated by a spin hot spot. The anisotropy of the spin-orbit interactions gives rise to easy passages, special directions of the magnetic field for which the relaxation is strongly suppressed. Quantitatively, the spin relaxation rates in Si are typically 2 orders of magnitude smaller than in GaAs due to the absence of the piezoelectric phonon potential and generally weaker spin-orbit interactions. ",https://doi.org/10.1103/PhysRevB.83.195318,1101.3858v3,Yes,potent(3)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Magnetic properties of HgTe quantum wells,1970,"  Using analytical formulas as well as a finite-difference scheme, we investigate the magnetic field dependence of the energy spectra and magnetic edge states of HgTe/CdTe-based quantum wells in the presence of perpendicular magnetic fields and hard walls, for the band-structure parameters corresponding to the normal and inverted regimes. Whereas one cannot find counterpropagating, spin-polarized states in the normal regime, below the crossover point between the uppermost (electron-like) valence and lowest (hole-like) conduction Landau levels, one can still observe such states at finite magnetic fields in the inverted regime, although these states are no longer protected by time-reversal symmetry. Furthermore, the bulk magnetization and susceptibility in HgTe quantum wells are studied, in particular their dependence on the magnetic field, chemical potential, and carrier densities. We find that for fixed chemical potentials as well as for fixed carrier densities, the magnetization and magnetic susceptibility in both the normal and the inverted regimes exhibit de Haas-van Alphen oscillations, whose amplitude decreases with increasing temperature. Moreover, if the band structure is inverted, the ground-state magnetization (and consequently also the ground-state susceptibility) is discontinuous at the crossover point between the uppermost valence and lowest conduction Landau levels. At finite temperatures and/or doping, this discontinuity is canceled by the contribution from the electrons and holes and the total magnetization and susceptibility are continuous. In the normal regime, this discontinuity of the ground-state magnetization does not arise and the magnetization is continuous for zero as well as finite temperatures. ",https://doi.org/10.1103/PhysRevB.86.075418,1207.4578v2,Yes,potent(2)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Microscopic study of the Josephson supercurrent diode effect in   Josephson junctions based on two-dimensional electron gas,1970,"  Superconducting systems that simultaneously lack space-inversion and time-reversal symmetries have recently been the subject of a flurry of experimental and theoretical research activities. Their ability to carry supercurrents with magnitudes depending on the polarity (current direction) - termed supercurrent diode effect - might be practically exploited to design dissipationless counterparts of contemporary semiconductor-based diodes. Magnetic Josephson junctions realized in the two-dimensional electron gas (2DEG) within a narrow quantum well through proximity to conventional superconductors perhaps belong to the most striking and versatile platforms for such supercurrent rectifiers. Starting from the Bogoliubov-de Gennes approach, we provide a minimal theoretical model to explore the impact of the spin-orbit coupling and magnetic exchange inside the 2DEG on the Andreev bound states and Josephson current-phase relations. Assuming realistic junction parameters, we evaluate the polarity-dependent critical currents to quantify the efficiency of these Josephson junctions as supercurrent diodes, and discuss the tunability of the Josephson supercurrent diode effect in terms of spin-orbit coupling, magnetic exchange, and transparency of the nonsuperconducting weak link. Furthermore, we demonstrate that the junctions might undergo current-reversing $ 0 $-$ \pi $-like phase transitions at large enough magnetic exchange, which appear as sharp peaks followed by a sudden suppression in the supercurrent-diode-effect efficiency. The characteristics of the Josephson supercurrent diode effect obtained from our model convincingly reproduce many unique features observed in recent experiments, validating its robustness and suitability for further studies. ",https://doi.org/10.1103/PhysRevB.108.054522,2303.14823v2,Yes,versatile(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Electronic and Spin-Orbit Properties of hBN Encapsulated Bilayer   Graphene,1970,"  Van der Waals (vdW) heterostructures consisting of Bernal bilayer graphene (BLG) and hexagonal boron nitride (hBN) are investigated. By performing first-principles calculations we capture the essential BLG band structure features for several stacking and encapsulation scenarios. A low-energy model Hamiltonian, comprising orbital and spin-orbit coupling (SOC) terms, is employed to reproduce the hBN-modified BLG dispersion, spin splittings, and spin expectation values. Most important, the hBN layers open an orbital gap in the BLG spectrum, which can range from zero to tens of meV, depending on the precise stacking arrangement of the individual atoms. Therefore, large local band gap variations may arise in experimentally relevant moir\'{e} structures. Moreover, the SOC parameters are small (few to tens of $\mu$eV), just as in bare BLG, but are markedly proximity modified by the hBN layers. Especially when BLG is encapsulated by monolayers of hBN, such that inversion symmetry is restored, the orbital gap and spin splittings of the bands vanish. In addition, we show that a transverse electric field mainly modifies the potential difference between the graphene layers, which perfectly correlates with the orbital gap for fields up to about 1~V/nm. Moreover, the layer-resolved Rashba couplings are tunable by $\sim 5~\mu$eV per V/nm. Finally, by investigating twisted BLG/hBN structures, with twist angles between 6$^{\circ}$ -- 20$^{\circ}$, we find that the global band gap increases linearly with the twist angle. The extrapolated $0^{\circ}$ band gap is about 23~meV and results roughly from the average of the stacking-dependent local band gaps. Our investigations give new insights into proximity spin physics of hBN/BLG heterostructures, which should be useful for interpreting experiments on extended as well as confined (quantum dot) systems. ",https://doi.org/10.1103/PhysRevB.108.125126,2307.11697v2,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,"Trivial and inverted Dirac bands, and emergence of quantum spin Hall   states in graphene on transition-metal dichalcogenides",1970,"  Proximity orbital and spin-orbital effects of graphene on monolayer transition-metal dichalcogenides (TMDCs) are investigated from first-principles. The Dirac band structure of graphene is found to lie within the semiconducting gap of TMDCs for sulfides and selenides, while it merges with the valence band for tellurides. In the former case the proximity-induced staggered potential gaps and spin-orbit couplings (all on the meV scale) of the Dirac electrons are established by fitting to a phenomenological effective Hamiltonian. While graphene on MoS$_2$, MoSe$_2$, and WS$_2$ has a topologically trivial band structure, graphene on WSe$_2$ exhibits inverted bands. Using a realistic tight-binding model we find topologically protected helical edge states for graphene zigzag nanoribbons on WSe$_2$, demonstrating the quantum spin Hall effect. This model also features ""half-topological states"", which are protected against time-reversal disorder on one edge only. ",https://doi.org/10.1103/PhysRevB.93.155104,1510.00166v1,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,"Graphene on two-dimensional hexagonal BN, AlN, and GaN: Electronic,   spin-orbit, and spin relaxation properties",1970,"  We investigate the electronic structure of graphene on a series of 2D hexagonal nitride insulators hXN, X = B, Al, and Ga, with DFT calculations. A symmetry-based model Hamiltonian is employed to extract orbital parameters and spin-orbit coupling (SOC) from the low-energy Dirac bands of proximitized graphene. While commensurate hBN induces a staggered potential of about 10 meV into the Dirac bands, less lattice-matched hAlN and hGaN disrupt the Dirac point much less, giving a staggered gap below 100 $\mu$eV. Proximitized intrinsic SOC surprisingly does not increase much above the pristine graphene value of 12 $\mu$eV; it stays in the window of (1-16) $\mu$eV, depending strongly on stacking. However, Rashba SOC increases sharply when increasing the atomic number of the boron group, with calculated maximal values of 8, 15, and 65 $\mu$eV for B, Al, and Ga-based nitrides, respectively. The individual Rashba couplings also depend strongly on stacking, vanishing in symmetrically-sandwiched structures, and can be tuned by a transverse electric field. The extracted spin-orbit parameters were used as input for spin transport simulations based on Chebyshev expansion of the time-evolution of the spin expectation values, yielding interesting predictions for the electron spin relaxation. Spin lifetime magnitudes and anisotropies depend strongly on the specific (hXN)/graphene/hXN system, and they can be efficiently tuned by an applied external electric field as well as the carrier density in the graphene layer. A particularly interesting case for experiments is graphene/hGaN, in which the giant Rashba coupling is predicted to induce spin lifetimes of 1-10 ns, short enough to dominate over other mechanisms, and lead to the same spin relaxation anisotropy as observed in conventional semiconductor heterostructures: 50\%, meaning that out-of-plane spins relax twice as fast as in-plane spins. ",https://doi.org/10.1103/PhysRevB.103.075129,2011.14588v2,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Numerical study of anharmonic vibrational decay in amorphous and   paracrystalline silicon,1970,"  The anharmonic decay rates of atomic vibrations in amorphous silicon (a-Si) and paracrystalline silicon (p-Si), containing small crystalline grains embedded in a disordered matrix, are calculated using realistic structural models. The models are 1000-atom four-coordinated networks relaxed to a local minimum of the Stillinger-Weber interatomic potential. The vibrational decay rates are calculated numerically by perturbation theory, taking into account cubic anharmonicity as the perturbation. The vibrational lifetimes for a-Si are found to be on picosecond time scales, in agreement with the previous perturbative and classical molecular dynamics calculations on a 216-atom model. The calculated decay rates for p-Si are similar to those of a-Si. No modes in p-Si reside entirely on the crystalline cluster, decoupled from the amorphous matrix. The localized modes with the largest (up to 59%) weight on the cluster decay primarily to two diffusons. The numerical results are discussed in relation to a recent suggestion by van der Voort et al. [Phys. Rev. B {\bf 62}, 8072 (2000)] that long vibrational relaxation inferred experimentally may be due to possible crystalline nanostructures in some types of a-Si. ",https://doi.org/10.1103/PhysRevB.67.224302,cond-mat/0301242v1,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Van der Waals heterostructures for spintronics and opto-spintronics,1970,"  The large variety of 2D materials and their co-integration in van der Waals (vdW) heterostructures enable innovative device engineering. In addition, their atomically-thin nature promotes the design of artificial materials by proximity effects that originate from short-range interactions. Such a designer approach is particularly compelling for spintronics, which typically harnesses functionalities from thin layers of magnetic and non-magnetic materials and the interfaces between them. Here, we overview recent progress on 2D spintronics and opto-spintronics using vdW heterostructures. After an introduction to the forefront of spin transport research, we highlight the unique spin-related phenomena arising from spin-orbit and magnetic proximity effects. We further describe the ability to create multi-functional hybrid heterostructures based on vdW materials, combining spin, valley and excitonic degrees of freedom. We end with an outlook on perspectives and challenges for the design and production of ultra-compact all-2D spin devices and their potential applications in conventional and quantum technologies. ",https://doi.org/10.1038/s41565-021-00936-x,2110.09944v1,Yes,"innovative(1), potent(1)"
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Scattering-induced and highly tunable by gate damping-like spin-orbit   torque in graphene doubly proximitized by two-dimensional magnet   Cr$_2$Ge$_2$Te$_6$ and WS$_2$,1970,"  Graphene sandwiched between semiconducting monolayers of ferromagnet Cr$_2$Ge$_2$Te$_6$ and transition-metal dichalcogenide WS$_2$ acquires both spin-orbit (SO), of valley-Zeeman and Rashba types, and exchange couplings. Using first-principles combined with quantum transport calculations, we predict that such doubly proximitized graphene within van der Waals heterostructure will exhibit SO torque driven by unpolarized charge current. This system lacking spin Hall current, putatively considered to be necessary for efficient damping-like (DL) SO torque that plays a key role in magnetization switching, demonstrates how DL torque component can be generated solely by skew-scattering off spin-independent potential barrier or impurities in purely two-dimensional electronic transport due to the presence of proximity SO coupling and its spin texture tilted out-of-plane. This leads to current-driven nonequilibrium spin density emerging in all spatial directions, whose cross product with proximity magnetization yields DL SO torque, unlike the ballistic regime with no scatterers in which only field-like (FL) SO torque appears. In contrast to SO torque on conventional metallic ferromagnets in contact with three dimensional SO-coupled materials, the ratio of FL and DL torque can be tuned by more than an order of magnitude via combined top and back gates. ",https://doi.org/10.1103/PhysRevResearch.2.043057,1910.08072v3,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Counterintuitive gate dependence of weak antilocalization in bilayer   graphene/WSe$_2$ heterostructures,1970,"  Strong gate control of proximity-induced spin-orbit coupling was recently predicted in bilayer graphene/transition metal dichalcogenides (BLG/TMDC) heterostructures, as charge carriers can easily be shifted between the two graphene layers, and only one of them is in close contact to the TMDC. The presence of spin-orbit coupling can be probed by weak antilocalization (WAL) in low field magnetotransport measurements. When the spin-orbit splitting in such a heterostructure increases with the out of plane electric displacement field $\bar D$, one intuitively expects a concomitant increase of WAL visibility. Our experiments show that this is not the case. Instead, we observe a maximum of WAL visibility around $\bar D=0$. This counterintuitive behaviour originates in the intricate dependence of WAL in graphene on symmetric and antisymmetric spin lifetimes, caused by the valley-Zeeman and Rashba terms, respectively. Our observations are confirmed by calculating spin precession and spin lifetimes from an $8\times 8$ model Hamiltonian of BLG/TMDC. ",https://doi.org/10.1103/PhysRevB.105.115425,2012.05718v4,Yes,intricate(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Magneto-optical anisotropies of 2D antiferromagnetic MPX$_3$ from first   principles,1970,"  Here we systematically investigate the impact of the spin direction on the electronic and optical properties of transition metal phosphorus trichalcogenides (MPX$_3$, M=Mn, Ni, Fe; X=S, Se) exhibiting various antiferromagnetic arrangement within the 2D limit. Our analysis based on the density functional theory and versatile formalism of Bethe-Salpeter equation reveals larger exciton binding energies for MPS$_3$ (up to 1.1 eV in air) than MPSe$_3$(up to 0.8 eV in air), exceeding the values of transition metal dichalcogenides (TMDs). For the (Mn,Fe)PX$_3$ we determine the optically active band edge transitions, revealing that they are sensitive to in-plane magnetic order, irrespective of the type of chalcogen atom. We predict the anistropic effective masses and the type of linear polarization as an important fingerprints for sensing the type of magnetic AFM arrangements. Furthermore, we identify the spin-orientation-dependent features such as the valley splitting, the effective mass of holes, and the exciton binding energy. In particular, we demonstrate that for MnPX$_3$ (X=S, Se) a pair of non equivalent K+ and K- points exists yielding the valley splittings that strongly depend on the direction of AFM aligned spins. Notably, for the out-of-plane direction of spins, two distinct peaks are expected to be visible below the absorption onset, whereas one peak should emerge for the in-plane configuration of spins. These spin-dependent features provide an insight into spin flop transitions of 2D materials. Finally, we propose a strategy how the spin valley polarization can be realized in 2D AFM within honeycomb lattice. ",Kein DOI-Link verfügbar,2308.13109v1,Yes,versatile(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Signatures of superconducting triplet pairing in Ni--Ga-bilayer   junctions,1970,"  Ni-Ga bilayers are a versatile platform for exploring the competition between strongly antagonistic ferromagnetic and superconducting phases. We characterize the impact of this competition on the transport properties of highly-ballistic Al/Al2O3(/EuS)/Ni-Ga tunnel junctions from both experimental and theoretical points of view. While the conductance spectra of junctions comprising Ni (3 nm)-Ga (60 nm) bilayers can be well understood within the framework of earlier results, which associate the emerging main conductance maxima with the junction films' superconducting gaps, thinner Ni (1.6 nm)-Ga (30 nm) bilayers entail completely different physics, and give rise to novel large-bias (when compared to the superconducting gap of the thin Al film as a reference) conductance-peak subseries that we term conductance shoulders. These conductance shoulders might attract considerable attention also in similar magnetic superconducting bilayer junctions, as we predict them to offer an experimentally well-accessible transport signature of superconducting triplet pairings that are induced around the interface of the Ni-Ga bilayer. We further substantiate this claim performing complementary polarized neutron reflectometry measurements on the bilayers, from which we deduce (1) a nonuniform magnetization structure in Ga in a several nanometer-thick area around the Ni-Ga boundary and can simultaneously (2) satisfactorily fit the obtained data only considering the paramagnetic Meissner response scenario. While the latter provides independent experimental evidence of induced triplet superconductivity inside the Ni-Ga bilayer, the former might serve as the first experimental hint of its potential microscopic physical origin. ",https://doi.org/10.1088/1367-2630/ac5bbb,2102.03083v3,Yes,"versatile(1), potent(1)"
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Layer-selective spin-orbit coupling and strong correlation in bilayer   graphene,1970,"  Spin-orbit coupling (SOC) and electron-electron interaction can mutually influence each other and give rise to a plethora of intriguing phenomena in condensed matter systems. In pristine bilayer graphene, which has weak SOC, intrinsic Lifshitz transitions and concomitant van-Hove singularities lead to the emergence of many-body correlated phases. Layer-selective SOC can be proximity induced by adding a layer of tungsten diselenide (WSe2) on its one side. By applying an electric displacement field, the system can be tuned across a spectrum wherein electronic correlation, SOC, or a combination of both dominates. Our investigations reveal an intricate phase diagram of proximity-induced SOC-selective bilayer graphene. Not only does this phase diagram include those correlated phases reminiscent of SOC-free doped bilayer graphene, but it also hosts unique SOC-induced states allowing a compelling measurement of valley g-factor and a seemingly impossible correlated insulator at charge neutrality, thereby showcasing the remarkable tunability of the interplay between interaction and SOC in WSe2 enriched bilayer graphene. ",Kein DOI-Link verfügbar,2403.17140v1,Yes,intricate(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Femtosecond photo-switching of interface polaritons in black phosphorus   heterostructures,1970,"  The possibility of hybridizing collective electronic motion with mid-infrared (mid-IR) light to form surface polaritons has made van der Waals layered materials a versatile platform for extreme light confinement and tailored nanophotonics. Graphene and its heterostructures have attracted particular attention because the absence of an energy gap allows for plasmon polaritons to be continuously tuned. Here, we introduce black phosphorus (BP) as a promising new material in surface polaritonics that features key advantages for ultrafast switching. Unlike graphene, BP is a van der Waals bonded semiconductor, which enables high-contrast interband excitation of electron-hole pairs by ultrashort near-infrared (near-IR) pulses. We design a SiO$_2$/BP/SiO$_2$ heterostructure in which the surface phonon modes of the SiO$_2$ layers hybridize with surface plasmon modes in BP that can be activated by photo-induced interband excitation. Within the Reststrahlen band of SiO$_2$, the hybrid interface polariton assumes surface-phonon-like properties, with a well-defined frequency and momentum and excellent coherence. During the lifetime of the photogenerated electron-hole plasma, coherent polariton waves can be launched by a broadband mid-IR pulse coupled to the tip of a scattering-type scanning near-field optical microscopy (s-SNOM) setup. The scattered radiation allows us to trace the new hybrid mode in time, energy, and space. We find that the surface mode can be activated within ~50 fs and disappears within 5 ps, as the electron-hole pairs in BP recombine. The excellent switching contrast and switching speed, the coherence properties, and the constant wavelength of this transient mode make it a promising candidate for ultrafast nanophotonic devices. ",https://doi.org/10.1038/nnano.2016.261,1709.09846v1,Yes,versatile(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Ultralong spin lifetimes in one-dimensional semiconductor nanowires,1970,"  We experimentally demonstrate ultralong spin lifetimes of electrons in the one-dimensional (1D) quantum limit of semiconductor nanowires. Optically probing single wires of different diameters reveals an increase in the spin relaxation time by orders of magnitude as the electrons become increasingly confined until only a single 1D subband is populated. We find the observed spin lifetimes of more than $200\,\textrm{ns}$ to result from the robustness of 1D electrons against major spin relaxation mechanisms, highlighting the promising potential of these wires for long-range transport of coherent spin information. ",https://doi.org/10.1063/1.5096970,1809.08009v2,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Sign reversal of the AC and DC supercurrent diode effect and   0-$π$-like transitions in ballistic Josephson junctions,1970,"  The recent discovery of intrinsic supercurrent diode effect, and its prompt observation in a rich variety of systems, has shown that nonreciprocal supercurrents naturally emerge when both space- and time-inversion symmetries are broken. In Josephson junctions, nonreciprocal supercurrent can be conveniently described in terms of spin-split Andreev states. Here, we demonstrate a sign reversal of the supercurrent diode effect, in both its AC and DC manifestations. In particular, the AC diode effect -- i.e., the asymmetry of the Josephson inductance as a function of the supercurrent -- allows us to probe the current-phase relation near equilibrium. Using a minimal theoretical model, we can then link the sign reversal of the AC diode effect to the so-called 0-$\pi$-like transition, a predicted, but still elusive feature of multi-channel junctions. Our results demonstrate the potential of inductance measurements as sensitive probes of the fundamental properties of unconventional Josephson junctions. ",https://doi.org/10.1038/s41565-023-01451-x,2212.13460v1,Yes,potent(1)
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,Amplification of interlayer exciton emission in twisted   WSe$_2$/WSe$_2$/MoSe$_2$ heterotrilayers,1970,"  Transition metal dichalcogenide (TMDC) heterostructures have unique properties that depend on the twisting angle and stacking order of two or more monolayers. However, their practical applications are limited by the low photoluminescence yield of interlayer excitons. This limits the use of layered 2D materials as a versatile platform for developing innovative optoelectronic and spintronic devices. In this study, we report on the emission enhancement of interlayer excitons in multilayered-stacked monolayers through the fabrication of heterotrilayers consisting of WSe$_2$/WSe$_2$/MoSe$_2$ with differing twist angles. Our results show that an additional WSe$_2$ monolayer introduces new absorption pathways, leading to an improvement in the emission of interlayer excitons by more than an order of magnitude. The emission boost is affected by the twist angle, and we observe a tenfold increase in the heterotrilayer area when there is a 44$^\circ$ angle between the WSe$_2$ and MoSe$_2$ materials, as opposed to their heterobilayer counterparts. Furthermore, using density functional theory, we identify the emergence of new carrier transfer pathways in the three-layer sample which extends the current understanding of 2D semiconducting heterostructures. In addition, our research provides a viable way to significantly enhance the emission of interlayer excitons. The emission enhancement of interlayer excitons is significant not only for studying the fundamental properties of interlayer excitons, but also for enabling optoelectronic applications that utilize engineered 2D quantum materials with high luminescence yield. ",Kein DOI-Link verfügbar,2311.02509v1,Yes,"innovative(1), versatile(1)"
0000-0002-3009-4525,Jaroslav Fabian,Universität Regensburg,A Josephson junction supercurrent diode,1970,"  Transport is called nonreciprocal when not only the sign, but also the absolute value of the current, depends on the polarity of the applied voltage. It requires simultaneously broken inversion and time-reversal symmetries, e.g., by the interplay of spin-orbit coupling and magnetic field. So far, observation of nonreciprocity was always tied to resistivity, and dissipationless nonreciprocal circuit elements were elusive. Here, we engineer fully superconducting nonreciprocal devices based on highly-transparent Josephson junctions fabricated on InAs quantum wells. We demonstrate supercurrent rectification far below the transition temperature. By measuring Josephson inductance, we can link nonreciprocal supercurrent to the asymmetry of the current-phase relation, and directly derive the supercurrent magnetochiral anisotropy coefficient for the first time. A semi-quantitative model well explains the main features of our experimental data. Nonreciprocal Josephson junctions have the potential to become for superconducting circuits what $pn$-junctions are for traditional electronics, opening the way to novel nondissipative circuit elements. ",https://doi.org/10.1038/s41565-021-01009-9,2103.06984v1,Yes,potent(1)
0000-0002-3051-1325,Matthijs Pals,Universität Tübingen,A Practical Guide to Statistical Distances for Evaluating Generative   Models in Science,1970,"  Generative models are invaluable in many fields of science because of their ability to capture high-dimensional and complicated distributions, such as photo-realistic images, protein structures, and connectomes. How do we evaluate the samples these models generate? This work aims to provide an accessible entry point to understanding popular notions of statistical distances, requiring only foundational knowledge in mathematics and statistics. We focus on four commonly used notions of statistical distances representing different methodologies: Using low-dimensional projections (Sliced-Wasserstein; SW), obtaining a distance using classifiers (Classifier Two-Sample Tests; C2ST), using embeddings through kernels (Maximum Mean Discrepancy; MMD), or neural networks (Fr\'echet Inception Distance; FID). We highlight the intuition behind each distance and explain their merits, scalability, complexity, and pitfalls. To demonstrate how these distances are used in practice, we evaluate generative models from different scientific domains, namely a model of decision making and a model generating medical images. We showcase that distinct distances can give different results on similar data. Through this guide, we aim to help researchers to use, interpret, and evaluate statistical distances for generative models in science. ",Kein DOI-Link verfügbar,2403.12636v1,Yes,invaluable(1)
0000-0002-3090-4655,Frank Trixler,"Ludwig Maximilians Universität München Zentrum for Nanoscience, Ludwig-Maximilians-Universität München","Revealing the Physico-Chemical Basis of Organic Solid-Solid Wetting   Deposition: Casimir-Like Forces, Hydrophobic Collapse, and the Role of the   Zeta Potential",1970,"  Supramolecular self-assembly at the solid-solid interface enables the deposition and monolayer formation of insoluble organic semiconductors under ambient conditions. The underlying process, termed as the Organic Solid-Solid Wetting Deposition (OSWD), generates two-dimensional adsorbates directly from dispersed three-dimensional organic crystals. This straightforward process has important implications in various fields of research and technology, such as in the domains of low-dimensional crystal engineering, the chemical doping and band-gap engineering of graphene, and in the area of field-effect transistor fabrication. However, till date, lack of an in-depth understanding of the physico-chemical basis of the OSWD prevented the identification of important parameters, essential to achieve a better control of the growth of monolayers and supramolecular assemblies with defined structures, sizes, and coverage areas. Here we propose a detailed model for the OSWD, derived from experimental and theoretical results that have been acquired by using the organic semiconductor quinacridone as an example system. The model reveals the vital role of the zeta potential and includes Casimir-like fluctuation-induced forces and the effect of dewetting in hydrophobic nano-confinements. Based on our results, the OSWD of insoluble organic molecules can hence be applied to environmental friendly and low-cost dispersing agents, such as water. In addition, the model substantially enhances the ability to control the OSWD in terms of adsorbate structure and substrate coverage. ",https://doi.org/10.1021/jacs.7b10282,1901.02917v1,Yes,potent(1)
0000-0002-3090-4655,Frank Trixler,"Ludwig Maximilians Universität München Zentrum for Nanoscience, Ludwig-Maximilians-Universität München",Doping Graphene via Organic Solid-Solid Wetting Deposition,1970,"  Organic Solid-Solid Wetting Deposition (OSWD) enables the fabrication of supramolecular architectures without the need for solubility or vacuum conditions. The technique is based on a process which directly generates two-dimensional monolayers from three-dimensional solid organic powders. Consequently, insoluble organic pigments and semiconductors can be made to induce monolayer self-assembly on substrate surfaces, such as graphene and carbon nanotubes, under ambient conditions. The above factuality hence opens up the potential of the OSWD for bandgap engineering applications within the context of carbon based nanoelectronics. However, the doping of graphene via OSWD has not yet been verified, primarily owing to the fact that the classical OSWD preparation procedures do not allow for the analysis via Raman spectroscopy, one of the main techniques to determine graphene doping. Hence, here we describe a novel approach to induce OSWD on graphene leading to samples suitable for Raman spectroscopy. The analysis reveals peak shifts within the Raman spectrum of graphene, which are characteristics for p-type doping. Additional evidence for chemical doping is found via Scanning Tunneling Spectroscopy. The results open up a very easily applicable, low-cost, and eco-friendly way for doping graphene via commercially available organic pigments. ",https://doi.org/10.1016/j.carbon.2017.09.043,1709.08752v1,Yes,potent(1)
0000-0002-3102-481X,Michael Steininger,Universität Würzburg,Deep Learning for Climate Model Output Statistics,1970,"  Climate models are an important tool for the assessment of prospective climate change effects but they suffer from systematic and representation errors, especially for precipitation. Model output statistics (MOS) reduce these errors by fitting the model output to observational data with machine learning. In this work, we explore the feasibility and potential of deep learning with convolutional neural networks (CNNs) for MOS. We propose the CNN architecture ConvMOS specifically designed for reducing errors in climate model outputs and apply it to the climate model REMO. Our results show a considerable reduction of errors and mostly improved performance compared to three commonly used MOS approaches. ",Kein DOI-Link verfügbar,2012.10394v1,Yes,potent(1)
0000-0002-3102-481X,Michael Steininger,Universität Würzburg,Do Different Deep Metric Learning Losses Lead to Similar Learned   Features?,1970,"  Recent studies have shown that many deep metric learning loss functions perform very similarly under the same experimental conditions. One potential reason for this unexpected result is that all losses let the network focus on similar image regions or properties. In this paper, we investigate this by conducting a two-step analysis to extract and compare the learned visual features of the same model architecture trained with different loss functions: First, we compare the learned features on the pixel level by correlating saliency maps of the same input images. Second, we compare the clustering of embeddings for several image properties, e.g. object color or illumination. To provide independent control over these properties, photo-realistic 3D car renders similar to images in the Cars196 dataset are generated. In our analysis, we compare 14 pretrained models from a recent study and find that, even though all models perform similarly, different loss functions can guide the model to learn different features. We especially find differences between classification and ranking based losses. Our analysis also shows that some seemingly irrelevant properties can have significant influence on the resulting embedding. We encourage researchers from the deep metric learning community to use our methods to get insights into the features learned by their proposed methods. ",Kein DOI-Link verfügbar,2205.02698v1,Yes,potent(1)
0000-0002-3142-5103,Michael Adams,Karlsruhe Institut für Technologie,High-temperature thermal conductivity measurements of macro-porous   graphite,1970,"  Graphite is a unique material for high temperature applications and will likely become increasingly important as we attempt to electrify industrial applications. However, high-quality graphite can be expensive, limiting the cost-competitiveness of high-quality graphite technologies. Here, we investigate the thermal properties of low-cost, low-quality, macro-porous graphite to determine the tradeoff between cost and thermal performance. We use laser flash analysis (LFA) to measure the thermal diffusivity of graphite at high temperatures. However, due to the large pores in the graphite samples preventing uniform laser flash heating, we must apply a thick coating to achieve the required flat, parallel surfaces for LFA measurements. The presence of the coating directly impacts the measured diffusivity, not only because of the added thickness but also because of the sample/coating interface profile generated. We therefore develop a methodology based on finite element modeling of a variety of sample/coating interface profiles to extract properties of the sample. Validating the methodology against a reference sample demonstrates a mean absolute percentage error of 8.5%, with potential improvement with better sample characterization. We show low-cost, low-quality graphite has a thermal conductivity of ~10 W/m/K up to 1000$^{\circ}$C, which is an order of magnitude lower than high-quality graphite, but contributions from photon conductivity may result in higher conductivities at higher temperatures. Overall, we demonstrate an approach for measuring thermal properties of macro-porous materials at high temperatures, and apply the approach to measuring thermal conductivity of porous graphite, which will aid in the design of high-temperature systems for cost-competitive decarbonization. ",Kein DOI-Link verfügbar,2301.03440v3,Yes,potent(1)
0000-0002-3223-6937,Benedikt Tissot,Universität Konstanz,Hyperfine Structure of Transition Metal Defects in SiC,1970,"  Transition metal (TM) defects in silicon carbide (SiC) are a promising platform in quantum technology, especially because some TM defects emit in the telecom band. We develop a theory for the interaction of an active electron in the $D$-shell of a TM defect in SiC with the TM nuclear spin and derive the effective hyperfine tensor within the Kramers doublets formed by the spin-orbit coupling. Based on our theory we discuss the possibility to exchange the nuclear and electron states with potential applications for nuclear spin manipulation and long-lived nunclear-spin based quantum memories. ",https://doi.org/10.1103/PhysRevB.104.064102,2104.12351v1,Yes,potent(1)
0000-0002-3223-6937,Benedikt Tissot,Universität Konstanz,Efficient High-Fidelity Flying Qubit Shaping,1970,"  Matter qubit to traveling photonic qubit conversion is the cornerstone of numerous quantum technologies such as distributed quantum computing, as well as several quantum internet and networking protocols. We formulate a theory for stimulated Raman emission which is applicable to a wide range of physical systems including quantum dots, solid state defects, and trapped ions, as well as various parameter regimes. We find the upper bound for the photonic pulse emission efficiency of arbitrary matter qubit states for imperfect emitters and show a path forward to optimizing the fidelity. Based on these results we propose a paradigm shift from optimizing the drive to directly optimizing the temporal mode of the flying qubit using a closed-form expression. Protocols for the production of time-bin encoding and spin-photon entanglement are proposed. Furthermore, the mathematical idea to use input-output theory for pulses to absorb the dominant emission process into the coherent dynamics, followed by a non-Hermitian Schr\""odinger equation approach has great potential for studying other physical systems. ",https://doi.org/10.1103/PhysRevResearch.6.013150,2212.11202v2,Yes,potent(1)
0000-0002-3223-6937,Benedikt Tissot,Universität Konstanz,Spin Structure and Resonant Driving of Spin-1/2 Defects in SiC,1970,"  Transition metal (TM) defects in silicon carbide have favorable spin coherence properties and are suitable as quantum memory for quantum communication. To characterize TM defects as quantum spin-photon interfaces, we model defects that have one active electron with spin 1/2 in the atomic $D$ shell. The spin structure, as well as the magnetic and optical resonance properties of the active electron emerge from the interplay of the crystal potential and spin-orbit coupling and are described by a general model derived using group theory. We find that the spin-orbit coupling leads to additional allowed transitions and a modification of the $g$-tensor. To describe the dependence of the Rabi frequency on the magnitude and direction of the static and driving fields, we derive an effective Hamiltonian. This theoretical description can also be instrumental to perform and optimize spin control in TM defects. ",https://doi.org/10.1103/PhysRevB.103.064106,2011.09987v1,Yes,potent(1)
0000-0002-3223-6937,Benedikt Tissot,Universität Konstanz,Extended spin relaxation times of optically addressed telecom defects in   silicon carbide,1970,"  Optically interfaced solid-state defects are promising candidates for quantum communication technologies. The ideal defect system would feature bright telecom emission, long-lived spin states, and a scalable material platform, simultaneously. Here, we employ one such system, vanadium (V4+) in silicon carbide (SiC), to establish a potential telecom spin-photon interface within a mature semiconductor host. This demonstration of efficient optical spin polarization and readout facilitates all optical measurements of temperature-dependent spin relaxation times (T1). With this technique, we lower the temperature from about 2K to 100 mK to observe a remarkable four-orders-of-magnitude increase in spin T1 from all measured sites, with site-specific values ranging from 57 ms to above 27 s. Furthermore, we identify the underlying relaxation mechanisms, which involve a two-phonon Orbach process, indicating the opportunity for strain-tuning to enable qubit operation at higher temperatures. These results position V4+ in SiC as a prime candidate for scalable quantum nodes in future quantum networks. ",Kein DOI-Link verfügbar,2405.16303v1,Yes,potent(1)
0000-0002-3231-3330,Michael Kuron,Universität Stuttgart,ESPResSo 4.0 -- An Extensible Software Package for Simulating Soft   Matter Systems,1970,"  ESPResSo 4.0 is an extensible simulation package for research on soft matter. This versatile molecular dynamics program was originally developed for coarse-grained simulations of charged systems Limbach et al., Comput. Phys. Commun. 174, 704 (2006). The scope of the software has since broadened considerably: ESPResSo can now be used to simulate systems with length scales spanning from the molecular to the colloidal. Examples include, self-propelled particles in active matter, membranes in biological systems, and the aggregation of soot particles in process engineering. ESPResSo also includes solvers for hydrodynamic and electrokinetic problems, both on the continuum and on the explicit particle level. Since our last description of version 3.1 Arnold et al., Meshfree Methods for Partial Differential Equations VI, Lect. Notes Comput. Sci. Eng. 89, 1 (2013), the software has undergone considerable restructuring. The biggest change is the replacement of the Tcl scripting interface with a much more powerful Python interface. In addition, many new simulation methods have been implemented. In this article, we highlight the changes and improvements made to the interface and code, as well as the new simulation techniques that enable a user of ESPResSo 4.0 to simulate physics that is at the forefront of soft matter research. ",https://doi.org/10.1140/epjst/e2019-800186-9,1811.07729v1,Yes,versatile(1)
0000-0002-3240-0952,Rebecca Bernemann,Universität Duisburg-Essen,Stochastic Decision Petri Nets,1970,"  We introduce stochastic decision Petri nets (SDPNs), which are a form of stochastic Petri nets equipped with rewards and a control mechanism via the deactivation of controllable transitions. Such nets can be translated into Markov decision processes (MDPs), potentially leading to a combinatorial explosion in the number of states due to concurrency. Hence we restrict ourselves to instances where nets are either safe, free-choice and acyclic nets (SAFC nets) or even occurrence nets and policies are defined by a constant deactivation pattern. We obtain complexity-theoretic results for such cases via a close connection to Bayesian networks, in particular we show that for SAFC nets the question whether there is a policy guaranteeing a reward above a certain threshold is $\mathsf{NP}^\mathsf{PP}$-complete. We also introduce a partial-order procedure which uses an SMT solver to address this problem. ",Kein DOI-Link verfügbar,2303.13344v1,Yes,potent(1)
0000-0002-3268-2013,Tobias Ludwig,Technische Universität Kaiserslautern,Independent components of human brain morphology,1970,"  Quantification of brain morphology has become an important cornerstone in understanding brain structure. Measures of cortical morphology such as thickness and surface area are frequently used to compare groups of subjects or characterise longitudinal changes. However, such measures are often treated as independent from each other.   A recently described scaling law, derived from a statistical physics model of cortical folding, demonstrates that there is a tight covariance between three commonly used cortical morphology measures: cortical thickness, total surface area, and exposed surface area.   We show that assuming the independence of cortical morphology measures can hide features and potentially lead to misinterpretations. Using the scaling law, we account for the covariance between cortical morphology measures and derive novel independent measures of cortical morphology. By applying these new measures, we show that new information can be gained; in our example we show that distinct morphological alterations underlie healthy ageing compared to temporal lobe epilepsy, even on the coarse level of a whole hemisphere.   We thus provide a conceptual framework for characterising cortical morphology in a statistically valid and interpretable manner, based on theoretical reasoning about the shape of the cortex. ",Kein DOI-Link verfügbar,2003.10514v1,Yes,potent(1)
0000-0002-3339-1760,Jan Laufer,Universität Duisburg-Essen,An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of   Service-oriented Systems,1970,"  Deep Reinforcement Learning (Deep RL) is increasingly used to cope with the open-world assumption in service-oriented systems. Deep RL was successfully applied to problems such as dynamic service composition, job scheduling, and offloading, as well as service adaptation. While Deep RL offers many benefits, understanding the decision-making of Deep RL is challenging because its learned decision-making policy essentially appears as a black box. Yet, understanding the decision-making of Deep RL is key to help service developers perform debugging, support service providers to comply with relevant legal frameworks, and facilitate service users to build trust. We introduce Chat4XAI to facilitate the understanding of the decision-making of Deep RL by providing natural-language explanations. Compared with visual explanations, the reported benefits of natural-language explanations include better understandability for non-technical users, increased user acceptance and trust, as well as more efficient explanations. Chat4XAI leverages modern AI chatbot technology and dedicated prompt engineering. Compared to earlier work on natural-language explanations using classical software-based dialogue systems, using an AI chatbot eliminates the need for eliciting and defining potential questions and answers up-front. We prototypically realize Chat4XAI using OpenAI's ChatGPT API and evaluate the fidelity and stability of its explanations using an adaptive service exemplar. ",Kein DOI-Link verfügbar,2309.14391v1,Yes,potent(1)
0000-0002-3364-1897,Michael Vogel,Universität Siegen,Particle rearrangements during transitions between local minima of the   potential energy landscape of a supercooled Lennard-Jones liquid,1970,"  The potential energy landscape (PEL) of supercooled binary Lennard-Jones (BLJ) mixtures exhibits local minima, or inherent structures (IS), which are organized into meta-basins (MB). We study the particle rearrangements related to transitions between both successive IS and successive MB for a small 80:20 BLJ system near the mode-coupling temperature T_MCT. The analysis includes the displacements of individual particles, the localization of the rearrangements and the relevance of string-like motion. We find that the particle rearrangements during IS and MB transitions do not change significantly at T_MCT. Further, it is demonstrated that IS and MB dynamics are spatially heterogeneous and facilitated by string-like motion. To investigate the mechanism of string-like motion, we follow the particle rearrangements during suitable sequences of IS transitions. We find that most strings observed after a series of transitions do not move coherently during a single transition, but subunits of different sizes are active at different times. Several findings suggest that the occurrence of a successful string enables the system to exit a MB. Moreover, we show that the particle rearrangements during two consecutive MB transitions are basically uncorrelated. Specifically, different groups of particles are highly mobile during subsequent MB transitions. Finally, the relation between the features of the PEL and the relaxation processes in supercooled liquids is discussed. ",https://doi.org/10.1063/1.1644538,cond-mat/0309153v1,Yes,potent(1)
0000-0002-3364-1897,Michael Vogel,Universität Siegen,Tuning edge localized spin waves in magnetic microstripes by proximate   magnetic structures,1970,"  The propagation of edge localized spin waves (E-SWs) in yttrium iron garnet (YIG) microstripes with/without the proximate magnetic microstructures is investigated by micromagnetic simulations. A splitting of the dispersion curve with the presence of permalloy (Py) stripe is also observed. The E-SWs on the two edges of YIG stripe have different wavelengths, group velocities, and decay lengths at the same frequencies. The role of the Py stripe was found to be the source of the inhomogeneous static dipolar field without dynamic coupling with YIG. This work opens new perspectives for the design of innovative SW interference-based logic devices. ",https://doi.org/10.1103/PhysRevB.100.174434,1907.06718v1,Yes,innovative(1)
0000-0002-3364-1897,Michael Vogel,Universität Siegen,Spin-Wave frequency division multiplexing in an yttrium iron garnet   microstripe magnetized by inhomogeneous field,1970,"  Spin waves are promising candidates for information processing and transmission in a broad frequency range. In the realization of magnonic devices, the frequency depended division of the spin wave frequencies is a critical function for parallel information processing. In this work, we demonstrate a proof-of-concept spin-wave frequency division multiplexing method by magnetizing a homogenous magnetic microstripe with an inhomogeneous field. The symmetry breaking additional field is introduced by a permalloy stripe simply placed in lateral proximity to the waveguide. Spin waves with different frequencies can propagate independently, simultaneously and separately in space along the shared waveguide. This work brings new potentials for parallel information transmission and processing in magnonics. ",https://doi.org/10.1063/1.5127881,1910.07136v1,Yes,potent(1)
0000-0002-3402-3724,Michael Schmitz,RWTH Aachen Universität,Raman spectroscopy as probe of nanometer-scale strain variations in   graphene,1970,"  Confocal Raman spectroscopy is a versatile, non-invasive investigation tool and a major workhorse for graphene characterization. Here we show that the experimentally observed Raman 2D line width is a measure of nanometer-scale strain variations in graphene. By investigating the relation between the G and 2D line at high magnetic fields we find that the 2D line width contains valuable information on nanometer-scale flatness and lattice deformations of graphene, making it a good quantity for classifying the structural quality of graphene even at zero magnetic field. ",https://doi.org/10.1038/ncomms9429,1406.7771v2,Yes,versatile(1)
0000-0002-3454-1804,Thomas Rung,Hamburg Universität für Technologie,Adjoint-based Shape Optimization for the Minimization of Flow-induced   Hemolysis in Biomedical Applications,1970,"  This paper reports on the derivation and implementation of a shape optimization procedure for the minimization of hemolysis induction in biomedical devices. Hemolysis is a blood damaging phenomenon that may occur in mechanical blood-processing applications where large velocity gradients are found. An increased level of damaged blood can lead to deterioration of the immune system and quality of life. It is, thus, important to minimize flow-induced hemolysis by improving the design of next-generation biomedical machinery. Emphasis is given to the formulation of a continuous adjoint complement to a power-law hemolysis prediction model dedicated to efficiently identifying the shape sensitivity to hemolysis. The computational approach is verified against the analytical solutions of a benchmark problem and computed sensitivity derivatives are validated by a finite differences study on a generic 2D stenosed geometry. The application included addresses a 3D ducted geometry which features typical characteristics of biomedical devices. An optimized shape, leading to a potential improvement in hemolysis induction up to 22%, is identified. It is shown, that the improvement persists for different, literature-reported hemolysis-evaluation parameters. ",Kein DOI-Link verfügbar,2101.10715v1,Yes,potent(1)
0000-0002-3454-1804,Thomas Rung,Hamburg Universität für Technologie,Parameter-free shape optimization: various shape updates for engineering   applications,1970,"  In the last decade, parameter-free approaches to shape optimization problems have matured to a state where they provide a versatile tool for complex engineering applications. However, sensitivity distributions obtained from shape derivatives in this context cannot be directly used as a shape update in gradient-based optimization strategies. Instead, an auxiliary problem has to be solved to obtain a gradient from the sensitivity. While several choices for these auxiliary problems were investigated mathematically, the complexity of the concepts behind their derivation has often prevented their application in engineering. This work aims at an explanation of several approaches to compute shape updates from an engineering perspective. We introduce the corresponding auxiliary problems in a formal way and compare the choices by means of numerical examples. To this end, a test case and exemplary applications from computational fluid dynamics are considered. ",https://doi.org/10.3390/aerospace10090751,2302.12100v1,Yes,versatile(1)
0000-0002-3470-6429,Maximilian Kloock,RWTH Aachen Universität,A Survey on Small-Scale Testbeds for Connected and Automated Vehicles   and Robot Swarms,1970,"  Connected and automated vehicles and robot swarms hold transformative potential for enhancing safety, efficiency, and sustainability in the transportation and manufacturing sectors. Extensive testing and validation of these technologies is crucial for their deployment in the real world. While simulations are essential for initial testing, they often have limitations in capturing the complex dynamics of real-world interactions. This limitation underscores the importance of small-scale testbeds. These testbeds provide a realistic, cost-effective, and controlled environment for testing and validating algorithms, acting as an essential intermediary between simulation and full-scale experiments. This work serves to facilitate researchers' efforts in identifying existing small-scale testbeds suitable for their experiments and provide insights for those who want to build their own. In addition, it delivers a comprehensive survey of the current landscape of these testbeds. We derive 62 characteristics of testbeds based on the well-known sense-plan-act paradigm and offer an online table comparing 22 small-scale testbeds based on these characteristics. The online table is hosted on our designated public webpage www.cpm-remote.de/testbeds, and we invite testbed creators and developers to contribute to it. We closely examine nine testbeds in this paper, demonstrating how the derived characteristics can be used to present testbeds. Furthermore, we discuss three ongoing challenges concerning small-scale testbeds that we identified, i.e., small-scale to full-scale transition, sustainability, and power and resource management. ",https://doi.org/10.13140/RG.2.2.16176.74248/1,2408.14199v1,Yes,potent(1)
0000-0002-3537-5019,Christopher Strothmann,Technische Universität Dortmund,Stochastic monotonicity and the Markov product for copulas,1970,"  Given two random variables $X$ and $Y$, stochastic monotonicity describes a monotone influence of $X$ on $Y$. We prove two different characterizations of stochastically monotone $2$-copulas using the isomorphism between $2$-copulas and Markov operators. The first approach establishes a one-to-one correspondence between stochastically monotone copulas and monotonicity-preserving Markov operators. The second approach characterizes stochastically monotone copulas by their monotonicity property with respect to the Markov product. Applying the latter result, we identify all idempotent stochastically monotone copulas as ordinal sums of the independence copula $\Pi$. ",https://doi.org/10.1016/j.jmaa.2021.125348,2012.08324v2,Yes,potent(1)
0000-0002-3537-5019,Christopher Strothmann,Technische Universität Dortmund,A Markov product for tail dependence functions,1970,"  We introduce a Markov product structure for multivariate tail dependence functions, building upon the well-known Markov product for copulas. We investigate algebraic and monotonicity properties of this new product as well as its role in describing the tail behaviour of the Markov product of copulas. For the bivariate case, we show additional smoothing properties and derive a characterization of idempotents together with the limiting behaviour of n-fold iterations. Finally, we establish a one-to-one correspondence between bivariate tail dependence functions and a class of positive, substochastic operators. These operators are contractions both on $L^1(\mathbb{R}_+)$ and $L^\infty(\mathbb{R}_+)$ and constitute a natural generalization of Markov operators. ",https://doi.org/10.1016/j.jmaa.2021.124942,2003.09636v2,Yes,potent(1)
0000-0002-3542-2583,Niko Zielinski,Kiel Universität,Magnetic field structure of OMC-3 in the far infrared revealed by   SOFIA/HAWC+,1970,"  We report the SOFIA/HAWC+ band D (154$\,\mu$m) and E (214$\,\mu$m) polarimetric observations of the filamentary structure OMC-3 that is part of the Orion molecular cloud. The polarization pattern is uniform for both bands and parallel to the filament structure. The polarization degree decreases toward regions with high intensity for both bands, revealing a so called ""polarization hole."" We identified an optical depth effect in which polarized emission and extinction act as counteracting mechanisms as a potential contributor to this phenomenon. Assuming that the detected polarization is caused by the emission of magnetically aligned non-spherical dust grains, the inferred magnetic field is uniform and oriented perpendicular to the filament. The magnetic field strength derived from the polarization patterns at 154$\,\mu$m and 214$\,\mu$m amounts to 202$\,\mu$G and 261$\,\mu$G, respectively. The derived magnetic field direction is consistent with that derived from previous polarimetric observations in the far infrared and submillimeter (submm) wavelength range. Investigating the far-infrared polarization spectrum derived from the SOFIA/HAWC+ observations, we do not find a clear correlation between the polarization spectrum and cloud properties, namely, the column density, $N(H_2$), and temperature, $T$. ",https://doi.org/10.1051/0004-6361/202141537,2111.10252v1,Yes,potent(1)
0000-0002-3644-1233,Kirankumar Karkihalli Umesh,Rheinische Friedrich-Wilhelms-Universität Bonn,Compressibility and the Equation of State of an Optical Quantum Gas in a   Box,1970,"  The compressibility of a medium, quantifying its response to mechanical perturbations, is a fundamental property determined by the equation of state. For gases of material particles, studies of the mechanical response are well established, in fields from classical thermodynamics to cold atomic quantum gases. Here we demonstrate a measurement of the compressibility of a two-dimensional quantum gas of light in a box potential and obtain the equation of state for the optical medium. The experiment is carried out in a nanostructured dye-filled optical microcavity. We observe signatures of Bose-Einstein condensation at high phase-space densities in the finite-size system. Strikingly, upon entering the quantum degenerate regime, the measured density response to an external force sharply increases, hinting at the peculiar prediction of an infinite compressibility of the deeply degenerate Bose gas. ",https://doi.org/10.1126/science.abm2543,2112.12787v1,Yes,potent(1)
0000-0002-3644-1233,Kirankumar Karkihalli Umesh,Rheinische Friedrich-Wilhelms-Universität Bonn,Dimensional Crossover in a Quantum Gas of Light,1970,"  The dimensionality of a system profoundly influences its physical behaviour, leading to the emergence of different states of matter in many-body quantum systems. In lower dimensions, fluctuations increase and lead to the suppression of long-range order. For example, in bosonic gases, Bose-Einstein condensation (BEC) in one dimension requires stronger confinement than in two dimensions. We experimentally study the properties of a harmonically trapped photon gas undergoing Bose-Einstein condensation along the dimensional crossover from one to two dimensions. The photons are trapped in a dye microcavity where polymer nanostructures provide the trapping potential for the photon gas. By varying the aspect ratio of the harmonic trap, we tune from an isotropic two-dimensional confinement to an anisotropic, highly elongated one-dimensional trapping potential. Along this transition we determine the caloric properties of the photon gas and find a softening of the second-order Bose-Einstein condensation phase transition observed in two dimensions to a crossover behaviour in one dimension. ",Kein DOI-Link verfügbar,2311.10485v2,Yes,potent(2)
0000-0002-3657-7042,Nicolas Vogt,Karlsruher Institut für Technologie,Depinning of disordered bosonic chains,1970,"  We consider one-dimensional bosonic chains with a repulsive boson-boson interaction that decays exponentially on large length-scales. This model describes transport of Cooper-pairs in a Josepshon junction array, or transport of magnetic flux quanta in quantum-phase-slip ladders, i.e. arrays of superconducting wires in a ladder-configuration that allow for the coherent tunnelling of flux quanta. In the low-frequency, long wave-length regime these chains can be mapped to an effective model of a one-dimensional elastic field in a disordered potential. The onset of transport in these systems, when biased by external voltage, is described by the standard depinning theory of elastic media in disordered pinning potentials. We numerically study the regimes that are of relevance for quantum-phase-slip ladders. These are (i) very short chains and (ii) the regime of weak disorder. For chains shorter than the typical pinning length, i.e., the Larkin length, the chains reach a saturation regime where the depinning voltage does not depend on the decay length of the repulsive interaction. In the regime of weak disorder we find an emergent correlation length-scale that depends on the disorder strength. For arrays shorter than this length the onset of transport is similar to the clean arrays, i.e., is due to the penetration of solitons into the array. We discuss the depinning scenarios for longer arrays in this regime. ",https://doi.org/10.1088/1367-2630/18/5/053026,1510.01383v1,Yes,potent(2)
0000-0002-3714-6885,Nazmul Hasan,Martin-Luther-Universität Halle-Wittenberg,Ferromagnetic Semiconductors and Spintronic Devices,1970,"  Ferromagnetic semiconductors play a crucial role in spintronic devices, enabling effective control of electron spin over charge. This study explores their unique properties, ongoing advancements in spin control, and potential integration into next-generation semiconductor technologies. ",Kein DOI-Link verfügbar,2401.17554v1,Yes,potent(1)
0000-0002-3714-6885,Nazmul Hasan,Martin-Luther-Universität Halle-Wittenberg,"Structural, elastic and optoelectronic properties of inorganic cubic   FrBX3 (B = Ge, Sn; X = Cl, Br, I) perovskite: the density functional theory   approach",1970,"  Inorganic metal-halide cubic perovskite semiconductors have become more popular in industrial applications of photovoltaic and optoelectronic devices. Among various perovskites, lead-free materials are currently most explored due to their non-toxic effect on the environment. In this study, the structural, electronic, optical, and mechanical properties of lead-free cubic perovskite materials FrBX3 (B = Ge, Sn; X = Cl, Br, I) are investigated through first-principles density-functional theory (DFT) calculations. These materials are found to exhibit semiconducting behavior with direct bandgap energy and mechanical phase stability. The observed variation in the bandgap is explained based on the substitutions of cations and anions sitting over B and X-sites of the FrBX3 compounds. The high absorption coefficient, low reflectivity, and high optical conductivity make these materials suitable for photovoltaic and other optoelectronic device applications. It is observed that the material containing Ge (germanium) in the B-site has higher optical absorption and conductivity than Sn containing materials. A systematic analysis of the electronic, optical, and mechanical properties suggests that among all the perovskite materials, FrGeI3 would be a potential candidate for optoelectronic applications. The radioactive element Fr-containing perovskite FrGeI3 may have applications in nuclear medicine and diagnosis such as X-ray imaging technology. ",https://doi.org/10.1039/d2ra00546h,2203.08754v1,Yes,potent(1)
0000-0002-3714-6885,Nazmul Hasan,Martin-Luther-Universität Halle-Wittenberg,Investigation of Minerals Using Hyperspectral Satellite Imagery in   Bangladesh,1970,"  Mineral identification using remote sensing technologies is becoming more dominant in this field since it saves time by demonstrating a more effective way for land resources survey. In such remote sensing technologies, hyperspectral remote sensing (HSRS) technology has increased gradually for its efficient manner. This technology is usually used from an airborne platform, i.e., satellite. Hence, satellite imagery remote sensing technology is now more capable of providing accuracy in mineral identification, and mapping. Hyperspectral satellite imagery can identify minerals more accurately compared to traditional technologies in remote sensing by constructing a complete reflectance of the spectrum from each pixel with its advanced imaging sensor. Bangladesh is a developing country with an area of 1,50,000 square kilometers located in Southeast Asia. Though it is a small country, it is enriched with several mineral resources through rivers, forests, hills, and the Bay of Bengal. In this study, hyperspectral imaging technology is employed on some major identical areas (Maheshkhali, Netrokona, Panchagarh, and Patuakhali) of Bangladesh to identify minerals there. As there are no studies done in Bangladesh using hyperspectral imaging yet, it is a good opportunity to explore the potentiality of HS imagery in this field. In this study, the FLAASH (Fast Line-of-sight Atmospheric Analysis) module with necessary parameter settings is used to filter the data, and finally, mineral identification is done by the spectral matched filtering method. Our investigation resulted in finding some potential minerals in those areas including Stariolite, Diasphore, Zircon, Alunite, Quartz, and so on. This indicates that there still is enormous potential for further exploration of minerals in Bangladesh by Hyperspectral Satellite Imagery. ",Kein DOI-Link verfügbar,2212.04468v1,Yes,potent(3)
0000-0002-3714-6885,Nazmul Hasan,Martin-Luther-Universität Halle-Wittenberg,Incorporating Multi-Agent Systems Technology in Power and Energy Systems   of Bangladesh: A Feasibility Study,1970,"  The power sector of Bangladesh is presently experiencing essential changes as demand for power services is increasing with rising population and economic development. With a gradual shift from a rigidly centralized structure to a more decentralized and fluid setup, fundamentally because of the enormous advancement of distributed renewable energy sources, the future power system of the nation requires new control strategies to work efficiently and sustainably in the face of evolving conditions and constraints. Multi-Agent Systems (MAS) technology has attributes that meet these prerequisites of modern power systems and has been shown to be effective in dealing with its distributed and complex nature. This is a literature-based feasibility study to explore whether MAS technology is suited to be applied in the context of Bangladesh. For this preliminary paper, we look at the topic from a holistic perspective and conduct a meta-review to curate common applications of Multi-Agent System-based concepts, tools and algorithms on the power and energy sector. We also identify the top challenges of this domain in Bangladesh and connect the potential MAS-based solutions to address each challenge. Our qualitative assessment is motivated to provide a starting point for local researchers eager to experiment with MAS technology for application in Bangladesh. ",Kein DOI-Link verfügbar,2203.08760v1,Yes,potent(1)
0000-0002-3740-5197,Markus Gallei,Universität des Saarlandes,Solvent-Free High-Temperature Capillary Stamping of Stimuli-Responsive   Polymers: Wettability Management by Orthogonal Substrate Functionalization,1970,"  The wettability of surfaces determines their antifouling, antifogging, anti-icing, and self-cleaning properties as well as their usability for sensing, oil-water separation, water collection, and water purification. Solvent-free high-temperature capillary stamping of stimuli-responsive polymers yielding arrays of stimuli-responsive polymer microdots on differently modified substrates enables the flexible generation of switchable surfaces with different water contact angles (WCAs). Potential problems associated with the deposition of polymer solutions, such as the handling of volatile organic solvents, phase separation induced by solvent evaporation, and capillarity-driven flow processes, are circumvented. We used composite stamps with topographically patterned contact surfaces consisting of metallic nickel cores and porous MnO2 coatings taking up the stimuli-responsive polymers. The short transport paths from the MnO2 contact layers to the counterpart substrates enabled the stamping of polymer melts containing components impeding flow, such as carbon nanotubes (CNTs). Thus-obtained arrays of polymer-CNT hybrid microdots prevent problems associated with continuous coatings including delamination and crack propagation. Moreover, the range within which the properties of the stamped stimuli-responsive polymer microdots are switchable can be tuned by orthogonal substrate modification. As an example, we stamped hybrid microdots consisting of poly(2-(methacryloyloxy)ethyl ferrocenecarboxylate) (PFcMA) and CNTs onto indium tin oxide (ITO) substrates. Coating the ITO substrates with a poly(ethylene oxide)-terminated silane shifted the WCAs obtained by switching the PFcMA between its oxidized and reduced states by nearly 50{\deg}. ",https://doi.org/10.1021/acsapm.3c01036,2401.14974v1,Yes,potent(1)
0000-0002-3773-6623,Christian Hirsch,Universität Leipzig,On the topology of higher-order age-dependent random connection models,1970,"  In this paper, we investigate the potential of the age-dependent random connection model (ADRCM) with the aim of representing higher-order networks. A key contribution of our work are probabilistic limit results in large domains. More precisely, we first prove that the higher-order degree distributions have a power-law tail. Second, we establish central limit theorems for the edge counts and Betti numbers of the ADRCM in the regime where the degree distribution is light tailed. Moreover, in the heavy-tailed regime, we prove that asymptotically, the recentered and suitably rescaled edge counts converge to a stable distribution. We also propose a modification of the ADRCM in the form of a thinning procedure that enables independent adjustment of the power-law exponents for vertex and edge degrees. To apply the derived theorems to finite networks, we conduct a simulation study illustrating that the power-law degree distribution exponents approach their theoretical limits for large networks. It also indicates that in the heavy-tailed regime, the limit distribution of the recentered and suitably rescaled Betti numbers is stable. We demonstrate the practical application of the theoretical results to real-world datasets by analyzing scientific collaboration networks based on data from arXiv. ",Kein DOI-Link verfügbar,2309.11407v1,Yes,potent(1)
0000-0002-3773-6623,Christian Hirsch,Universität Leipzig,Large deviations in the quantum quasi-1D jellium,1970,"  Wigner's jellium is a model for a gas of electrons. The model consists of $N$ unit negatively charged particles lying in a sea of neutralizing homogeneous positive charge spread out according to Lebesgue measure, and interactions are governed by the Coulomb potential. In this work we consider the quantum jellium on quasi-one-dimensional spaces with Maxwell-Boltzmann statistics. Using the Feynman-Kac representation, we replace particle locations with Brownian bridges. We then adapt the approach of Lebl\'e and Serfaty (2017) to prove a process-level large deviation principle for the empirical fields of the Brownian bridges. ",https://doi.org/10.2140/pmp.2022.3.381,2009.14144v2,Yes,potent(1)
0000-0002-3773-6623,Christian Hirsch,Universität Leipzig,Percolation and connection times in multi-scale dynamic networks,1970,"  We study the effects of mobility on two crucial characteristics in multi-scale dynamic networks: percolation and connection times. Our analysis provides insights into the question, to what extent long-time averages are well-approximated by the expected values of the corresponding quantities, i.e., the percolation and connection probabilities. In particular, we show that in multi-scale models, strong random effects may persist in the limit. Depending on the precise model choice, these may take the form of a spatial birth-death process or a Brownian motion. Despite the variety of structures that appear in the limit, we show that they can be tackled in a common framework with the potential to be applicable more generally in order to identify limits in dynamic spatial network models going beyond the examples considered in the present work. ",Kein DOI-Link verfügbar,2103.03171v1,Yes,potent(1)
0000-0002-3773-6623,Christian Hirsch,Universität Leipzig,Large deviations in relay-augmented wireless networks,1970,"  We analyze a model of relay-augmented cellular wireless networks. The network users, who move according to a general mobility model based on a Poisson point process of continuous trajectories in a bounded domain, try to communicate with a base station located at the origin. Messages can be sent either directly or indirectly by relaying over a second user. We show that in a scenario of an increasing number of users, the probability that an atypically high number of users experiences bad quality of service over a certain amount of time, decays at an exponential speed. This speed is characterized via a constrained entropy minimization problem. Further, we provide simulation results indicating that solutions of this problem are potentially non-unique due to symmetry breaking. Also two general sources for bad quality of service can be detected, which we refer to as isolation and screening. ",Kein DOI-Link verfügbar,1510.04146v2,Yes,potent(1)
0000-0002-3835-4870,Hannes Albers,Universität Bremen,Modeling the Magnetization Dynamics for Large Ensembles of Immobilized   Magnetic Nanoparticles in Multi-dimensional Magnetic Particle Imaging,1970,"  Magnetic nanoparticles (MNPs) play an important role in biomedical applications including imaging modalities such as MRI and magnetic particle imaging (MPI). The latter one exploits the non-linear magnetization response of a large ensemble of magnetic nanoparticles to magnetic fields which allows determining the spatial distribution of the MNP concentration from measured voltage signals. Currently, modeling the voltage signals of large ensembles of MNPs in an MPI environment is not yet accurately possible, especially for liquid tracers in multi-dimensional magnetic excitation fields. Thus, the voltage-to-image mapping is still obtained in a time consuming calibration procedure. While the ferrofluidic case can be seen as the typical setting, more recently immobilized and potentially oriented MNPs have received considerable attention. By aligning the particles during immobilization, one can encode the angle of the easy axis into the magnetization response providing a sophisticated benchmark system for model-based approaches. In this work, we address the modeling problem for immobilized, oriented MNPs in the context of MPI. We investigate a model-based approach where the magnetization response is simulated by a N\'eel rotation model for the particle's magnetic moments and the ensemble magnetization is obtained by solving a Fokker-Planck equation approach. Since the parameters of the model are a-priori unknown, we investigate different methods for performing a parameter identification and discuss two models: One where a single function vector is used from the space spanned by the model parameters and another where a superposition of function vectors is considered. We show that our model can much more accurately reproduce the orientation dependent signal response when compared to the equilibrium model, which marks the current state-of-the-art for model-based system matrix simulations in MPI. ",https://doi.org/10.1016/j.jmmm.2021.168534,2106.08040v1,Yes,potent(1)
0000-0002-3871-4995,Jimin Wang,Universität Regensburg,Baryogenesis via QCD preheating with nonadiabatic baryon chemical   potential,1970,"  The chiral phase transition in QCD can be supercooled in the thermal history of the universe to be instantaneously out-of equilibrium, if QCD is coupled to a dark QCD sector exhibiting the dark chiral phase transition of the first order. In that case the QCD sigma meson field (as the chiral order parameter, or the light quark condensate) starts to roll in a nonadiabatic way down to the true QCD vacuum. Meanwhile a dynamic baryonic chemical potential can be generated solely within QCD, which is governed by the dynamic motion of the QCD sigma meson field, analogously to the spontaneous baryogenesis or the leptogenesis via the Higgs or axionlike relaxation scenario. When QCD is further allowed to communicate with a dark fermion with mass of order of 1 GeV and the baryon number violating coupling to neutron, the nonadiabatic QCD sigma motion along with the nonadiabatic baryon chemical potential can trigger the preheating and produce the baryon number asymmetry. We discuss this scenario in details to find that the QCD-induced dynamic baryon chemical potential plays a significant role for the QCD preheating and the baryogenesis, which yields the desired amount of the asymmetry today consistently with current astrophysical, cosmological, and terrestrial experimental constraints. Cosmological and phenomenological consequences characteristic to the present scenario are also addressed. ",Kein DOI-Link verfügbar,2406.03261v4,Yes,potent(3)
0000-0002-3881-5462,Tobias Hartl,Universität zu Köln,Macroeconomic Forecasting with Fractional Factor Models,1970,"  We combine high-dimensional factor models with fractional integration methods and derive models where nonstationary, potentially cointegrated data of different persistence is modelled as a function of common fractionally integrated factors. A two-stage estimator, that combines principal components and the Kalman filter, is proposed. The forecast performance is studied for a high-dimensional US macroeconomic data set, where we find that benefits from the fractional factor models can be substantial, as they outperform univariate autoregressions, principal components, and the factor-augmented error-correction model. ",Kein DOI-Link verfügbar,2005.04897v1,Yes,potent(1)
0000-0002-3881-5462,Tobias Hartl,Universität zu Köln,Monitoring the pandemic: A fractional filter for the COVID-19 contact   rate,1970,"  This paper aims to provide reliable estimates for the COVID-19 contact rate of a Susceptible-Infected-Recovered (SIR) model. From observable data on confirmed, recovered, and deceased cases, a noisy measurement for the contact rate can be constructed. To filter out measurement errors and seasonality, a novel unobserved components (UC) model is set up. It specifies the log contact rate as a latent, fractionally integrated process of unknown integration order. The fractional specification reflects key characteristics of aggregate social behavior such as strong persistence and gradual adjustments to new information. A computationally simple modification of the Kalman filter is introduced and is termed the fractional filter. It allows to estimate UC models with richer long-run dynamics, and provides a closed-form expression for the prediction error of UC models. Based on the latter, a conditional-sum-of-squares (CSS) estimator for the model parameters is set up that is shown to be consistent and asymptotically normally distributed. The resulting contact rate estimates for several countries are well in line with the chronology of the pandemic, and allow to identify different contact regimes generated by policy interventions. As the fractional filter is shown to provide precise contact rate estimates at the end of the sample, it bears great potential for monitoring the pandemic in real time. ",Kein DOI-Link verfügbar,2102.10067v1,Yes,potent(1)
0000-0002-3881-5462,Tobias Hartl,Universität zu Köln,Approximate State Space Modelling of Unobserved Fractional Components,1970,"  We propose convenient inferential methods for potentially nonstationary multivariate unobserved components models with fractional integration and cointegration. Based on finite-order ARMA approximations in the state space representation, maximum likelihood estimation can make use of the EM algorithm and related techniques. The approximation outperforms the frequently used autoregressive or moving average truncation, both in terms of computational costs and with respect to approximation quality. Monte Carlo simulations reveal good estimation properties of the proposed methods for processes of different complexity and dimension. ",https://doi.org/10.1080/07474938.2020.1841444,1812.09142v3,Yes,potent(1)
0000-0002-3903-2582,Dominik Weber,Universität Stuttgart,Exciplex-driven blue OLEDs: unlocking multifunctionality applications,1970,"  We present the development of multifunctional blue-emission organic light-emitting diodes (OLEDs) using TADF-exciplex materials. These OLEDs exhibit sensitivity to external stimuli and achieve a maximum external quantum efficiency (EQE) of 11.6 % through partly liquid processing. This technique allows for large-scale production on arbitrary geometries.   The potential multifunctionality of the devices arises from their response to low external magnetic fields (up to 100 mT) with an efficiency up to 2.5 % for magnetoconductance, while maximum magneto-electroluminescence effects of 4.1 % were detected. We investigated novel aspects, including the utilization of two organic materials without further doping and the investigation of the impact of 2,2',2''-(1,3,5-Benzinetriyl)-tris(1phenyl-1-H-benzimidazole) (TPBi) processing in liquid and vapor form. The insights gained provide a fundamental understanding regarding the applicability of exciplex (EX) materials for fully solution-processed OLEDs through a deliberate omission of doping. Our work represents a significant advancement on the path towards multifunctional OLED technology, with potential applications in cost-efficient, scalable organic full-color displays and advanced sensing system ",Kein DOI-Link verfügbar,2403.02987v1,Yes,potent(2)
0000-0002-3961-6211,Michael Braun,Universität Duisburg-Essen,Scalable Inference of Customer Similarities from Interactions Data using   Dirichlet Processes,1970,"  Under the sociological theory of homophily, people who are similar to one another are more likely to interact with one another. Marketers often have access to data on interactions among customers from which, with homophily as a guiding principle, inferences could be made about the underlying similarities. However, larger networks face a quadratic explosion in the number of potential interactions that need to be modeled. This scalability problem renders probability models of social interactions computationally infeasible for all but the smallest networks. In this paper we develop a probabilistic framework for modeling customer interactions that is both grounded in the theory of homophily, and is flexible enough to account for random variation in who interacts with whom. In particular, we present a novel Bayesian nonparametric approach, using Dirichlet processes, to moderate the scalability problems that marketing researchers encounter when working with networked data. We find that this framework is a powerful way to draw insights into latent similarities of customers, and we discuss how marketers can apply these insights to segmentation and targeting activities. ",https://doi.org/10.1287/mksc.1110.0640,1012.4769v1,Yes,potent(1)
0000-0002-3961-6211,Michael Braun,Universität Duisburg-Essen,What If Your Car Would Care? Exploring Use Cases For Affective   Automotive User Interfaces,1970,"  In this paper we present use cases for affective user interfaces (UIs) in cars and how they are perceived by potential users in China and Germany. Emotion-aware interaction is enabled by the improvement of ubiquitous sensing methods and provides potential benefits for both traffic safety and personal well-being. To promote the adoption of affective interaction at an international scale, we developed 20 mobile in-car use cases through an inter-cultural design approach and evaluated them with 65 drivers in Germany and China. Our data shows perceived benefits in specific areas of pragmatic quality as well as cultural differences, especially for socially interactive use cases. We also discuss general implications for future affective automotive UI. Our results provide a perspective on cultural peculiarities and a concrete starting point for practitioners and researchers working on emotion-aware interfaces. ",https://doi.org/10.1145/3379503.3403530,2004.02481v1,Yes,potent(2)
0000-0002-3961-6211,Michael Braun,Universität Duisburg-Essen,Design and application of robust rf pulses for toroid cavity NMR   spectroscopy,1970,"  We present robust radio frequency (rf) pulses that tolerate a factor of six inhomogeneity in the B1 field, significantly enhancing the potential of toroid cavity resonators for NMR spectroscopic applications. Both point-to-point (PP) and unitary rotation (UR) pulses were optimized for excitation, inversion, and refocusing using the gradient ascent pulse engineering (GRAPE) algorithm based on optimal control theory. In addition, the optimized parameterization (OP) algorithm applied to the adiabatic BIR-4 UR pulse scheme enabled ultra-short (50 microsec) pulses with acceptable performance compared to standard implementations. OP also discovered a new class of non-adiabatic pulse shapes with improved performance within the BIR-4 framework. However, none of the OP-BIR4 pulses are competitive with the more generally optimized UR pulses. The advantages of the new pulses are demonstrated in simulations and experiments. In particular, the DQF COSY result presented here represents the first implementation of 2D NMR spectroscopy using a toroid probe. ",https://doi.org/10.1016/j.jmr.2011.01.026,1011.6258v1,Yes,potent(1)
0000-0002-4000-6525,Niklas Hartung,Universität Potsdam,A mechanistic framework for a priori pharmacokinetic predictions of   orally inhaled drugs,1970,"  The fate of orally inhaled drugs is determined by pulmonary pharmacokinetic (PK) processes such as particle deposition, pulmonary drug dissolution, and mucociliary clearance. Although each single process has been systematically investigated, a quantitative understanding on their interaction remains limited and hence identifying optimal drug and formulation characteristics for orally inhaled drugs is still challenging. To investigate this complex interplay, the pulmonary processes can be integrated into mathematical models. However, existing modeling attempts considerably simplify these processes or are not systematically evaluated against (clinical) data. In this work, we developed a mathematical framework based on physiologically-structured population equations to integrate all relevant pulmonary processes mechanistically. A tailored numerical resolution strategy was chosen and the mechanistic model was evaluated systematically against different clinical datasets. Without any parameter estimation based on individual study data, the developed model simultaneously predicted (1) lung retention profiles of inhaled insoluble particles, (2) particle size-dependent PK of inhaled monodisperse particles, (3) PK differences between inhaled fluticasone propionate and budesonide, and (4) PK differences between healthy volunteers and asthmatic patients. Finally, to identify the most impactful optimization criteria for orally inhaled drugs, we investigated the impact of input parameters on both pulmonary and systemic exposure. Solubility of the inhaled drug did not have any relevant impact on local and systemic PK. Instead, pulmonary dissolution rate, particle size, tissue affinity, and systemic clearance were impactful potential optimization parameters. In the future, the developed prediction framework should be considered a powerful tool to identify optimal drug and formulation characteristics. ",https://doi.org/10.1371/journal.pcbi.1008466,2006.05092v1,Yes,potent(1)
0000-0002-4000-6525,Niklas Hartung,Universität Potsdam,Information-theoretic evaluation of covariate distributions models,1970,"  Statistical modelling of covariate distributions allows to generate virtual populations or to impute missing values in a covariate dataset. Covariate distributions typically have non-Gaussian margins and show nonlinear correlation structures, which simple multivariate Gaussian distributions fail to represent. Prominent non-Gaussian frameworks for covariate distribution modelling are copula-based models and models based on multiple imputation by chained equations (MICE). While both frameworks have already found applications in the life sciences, a systematic investigation of their goodness-of-fit to the theoretical underlying distribution, indicating strengths and weaknesses under different conditions, is still lacking. To bridge this gap, we thoroughly evaluated covariate distribution models in terms of Kullback-Leibler divergence (KL-D), a scale-invariant information-theoretic goodness-of-fit criterion for distributions. Methodologically, we proposed a new approach to construct confidence intervals for KL-D by combining nearest neighbour-based KL-D estimators with subsampling-based uncertainty quantification. In relevant data sets of different sizes and dimensionalities with both continuous and discrete covariates, non-Gaussian models showed consistent improvements in KL-D, compared to simpler Gaussian or scale transform approximations. KL-D estimates were also robust to the inclusion of latent variables and large fractions of missing values. While good generalization behaviour to new data could be seen in copula-based models, MICE shows a trend for overfitting and its performance should always be evaluated on separate test data. Parametric copula models and MICE were found to scale much better with the dataset dimension than nonparametric copula models. These findings corroborate the potential of non-Gaussian models for modelling realistic life science covariate distributions. ",Kein DOI-Link verfügbar,2406.10611v1,Yes,potent(1)
0000-0002-4000-6525,Niklas Hartung,Universität Potsdam,Reinforcement learning and Bayesian data assimilation for model-informed   precision dosing in oncology,1970,"  Model-informed precision dosing (MIPD) using therapeutic drug/biomarker monitoring offers the opportunity to significantly improve the efficacy and safety of drug therapies. Current strategies comprise model-informed dosing tables or are based on maximum a-posteriori estimates. These approaches, however, lack a quantification of uncertainty and/or consider only part of the available patient-specific information. We propose three novel approaches for MIPD employing Bayesian data assimilation (DA) and/or reinforcement learning (RL) to control neutropenia, the major dose-limiting side effect in anticancer chemotherapy. These approaches have the potential to substantially reduce the incidence of life-threatening grade 4 and subtherapeutic grade 0 neutropenia compared to existing approaches. We further show that RL allows to gain further insights by identifying patient factors that drive dose decisions. Due to its flexibility, the proposed combined DA-RL approach can easily be extended to integrate multiple endpoints or patient-reported outcomes, thereby promising important benefits for future personalized therapies. ",Kein DOI-Link verfügbar,2006.01061v1,Yes,potent(1)
0000-0002-4093-8381,Rüdiger U. Franz von Bock und Polach,Technische Universität Hamburg,The non-linear behavior of aqueous model ice in downward flexure,1970,"  As aqueous model ice is used extensively in ice tanks tests on the performance of ship hulls in sheet ice, it is imperative that such model ice replicate the main flexural strength behavior of sheets of sea ice and freshwater ice. Ice tanks use various types of aqueous model ice types, each of which contain brine dopants to scale-reduce ice-sheet strength. Dopants, though, introduce non-linear trends in the scaled flexural behavior of model ice sheets, and can affect ice loads and ice-rubble at ship-hulls and structures. This paper analyzes the non-linear behavior of model ices, and shows that all types behave non-linearly in flexure independent from crystal structure or chemical dopant. Such behavior is attributable to plasticity and vertical variations in stiffness and strength through sheets of model ice. Additionally, the problematic formation of a top layer in model ice sheets is shown to have a greater impact of sheet behavior than the literature reports heretofore. There remains a significant knowledge gap regarding the freezing and movement of brine dopants within ice sheets and their impact on the non-linear behavior. Additionally, it is found that the Hertz method for estimating the Cauchy number of model ice does not reflect the actual deformation behavior of model ice and should be revised. ",Kein DOI-Link verfügbar,1901.00641v1,Yes,fresh(1)
0000-0002-4180-0819,Ralf Seemann,Universität des Saarlandes,Stability and dewetting of thin liquid films,1970,"  The stability of thin liquid coatings is of fundamental interest in every- day life. Homogeneous and non-volatile liquid coatings may dewet either by heterogeneous nucleation, thermal nucleation, or spinodal dewetting. Wetting and dewetting is explained on a fundamental level, including a discussion of relevant interactions. The article will also address the various dewetting scenarios and explain how the effective interface potential governs the behavior obtained for various stratified substrates and film thicknesses. ",Kein DOI-Link verfügbar,0805.4336v1,Yes,potent(1)
0000-0002-4180-0819,Ralf Seemann,Universität des Saarlandes,Dynamical pattern formation upon dewetting,1970,"  Dewetting of thin liquid films is monitored in situ by atomic force microscopy, results are compared with simulations. The experimental setting is mimicked as close as possible using the experimental parameters including the effective interface potential. Numerics for the thin film equation are based on recently developed schemes which are up to now the only methods convergent in all relevant space dimensions. Temporal evolution and morphology of experiment and simulation are compared quantitatively. Our results explain the origin of complex generic patterns that evolve upon dewetting. ",Kein DOI-Link verfügbar,cond-mat/0106313v1,Yes,potent(1)
0000-0002-4180-0819,Ralf Seemann,Universität des Saarlandes,Deposit of Red Blood Cells at low concentrations in evaporating   droplets: central edge growth and potential applications,1970,"  Evaporation of blood droplets and diluted blood samples is a topic of intensive research, as it is seen as a possible low-cost tool for diagnosis. So far, samples with volume fraction down to a few percents of Red Blood Cells (RBCs) have been studied, and those were reportedly dominated by a ``coffee-ring'' deposit. In this study, samples with lower volume fractions have been used in order to study the growth of the evaporative deposit from sessile droplets more in details. We observed that blood samples and salt solutions with less than 1\% volume fraction of RBCs are dominated by a central deposit. We characterized the growth process of this central deposit by evaporating elongated drops, and determined that it is consistent with the Kardar-Parisi-Zhang process in the presence of quenched disorder. Our results showed a sensitivity of this deposit size to the fibrinogen concentration and shape of the RBCs, meaning that this parameter could be used to develop a new and cost-effective clinical marker for inflammation and RBC deformation. ",Kein DOI-Link verfügbar,2406.19826v1,Yes,reportedly(1)
0000-0002-4409-5457,Anna Malinovskaya,Leibniz Universität Hannover,Statistical process monitoring of artificial neural networks,1970,"  The rapid advancement of models based on artificial intelligence demands innovative monitoring techniques which can operate in real time with low computational costs. In machine learning, especially if we consider artificial neural networks (ANNs), the models are often trained in a supervised manner. Consequently, the learned relationship between the input and the output must remain valid during the model's deployment. If this stationarity assumption holds, we can conclude that the ANN provides accurate predictions. Otherwise, the retraining or rebuilding of the model is required. We propose considering the latent feature representation of the data (called ""embedding"") generated by the ANN to determine the time when the data stream starts being nonstationary. In particular, we monitor embeddings by applying multivariate control charts based on the data depth calculation and normalized ranks. The performance of the introduced method is compared with benchmark approaches for various ANN architectures and different underlying data formats. ",https://doi.org/10.1080/00401706.2023.2239886,2209.07436v2,Yes,innovative(1)
0000-0002-4544-8189,Dennis Becker,Technische Universität Dortmund,Integrating Uncertainty into Neural Network-based Speech Enhancement,1970,"  Supervised masking approaches in the time-frequency domain aim to employ deep neural networks to estimate a multiplicative mask to extract clean speech. This leads to a single estimate for each input without any guarantees or measures of reliability. In this paper, we study the benefits of modeling uncertainty in clean speech estimation. Prediction uncertainty is typically categorized into aleatoric uncertainty and epistemic uncertainty. The former refers to inherent randomness in data, while the latter describes uncertainty in the model parameters. In this work, we propose a framework to jointly model aleatoric and epistemic uncertainties in neural network-based speech enhancement. The proposed approach captures aleatoric uncertainty by estimating the statistical moments of the speech posterior distribution and explicitly incorporates the uncertainty estimate to further improve clean speech estimation. For epistemic uncertainty, we investigate two Bayesian deep learning approaches: Monte Carlo dropout and Deep ensembles to quantify the uncertainty of the neural network parameters. Our analyses show that the proposed framework promotes capturing practical and reliable uncertainty, while combining different sources of uncertainties yields more reliable predictive uncertainty estimates. Furthermore, we demonstrate the benefits of modeling uncertainty on speech enhancement performance by evaluating the framework on different datasets, exhibiting notable improvement over comparable models that fail to account for uncertainty. ",https://doi.org/10.1109/TASLP.2023.3265202,2305.08744v1,Yes,notable(1)
0000-0002-4544-8189,Dennis Becker,Technische Universität Dortmund,Explain yourself! Effects of Explanations in Human-Robot Interaction,1970,"  Recent developments in explainable artificial intelligence promise the potential to transform human-robot interaction: Explanations of robot decisions could affect user perceptions, justify their reliability, and increase trust. However, the effects on human perceptions of robots that explain their decisions have not been studied thoroughly. To analyze the effect of explainable robots, we conduct a study in which two simulated robots play a competitive board game. While one robot explains its moves, the other robot only announces them. Providing explanations for its actions was not sufficient to change the perceived competence, intelligence, likeability or safety ratings of the robot. However, the results show that the robot that explains its moves is perceived as more lively and human-like. This study demonstrates the need for and potential of explainable human-robot interaction and the wider assessment of its effects as a novel research direction. ",Kein DOI-Link verfügbar,2204.04501v2,Yes,potent(2)
0000-0002-4721-5354,Matthias Mnich,Technische Universität Hamburg,Scheduling Meets Fixed-Parameter Tractability,1970,"  Fixed-parameter tractability analysis and scheduling are two core domains of combinatorial optimization which led to deep understanding of many important algorithmic questions. However, even though fixed-parameter algorithms are appealing for many reasons, no such algorithms are known for many fundamental scheduling problems.   In this paper we present the first fixed-parameter algorithms for classical scheduling problems such as makespan minimization, scheduling with job-dependent cost functions-one important example being weighted flow time-and scheduling with rejection. To this end, we identify crucial parameters that determine the problems' complexity. In particular, we manage to cope with the problem complexity stemming from numeric input values, such as job processing times, which is usually a core bottleneck in the design of fixed-parameter algorithms. We complement our algorithms with W[1]-hardness results showing that for smaller sets of parameters the respective problems do not allow FPT-algorithms. In particular, our positive and negative results for scheduling with rejection explore a research direction proposed by D\'aniel Marx.   We hope that our contribution yields a new and fresh perspective on scheduling and fixed-parameter algorithms and will lead to further fruitful interdisciplinary research connecting these two areas. ",Kein DOI-Link verfügbar,1311.4021v1,Yes,fresh(1)
0000-0002-4741-6500,Stefan Vater,Freie Universität Berlin,A limiter-based well-balanced discontinuous Galerkin method for   shallow-water flows with wetting and drying: Triangular grids,1970,"  A novel wetting and drying treatment for second-order Runge-Kutta discontinuous Galerkin (RKDG2) methods solving the non-linear shallow water equations is proposed. It is developed for general conforming two-dimensional triangular meshes and utilizes a slope limiting strategy to accurately model inundation. The method features a non-destructive limiter, which concurrently meets the requirements for linear stability and wetting and drying. It further combines existing approaches for positivity preservation and well-balancing with an innovative velocity-based limiting of the momentum. This limiting controls spurious velocities in the vicinity of the wet/dry interface. It leads to a computationally stable and robust scheme -- even on unstructured grids -- and allows for large time steps in combination with explicit time integrators. The scheme comprises only one free parameter, to which it is not sensitive in terms of stability. A number of numerical test cases, ranging from analytical tests to near-realistic laboratory benchmarks, demonstrate the performance of the method for inundation applications. In particular, super-linear convergence, mass-conservation, well-balancedness, and stability are verified. ",https://doi.org/10.1002/fld.4762,1811.09505v2,Yes,innovative(1)
0000-0002-4771-6079,Sebastian Gartzke,Universität Duisburg-Essen,"Traffic Response Functions: Patterns, Propagation and Congestion",1970,"  Using empirical data gathered on motorways in Germany, we follow a new approach by further exploring response functions as a possible tool to study traffic dynamics in motorway networks. We uncover the basic characteristics of responses of flow and density to given signals and the capability of responses to capture the correlation between these fundamental observables. Furthermore, we uncover the potential use of responses to characterize traffic patterns. We are able to demonstrate the differentiation of congestion patterns and the determination of the propagation velocity of moving congestion. ",Kein DOI-Link verfügbar,2406.02307v1,Yes,potent(1)
0000-0002-4771-6079,Sebastian Gartzke,Universität Duisburg-Essen,Spatial Correlation Analysis of Traffic Flow on Parallel Motorways in   Germany,1970,"  With the widely used method of correlation matrix analysis, this study reveals the change of traffic states on parallel motorways in North Rhine-Westphalia, Germany. In terms of the time series of traffic flow and velocity, we carry out a quantitative analysis in correlations and reveal a high level of strongly positive traffic flow correlation and rich structural features in the corresponding correlation matrices. The strong correlation is mainly ascribed to the daily time evolution of traffic flow during the periods of rush hours and non-rush hours. In terms of free flow and congestion, the structural features are able to capture the average traffic situation we derive from our data. Furthermore, the structural features in correlation matrices for individual time periods corroborate our results from the correlation matrices regarding a whole day. The average correlations in traffic flows and velocities over all pairwise sections disclose the traffic behavior during each individual time period. Our contribution uncovers the potential application of correlation analysis on the study of traffic networks as a complex system. ",https://doi.org/10.1016/j.physa.2022.127367,2109.04268v2,Yes,potent(1)
0000-0002-4786-7483,Amir Najafi,"Universität Bremen, Universität Bremen, ITEM institute",Regularizing Recurrent Neural Networks via Sequence Mixup,1970,"  In this paper, we extend a class of celebrated regularization techniques originally proposed for feed-forward neural networks, namely Input Mixup (Zhang et al., 2017) and Manifold Mixup (Verma et al., 2018), to the realm of Recurrent Neural Networks (RNN). Our proposed methods are easy to implement and have a low computational complexity, while leverage the performance of simple neural architectures in a variety of tasks. We have validated our claims through several experiments on real-world datasets, and also provide an asymptotic theoretical analysis to further investigate the properties and potential impacts of our proposed techniques. Applying sequence mixup to BiLSTM-CRF model (Huang et al., 2015) to Named Entity Recognition task on CoNLL-2003 data (Sang and De Meulder, 2003) has improved the F-1 score on the test stage and reduced the loss, considerably. ",Kein DOI-Link verfügbar,2012.07527v1,Yes,potent(1)
0000-0002-4805-3721,Erik Buhmann,Universität Hamburg,Flow Matching Beyond Kinematics: Generating Jets with Particle-ID and   Trajectory Displacement Information,1970,"  We introduce the first generative model trained on the JetClass dataset. Our model generates jets at the constituent level, and it is a permutation-equivariant continuous normalizing flow (CNF) trained with the flow matching technique. It is conditioned on the jet type, so that a single model can be used to generate the ten different jet types of JetClass. For the first time, we also introduce a generative model that goes beyond the kinematic features of jet constituents. The JetClass dataset includes more features, such as particle-ID and track impact parameter, and we demonstrate that our CNF can accurately model all of these additional features as well. Our generative model for JetClass expands on the versatility of existing jet generation techniques, enhancing their potential utility in high-energy physics research, and offering a more comprehensive understanding of the generated jets. ",Kein DOI-Link verfügbar,2312.00123v1,Yes,potent(1)
0000-0002-4816-7470,Matthias Becker,TU Darmstadt,Towards Biologically Plausible and Private Gene Expression Data   Generation,1970,"  Generative models trained with Differential Privacy (DP) are becoming increasingly prominent in the creation of synthetic data for downstream applications. Existing literature, however, primarily focuses on basic benchmarking datasets and tends to report promising results only for elementary metrics and relatively simple data distributions. In this paper, we initiate a systematic analysis of how DP generative models perform in their natural application scenarios, specifically focusing on real-world gene expression data. We conduct a comprehensive analysis of five representative DP generation methods, examining them from various angles, such as downstream utility, statistical properties, and biological plausibility. Our extensive evaluation illuminates the unique characteristics of each DP generation method, offering critical insights into the strengths and weaknesses of each approach, and uncovering intriguing possibilities for future developments. Perhaps surprisingly, our analysis reveals that most methods are capable of achieving seemingly reasonable downstream utility, according to the standard evaluation metrics considered in existing literature. Nevertheless, we find that none of the DP methods are able to accurately capture the biological characteristics of the real dataset. This observation suggests a potential over-optimistic assessment of current methodologies in this field and underscores a pressing need for future enhancements in model design. ",Kein DOI-Link verfügbar,2402.04912v1,Yes,potent(1)
0000-0002-4951-5115,Jan Nagel,TU Dortmund Universität,Sum rules via large deviations: extension to polynomial potentials and   the multi-cut regime,1970,"  A sum rule is an identity connecting the entropy of a measure with coefficients involved in the construction of its orthogonal polynomials (Jacobi coefficients). Our paper is an extension of Gamboa, Nagel and Rouault (2016), where we have showed sum rules by using only probabilistic tools (namely the large deviations theory). Here, we prove large deviation principles for the weighted spectral measure of unitarily invariant random matrices in two general situations: firstly, when the equilibrium measure is not necessarily supported by a single interval and secondly, when the potential is a nonnegative polynomial. The rate functions can be expressed as functions of the Jacobi coefficients. These new large deviation results lead to original sum rules both for the one and the multi-cut regime and also answer a conjecture stated in Gamboa, Nagel and Rouault (2016) concerning general sum rules. ",Kein DOI-Link verfügbar,2004.13566v1,Yes,potent(1)
0000-0002-4951-5115,Jan Nagel,TU Dortmund Universität,The hybrid Landau-Ginzburg models of Calabi-Yau complete intersections,1970,  We observe that the state space of Landau-Ginzburg isolated singularities is simply a special case of Chen-Ruan orbifold cohomology relative to the generic fibre of the potential. This leads to the definition of the cohomology of hybrid Landau-Ginzburg models and its identification via an explicit isomorphism to the cohomology of Calabi-Yau complete intersections inside weighted projective spaces. The combinatorial method used in the case of hypersurfaces proven by the first named author in collaboration with Ruan is streamlined and generalised after an orbifold version of the Thom isomorphism and of the Tate twist. ,Kein DOI-Link verfügbar,1506.02989v2,Yes,potent(1)
0000-0002-4951-5115,Jan Nagel,TU Dortmund Universität,Sum rules and large deviations for spectral measures on the unit circle,1970,"  This work is a companion paper of Gamboa, Nagel, Rouault (J. Funct. Anal. 2016). We continue to explore the connections between large deviations for random objects issued from random matrix theory and sum rules. Here, we are concerned essentially with measures on the unit circle whose support is an arc that is possibly proper. We particularly focus on two matrix models. The first one is the Gross-Witten ensemble. In the gapped regime we give a probabilistic interpretation of a Simon sum rule. The second matrix model is the Hua-Pickrell ensemble. Unlike the Gross-Witten ensemble the potential is here infinite at one point. Surprisingly, but as in the above mentioned paper, we obtain a completely new sum rule for the deviation to the equilibrium measure of the Hua-Pickrell ensemble. The extension to matrix measures is also studied. ",Kein DOI-Link verfügbar,1604.06934v4,Yes,potent(1)
0000-0002-4984-3426,Conrad Caliari,TU Darmstadt,Beam-based Identification of Magnetic Field Errors in a Synchrotron   using Deep Lie Map Networks,1970,"  We present the first experimental validation of the Deep Lie Map Network (DLMN) approach for recovering both linear and non-linear optics in a synchrotron. The DLMN facilitates the construction of a detailed accelerator model by integrating charged particle dynamics with machine learning methodology in a data-driven framework. The primary observable is the centroid motion over a limited number of turns, captured by beam position monitors. The DLMN produces an updated description of the accelerator in terms of magnetic multipole components, which can be directly utilized in established accelerator physics tools and tracking codes for further analysis. In this study, we apply the DLMN to the SIS18 hadron synchrotron at GSI for the first time.   We discuss the validity of the recovered linear and non-linear optics, including quadrupole and sextupole errors, and compare our results with alternative methods, such as the LOCO fit of a measured orbit response matrix and the evaluation of resonance driving terms. The small number of required trajectory measurements, one for linear and three for non-linear optics reconstruction, demonstrates the method's time efficiency. Our findings indicate that the DLMN is well-suited for identifying linear optics, and the recovery of non-linear optics is achievable within the capabilities of the current beam position monitor system. We demonstrate the application of DLMN results through simulated resonance diagrams in tune space and their comparison with measurements. The DLMN provides a novel tool for analyzing the causal origins of resonances and exploring potential compensation schemes. ",Kein DOI-Link verfügbar,2408.11677v1,Yes,potent(1)
0000-0002-4994-7567,Christian Koch,Technische Universität Darmstadt,Hybrid Parallelization of Euler-Lagrange Simulations Based on MPI-3   Shared Memory,1970,"  The use of Euler-Lagrange methods on unstructured grids extends their application area to more versatile setups. However, the lack of a regular topology limits the scalability of distributed parallel methods, especially for routines that perform a physical search in space. One of the most prominent slowdowns is the search for halo elements in physical space for the purpose of runtime communication avoidance. In this work, we present a new communication-free halo element search algorithm utilizing the MPI-3 shared memory model. This novel method eliminates the severe performance bottleneck of many-to-many communication during initialization compared to the distributed parallelization approach and extends the possible applications beyond those achievable with the previous approach. Building on these data structures, we then present methods for efficient particle emission, scalable deposition schemes for particle-field coupling, and latency hiding approaches. The scaling performance of the proposed algorithms is validated through plasma dynamics simulations of an open-source framework on a massively parallel system, demonstrating an efficiency of up to 80% on 131000 cores. ",https://doi.org/10.1016/j.advengsoft.2022.103291,2203.13840v1,Yes,versatile(1)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Statics and dynamics of inhomogeneous liquids via the internal-energy   functional,1970,"  We give a variational formulation of classical statistical mechanics where the one-body density and the local entropy distribution constitute the trial fields. Using Levy's constrained search method it is shown that the grand potential is a functional of both distributions, that it is minimal in equilibrium, and that the minimizing fields are those at equilibrium. The functional splits into a sum of entropic, external energetic and internal energetic contributions. Several common approximate Helmholtz free energy density functionals, such as the Rosenfeld fundamental measure theory for hard sphere mixtures, are transformed to internal energy functionals. The variational derivatives of the internal energy functional are used to generalize dynamical density functional theory to include the dynamics of the microscopic entropy distribution, as is relevant for studying heat transport and thermal diffusion. ",https://doi.org/10.1103/PhysRevE.84.051203,1110.4496v1,Yes,potent(1)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Superadiabatic forces in the dynamics of the one-dimensional Gaussian   core model,1970,"  Using Brownian dynamics computer simulations we investigate the dynamics of the one-body density and one-body current in a one-dimensional system of particles that interact with a repulsive Gaussian pair potential. We systematically split the internal force distribution into an adiabatic part, which originates from the equilibrium free energy, and a superadiabatic contribution, which is neglected in dynamical density functional theory. We find a strong dependence of the magnitude and phase of the superadiabatic force distribution on the initial state of the system. While the magnitude of the superadiabatic force is small if the system evolves from an equilibrium state inside of a parabolic external potential, it is large for particles with equidistant initial separations at high temperature. We analyze these findings in the light of the known mean-field behavior of Gaussian core particles and discuss a multi-occupancy mechanism which generates superadiabatic forces that are out of phase with respect to the adiabatic force. ",https://doi.org/10.1103/PhysRevE.94.022105,1608.01171v1,Yes,potent(2)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Variance of fluctuations from Noether invariance,1970,"  The strength of fluctuations, as measured by their variance, is paramount in the quantitative description of a large class of physical systems, ranging from simple and complex liquids to active fluids and solids. Fluctuations originate from the irregular motion of thermal degrees of freedom and statistical mechanics facilitates their description. Here we demonstrate that fluctuations are constrained by the inherent symmetries of the given system. For particle-based classical many-body systems, Noether invariance at second order in the symmetry parameter leads to exact sum rules. These identities interrelate the global force variance with the mean potential energy curvature. Noether invariance is restored by an exact balance between these distinct mechanisms. The sum rules provide a practical guide for assessing and constructing theories, for ensuring self-consistency in simulation work, and for providing a systematic pathway to the theoretical quantification of fluctuations. ",https://doi.org/10.1038/s42005-022-01046-3,2203.15654v2,Yes,potent(1)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Variational Principle of Classical Density Functional Theory via Levy's   Constrained Search Method,1970,"  We show that classical density functional theory can be based on the constrained search method [M. Levy, Proc. Natl. Acad. Sci. 76, 6062 (1979)]. From the Gibbs inequality one first derives a variational principle for the grand potential as a functional of a trial many-body distribution. This functional is minimized in two stages. The first step consists of a constrained search of all many-body distributions that generate a given one-body density. The result can be split into internal and external contributions to the total grand potential. In contrast to the original approach by Mermin and Evans, here the intrinsic Helmholtz free energy functional is defined by an explicit expression that does not refer to an external potential in order to generate the given one-body density. The second step consists of minimizing with respect to the one-body density. We show that this framework can be applied in a straightforward way to the canonical ensemble. ",Kein DOI-Link verfügbar,1104.3951v1,Yes,potent(3)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Phase stacking diagram of colloidal mixtures under gravity,1970,"  The observation of stacks of distinct layers in a colloidal or liquid mixture in sedimentation-diffusion equilibrium is a striking consequence of bulk phase separation. Drawing quantitative conclusions about the phase diagram is, however, very delicate. Here we introduce the Legendre transform of the chemical potential representation of the bulk phase diagram to obtain a unique stacking diagram of all possible stacks under gravity. Simple bulk phase diagrams generically lead to complex stacking diagrams. We apply the theory to a binary hard core platelet mixture with only two-phase bulk coexistence, and find that the stacking diagram contains six types of stacks with up to four distinct layers. These results can be tested experimentally in colloidal platelet mixtures. In general, an extended Gibbs phase rule determines the maximum number of sedimented layers to be $3+2(n_b-1)+n_i$, where $n_b$ is the number of binodals and $n_i$ is the number of their inflection points. ",https://doi.org/10.1039/C3SM51491A,1305.6454v1,Yes,potent(1)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Sedimentation stacking diagram of binary colloidal mixtures and bulk   phases in the plane of chemical potentials,1970,"  We give a full account of a recently proposed theory that explicitly relates the bulk phase diagram of a binary colloidal mixture to its phase stacking phenomenology under gravity [Soft Matter 9, 8636 (2013)]. As we demonstrate, the full set of possible phase stacking sequences in sedimentation-diffusion equilibrium originates from straight lines (sedimentation paths) in the chemical potential representation of the bulk phase diagram. From the analysis of various standard topologies of bulk phase diagrams, we conclude that the corresponding sedimentation stacking diagrams can be very rich, even more so when finite sample height is taken into account. We apply the theory to obtain the stacking diagram of a mixture of nonadsorbing polymers and colloids. We also present a catalog of generic phase diagrams in the plane of chemical potentials in order to facilitate the practical application of our concept, which also generalizes to multi component mixtures. ",https://doi.org/10.1088/0953-8984/27/19/194115,1411.5147v1,Yes,potent(2)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Comparative study of force-based classical density functional theory,1970,"  We reexamine results obtained with the recently proposed density functional theory framework based on forces (force-DFT) [Tschopp et al., Phys. Rev. E 106, 014115 (2022)]. We compare inhomogeneous density profiles for hard sphere fluids to results from both standard density functional theory and from computer simulations. Test situations include the equilibrium hard sphere fluid adsorbed against a planar hard wall and the dynamical relaxation of hard spheres in a switched harmonic potential. The comparison to grand canonical Monte Carlo simulation profiles shows that equilibrium force-DFT alone does not improve upon results obtained with the standard Rosenfeld functional. Similar behavior holds for the relaxation dynamics, where we use our event-driven Brownian dynamics data as benchmark. Based on an appropriate linear combination of standard and force-DFT results, we investigate a simple hybrid scheme which rectifies these deficiencies in both the equilibrium and the dynamical case. We explicitly demonstrate that although the hybrid method is based on the original Rosenfeld fundamental measure functional, its performance is comparable to that of the more advanced White Bear theory. ",https://doi.org/10.1103/PhysRevE.107.034109,2212.01780v3,Yes,potent(1)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Phase behavior and structure of model colloid-polymer mixtures confined   between two parallel planar walls,1970,"  Using Gibbs ensemble Monte Carlo simulations and density functional theory we investigate the fluid-fluid demixing transition in inhomogeneous colloid-polymer mixtures confined between two parallel plates with separation distances between one and ten colloid diameters covering the complete range from quasi two-dimensional to bulk-like behavior. We use the Asakura-Oosawa-Vrij model in which colloid-colloid and colloid-polymer interactions are hard-sphere like, whilst the pair potential between polymers vanishes. Two different types of confinement induced by a pair of parallel walls are considered, namely either through two hard walls or through two semi-permeable walls that repel colloids but allow polymers to freely penetrate. For hard (semi-permeable) walls we find that the capillary binodal is shifted towards higher (lower) polymer fugacities and lower (higher) colloid fugacities as compared to the bulk binodal; this implies capillary condensation (evaporation) of the colloidal liquid phase in the slit. A macroscopic treatment is provided by a novel symmetric Kelvin equation for general binary mixtures, based on the proximity in chemical potentials of statepoints at capillary coexistence and the reference bulk coexistence. Results for capillary binodals compare well with those obtained from the classic version of the Kelvin equation due to Evans and Marini Bettolo Marconi [J. Chem. Phys. 86, 7138 (1987)], and are quantitatively accurate away from the fluid-fluid critical point, even at small wall separations. For hard walls the density profiles of polymers and colloids inside the slit display oscillations due to packing effects for all statepoints. For semi-permeable walls either similar structuring or flat profiles are found, depending on the statepoint considered. ",https://doi.org/10.1103/PhysRevE.73.051502,cond-mat/0603749v1,Yes,potent(2)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Neural density functional theory of liquid-gas phase coexistence,1970,"  We use supervised machine learning together with the concepts of classical density functional theory to investigate the effects of interparticle attraction on the pair structure, thermodynamics, bulk liquid-gas coexistence, and associated interfacial phenomena in many-body systems. Local learning of the one-body direct correlation functional is based on Monte Carlo simulations of inhomogeneous systems with randomized thermodynamic conditions, randomized planar shapes of the external potential, and randomized box sizes. Focusing on the prototypical Lennard-Jones system, we test predictions of the resulting neural attractive density functional across a broad spectrum of physical behaviour associated with liquid-gas phase coexistence in bulk and at interfaces. We analyse the bulk radial distribution function $g(r)$ obtained from automatic differentiation and the Ornstein-Zernike route and determine i) the Fisher-Widom line, i.e.\ the crossover of the asymptotic (large distance) decay of $g(r)$ from monotonic to oscillatory, ii) the (Widom) line of maximal correlation length, iii) the line of maximal isothermal compressibility and iv) the spinodal by calculating the poles of the structure factor in the complex plane. The bulk binodal and the density profile of the free liquid-gas interface are obtained from density functional minimization and the corresponding surface tension from functional line integration. We also show that the neural functional describes accurately the phenomena of drying at a hard wall and of capillary evaporation for a liquid confined in a slit pore. Our neural framework yields results that improve significantly upon standard mean-field treatments of interparticle attraction. Comparison with independent simulation results demonstrates a consistent picture of phase separation even when restricting the training to supercritical states only. ",Kein DOI-Link verfügbar,2408.15835v1,Yes,potent(1)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Custom Flow in Molecular Dynamics,1970,"  Driving an inertial many-body system out of equilibrium generates complex dynamics due to memory effects and the intricate relationships between the external driving force, internal forces, and transport effects. Understanding the underlying physics is challenging and often requires carrying out case-by-case analysis. To systematically study the interplay between all types of forces that contribute to the dynamics, a method to generate prescribed flow patterns could be of great help. We develop a custom flow method to numerically construct the external force field required to obtain the desired time evolution of an inertial many-body system, as prescribed by its one-body current and density profiles. We validate the custom flow method in a Newtonian system of purely repulsive particles by creating a slow motion dynamics of an out-of-equilibrium process and by prescribing the full time evolution between two distinct equilibrium states. The method can also be used with thermostat algorithms to control the temperature. ",https://doi.org/10.1103/PhysRevResearch.3.013281,2101.02915v1,Yes,intricate(1)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Inhomogeneous steady shear dynamics of a three-body colloidal gel former,1970,"  We investigate the stationary flow of a colloidal gel under an inhomogeneous external shear force using adaptive Brownian dynamics simulations. The interparticle forces are derived from the Stillinger-Weber potential, where the three-body term is tuned to enable network formation and gelation in equilibrium. When subjected to the shear force field, the system develops remarkable modulations in the one-body density profile. Depending on the shear magnitude, particles accumulate either in quiescent regions or in the vicinity of maximum net flow, and we deduce this strong non-equilibrium response to be characteristic of the gel state. Studying the components of the internal force parallel and perpendicular to the flow direction reveals that the emerging flow and structure of the stationary state are driven by significant viscous and structural superadiabatic forces. Thereby, the magnitude and nature of the observed non-equilibrium phenomena differs from the corresponding behavior of simple fluids. We demonstrate that a simple power functional theory reproduces accurately the viscous force profile, giving a rationale of the complex dynamical behavior of the system. ",https://doi.org/10.1063/5.0130655,2210.07679v2,Yes,potent(1)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Reduced-variance orientational distribution functions from torque   sampling,1970,"  We introduce a method to sample the orientational distribution function in computer simulations. The method is based on the exact torque balance equation for classical many-body systems of interacting anisotropic particles in equilibrium. Instead of the traditional counting of events, we reconstruct the orientational distribution function via an orientational integral of the torque acting on the particles. We test the torque sampling method in two- and three-dimensions, using both Langevin dynamics and overdamped Brownian dynamics, and with two interparticle interaction potentials. In all cases the torque sampling method produces profiles of the orientational distribution function with better accuracy than those obtained with the traditional counting method. The accuracy of the torque sampling method is independent of the bin size, and hence it is possible to resolve the orientational distribution function with arbitrarily small angular resolutions. ",https://doi.org/10.1088/1361-648X/acc522,2212.11576v2,Yes,potent(1)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Custom flow in overdamped Brownian Dynamics,1970,"  When an external field drives a colloidal system out of equilibrium, the ensuing colloidal response can be very complex and obtaining a detailed physical understanding often requires case-by-case considerations. In order to facilitate systematic analysis, here we present a general iterative scheme for the determination of the unique external force field that yields a prescribed inhomogeneous stationary or time-dependent flow in an overdamped Brownian many-body system. The computer simulation method is based on the exact one-body force balance equation and allows to specifically tailor both gradient and rotational velocity contributions, as well as to freely control the one-body density distribution. Hence compressibility of the flow field can be fully adjusted. The practical convergence to a unique external force field demonstrates the existence of a functional map from both velocity and density to external force field, as predicted by the power functional variational framework. In equilibrium, the method allows to find the conservative force field that generates a prescribed target density profile, and hence implements the Mermin-Evans classical density functional map from density distribution to external potential. The conceptual tools developed here enable one to gain detailed physical insight into complex flow behaviour, as we demonstrate in prototypical situations. ",https://doi.org/10.1103/PhysRevE.99.023306,1812.02185v1,Yes,potent(1)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Perspective: How to overcome dynamical density functional theory,1970,"  We argue in favour of developing a comprehensive dynamical theory for rationalizing, predicting, designing, and machine learning nonequilibrium phenomena that occur in soft matter. To give guidance for navigating the theoretical and practical challenges that lie ahead, we discuss and exemplify the limitations of dynamical density functional theory. Instead of the implied adiabatic sequence of equilibrium states that this approach provides as a makeshift for the true time evolution, we posit that the pending theoretical tasks lie in developing a systematic understanding of the dynamical functional relationships that govern the genuine nonequilibrium physics. While static density functional theory gives a comprehensive account of the equilibrium properties of many-body systems, we argue that power functional theory is the only present contender to shed similar insights into nonequilibrium dynamics, including the recognition and implementation of exact sum rules that result from the Noether theorem. As~a~demonstration of the power functional point of view, we consider an idealized steady sedimentation flow of the three-dimensional Lennard-Jones fluid and machine-learn the kinematic map from the mean motion to the internal force field. The trained model is capable of both predicting and designing the steady state dynamics universally for various target density modulations. This demonstrates the significant potential of using such techniques in nonequilibrium many-body physics and overcomes both the conceptual constraints of dynamical density functional theory as well as the limited availability of its analytical functional approximations. ",https://doi.org/10.1088/1361-648X/accb33,2301.12156v2,Yes,potent(1)
0000-0002-5015-2972,Matthias Schmidt,Universität Bayreuth,Floating nematic phase in colloidal platelet-sphere mixtures,1970,"  The phase behaviour of colloidal dispersions is interesting for fundamental reasons and for technological applications such as photonic crystals and electronic paper. Sedimentation, which in everyday life is relevant from blood analysis to the shelf life of paint, is a means to determine phase boundaries by observing distinct layers in samples that are in sedimentation-diffusion equilibrium. However, disentangling the effects due to interparticle interactions, which generate the bulk phase diagram, from those due to gravity is a complex task. Here we show that a line in the space of chemical potentials $\mu_i$, where $i$ labels the species, represents a sedimented sample and that each crossing of this sedimentation path with a binodal generates an interface under gravity. Complex phase stacks can result, such as the sandwich of a floating nematic layer between top and bottom isotropic phases that we observed in a mixture of silica spheres and gibbsite platelets. ",https://doi.org/10.1038/srep00789,1211.3142v1,Yes,potent(1)
0000-0002-5066-9314,Amine Chabane,Goethe Universität Frankfurt,Roberge-Weiss transitions at imaginary isospin chemical potential,1970,"  At finite imaginary values of the chemical potential, QCD is free of the sign problem. Moreover, at high temperatures the partition function exhibits a new symmetry (the Roberge-Weiss symmetry) connecting phases with different orientations of the Polyakov loop, and the corresponding phase transitions between these. In this contribution we investigate the perturbative one-loop effective potential for the Polyakov loop in the presence of imaginary isospin as well as baryon chemical potentials. This leads to a novel phase diagram, which reveals an interesting insight about the rich phase structure of the system and the center symmetry breaking. We check the perturbative results using direct lattice simulations. ",Kein DOI-Link verfügbar,2110.13536v1,Yes,potent(3)
0000-0002-5066-9314,Amine Chabane,Goethe Universität Frankfurt,Towards the phase diagram of cold and dense heavy QCD,1970,"  The thermodynamics of QCD with sufficiently heavy dynamical quarks can be described by a three-dimensional Polyakov loop effective theory, obtained after a truncated character and hopping expansion. We investigate the resulting phase diagram for low temperatures by mean field methods. Taking into account chemical potentials for both baryon number and isospin, we obtain clear signals for a liquid-gas type transition to baryon matter at $\mu_I=0$ and a Bose-Einstein condensation transition at $\mu_B=0$, as well as for their connection when both chemical potentials are non-zero. ",Kein DOI-Link verfügbar,2212.09591v1,Yes,potent(2)
0000-0002-5066-9314,Amine Chabane,Goethe Universität Frankfurt,The light Roberge-Weiss tricritical endpoint at imaginary isospin and   baryon chemical potential,1970,"  Imaginary chemical potentials serve as a useful tool to constrain the QCD phase diagram and to gain insight into the thermodynamics of strongly interacting matter. In this study, we report on the first determination of the phase diagram for arbitrary imaginary baryon and isospin chemical potentials at high temperature using one-loop perturbation theory, revealing a nontrivial structure of Roberge-Weiss (RW) phase transitions in this plane. Subsequently, this system is simulated numerically with $N_{\rm f}=2$ unimproved staggered quarks on $N_{\tau}=4$ lattices at a range of temperatures at one of the RW phase transitions. We establish a lower bound for the light quark mass, where the first-order transition line terminates in a tricritical point. It is found that this tricritical mass is increased as compared to the case of purely baryonic imaginary chemical potentials, indicating that our setup is more advantageous for identifying critical behavior towards the chiral limit. Finally, the dynamics of local Polyakov loop clusters is also studied in conjuction with the RW phase transition. ",Kein DOI-Link verfügbar,2207.10117v1,Yes,potent(3)
0000-0002-5109-2203,Wolfgang Belzig,Universität Konstanz,Reflectionless Transport of Surface Dirac Fermions on Topological   Insulators with Induced Ferromagnetic Domain Walls,1970,"  The properties of surface Dirac Fermions on a 3D topological insulator in proximity to a magnetic insulator with spatially textured magnetization are considered. We present an exact analytical treatment of the spectrum, the bound states and the domain wall resistance for an extended generic domain wall with in-plane and out-of-plane magnetizations. In the latter case, we find oscillations in the domain wall resistance as a function of the wall width and for certain widths a complete absence of reflections for all incoming momenta. The surprising occurrence of oscillations and the reflectionless potentials can be related to a supersymmetry of the surface Dirac Hamiltonian combined with the domain wall profile. ",https://doi.org/10.1103/PhysRevB.86.035151,1202.3580v2,Yes,potent(1)
0000-0002-5109-2203,Wolfgang Belzig,Universität Konstanz,Photon-assisted electronic and spin transport in a junction containing   precessing molecular spin,1970,"  We study the ac charge and -spin transport through an orbital of a magnetic molecule with spin precessing in a constant magnetic field. We assume that the source and drain contacts have time-dependent chemical potentials. We employ the Keldysh nonequilibrium Green's functions method to calculate the spin and charge currents to linear order in the time-dependent potentials. The molecular and electronic spins are coupled via exchange interaction. The time-dependent molecular spin drives inelastic transitions between the molecular quasienergy levels, resulting in a rich structure in the transport characteristics. The time-dependent voltages allow us to reveal the internal precession time scale (the Larmor frequency) by a dc conductance measurement if the ac frequency matches the Larmor frequency. In the low-ac-frequency limit the junction resembles a classical electric circuit. Furthermore, we show that the setup can be used to generate dc-spin currents, which are controlled by the molecular magnetization direction and the relative phases between the Larmor precession and the ac voltage. ",https://doi.org/10.1103/PhysRevB.93.075402,1412.3994v2,Yes,potent(2)
0000-0002-5109-2203,Wolfgang Belzig,Universität Konstanz,Thermally induced spin-transfer torques in superconductor/ferromagnet   bilayers,1970,  Thermally induced magnetization dynamics is currently a flourishing field of research due to its potential application in information technology. We study the paradigmatic system of a magnetic domain wall in a thermal gradient which is interacting with an adjacent superconductor. The spin-transfer torques arising in this system due to the combined action of the giant thermoelectric effect and the creation of equal-spin pairs in the superconductor are large enough to give rise to high domain wall velocities $10^3$ times larger than previously predicted. ,https://doi.org/10.1103/PhysRevB.103.L020503,1909.04418v2,Yes,potent(1)
0000-0002-5109-2203,Wolfgang Belzig,Universität Konstanz,Signatures of spin-triplet Cooper pairing in the density of states of   spin-textured superconductor-ferromagnet bilayers,1970,"  The existence of spin-triplet superconductivity in non-collinear magnetic heterostructures with superconductors is by now well established. This observation lays the foundation of superconducting spintronics with the aim to create a low-power consuming devices in order to replace the conventional electronics limited by heating. From a fundamental point of view the investigation of the structure and properties of spin-triplet Cooper pairs continues. Recently, spectroscopic evidence has shown to offer more detailed insights in the structure of triplet Cooper pairs than the supercurrent. Hence, we study here the structure of spin-triplet Cooper pairs through the density of states in bilayers of a textured magnetic insulator in proximity to a superconductor. Using quasiclassical Green function methods, we study the local density of states, both spin-resolved and spin-independent. We show that the equal-spin and mixed-spin triplet Cooper pairs leads to different spectroscopic signatures, which can be further enhanced by spin-polarized spectroscopy. Our results show the huge potential spin-polarized tunneling methods offer in characterizing unconventional superconductivity in heterostructures. ",https://doi.org/10.1088/1367-2630/ab0e20,1812.09937v1,Yes,potent(1)
0000-0002-5109-2203,Wolfgang Belzig,Universität Konstanz,Single-photon pump by Cooper-pair splitting,1970,"  Hybrid quantum dot-oscillator systems have become attractive platforms to inspect quantum coherence effects at the nanoscale. Here, we investigate a Cooper-pair splitter setup consisting of two quantum dots, each linearly coupled to a local resonator. The latter can be realized either by a microwave cavity or a nanomechanical resonator. Focusing on the subgap regime, we demonstrate that cross-Andreev reflection, through which Cooper pairs are split into both dots, can efficiently cool down simultaneously both resonators into their ground state. Moreover, we show that a nonlocal heat transfer between the two resonators is activated when opportune resonance conditions are matched. The proposed scheme can act as a heat-pump device with potential applications in heat control and cooling of mesoscopic quantum resonators. ",https://doi.org/10.1103/PhysRevResearch.1.033098,1907.04308v3,Yes,potent(1)
0000-0002-5109-2203,Wolfgang Belzig,Universität Konstanz,Exponential speedup of incoherent tunneling via dissipation,1970,"  We study the escape rate of a particle in a metastable potential in presence of a dissipative bath coupled to the momentum of the particle. Using the semiclassical bounce technique, we find that this rate is exponentially enhanced. In particular, the influence of momentum dissipation depends on the slope of the barrier that the particle is tunneling through. We investigate also the influence of dissipative baths coupled to the position, and to the momentum of the particle, respectively. In this case the rate exhibits a non-monotonic behavior as a function of the dissipative coupling strengths. Remarkably, even in presence of position dissipation, momentum dissipation can enhance exponentially the escape rate in a large range of the parameter space. The influence of the momentum dissipation is also witnessed by the substantial increase of the average energy loss during inelastic (environment-assisted) tunneling. ",https://doi.org/10.1103/PhysRevResearch.3.033019,2102.02660v2,Yes,potent(1)
0000-0002-5109-2203,Wolfgang Belzig,Universität Konstanz,Fractional positional jumps in stochastic systems with tilted periodic   double-well potentials,1970,"  We present a theoretical investigation of the stochastic dynamics of a damped particle in a tilted periodic potential with a double well per period. By applying the matrix continued fraction technique to the Fokker-Planck equation in conjunction with the full counting statistics and master equation approaches, we determine the rates of specific processes contributing to the system's overall dynamics. At low temperatures, the system can exhibit one running state and two distinct locked metastable states. We focus primarily on two aspects: the dynamics of positional jumps, which are rare thermally induced particle jumps over potential maxima, and their impact on the overall velocity noise; and the retrapping process, involving the transition from the running to the locked metastable states. We demonstrate the existence of fractional (in units of $2\pi$) positional slips that differ qualitatively from conventional $2\pi$ jumps observed in single-well systems. Fractional positional slips significantly influence the system dynamics even in regimes dominated by dichotomous-like switching between running and locked states. Furthermore, we introduce a simple master equation approach that proves effective in analyzing various stages of the retrapping process. Interestingly, our analysis shows that even for a system featuring a well-developed double-well periodic potential, there exists a broad parameter range where the stochastic dynamics can be accurately described by an effective single-well periodic model. The techniques introduced here allow for valuable insights into the complex behavior of the system, offering avenues for understanding and controlling its steady-state and transient dynamics, which go beyond or can be complementary to direct stochastic simulations. ",https://doi.org/10.1103/PhysRevB.110.054306,2402.15287v2,Yes,potent(3)
0000-0002-5109-2203,Wolfgang Belzig,Universität Konstanz,Exchange-enhanced Ultrastrong Magnon-Magnon Coupling in a Compensated   Ferrimagnet,1970,"  The ultrastrong coupling of (quasi-)particles has gained considerable attention due to its application potential and richness of the underlying physics. Coupling phenomena arising due to electromagnetic interactions are well explored. In magnetically ordered systems, the quantum-mechanical exchange-interaction should furthermore enable a fundamentally different coupling mechanism. Here, we report the observation of ultrastrong intralayer exchange-enhanced magnon-magnon coupling in a compensated ferrimagnet. We experimentally study the spin dynamics in a gadolinium iron garnet single crystal using broadband ferromagnetic resonance. Close to the ferrimagnetic compensation temperature, we observe ultrastrong coupling of clockwise and anticlockwise magnon modes. The magnon-magnon coupling strength reaches more than 30% of the mode frequency and can be tuned by varying the direction of the external magnetic field. We theoretically explain the observed phenomenon in terms of an exchange-enhanced mode-coupling mediated by a weak cubic anisotropy. ",https://doi.org/10.1103/PhysRevLett.123.117204,1903.04330v2,Yes,potent(1)
0000-0002-5447-8267,Xuan Liu,Universität Duisburg-Essen,Learning Contact-aware CPG-based Locomotion in a Soft Snake Robot,1970,"  In this paper, we present a model-free learning-based control scheme for the soft snake robot to improve its contact-aware locomotion performance in a cluttered environment. The control scheme includes two cooperative controllers: A bio-inspired controller (C1) that controls both the steering and velocity of the soft snake robot, and an event-triggered regulator (R2) that controls the steering of the snake in anticipation of obstacle contacts and during contact. The inputs from the two controllers are composed as the input to a Matsuoka CPG network to generate smooth and rhythmic actuation inputs to the soft snake. To enable stable and efficient learning with two controllers, we develop a game-theoretic process, fictitious play, to train C1 and R2 with a shared potential-field-based reward function for goal tracking tasks. The proposed approach is tested and evaluated in the simulator and shows significant improvement of locomotion performance in the obstacle-based environment comparing to two baseline controllers. ",Kein DOI-Link verfügbar,2105.04608v1,Yes,potent(1)
0000-0002-5447-8267,Xuan Liu,Universität Duisburg-Essen,"Revisiting GANs by Best-Response Constraint: Perspective, Methodology,   and Application",1970,"  In past years, the minimax type single-level optimization formulation and its variations have been widely utilized to address Generative Adversarial Networks (GANs). Unfortunately, it has been proved that these alternating learning strategies cannot exactly reveal the intrinsic relationship between the generator and discriminator, thus easily result in a series of issues, including mode collapse, vanishing gradients and oscillations in the training phase, etc. In this work, by investigating the fundamental mechanism of GANs from the perspective of hierarchical optimization, we propose Best-Response Constraint (BRC), a general learning framework, that can explicitly formulate the potential dependency of the generator on the discriminator. Rather than adopting these existing time-consuming bilevel iterations, we design an implicit gradient scheme with outer-product Hessian approximation as our fast solution strategy. \emph{Noteworthy, we demonstrate that even with different motivations and formulations, a variety of existing GANs ALL can be uniformly improved by our flexible BRC methodology.} Extensive quantitative and qualitative experimental results verify the effectiveness, flexibility and stability of our proposed framework. ",Kein DOI-Link verfügbar,2205.10146v1,Yes,"noteworthy(1), potent(1)"
0000-0002-5447-8267,Xuan Liu,Universität Duisburg-Essen,A Multi-Modal Contrastive Diffusion Model for Therapeutic Peptide   Generation,1970,"  Therapeutic peptides represent a unique class of pharmaceutical agents crucial for the treatment of human diseases. Recently, deep generative models have exhibited remarkable potential for generating therapeutic peptides, but they only utilize sequence or structure information alone, which hinders the performance in generation. In this study, we propose a Multi-Modal Contrastive Diffusion model (MMCD), fusing both sequence and structure modalities in a diffusion framework to co-generate novel peptide sequences and structures. Specifically, MMCD constructs the sequence-modal and structure-modal diffusion models, respectively, and devises a multi-modal contrastive learning strategy with intercontrastive and intra-contrastive in each diffusion timestep, aiming to capture the consistency between two modalities and boost model performance. The inter-contrastive aligns sequences and structures of peptides by maximizing the agreement of their embeddings, while the intra-contrastive differentiates therapeutic and non-therapeutic peptides by maximizing the disagreement of their sequence/structure embeddings simultaneously. The extensive experiments demonstrate that MMCD performs better than other state-of-theart deep generative methods in generating therapeutic peptides across various metrics, including antimicrobial/anticancer score, diversity, and peptide-docking. ",Kein DOI-Link verfügbar,2312.15665v2,Yes,potent(1)
0000-0002-5447-8267,Xuan Liu,Universität Duisburg-Essen,Holographic Schwinger Effect in Flavor-Dependent Systems,1970,"  The holographic Schwinger effect is investigated in systems with Nf = 0, Nf = 2, and Nf = 2+1 using the Einstein-Maxwell-Dilaton (EMD) model, incorporating equation of state and baryon number susceptibility information from lattice QCD. It is found that the critical electric field is smallest for Nf = 0, indicating that the Schwinger effect is more likely to occur than in systems with Nf = 2 and Nf = 2+ 1. The critical electric field decreases with increasing chemical potential and temperature across all systems. Additionally, potential analysis confirms that the maximum total potential energy increases with the number of flavors, suggesting that existing particles may reduce the probability of particle pair production. ",Kein DOI-Link verfügbar,2407.14828v2,Yes,potent(3)
0000-0002-5447-8267,Xuan Liu,Universität Duisburg-Essen,Exploring Prosocial Irrationality for LLM Agents: A Social Cognition   View,1970,"  Large language models (LLMs) have been shown to face hallucination issues due to the data they trained on often containing human bias; whether this is reflected in the decision-making process of LLM agents remains under-explored. As LLM Agents are increasingly employed in intricate social environments, a pressing and natural question emerges: Can LLM Agents leverage hallucinations to mirror human cognitive biases, thus exhibiting irrational social intelligence? In this paper, we probe the irrational behavior among contemporary LLM agents by melding practical social science experiments with theoretical insights. Specifically, We propose CogMir, an open-ended Multi-LLM Agents framework that utilizes hallucination properties to assess and enhance LLM Agents' social intelligence through cognitive biases. Experimental results on CogMir subsets show that LLM Agents and humans exhibit high consistency in irrational and prosocial decision-making under uncertain conditions, underscoring the prosociality of LLM Agents as social entities, and highlighting the significance of hallucination properties. Additionally, CogMir framework demonstrates its potential as a valuable platform for encouraging more research into the social intelligence of LLM Agents. ",Kein DOI-Link verfügbar,2405.14744v1,Yes,"intricate(1), potent(1)"
0000-0002-5447-8267,Xuan Liu,Universität Duisburg-Essen,Doubly-heavy tetraquark at finite temperature in a holographic model,1970,"  In this paper, we employ gauge/gravity duality to investigate the string breaking and melting of doubly-heavy tetraquark that includes two heavy quarks and two light antiquarks in a holographic model at finite temperature. Firstly, we investigate four configurations of $\rm{QQ\bar{q}\bar{q}}$ in the confined phase and consider different separation distances of the heavy quarks at varying temperatures. At high temperature, $\rm{QQ\bar{q}\bar{q}}$ melts at certain distances and the confined quarks are released. As the temperature continues to increase, some configurations of doubly-heavy tetraquark can not exist. Furthermore, we investigate three decay modes of $\rm{QQ\bar{q}\bar{q}}$ and compare the potential energy of $\rm{QQ\bar{q}\bar{q}}$ with that of $\rm{QQq}$ at finite temperature . ",Kein DOI-Link verfügbar,2306.06976v2,Yes,potent(1)
0000-0002-5447-8267,Xuan Liu,Universität Duisburg-Essen,A Parallel Beam Splitting Based on Gradient Metasurface: Preparation and   Fusion of Quantum Entanglement,1970,"  Gradient metasurface, formed by a set of subwavelength unit cells with different phase modulation, is widely used in polarized beam splitting (BS) in the classical and quantum optics. Specifically, its phase gradient allows the path and polarization of multiple output lights to be locked by corresponding inputs.Using this unique path-polarization locked property, we demonstrate that the single metasurface can function as sequentially linked beamsplitters, enabling the parallelization of a series of BS processes. Such a parallel BS metasurface provides a multi-beam interference capability for both classical and quantum light manipulation. Taking this advantage, we first prepare path and polarization hybrid entangled states of two, three, and multi photons from unentangled photon sources. Then, the ability of parallel BS-facilitated entanglement is applied to demonstrate entanglement fusion among entangled photon pairs, which can greatly enlarge the entanglement dimension. The principle of parallel BS through the metasurface opens up a versatile way to manipulate the quantum state at the micro/nano scale, which will have potential applications in on-chip quantum optics and quantum information processing. ",Kein DOI-Link verfügbar,2403.08233v1,Yes,"versatile(1), potent(1)"
0000-0002-5447-8267,Xuan Liu,Universität Duisburg-Essen,Defending Against Adversarial Attacks in Transmission- and   Distribution-level PMU Data,1970,"  Phasor measurement units (PMUs) provide high-fidelity data that improve situation awareness of electric power grid operations. PMU datastreams inform wide-area state estimation, monitor area control error, and facilitate event detection in real time. As PMU data become more available and increasingly reliable, these devices are found in new roles within control systems, such as remedial action schemes and early warning detection systems. As with other cyber physical systems, maintaining data integrity and security pose a significant challenge for power system operators. In this paper, we present a comprehensive analysis of multiple machine learning techniques to detect malicious data injection within PMU data streams. The two datasets used in this study come from two PMU networks: an inter-university, research-grade distribution network spanning three institutions in the U.S. Pacific Northwest, and a utility transmission network from the Bonneville Power Administration. We implement the detection algorithms with TensorFlow, an open-source software library for machine learning, and the results demonstrate potential for distributing the training workload and achieving higher performance, while maintaining effectiveness in the detection of spoofed data. ",Kein DOI-Link verfügbar,2008.09153v1,Yes,potent(1)
0000-0002-5521-0326,Lukas Pfannschmidt,Bielefeld Universität,Feature Relevance Determination for Ordinal Regression in the Context of   Feature Redundancies and Privileged Information,1970,"  Advances in machine learning technologies have led to increasingly powerful models in particular in the context of big data. Yet, many application scenarios demand for robustly interpretable models rather than optimum model accuracy; as an example, this is the case if potential biomarkers or causal factors should be discovered based on a set of given measurements. In this contribution, we focus on feature selection paradigms, which enable us to uncover relevant factors of a given regularity based on a sparse model. We focus on the important specific setting of linear ordinal regression, i.e.\ data have to be ranked into one of a finite number of ordered categories by a linear projection. Unlike previous work, we consider the case that features are potentially redundant, such that no unique minimum set of relevant features exists. We aim for an identification of all strongly and all weakly relevant features as well as their type of relevance (strong or weak); we achieve this goal by determining feature relevance bounds, which correspond to the minimum and maximum feature relevance, respectively, if searched over all equivalent models. In addition, we discuss how this setting enables us to substitute some of the features, e.g.\ due to their semantics, and how to extend the framework of feature relevance intervals to the setting of privileged information, i.e.\ potentially relevant information is available for training purposes only, but cannot be used for the prediction itself. ",https://doi.org/10.1016/j.neucom.2019.12.133,1912.04832v1,Yes,potent(3)
0000-0002-5536-048X,Mustafa Kahraman,Universität des Saarlandes,Electron ground state $g$ factor in embedded InGaAs quantum dots: An   atomistic study,1970,"  We present atomistic computations within an empirical pseudopotential framework for the electron $s$-shell ground state $g$ tensor of InGaAs quantum dots (QDs) embedded to host matrices that grant electronic confinement. A large structural set consisting of geometry, size, and molar fraction variations is worked out which also includes a few representative uniform strain cases. The tensor components are observed to display insignificant discrepancies even for the highly anisotropic shapes. The family of $g$-factor curves associated with these parameter combinations coalesces to a single universal one when plotted as a function of the gap energy, thus confirming a recent assertion reached under much restrictive conditions. Our work extends its validity to alloy QDs with various shapes and finite confinement that allows for penetration to the host matrix, placing it on a more realistic basis. Accordingly, the electrons in InGaAs QDs having $s$-shell transition energies close to 1.13 eV will be least susceptible to magnetic field. We also show that low indium concentration offer limited $g$-factor tunability under shape or confinement variations. These findings can be taken into consideration in the fabrication and the use of InGaAs QDs with $g$-near-zero or other targeted $g$ values for spintronic or electron spin resonance-based direct quantum logic applications. ",https://doi.org/10.1103/PhysRevB.103.115303,2009.08055v2,Yes,potent(1)
0000-0002-5537-5032,Anne Neumann,Universität Potsdam,Solidarity in natural gas storage: A potential allocation mechanism of   stored quantities among several players during times of crisis,1970,"  The recently experienced disruptions in the EU's energy supply pointed out that supply crises pose a real thread and the member states must be better prepared do deal with the related challenges. According to the current practice, member states fill their gas storages independently, while it is not clear how solidarity could be put into practice in the future, i.e. how the accumulated reserves of one or more members may be potentially redistributed to help others in need. In this paper we propose some possible guidelines for a potential solidarity framework, and formalize a game-theoretic model in order to capture the basic features of the problem, considering the related uncertainty of the future conditions related to gas storage levels and possible transmission bottlenecks as well. The proposed mechanism of supply-security related cooperation is based on voluntary participation, and may contribute to the more efficient utilization of storage capacities. Via the computational model we demonstrate the operation of the proposed framework on a simple example and show that under the assumption of risk-averse participants, the concept exhibits potential. ",Kein DOI-Link verfügbar,2209.05089v2,Yes,potent(3)
0000-0002-5544-5221,Xianghui Zhang,Bielefeld Universität,SMA-Hyper: Spatiotemporal Multi-View Fusion Hypergraph Learning for   Traffic Accident Prediction,1970,"  Predicting traffic accidents is the key to sustainable city management, which requires effective address of the dynamic and complex spatiotemporal characteristics of cities. Current data-driven models often struggle with data sparsity and typically overlook the integration of diverse urban data sources and the high-order dependencies within them. Additionally, they frequently rely on predefined topologies or weights, limiting their adaptability in spatiotemporal predictions. To address these issues, we introduce the Spatiotemporal Multiview Adaptive HyperGraph Learning (SMA-Hyper) model, a dynamic deep learning framework designed for traffic accident prediction. Building on previous research, this innovative model incorporates dual adaptive spatiotemporal graph learning mechanisms that enable high-order cross-regional learning through hypergraphs and dynamic adaptation to evolving urban data. It also utilises contrastive learning to enhance global and local data representations in sparse datasets and employs an advance attention mechanism to fuse multiple views of accident data and urban functional features, thereby enriching the contextual understanding of risk factors. Extensive testing on the London traffic accident dataset demonstrates that the SMA-Hyper model significantly outperforms baseline models across various temporal horizons and multistep outputs, affirming the effectiveness of its multiview fusion and adaptive learning strategies. The interpretability of the results further underscores its potential to improve urban traffic management and safety by leveraging complex spatiotemporal urban data, offering a scalable framework adaptable to diverse urban environments. ",Kein DOI-Link verfügbar,2407.17642v1,Yes,"innovative(1), potent(1)"
0000-0002-5552-9599,Lennart Hofeditz,Universität Duisburg-Essen,Strategies and Influence of Social Bots in a 2017 German state election   - A case study on Twitter,1970,"  As social media has permeated large parts of the population it simultaneously has become a way to reach many people e.g. with political messages. One way to efficiently reach those people is the application of automated computer programs that aim to simulate human behaviour - so called social bots. These bots are thought to be able to potentially influence users' opinion about a topic. To gain insight in the use of these bots in the run-up to the German Bundestag elections, we collected a dataset from Twitter consisting of tweets regarding a German state election in May 2017. The strategies and influence of social bots were analysed based on relevant features and network visualization. 61 social bots were identified. Possibly due to the concentration on German language as well as the elections regionality, identified bots showed no signs of collective political strategies and low to none influence. Implications are discussed. ",Kein DOI-Link verfügbar,1710.07562v1,Yes,potent(1)
0000-0002-5635-1868,Xue Guo,Universität Göttingen,Splitting of temperature distributions due to dual-channel photon heat   exchange in many-body systems,1970,"  We investigate the radiative heat transfer and spatial distributions of stationary temperatures in periodic many-body systems composed of alternating slabs of two different materials. We show that temperature distributions exhibit an alternating spatial pattern and split into two distinct components, with each component corresponding to one of the two materials. Spatial temperature variations following the periodicity of the structure can be attributed to a dual-channel photon heat exchange through a long-range coupling of electromagnetic modes supported by bodies of the same material. We also analyze the thermal relaxation of the temperatures in the system to verify potential applications in dynamical situations. The results reveal that tunable nonmonotonic temperature variations can be also designed and utilized at a transient mode. The dual-channel mechanism to control temperature distributions proposed in the present work may pave new avenues for prospective applications in nano devices, especially for thermal photon-driven logic circuitry and thermal management. ",Kein DOI-Link verfügbar,2306.13862v1,Yes,potent(1)
0000-0002-5635-1868,Xue Guo,Universität Göttingen,Performance improvement of three-body radiative diode driven by graphene   surface plasmon polaritons,1970,"  As an analogue to electrical diode, a radiative thermal diode allows radiation to transfer more efficiently in one direction than in the opposite direction by operating in a contactless mode. In this study, we demonstrated that, within the framework of three-body photon thermal tunneling, the rectification performance of three-body radiative diode can be greatly improved by bringing graphene into the system. The system is composed of three parallel slabs, with the hot and cold terminals of the diode coated with graphene films, and the intermediate body made of vanadium dioxide (VO2). The rectification factor of the proposed radiative thermal diode reaches 300 % with a 350 nm separation distance between the hot and cold terminals of the diode. With the help of graphene, the rectification performance of the radiative thermal diode can be improved by over 11 times. By analyzing the spectral heat flux and energy transmission coefficients, it was found that the improved performance is primarily attributed to the surface plasmon polaritons (SPPs) of graphene. They excite the modes of insulating VO2 in the forward-biased scenario by forming strongly coupled modes between graphene and VO2, and thus dramatically enhance the heat flux. While, for the reverse-biased scenario, the VO2 is at its metallic state and thus graphene SPPs cannot work by three-body photon thermal tunneling. Furthermore, the improvement was also investigated for different chemical potentials of graphene, and geometric parameters of the three-body system. Our findings demonstrate the feasibility of using thermal-photon-based logical circuits, creating radiation-based communication technology, and implementing thermal management approaches at the nanoscale. ",https://doi.org/10.1039/D3CP01912H,2306.13851v1,Yes,potent(1)
0000-0002-5693-9557,Michael Herzog,Ruhr-Universität Bochum,Aardvark weather: end-to-end data-driven weather forecasting,1970,"  Weather forecasting is critical for a range of human activities including transportation, agriculture, industry, as well as the safety of the general public. Machine learning models have the potential to transform the complex weather prediction pipeline, but current approaches still rely on numerical weather prediction (NWP) systems, limiting forecast speed and accuracy. Here we demonstrate that a machine learning model can replace the entire operational NWP pipeline. Aardvark Weather, an end-to-end data-driven weather prediction system, ingests raw observations and outputs global gridded forecasts and local station forecasts. Further, it can be optimised end-to-end to maximise performance over quantities of interest. Global forecasts outperform an operational NWP baseline for multiple variables and lead times. Local station forecasts are skillful up to ten days lead time and achieve comparable and often lower errors than a post-processed global NWP baseline and a state-of-the-art end-to-end forecasting system with input from human forecasters. These forecasts are produced with a remarkably simple neural process model using just 8% of the input data and three orders of magnitude less compute than existing NWP and hybrid AI-NWP methods. We anticipate that Aardvark Weather will be the starting point for a new generation of end-to-end machine learning models for medium-range forecasting that will reduce computational costs by orders of magnitude and enable the rapid and cheap creation of bespoke models for users in a variety of fields, including for the developing world where state-of-the-art local models are not currently available. ",Kein DOI-Link verfügbar,2404.00411v3,Yes,potent(1)
0000-0002-5740-8803,Bernhard Kliem,Universität Potsdam,Pre-eruption Splitting of the Double-Decker Structure in a Solar   Filament,1970,"  Solar filaments often erupt partially. Although how they split remains elusive, the splitting process has the potential of revealing the filament structure and eruption mechanism. Here we investigate the pre-eruption splitting of an apparently single filament and its subsequent partial eruption on 2012 September 27. The evolution is characterized by three stages with distinct dynamics. During the quasi-static stage, the splitting proceeds gradually for about 1.5 hrs, with the upper branch rising at a few kilometers per second and displaying swirling motions about its axis. During the precursor stage that lasts for about 10 min, the upper branch rises at tens of kilometers per second, with a pair of conjugated dimming regions starting to develop at its footpoints; with the swirling motions turning chaotic, the axis of the upper branch whips southward, which drives an arc-shaped EUV front propagating in the similar direction. During the eruption stage, the upper branch erupts with the onset of a C3.7-class two-ribbon flare, while the lower branch remains stable. Judging from the well separated footpoints of the upper branch from those of the lower one, we suggest that the pre-eruption filament processes a double-decker structure composed of two distinct flux bundles, whose formation is associated with gradual magnetic flux cancellations and converging photospheric flows around the polarity inversion line. ",https://doi.org/10.3847/1538-4357/abda4e,2101.03296v1,Yes,potent(1)
0000-0002-5782-804X,Matthias Kleinmann,Universität Siegen,Newton's laws of motion can generate gravity-mediated entanglement,1970,"  The interface between quantum theory and gravity represents still uncharted territory. Recently, some works suggested promising alternative approaches aimed at witnessing quantum features to test the fundamental nature of gravity in tabletop experiments: Two masses in an initial superposition of spatially localized states are allowed to interact only through gravity and it is measured whether the final state is entangled. Here we show that one can generate the same amount of entanglement in this setup by using classical time evolution given by Newton's laws of motion. We argue that theories of quantum gravity that can be approximated by the Newtonian potential and classical time evolution given by Newton's laws of motion will generate gravity-mediated entanglement. ",Kein DOI-Link verfügbar,2401.07832v1,Yes,potent(1)
0000-0002-5783-4108,Laura Mack,Universität Hohenheim,Identifying atmospheric fronts based on diabatic processes using the   dynamic state index (DSI),1970,"  Atmospheric fronts are associated with precipitation and strong diabatic processes. Therefore, detecting fronts objectively from reanalyses is a prerequisite for the long-term study of their weather impacts. For this purpose, several algorithms exist, e.g., based on the thermic front parameter (TFP) or the F diagnostic. It is shown that both methods have problems to identify weak warm fronts since they are characterized by low baroclinicity. To avoid this inaccuracy, a new algorithm is developed that considers fronts as deviation from an adiabatic and steady state. These deviations can be accurately measured using the dynamic state index (DSI). The DSI shows a coherent dipole structure along fronts and is strongly correlated with precipitation sums. It is shown that the North Atlantic storm tracks can be clearly identified by the DSI method. Compared to other front identification methods, fronts identified with the DSI method have particularly high specific humidity. Using a simple estimate for front speed, it is shown that fronts identified using DSI method move faster then fronts identified with TFP method, demonstrating the potential of the DSI to indicate movement speed and direction in atmospheric flows. ",Kein DOI-Link verfügbar,2208.11438v1,Yes,potent(1)
0000-0002-5848-3266,Wolfgang Schweiger,Universität Hohenheim,Resonances and Decay Widths within a Relativistic Coupled Channel   Approach,1970,"  We present a microscopic model for hadron resonances which contains, in addition to constituent (anti)quarks, mesonic degrees of freedom. It is assumed that the (anti)quarks are confined by an instantaneous potential and that the mesons can couple directly to the (anti)quarks. This system is treated within a relativistic coupled-channel formalism in order to take the dynamics of the mesonic degrees of freedom fully into account. It is demonstrated that the mass eigenvalue problem for such a system can be reformulated as a purely hadronic eigenvalue problem in which bare hadrons, i.e. eigenstates of the pure confinement problem, are coupled via meson loops. The substructure of the bare hadrons is then hidden in (bare) hadron-meson vertex form factors. It is shown for a simple toy model that such a kind of approach may lead to reasonable (non-perturbative) decay widths for hadron resonances. ",Kein DOI-Link verfügbar,1010.3919v1,Yes,potent(1)
0000-0002-5848-3266,Wolfgang Schweiger,Universität Hohenheim,"On the microscopic structure of $πNN$, $πNΔ$ and   $πΔΔ$ vertices",1970,"  We use a hybrid constituent-quark model for the microscopic description of $\pi N N$, $\pi N \Delta$ and $\pi \Delta \Delta$ vertices. In this model quarks are confined by an instantaneous potential and are allowed to emit and absorb a pion, which is also treated as dynamical degree of freedom. The point form of relativistic quantum mechanics is employed to achieve a relativistically invariant description of this system. Starting with an $SU(6)$ spin-flavor symmetric wave function for $N_0$ and $\Delta_0$, i.e. the eigenstates of the pure confinement problem, we calculate the strength of the $\pi N_0 N_0$, $\pi N_0 \Delta_0$ and $\pi \Delta_0 \Delta_0$ couplings and the corresponding vertex form factors. Interestingly the ratios of the resulting couplings resemble strongly those needed in purely hadronic coupled-channel models, but deviate significantly from the ratios following from SU(6) spin-flavor symmetry in the non-relativistic constituent-quark model. ",https://doi.org/10.1007/s00601-017-1234-1,1701.03059v1,Yes,potent(1)
0000-0002-5848-3266,Wolfgang Schweiger,Universität Hohenheim,Polynomial Solutions of Generalized Quartic Anharmonic Oscillators,1970,"  This paper deals with the partial solution of the energy eigenvalue problem for generalized symmetric quartic oscillators. Algebraization of the problem is achieved by expressing the Schroedinger operator in terms of the generators of a nilpotent group, which we call the quartic group. Energy eigenvalues are then seen to depend on the values of the two Casimir operators of the group. This dependence exhibits a scaling law which follows from the scaling properties of the group generators. Demanding that the potential gives rise to polynomial solutions in a particular Lie algebra element puts constraints on the four potential parameters, leaving only two of them free. For potentials satisfying such constraints at least one of the energy eigenvalues and the corresponding eigenfunctions can be obtained in closed analytic form {by pure algebraic means. With our approach we extend the class of quasi-exactly solvable quartic oscillators which have been obtained in the literature by means of the more common sl(2,R) algebraization. Finally we show, how solutions of the generalized quartic oscillator problem give rise to solutions for a charged particle moving in particular non-constant electromagnetic fields. ",Kein DOI-Link verfügbar,2007.11326v2,Yes,potent(4)
0000-0002-5848-3266,Wolfgang Schweiger,Universität Hohenheim,$ρ$-Meson Form Factors in the Point Form,1970,"  We present a calculation of the electromagnetic form factors of the $\rho^+$ meson. Our formalism is based on the point-form of relativistic quantum mechanics. Electron-$\rho$-meson scattering is formulated as a coupled-channel problem for a Bakamjian-Thomas mass operator, such that the dynamics of the exchanged photon is taken explicitly into account. The $\rho$-meson current is extracted from on-shell matrix elements of the optical potential of the scattering process. As a consequence of the violation of cluster separability in the Bakamjian-Thomas framework, our current includes additional, unphysical contributions, which can be separated from the physical ones uniquely. Our results for the form factors are in good agreement with other approaches. ",Kein DOI-Link verfügbar,1708.03170v1,Yes,potent(1)
0000-0002-5848-3266,Wolfgang Schweiger,Universität Hohenheim,Electromagnetic meson form factor from a relativistic coupled-channel   approach,1970,"  Point-form relativistic quantum mechanics is used to derive an expression for the electromagnetic form factor of a pseudoscalar meson for space-like momentum transfers. The elastic scattering of an electron by a confined quark-antiquark pair is treated as a relativistic two-channel problem for the $q\bar{q}e$ and $q\bar{q}e\gamma$ states. With the approximation that the total velocity of the $q\bar{q}e$ system is conserved at (electromagnetic) interaction vertices this simplifies to an eigenvalue problem for a Bakamjian-Thomas type mass operator. After elimination of the $q\bar{q}e\gamma$ channel the electromagnetic meson current and form factor can be directly read off from the one-photon-exchange optical potential. By choosing the invariant mass of the electron-meson system large enough, cluster separability violations become negligible. An equivalence with the usual front-form expression, resulting from a spectator current in the $q^+=0$ reference frame, is established. The generalization of this multichannel approach to electroweak form factors for an arbitrary bound few-body system is quite obvious. By an appropriate extension of the Hilbert space this approach is also able to accommodate exchange-current effects. ",https://doi.org/10.1103/PhysRevC.79.055203,0902.2348v1,Yes,potent(1)
0000-0002-5848-3266,Wolfgang Schweiger,Universität Hohenheim,A relativistic coupled-channel formalism for electromagnetic form   factors of 2-body bound states,1970,"  We discuss a Poincar\'e invariant coupled-channel formalism which is based on the point-form of relativistic quantum mechanics. Electromagnetic scattering of an electron by a 2-body bound state is treated as a 2-channel problem for a Bakamjian-Thomas-type mass operator. In this way retardation effects in the photon-exchange interaction are fully taken into account. The electromagnetic current of the 2-body bound state is then extracted from the one-photon-exchange optical potential. As an application we calculate electromagnetic pion and deuteron form factors. Wrong cluster properties, inherent in the Bakamjian-Thomas framework, are seen to cause spurious (unphysical) contributions in the current. These are separated and eliminated in an unambiguous way such that one is left with a current that has all the desired properties. ",https://doi.org/10.1007/s00601-010-0180-y,1011.0170v1,Yes,potent(1)
0000-0002-5861-3673,Sarah Leweke,Universität Siegen,Vector-valued Spline Method for the Spherical Multiple-shell   Electro-magnetoencephalography Problem,1970,"  Human brain activity is based on electrochemical processes, which can only be measured invasively. Therefore, quantities such as magnetic flux density (MEG) or electric potential differences (EEG) are measured non-invasively in medicine and research. The reconstruction of the neuronal current from the measurements is a severely ill-posed problem though its visualization is one of the main research tools in cognitive neuroscience. Here, using an isotropic multiple-shell model for the geometry of the head and a quasi-static approach for modeling the electro-magnetic processes, we derive a novel vector-valued spline method based on reproducing kernel Hilbert spaces. The presented vector spline method follows the path of former spline approaches and provides classical minimum norm properties. In addition, it minimizes the (infinite-dimensional) Tikhonov-Philips functional handling the instability of the inverse problem. This optimization problem reduces to solving a finite-dimensional system of linear equations without loss of information. It results in a unique solution which takes into account that only the harmonic and solenoidal component of the current affects the measurements. Besides, we prove a convergence result: the solution achieved by the vector spline method converges to the generator of the data as the number of measurements increases. The vector splines are applied to the inversion of synthetic test cases, where the irregularly distributed data situation could be handled very well. Combined with parameter choice methods, numerical results are shown with and without additional Gaussian white noise. Former approaches based on scalar splines are outperformed by the vector splines results with respect to the normalized root mean square error. Finally, reasonable results with respect to physiological expectations for real data are shown. ",https://doi.org/10.1088/1361-6420/ac62f5,2112.12015v1,Yes,potent(1)
0000-0002-5887-3037,Marco Caliendo,Universität Potsdam,The Accuracy of Job Seekers' Wage Expectations,1970,"  Job seekers' misperceptions about the labor market can distort their decision-making and increase the risk of long-term unemployment. Our study establishes objective benchmarks for the subjective wage expectations of unemployed workers. This enables us to provide novel insights into the accuracy of job seekers' wage expectations. First, especially workers with low objective earnings potential tend to display excessively optimistic beliefs about their future wages and anchor their wage expectations too strongly to their pre-unemployment wages. Second, among long-term unemployed workers, overoptimism remains persistent throughout the unemployment spell. Third, higher extrinsic incentives to search more intensively lead job seekers to hold more optimistic wage expectations, yet this does not translate into higher realized wages for them. Lastly, we document a connection between overoptimistic wage expectations and job seekers' tendency to overestimate their reemployment chances. We discuss the role of information frictions and motivated beliefs as potential sources of job seekers' optimism and the heterogeneity in their beliefs. ",Kein DOI-Link verfügbar,2309.14044v1,Yes,potent(2)
0000-0002-5987-746X,Stefan Kraus,Universität zu Köln,GW Orionis: A pre-main-sequence triple with a warped disk and a   torn-apart ring as benchmark for disk hydrodynamics,1970,"  Understanding how bodies interact with each other and with disk material holds the key to understanding the architecture of stellar systems and of planetary systems. While the interactions between point sources can be described by simple gravity, interactions with disk material require further knowledge about the gas viscosity and dust microphysics that needs to be included when simulating disk-body interactions. Pre-main-sequence multiple systems provide us with a unique laboratory to calibrate fundamental parameters such as the viscosity and to test theories of hydrodynamic processes that might shape protoplanetary disk structure and affect the planet populations forming from these disks. In this article I briefly review our knowledge about a particularly intriguing T Tauri triple star system, GW Orionis, that has the potential to serve as a rosetta stone for hydrodynamic studies. The 3-dimensional orbits and masses of the stars in GW Orionis have been constrained by long-term interferometric and radial velocity monitoring. Also, the 3-dimensional geometry of the strongly distorted disk has been tightly contrained based on high-angular resolution thermal dust emission and scattered-light imaging. The disk-tearing effect that we might witness in GW Ori in action constitutes an important new mechanism for moving disk material onto highly oblique or retrograde orbits, even at very wide separations from the star. At the same time, the observed torn ring seems sufficiently massive, and might be sufficiently stable, for planet formation to occur, potentially giving rise to an yet-undiscovered population of circum-multiple planets on highly oblique, long-period orbits. ",Kein DOI-Link verfügbar,2012.06578v1,Yes,potent(2)
0000-0002-5987-746X,Stefan Kraus,Universität zu Köln,Cophasing the Planet Formation Imager,1970,"  The Planet Formation Imager (PFI) is a project for a very large optical interferometer intended to obtain images of the planet formation process at scales as small as the Hill sphere of giant exoplanets. Its main science instruments will work in the thermal infrared but it will be cophased in the near infrared, where it requires also some capacity for scientific imaging. PFI imaging and resolution specifications imply an array of 12 to 20 apertures and baselines up to a few kilometers cophased at near infrared coherent magnitudes as large as 10. This paper discusses various cophasing architectures and the corresponding minimum diameter of individual apertures, which is the dominant element of PFI cost estimates. From a global analysis of the possible combinations of pairwise fringe sensors, we show that conventional approaches used in current interferometers imply the use of prohibitively large telescopes and we indicate the innovative strategies that would allow building PFI with affordable apertures smaller than 2 m in diameter. The approach with the best potential appears to be Hierarchical Fringe Tracking based on ""two beams spatial filters"" that cophase pairs of neighboring telescopes with all the efficiency of a two telescopes fringe tracker and transmit most of the flux as if it was produced by an unique single mode aperture to cophase pairs of pairs and then pairs of groups of apertures. We consider also the adaptation to PFI of more conventional approaches such as a combination of GRAVITY like fringe trackers or single or multiple chains of 2T fringe trackers. ",https://doi.org/10.1117/12.2231081,1610.08289v1,Yes,"innovative(1), potent(1)"
0000-0002-5987-746X,Stefan Kraus,Universität zu Köln,Single-crystal graphene on Ir(110),1970,"  A single-crystal sheet of graphene is synthesized on the low-symmetry substrate Ir(110) by thermal decomposition of C$_2$H$_4$ at 1500 K. Using scanning tunneling microscopy, low-energy electron diffraction, angle-resolved photoemission spectroscopy, and ab initio density functional theory the structure and electronic properties of the adsorbed graphene sheet and its moir\'e with the substrate are uncovered. The adsorbed graphene layer forms a wave pattern of nm wave length with a corresponding modulation of its electronic properties. This wave pattern is demonstrated to enable the templated adsorption of aromatic molecules and the uniaxial growth of organometallic wires. Not limited to this, graphene on Ir(110) is also a versatile substrate for 2D-layer growth and makes it possible to grow epitaxial layers on ureconstructed Ir(110). ",https://doi.org/10.1103/PhysRevB.105.165405,2109.04198v1,Yes,versatile(1)
0000-0002-5987-746X,Stefan Kraus,Universität zu Köln,Spin-orbit alignment of the $β$ Pictoris planetary system,1970,"  A crucial diagnostic that can tell us about processes involved in the formation and dynamical evolutionof planetary systems is the angle between the rotation axis of a star and a planet's orbital angular momentum vector (""spin-orbit"" alignment or ""obliquity""). Here we present the first spin-orbit alignment measurement for a wide-separation exoplanetary system, namely on the directly-imaged planet $\beta$ Pictoris b. We use VLTI/GRAVITY spectro-interferometry with an astrometric accuracy of 1 $\mu$as (microarcsecond) in the Br$\gamma$ photospheric absorption line to measure the photocenter displacement associated with the stellar rotation. Taking inclination constraints from astroseismology into account, we constrain the 3-dimensional orientation of the stellar spin axis and find that $\beta$ Pic b orbits its host star on a prograde orbit. The angular momentum vectors of the stellar photosphere, the planet, and the outer debris disk are well-aligned with mutual inclinations $<3\pm5^{\circ}$, which indicates that $\beta$ Pic b formed in a system without significant primordial misalignments. Our results demonstrate the potential of infrared interferometry to measure the spin-orbit alignment for wide-separation planetary systems, probing a highly complementary regime to the parameter space accessible with the Rossiter-McLaughlin effect. If the low obliquity is confirmed by measurements on a larger sample of wide-separation planets, it would lend support to theories that explain the obliquity in Hot Jupiter systems with dynamical scattering and the Kozai-Lidov mechanism. ",https://doi.org/10.3847/2041-8213/ab9d27,2006.10784v1,Yes,potent(1)
0000-0002-5994-3762,Volker Diekert,Universität Stuttgart,Equations over free inverse monoids with idempotent variables,1970,"  We introduce the notion of idempotent variables for studying equations in inverse monoids.   It is proved that it is decidable in singly exponential time (DEXPTIME) whether a system of equations in idempotent variables over a free inverse monoid has a solution. The result is proved by a direct reduction to solve language equations with one-sided concatenation and a known complexity result by Baader and Narendran: Unification of concept terms in description logics, 2001. We also show that the problem becomes DEXPTIME hard , as soon as the quotient group of the free inverse monoid has rank at least two.   Decidability for systems of typed equations over a free inverse monoid with one irreducible variable and at least one unbalanced equation is proved with the same complexity for the upper bound.   Our results improve known complexity bounds by Deis, Meakin, and Senizergues: Equations in free inverse monoids, 2007.   Our results also apply to larger families of equations where no decidability has been previously known. ",Kein DOI-Link verfügbar,1412.4737v2,Yes,potent(2)
0000-0002-6004-6567,Thomas Graule,Universität Siegen,Effect of lattice volume and strain on the conductivity of BaCeY-oxide   ceramic proton conductors,1970,"  In-situ electrochemical impedance spectroscopy was used to study the effect of lattice volume and strain on the proton conductivity of the yttrium-doped barium cerate proton conductor by applying the hydrostatic pressure up to 1.25 GPa. An increase from 0.62 eV to 0.73 eV in the activation energy of the bulk conductivity was found with increasing pressure during a unit cell volume change of 0.7%, confirming a previously suggested correlation between lattice volume and proton diffusivity in the crystal lattice. One strategy worth trying in the future development of the ceramic proton conductors could be to expand the lattice and potentially lower the activation energy under tensile strain. ",https://doi.org/10.1016/j.jeurceramsoc.2011.02.014,1206.6287v1,Yes,potent(1)
0000-0002-6004-6567,Thomas Graule,Universität Siegen,An electron hole doping and soft x-ray spectroscopy study on   La1-xSrxFe0.75Ni0.25O3-δ,1970,"  The conductivity of the electron hole and polaron conductor La1-xSrxFe0.75Ni0.25O3-{\delta}, a potential cathode material for intermediate temperature solid oxide fuel cells, was studied for 0 <x < 1 and for temperatures 300 K <T < 1250 K. In LaSrFe-oxide, an ABO3 type perovskite, A-site substitu-tion of the trivalent La3+ by the divalent Sr2+ causes oxidation of Fe3+ towards Fe4+, which forms conducting electron holes. Here we have in addition a B-site substitution by Ni. The compound for x = 0.5 is identified as the one with the highest conductivity ({\sigma} ~ 678 S/cm) and lowest activation energy for polaron conductivity (Ep = 39 meV). The evolution of the electronic structure was monitored by soft x-ray Fe and oxygen K-edge spectroscopy. Homogeneous trend for the oxida-tion state of the Fe was observed. The variation of the ambient temperature conductivity and activation energy with relative Sr content (x) shows a correlation with the ratio of (eg/eg+t2g) in Fe L3 edge up to x=0.5. The hole doping process is reflected by an almost linear trend by the variation of the pre-peaks of the oxygen K-edge soft x-ray absorption spectra. ",https://doi.org/10.1063/1.3246145,1106.1019v1,Yes,potent(1)
0000-0002-6004-6567,Thomas Graule,Universität Siegen,Evolution of an oxygen NEXAFS transition in the upper Hubbard band in   α-Fe2O3 upon electrochemical oxidation,1970,"  Electrochemical oxidation of hematite ({\alpha}-Fe2O3) nano-particulate films at 600 mV vs. Ag+/AgCl reference in KOH electrolyte forms a species at the hematite surface which causes a new transition in the upper Hubbard band between the Fe(3d)-O(2p) state region and the Fe(4sp)-O(2p) region, as evidenced by oxygen near edge x-ray absorption fine structure (NEXAFS) spectra. The electrochemical origin of this transition suggests that it is related with a surface state. This transition, not known for pristine {\alpha}-Fe2O3 is at about the same x-ray energy, where pristine 1% Si doped Si:Fe2O3 has such transition. Occurrence of this state coincides with the onset of an oxidative dark current wave at around 535 mV - a potential range, where the tunneling exchange current has been previously reported to increase by three orders of magnitude with the valence band and the transfer coefficient by a factor of 10. Oxidation to only 200 mV does not form such extra NEXAFS feature, supporting that a critical electrochemical potential between 200 and 600 mV is necessary to change the electronic structure of the iron oxide at the surface. Decrease of the surface roughness, as suggested by visual inspection, profilometry and x-ray reflectivity, points to faceting as potential structural origin of the surface state. ",https://doi.org/10.1021/jp108230r,1106.1089v1,Yes,potent(3)
0000-0002-6124-3255,Martin Antonio Unland Elorrieta,Universität Münster,Sensitivity of multi-PMT Optical Modules in Antarctic Ice to Supernova   Neutrinos of MeV energy,1970,"  New optical sensors with a segmented photosensitive area are being developed for the next generation of neutrino telescopes at the South Pole. In addition to increasing sensitivity to high-energy astrophysical neutrinos, we show that this will also lead to a significant improvement in sensitivity to MeV neutrinos, such as those produced in core-collapse supernovae (CCSN). These low-energy neutrinos can provide a detailed picture of the events after stellar core collapse, testing our understanding of these violent explosions. We present studies on the event-based detection of MeV neutrinos with a segmented sensor and, for the first time, the potential of a corresponding detector in the deep ice at the South Pole for the detection of extra-galactic CCSN. We find that exploiting temporal coincidences between signals in different photocathode segments, a $27\ \mathrm{M}_{\odot}$ progenitor mass CCSN can be detected up to a distance of 269 kpc with a false detection rate of $0.01$ year$^{-1}$ with a detector consisting of 10000 sensors. Increasing the number of sensors to 20000 and reducing the optical background by a factor of 140 expands the range such that a CCSN detection rate of $0.08$ per year is achieved, while keeping the false detection rate at $0.01$ year$^{-1}$. ",https://doi.org/10.1140/epjc/s10052-021-09809-y,2106.14199v4,Yes,potent(1)
0000-0002-6193-1904,Jingjing Ye,Universität Leipzig,"Extent of Safety Database in Pediatric Drug Development: Types of   Assessment, Analytical Precision, and Pathway for Extrapolation through   On-Target Effects",1970,"  Pediatric patients should have access to medicines that have been appropriately evaluated for safety and efficacy. Given this goal of revised labelling, the adequacy of the pediatric clinical development plan and resulting safety database must inform a favorable benefit-risk assessment for the intended use of the medicinal product. While extrapolation from adults can be used to support efficacy of drugs in children, there may be a reluctance to use the same approach in safety assessments, wiping out potential gains in trial efficiency through a reduction of sample size. To address this reluctance, we explore safety review in pediatric trials, including factors affecting these data, specific types of safety assessments, and precision on the estimation of event rates for specific adverse events (AEs) that can be achieved. In addition, we discuss the assessments which can provide a benchmark for the use of extrapolation of safety that focuses on on-target effects. Finally, we explore a unified approach for understanding precision using Bayesian approaches as the most appropriate methodology to describe/ascertain risk in probabilistic terms for the estimate of the event rate of specific AEs. ",Kein DOI-Link verfügbar,2211.13329v1,Yes,potent(1)
0000-0002-6237-0918,Johannes Thomas,Heinrich-Heine-Universität Düsseldorf,Relativistic electron Wigner crystal formation in a cavity for electron   acceleration,1970,"  It is known that a gas of electrons in a uniform neutralizing background can crystallize and form a lattice if the electron density is less than a critical value. This crystallization may have two- or three-dimensional structure. Since the wake field potential in the highly-nonlinear-broken-wave regime (bubble regime) has the form of a cavity where the background electrons are evacuated from and only the positively charged ions remain, it is suited for crystallization of trapped and accelerated electron bunches. However, in this case, the crystal is moving relativistically and shows new three-dimensional structures that we call relativistic Wigner crystals. We analyze these structures using a relativistic Hamiltonian approach. We also check for stability and phase transitions of the relativistic Wigner crystals. ",Kein DOI-Link verfügbar,1404.3576v2,Yes,potent(1)
0000-0002-6237-0918,Johannes Thomas,Heinrich-Heine-Universität Düsseldorf,2D structures of electron bunches in relativistic plasma cavities,1970,  The spatial structure of an ultra-low emittance electron bunch in a plasma wakefield blowout regime is studied. The full Li\'{e}nard-Wiechert potentials are considered for mutual inter-particle interactions in the framework of the equilibrium slice model (ESM). This model uses the quasi-static theory which allows to solve the Li\'{e}nard-Wiechert potentials without knowledge of the electrons' history. The equilibrium structure we find is similar to already observed hexagonal lattices but shows topological defects. Scaling laws for interparticle distances are obtained from numerical simulations and analytical estimations. ,https://doi.org/10.1103/PhysRevE.98.013201,1805.01312v1,Yes,potent(2)
0000-0002-6237-0918,Johannes Thomas,Heinrich-Heine-Universität Düsseldorf,Spin polarized proton beam generation from gas-jet targets by intense   laser pulses,1970,"  A method of generating spin polarized proton beams from a gas jet by using a multi-petawatt laser is put forward. With currently available techniques of producing pre-polarized monatomic gases from photodissociated hydrogen halide molecules and petawatt lasers, proton beams with energy ~ 50 MeV and ~ 80 % polarization are proved to be obtained. Two-stage acceleration and spin dynamics of protons are investigated theoretically and by means of fully self-consistent three dimensional particle-in-cell simulations. Our results predict the dependence of the beam polarization on the intensity of the driving laser pulse. Generation of bright energetic polarized proton beams would open a domain of polarization studies with laser driven accelerators, and have potential application to enable effective detection in explorations of quantum chromodynamics. ",https://doi.org/10.1103/PhysRevE.102.011201,2001.11398v3,Yes,potent(1)
0000-0002-6237-0918,Johannes Thomas,Heinrich-Heine-Universität Düsseldorf,Polarized Proton Beams from Laser-induced Plasmas,1970,"  We report on the concept of an innovative source to produce polarized proton/deuteron beams of a kinetic energy up to several GeV from a laser-driven plasma accelerator. Spin effects have been implemented into the PIC simulation code VLPL to make theoretical predictions about the behavior of proton spins in laser-induced plasmas. Simulations of spin-polarized targets show that the polarization is conserved during the acceleration process. For the experimental realization, a polarized HCl gas-jet target is under construction using the fundamental wavelength of a Nd:YAG laser system to align the HCl bonds and simultaneously circular polarized light of the fifth harmonic to photo-dissociate, yielding nuclear polarized H atoms. Subsequently, their degree of polarization is measured with a Lamb-shift polarimeter. The final experiments, aiming at the first observation of a polarized particle beam from laser-generated plasmas, will be carried out at the 10 PW laser system SULF at SIOM/Shanghai. ",https://doi.org/10.1017/hpl.2018.73,1810.02247v2,Yes,innovative(1)
0000-0002-6239-3271,Klaus Zollner,Universität Regensburg,Engineering Proximity Exchange by Twisting: Reversal of Ferromagnetic   and Emergence of Antiferromagnetic Dirac Bands in Graphene/Cr$_2$Ge$_2$Te$_6$,1970,"  We investigate the twist-angle and gate dependence of the proximity exchange coupling in twisted graphene on monolayer Cr$_2$Ge$_2$Te$_6$ from first principles. The proximitized Dirac band dispersions of graphene are fitted to a model Hamiltonian, yielding effective sublattice-resolved proximity-induced exchange parameters ($\lambda_{\textrm{ex}}^\textrm{A}$ and $\lambda_{\textrm{ex}}^\textrm{B}$) for a series of twist angles between 0$^{\circ}$ and 30$^{\circ}$. For aligned layers (0$^{\circ}$ twist angle), the exchange coupling of graphene is the same on both sublattices, $\lambda_{\textrm{ex}}^\textrm{A} \approx \lambda_{\textrm{ex}}^\textrm{B} \approx 4$ meV, while the coupling is reversed at 30$^{\circ}$ (with $\lambda_{\textrm{ex}}^\textrm{A} \approx \lambda_{\textrm{ex}}^\textrm{B} \approx -4$ meV). Remarkably, at 19.1$^{\circ}$ the induced exchange coupling becomes antiferromagnetic: $\lambda_{\textrm{ex}}^\textrm{A} < 0, \lambda_{\textrm{ex}}^\textrm{B} > 0$. Further tuning is provided by a transverse electric field and the interlayer distance. The predicted proximity magnetization reversal and emergence of an antiferromagnetic Dirac dispersion make twisted graphene/Cr$_2$Ge$_2$Te$_6$ bilayers a versatile platform for realizing topological phases and for spintronics applications. ",https://doi.org/10.1103/PhysRevLett.128.106401,2108.03984v2,Yes,versatile(1)
0000-0002-6239-3271,Klaus Zollner,Universität Regensburg,Swapping Exchange and Spin-Orbit Coupling in 2D van der Waals   Heterostructures,1970,"  The concept of swapping the two most important spin interactions -- exchange and spin-orbit coupling -- is proposed based on two-dimensional multilayer van der Waals heterostructures. Specifically, we show by performing realistic ab initio simulations, that a single device consisting of a bilayer graphene sandwiched by a 2D ferromagnet Cr$_2$Ge$_2$Te$_6$ (CGT) and a monolayer WS$_2$, is able not only to generate, but also to swap the two interactions. The highly efficient swapping is enabled by the interplay of gate-dependent layer polarization in bilayer graphene and short-range spin-orbit and exchange proximity effects affecting only the layers in contact with the sandwiching materials. We call these structures ex-so-tic, for supplying either exchange (ex) or spin-orbit (so) coupling in a single device, by gating. Such bifunctional devices demonstrate the potential of van der Waals spintronics engineering using 2D crystal multilayers. ",https://doi.org/10.1103/PhysRevLett.125.196402,2005.11058v2,Yes,potent(1)
0000-0002-6239-3271,Klaus Zollner,Universität Regensburg,Electronic and Spin-Orbit Properties of hBN Encapsulated Bilayer   Graphene,1970,"  Van der Waals (vdW) heterostructures consisting of Bernal bilayer graphene (BLG) and hexagonal boron nitride (hBN) are investigated. By performing first-principles calculations we capture the essential BLG band structure features for several stacking and encapsulation scenarios. A low-energy model Hamiltonian, comprising orbital and spin-orbit coupling (SOC) terms, is employed to reproduce the hBN-modified BLG dispersion, spin splittings, and spin expectation values. Most important, the hBN layers open an orbital gap in the BLG spectrum, which can range from zero to tens of meV, depending on the precise stacking arrangement of the individual atoms. Therefore, large local band gap variations may arise in experimentally relevant moir\'{e} structures. Moreover, the SOC parameters are small (few to tens of $\mu$eV), just as in bare BLG, but are markedly proximity modified by the hBN layers. Especially when BLG is encapsulated by monolayers of hBN, such that inversion symmetry is restored, the orbital gap and spin splittings of the bands vanish. In addition, we show that a transverse electric field mainly modifies the potential difference between the graphene layers, which perfectly correlates with the orbital gap for fields up to about 1~V/nm. Moreover, the layer-resolved Rashba couplings are tunable by $\sim 5~\mu$eV per V/nm. Finally, by investigating twisted BLG/hBN structures, with twist angles between 6$^{\circ}$ -- 20$^{\circ}$, we find that the global band gap increases linearly with the twist angle. The extrapolated $0^{\circ}$ band gap is about 23~meV and results roughly from the average of the stacking-dependent local band gaps. Our investigations give new insights into proximity spin physics of hBN/BLG heterostructures, which should be useful for interpreting experiments on extended as well as confined (quantum dot) systems. ",https://doi.org/10.1103/PhysRevB.108.125126,2307.11697v2,Yes,potent(1)
0000-0002-6239-3271,Klaus Zollner,Universität Regensburg,"Graphene on two-dimensional hexagonal BN, AlN, and GaN: Electronic,   spin-orbit, and spin relaxation properties",1970,"  We investigate the electronic structure of graphene on a series of 2D hexagonal nitride insulators hXN, X = B, Al, and Ga, with DFT calculations. A symmetry-based model Hamiltonian is employed to extract orbital parameters and spin-orbit coupling (SOC) from the low-energy Dirac bands of proximitized graphene. While commensurate hBN induces a staggered potential of about 10 meV into the Dirac bands, less lattice-matched hAlN and hGaN disrupt the Dirac point much less, giving a staggered gap below 100 $\mu$eV. Proximitized intrinsic SOC surprisingly does not increase much above the pristine graphene value of 12 $\mu$eV; it stays in the window of (1-16) $\mu$eV, depending strongly on stacking. However, Rashba SOC increases sharply when increasing the atomic number of the boron group, with calculated maximal values of 8, 15, and 65 $\mu$eV for B, Al, and Ga-based nitrides, respectively. The individual Rashba couplings also depend strongly on stacking, vanishing in symmetrically-sandwiched structures, and can be tuned by a transverse electric field. The extracted spin-orbit parameters were used as input for spin transport simulations based on Chebyshev expansion of the time-evolution of the spin expectation values, yielding interesting predictions for the electron spin relaxation. Spin lifetime magnitudes and anisotropies depend strongly on the specific (hXN)/graphene/hXN system, and they can be efficiently tuned by an applied external electric field as well as the carrier density in the graphene layer. A particularly interesting case for experiments is graphene/hGaN, in which the giant Rashba coupling is predicted to induce spin lifetimes of 1-10 ns, short enough to dominate over other mechanisms, and lead to the same spin relaxation anisotropy as observed in conventional semiconductor heterostructures: 50\%, meaning that out-of-plane spins relax twice as fast as in-plane spins. ",https://doi.org/10.1103/PhysRevB.103.075129,2011.14588v2,Yes,potent(1)
0000-0002-6239-3271,Klaus Zollner,Universität Regensburg,Scattering-induced and highly tunable by gate damping-like spin-orbit   torque in graphene doubly proximitized by two-dimensional magnet   Cr$_2$Ge$_2$Te$_6$ and WS$_2$,1970,"  Graphene sandwiched between semiconducting monolayers of ferromagnet Cr$_2$Ge$_2$Te$_6$ and transition-metal dichalcogenide WS$_2$ acquires both spin-orbit (SO), of valley-Zeeman and Rashba types, and exchange couplings. Using first-principles combined with quantum transport calculations, we predict that such doubly proximitized graphene within van der Waals heterostructure will exhibit SO torque driven by unpolarized charge current. This system lacking spin Hall current, putatively considered to be necessary for efficient damping-like (DL) SO torque that plays a key role in magnetization switching, demonstrates how DL torque component can be generated solely by skew-scattering off spin-independent potential barrier or impurities in purely two-dimensional electronic transport due to the presence of proximity SO coupling and its spin texture tilted out-of-plane. This leads to current-driven nonequilibrium spin density emerging in all spatial directions, whose cross product with proximity magnetization yields DL SO torque, unlike the ballistic regime with no scatterers in which only field-like (FL) SO torque appears. In contrast to SO torque on conventional metallic ferromagnets in contact with three dimensional SO-coupled materials, the ratio of FL and DL torque can be tuned by more than an order of magnitude via combined top and back gates. ",https://doi.org/10.1103/PhysRevResearch.2.043057,1910.08072v3,Yes,potent(1)
0000-0002-6239-3271,Klaus Zollner,Universität Regensburg,Layer-selective spin-orbit coupling and strong correlation in bilayer   graphene,1970,"  Spin-orbit coupling (SOC) and electron-electron interaction can mutually influence each other and give rise to a plethora of intriguing phenomena in condensed matter systems. In pristine bilayer graphene, which has weak SOC, intrinsic Lifshitz transitions and concomitant van-Hove singularities lead to the emergence of many-body correlated phases. Layer-selective SOC can be proximity induced by adding a layer of tungsten diselenide (WSe2) on its one side. By applying an electric displacement field, the system can be tuned across a spectrum wherein electronic correlation, SOC, or a combination of both dominates. Our investigations reveal an intricate phase diagram of proximity-induced SOC-selective bilayer graphene. Not only does this phase diagram include those correlated phases reminiscent of SOC-free doped bilayer graphene, but it also hosts unique SOC-induced states allowing a compelling measurement of valley g-factor and a seemingly impossible correlated insulator at charge neutrality, thereby showcasing the remarkable tunability of the interplay between interaction and SOC in WSe2 enriched bilayer graphene. ",Kein DOI-Link verfügbar,2403.17140v1,Yes,intricate(1)
0000-0002-6342-1799,Ralf Hielscher,TU Bergakademie Freiberg,Parent grain reconstruction from partially or fully transformed   microstructures in MTEX,1970,"  A versatile generic framework for parent grain reconstruction from fully or partially transformed child microstructures was integrated into the open-source crystallographic toolbox MTEX. The framework extends traditional parent grain reconstruction, phase transformation and variant analysis to all parent-child crystal symmetry combinations. The inherent versatility of the universally applicable parent grain reconstruction methods, and the ability to conduct in-depth variant analysis are showcased via example workflows that can be programmatically modified by users to suit their specific applications. This is highlighted by three applications namely, $\alpha$-to-$\gamma$ reconstruction in a lath martensitic steel, $\alpha$-to-$\beta$ reconstruction in a Ti alloy, and a two-step reconstruction from $\alpha$-to-$\varepsilon$-to-$\gamma$ in a twinning and transformation -induced plasticity steel. Advanced orientation relationship discovery and analysis options, including variant analysis, is demonstrated via the add-on function library, ORTools. ",Kein DOI-Link verfügbar,2104.14603v1,Yes,versatile(1)
0000-0002-6342-1799,Ralf Hielscher,TU Bergakademie Freiberg,The variant graph approach to improved parent grain reconstruction,1970,"  The variant graph is a new, hybrid algorithm that combines the strengths of established global grain graph and local neighbor level voting approaches, while alleviating their shortcomings, to reconstruct parent grains from orientation maps of partially or fully phase-transformed microstructures. The variant graph algorithm is versatile and is capable of reconstructing transformation microstructures from any parent-child combination by clustering together child grains based on a common parent orientation variant. The main advantage of the variant graph over the grain graph is its inherent ability to more accurately detect prior austenite grain boundaries.   A critical examination of Markovian clustering and neighbor level voting as methods to reconstruct prior austenite orientations is first conducted. Following this, the performance of the variant graph algorithm is showcased by reconstructing the prior austenite grains and boundaries from an example low-carbon lath martensite steel microstructure. Programmatic extensions to the variant graph algorithm for specific morphological conditions and the merging of variants with small mutual disorientation angles are also proposed. The accuracy of the reconstruction and the computational performance of the variant graph algorithm is either on-par or outperforms alternate methods for parent grain reconstruction.   The variant graph algorithm is implemented as a new addition to the functionalities for phase transformation analysis in MTEX 5.8 and is freely available for download by the community. ",Kein DOI-Link verfügbar,2201.02103v1,Yes,versatile(1)
0000-0002-6396-3408,Hongri Gu,Universität Konstanz,Counterfactual rewards promote collective transport using individually   controlled swarm microrobots,1970,"  Swarm robots offer fascinating opportunities to perform complex tasks beyond the capabilities of individual machines. Just as a swarm of ants collectively moves a large object, similar functions can emerge within a group of robots through individual strategies based on local sensing. However, realizing collective functions with individually controlled microrobots is particularly challenging due to their micrometer size, large number of degrees of freedom, strong thermal noise relative to the propulsion speed, complex physical coupling between neighboring microrobots, and surface collisions. Here, we implement Multi-Agent Reinforcement Learning (MARL) to generate a control strategy for up to 200 microrobots whose motions are individually controlled by laser spots. During the learning process, we employ so-called counterfactual rewards that automatically assign credit to the individual microrobots, which allows for fast and unbiased training. With the help of this efficient reward scheme, swarm microrobots learn to collectively transport a large cargo object to an arbitrary position and orientation, similar to ant swarms. We demonstrate that this flexible and versatile swarm robotic system is robust to variations in group size, the presence of malfunctioning units, and environmental noise. Such control strategies can potentially enable complex and automated assembly of mobile micromachines, programmable drug delivery capsules, and other advanced lab-on-a-chip applications. ",Kein DOI-Link verfügbar,2407.20041v1,Yes,"versatile(1), potent(1)"
0000-0002-6448-6914,Frank Daschner,Christian-Albrechts-Universität zu Kiel,Estimation of the Soil Water Characteristics from Dielectric Relaxation   Spectra -- a Machine Learning Approach,1970,"  The frequency dependence of dielectric material properties of water saturated and unsaturated porous materials such as soil is not only disturbing in applications with high frequency electromagnetic (HF-EM) techniques but also contains valuable information of the material due to strong contributions by interactions between the aqueous pore solution and mineral phases. Hence, broadband HF-EM sensor techniques enable the estimation of soil physico-chemical parameters such as water content, texture, mineralogy, cation exchange capacity and matric potential. In this context, a multivariate (MV) machine learning approach (principal component regression, partial least squares regression, artificial neural networks) was applied to estimate the Soil Water Characteristic Curve (SWCC) from experimentally determined dielectric relaxation spectra of a silty clay soil. The results of the MV-approach were compared with results obtained from empirical equations and theoretical models as well as a novel hydraulic/electromagnetic coupling approach. The applied MV-approach gives evidence, (i) of a physical relationship between soil dielectric relaxation behavior and soil water characteristics as an important hydraulic material property and (ii) the applicability of appropriate sensor techniques for the estimation of physico-chemical parameters of porous media from broadband measured dielectric spectra. ",https://doi.org/10.1109/SAS.2014.6798954,2406.15756v1,Yes,potent(1)
0000-0002-6459-1204,Felix Maurer,Universität des Saarlandes,Deposit of Red Blood Cells at low concentrations in evaporating   droplets: central edge growth and potential applications,1970,"  Evaporation of blood droplets and diluted blood samples is a topic of intensive research, as it is seen as a possible low-cost tool for diagnosis. So far, samples with volume fraction down to a few percents of Red Blood Cells (RBCs) have been studied, and those were reportedly dominated by a ``coffee-ring'' deposit. In this study, samples with lower volume fractions have been used in order to study the growth of the evaporative deposit from sessile droplets more in details. We observed that blood samples and salt solutions with less than 1\% volume fraction of RBCs are dominated by a central deposit. We characterized the growth process of this central deposit by evaporating elongated drops, and determined that it is consistent with the Kardar-Parisi-Zhang process in the presence of quenched disorder. Our results showed a sensitivity of this deposit size to the fibrinogen concentration and shape of the RBCs, meaning that this parameter could be used to develop a new and cost-effective clinical marker for inflammation and RBC deformation. ",Kein DOI-Link verfügbar,2406.19826v1,Yes,reportedly(1)
0000-0002-6524-9267,Stefano Ponzoni,Technische Universität Dortmund,Extremely low energy ARPES of quantum well states in cubic-GaN/AlN and   GaAs/GaAlAs heterostructures,1970,"  Quantum well (QW) heterostructures have been extensively used for the realization of a wide range of optical and electronic devices. Exploiting their potential for further improvement and development requires a fundamental understanding of their electronic structure. So far, the most commonly used experimental techniques for this purpose have been all-optical spectroscopy methods that, however, are generally averaged in momentum space. Additional information can be gained by angle-resolved photoelectron spectroscopy (ARPES), which measures the electronic structure with momentum resolution. Here we report on the use of extremely low energy ARPES (photon energy $\sim$ 7 eV) to increase its depth sensitivity and access buried QW states, located at 3 nm and 6 nm below the surface of cubic-GaN/AlN and GaAs/AlGaAs heterostructures, respectively. We find that the QW states in cubic-GaN/AlN can indeed be observed, but not their energy dispersion because of the high surface roughness. The GaAs/AlGaAs QW states, on the other hand, are buried too deep to be detected by extremely low energy ARPES. Since the sample surface is much flatter, the ARPES spectra of the GaAs/AlGaAs show distinct features in momentum space, which can be reconducted to the band structure of the topmost surface layer of the QW structure. Our results provide important information about the samples' properties required to perform extremely low energy ARPES experiments on electronic states buried in semiconductor heterostructures. ",Kein DOI-Link verfügbar,2105.05166v1,Yes,potent(1)
0000-0002-6524-9267,Stefano Ponzoni,Technische Universität Dortmund,Metalloporphyrins on Oxygen-Passivated Iron: Conformation and Order   Beyond the First Layer,1970,"  On-surface metal porphyrins can undergo electronic and conformational changes that play a crucial role in determining the chemical reactivity of the molecular layer. Therefore, understanding those properties is pivotal for the design and implementation of organic-based devices. Here, by means of photoemission orbital tomography supported by density functional theory calculations, we investigate the electronic and geometrical structure of two metallated tetraphenyl porphyrins (MTPPs), namely ZnTPP and NiTPP, adsorbed on the oxygen-passivated Fe(100)-p(1x1)O surface. Both molecules weakly interact with the surface as no charge transfer is observed. In the case of ZnTPP our data correspond to those of moderately distorted molecules, while NiTPP exhibits a severe saddle-shape deformation. From additional experiments on NiTPP multilayer films, we conclude that this distortion is a consequence of the interaction with the substrate, as the NiTPP macrocycle of the second layer turns out to be flat. We further find that distortions in the MTPP macrocycle are accompanied by an increasing energy gap between the highest occupied molecular orbitals (HOMO and HOMO-1). Our results demonstrate that photoemission orbital tomography can simultaneously probe the energy level alignment, the azimuthal orientation, and the adsorption geometry of complex aromatic molecules even in the multilayer regime. ",https://doi.org/10.1016/j.ica.2023.121705,2304.13331v2,Yes,pivotal(1)
0000-0002-6606-4352,Helmut Abels,Universität Regensburg,"Strong Well-Posedness of a Diffuse Interface Model for a Viscous,   Quasi-Incompressible Two-Phase Flow",1970,"  We study a diffuse interface model for the flow of two viscous incompressible Newtonian fluids in a bounded domain. The fluids are assumed to be macroscopically immiscible, but a partial mixing in a small interfacial region is assumed in the model. Moreover, diffusion of both components is taken into account. In contrast to previous works, we study a model for the general case that the fluids have different densities due to Lowengrub and Truskinovski. This leads to an inhomogeneous Navier-Stokes system coupled to a Cahn-Hilliard system, where the density of the mixture depends on the concentration, the velocity field is no longer divergence free, and the pressure enters the equation for the chemical potential. We prove existence of unique strong solutions for the non-stationary system for sufficiently small times. ",Kein DOI-Link verfügbar,1103.6211v1,Yes,potent(1)
0000-0002-6606-4352,Helmut Abels,Universität Regensburg,Fractional-Order Operators on Nonsmooth Domains,1970,"  The fractional Laplacian $(-\Delta )^a$, $a\in(0,1)$, and its generalizations to variable-coefficient $2a$-order pseudodifferential operators $P$, are studied in $L_q$-Sobolev spaces of Bessel-potential type $H^s_q$. For a bounded open set $\Omega \subset \mathbb R^n$, consider the homogeneous Dirichlet problem: $Pu =f$ in $\Omega $, $u=0$ in $ \mathbb R^n\setminus\Omega $. We find the regularity of solutions and determine the exact Dirichlet domain $D_{a,s,q}$ (the space of solutions $u$ with $f\in H_q^s(\overline\Omega )$) in cases where $\Omega $ has limited smoothness $C^{1+\tau }$, for $2a<\tau <\infty $, $0\le s<\tau -2a$. Earlier, the regularity and Dirichlet domains were determined for smooth $\Omega$ by the second author, and the regularity was found in low-order H\""older spaces for $\tau =1$ by Ros-Oton and Serra. The $H_q^s$-results obtained now when $\tau <\infty $ are new, even for $(-\Delta )^a$. In detail, the spaces $D_{a,s,q}$ are identified as $a$-transmission spaces $H_q^{a(s+2a)}(\overline\Omega )$, exhibiting estimates in terms of $\operatorname{dist}(x,\partial\Omega )^a$ near the boundary. The result has required a new development of methods to handle nonsmooth coordinate changes for pseudodifferential operators, which have not been available before; this constitutes another main contribution of the paper. ",https://doi.org/10.1112/jlms.12712,2004.10134v4,Yes,potent(1)
0000-0002-6606-4352,Helmut Abels,Universität Regensburg,Global regularity and asymptotic stabilization for the incompressible   Navier-Stokes-Cahn-Hilliard model with unmatched densities,1970,"  We study an initial-boundary value problem for the incompressible Navier-Stokes-Cahn-Hilliard system with non-constant density proposed by Abels, Garcke and Gr\""{u}n in 2012. This model arises in the diffuse interface theory for binary mixtures of viscous incompressible fluids. This system is a generalization of the well-known model H in the case of fluids with unmatched densities. In three dimensions, we prove that any global weak solution (for which uniqueness is not known) exhibits a propagation of regularity in time and stabilizes towards an equilibrium state as $t \rightarrow \infty$. More precisely, the concentration function $\phi$ is a strong solution of the Cahn-Hilliard equation for (arbitrary) positive times, whereas the velocity field $\mathbf{u}$ becomes a strong solution of the momentum equation for large times. Our analysis hinges upon the following key points: a novel global regularity result (with explicit bounds) for the Cahn-Hilliard equation with divergence-free velocity belonging only to $L^2(0,\infty; \mathbf{H}^1_{0,\sigma}(\Omega))$, the energy dissipation of the system, the separation property for large times, a weak-strong uniqueness type result, and the Lojasiewicz-Simon inequality. Additionally, in two dimensions, we show the existence and uniqueness of global strong solutions for the full system. Finally, we discuss the existence of global weak solutions for the case of the double obstacle potential. ",Kein DOI-Link verfügbar,2209.10836v2,Yes,potent(1)
0000-0002-6606-4352,Helmut Abels,Universität Regensburg,Cahn-Hilliard Equation with Nonlocal Singular Free Energies,1970,"  We consider a Cahn-Hilliard equation which is the conserved gradient flow of a nonlocal total free energy functional. This functional is characterized by a Helmholtz free energy density, which can be of logarithmic type. Moreover, the spatial interactions between the different phases are modeled by a singular kernel. As a consequence, the chemical potential $\mu$ contains an integral operator acting on the concentration difference $c$, instead of the usual Laplace operator. We analyze the equation on a bounded domain subject to no-flux boundary condition for $\mu$ and by assuming constant mobility. We first establish the existence and uniqueness of a weak solution and some regularity properties. These results allow us to define a dissipative dynamical system on a suitable phase-space and we prove that such a system has a (connected) global attractor. Finally, we show that a Neumann-like boundary condition can be recovered for $c$, provided that it is supposed to be regular enough. ",Kein DOI-Link verfügbar,1311.3642v1,Yes,potent(1)
0000-0002-6606-4352,Helmut Abels,Universität Regensburg,Diffuse Interface Model for Two-Phase Flows on Evolving Surfaces with   Different Densities: Local Well-Posedness,1970,"  A Cahn-Hilliard-Navier-Stokes system for two-phase flow on an evolving surface with non-matched densities is derived using methods from rational thermodynamics. For a Cahn-Hilliard energy with a singular (logarithmic) potential short time well-posedness of strong solutions together with a separation property is shown, under the assumption of a priori prescribed surface evolution. The problem is reformulated with the help of a pullback to the initial surface. Then a suitable linearization and a contraction mapping argument for the pullback system are used. In order to deal with the linearized system, it is necessary to show maximal $L^2$-regularity for the surface Stokes operator in the case of variable viscosity and to obtain maximal $L^p$-regularity for the linearized Cahn-Hilliard system. ",Kein DOI-Link verfügbar,2407.14941v1,Yes,potent(1)
0000-0002-6606-4352,Helmut Abels,Universität Regensburg,Diffuse Interface Model for Two-Phase Flows on Evolving Surfaces with   Different Densities: Global Well-Posedness,1970,  We show existence and uniqueness of strong solutions to a Navier-Stokes/Cahn-Hilliard type system on a given two-dimensional evolving surface in the case of different densities and a singular (logarithmic) potential. The system describes a diffuse interface model for a two-phase flow of viscous incompressible fluids on an evolving surface. We also establish the validity of the instantaneous strict separation property from the pure phases. To show these results we use our previous achievements on local well-posedness together with suitable novel regularity results for the convective Cahn-Hilliard equation. The latter allows to obtain higher-order energy estimates to extend the local solution globally in time. To this aim the time evolution of energy type quantities has to be calculated and estimated carefully. ,Kein DOI-Link verfügbar,2408.07449v1,Yes,potent(1)
0000-0002-6631-4868,Sergei Ivanov,Universität Rostock,High-Order Optimization of Gradient Boosted Decision Trees,1970,"  Gradient Boosted Decision Trees (GBDTs) are dominant machine learning algorithms for modeling discrete or tabular data. Unlike neural networks with millions of trainable parameters, GBDTs optimize loss function in an additive manner and have a single trainable parameter per leaf, which makes it easy to apply high-order optimization of the loss function. In this paper, we introduce high-order optimization for GBDTs based on numerical optimization theory which allows us to construct trees based on high-order derivatives of a given loss function. In the experiments, we show that high-order optimization has faster per-iteration convergence that leads to reduced running time. Our solution can be easily parallelized and run on GPUs with little overhead on the code. Finally, we discuss future potential improvements such as automatic differentiation of arbitrary loss function and combination of GBDTs with neural networks. ",Kein DOI-Link verfügbar,2211.11367v1,Yes,potent(1)
0000-0002-6631-4868,Sergei Ivanov,Universität Rostock,Multilingual Disinformation Detection for Digital Advertising,1970,"  In today's world, the presence of online disinformation and propaganda is more widespread than ever. Independent publishers are funded mostly via digital advertising, which is unfortunately also the case for those publishing disinformation content. The question of how to remove such publishers from advertising inventory has long been ignored, despite the negative impact on the open internet. In this work, we make the first step towards quickly detecting and red-flagging websites that potentially manipulate the public with disinformation. We build a machine learning model based on multilingual text embeddings that first determines whether the page mentions a topic of interest, then estimates the likelihood of the content being malicious, creating a shortlist of publishers that will be reviewed by human experts. Our system empowers internal teams to proactively, rather than defensively, blacklist unsafe content, thus protecting the reputation of the advertisement provider. ",Kein DOI-Link verfügbar,2207.10649v1,Yes,potent(1)
0000-0002-6709-9987,Christian Hoffmann,Technische Universität Bergakademie Freiberg,Boson Stars with Nontrivial Topology,1970,"  We construct boson star solutions in the presence of a phantom field, allowing for a nontrivial topology of the solutions. The wormholes residing at the core of the configurations lead to a number of qualitative changes of the boson star solutions. In particular, the typical spiraling dependence of the mass and the particle number on the frequency of the boson stars is lost. Instead, the boson stars with nontrivial topology approach a singular configuration in the limit of vanishing frequency. Depending on the value of the coupling constant, the wormhole geometry changes from a single throat configuration to a double throat configuration, featuring a belly inbetween the two throats. Depending on the mass of the boson field and its self-interaction, the mass and the size of these objects cover many orders of magnitude, making them amenable to various astrophysical observations. A stability analysis reveals, that the unstable mode of the Ellis wormhole is retained in the presence of the bosonic matter. However, the negative eigenvalue can get very close to zero, by tuning the parameters of the self-interaction potential appropriately. ",https://doi.org/10.1103/PhysRevD.90.124038,1409.6978v1,Yes,potent(1)
0000-0002-6774-2493,Florian Weber,Technische Universität Dortmund,What If Your Car Would Care? Exploring Use Cases For Affective   Automotive User Interfaces,1970,"  In this paper we present use cases for affective user interfaces (UIs) in cars and how they are perceived by potential users in China and Germany. Emotion-aware interaction is enabled by the improvement of ubiquitous sensing methods and provides potential benefits for both traffic safety and personal well-being. To promote the adoption of affective interaction at an international scale, we developed 20 mobile in-car use cases through an inter-cultural design approach and evaluated them with 65 drivers in Germany and China. Our data shows perceived benefits in specific areas of pragmatic quality as well as cultural differences, especially for socially interactive use cases. We also discuss general implications for future affective automotive UI. Our results provide a perspective on cultural peculiarities and a concrete starting point for practitioners and researchers working on emotion-aware interfaces. ",https://doi.org/10.1145/3379503.3403530,2004.02481v1,Yes,potent(2)
0000-0002-6879-9467,Thomas Hummel,Karlsruher Institut für Technologie,Optical Bias and Cryogenic Laser Readout of a Multipixel Superconducting   Nanowire Single Photon Detector,1970,"  Cryogenic opto-electronic interconnects are gaining increasing interest as a means to control and read out cryogenic electronic components. The challenge is to achieve sufficient signal integrity with low heat load processing. In this context, we demonstrate the opto-electronic bias and readout of a commercial four-pixel superconducting nanowire single-photon detector array using a cryogenic photodiode and laser. We show that this approach has a similar system detection efficiency to a conventional bias. Furthermore, multi-pixel detection events are faithfully converted between the optical and electrical domain, which allows reliable extraction of amplitude multiplexed photon statistics. Our device has a passive heat dissipation of 2.6mW, maintains the signal rise time of 3ns, and operates in free-running (self-resetting) mode at a repetition rate of 600kHz. This demonstrates the potential of high-bandwidth, low noise, and low heat load opto-electronic interconnects for scalable cryogenic signal processing and transmission. ",Kein DOI-Link verfügbar,2403.14276v1,Yes,potent(1)
0000-0002-6879-9467,Thomas Hummel,Karlsruher Institut für Technologie,All optical operation of a superconducting photonic interface,1970,"  Advanced electro-optic processing combines electrical control with optical modulation and detection. For quantum photonic applications these processes must be carried out at the single photon level with high efficiency and low noise. Integrated quantum photonics has made great strides achieving single photon manipulation by combining key components on integrated chips which are operated by external driving electronics. Nevertheless, electrical interconnects between driving electronics and the electro-optic components, some of which require cryogenic operating conditions, can introduce parasitic effects. Here we show an all-optical interface which simultaneously delivers the operation power to, and extracts the measurement signal from, an advanced photonic circuit, namely, bias and readout of a superconducting nanowire single photon detector (SNSPD) on a single stage in a 1K cryostat. To do so, we supply all power for the single photon detector, output signal conditioning, and electro-optic readout using optical interconnects alone, thereby fully decoupling the cryogenic circuitry from the external environment. This removes the need to heatsink electrical connections, and potentially offers low-loss, high-bandwidth signal processing. This method opens the possibility to operate other advanced electrically decoupled photonic circuits such as optical control and readout of superconducting circuits, and feedforward for photonic quantum computing. ",Kein DOI-Link verfügbar,2302.12123v1,Yes,potent(1)
0000-0002-6901-5265,Ruikun Hou,Universität Tübingen,Automated Assessment of Encouragement and Warmth in Classrooms   Leveraging Multimodal Emotional Features and ChatGPT,1970,"  Classroom observation protocols standardize the assessment of teaching effectiveness and facilitate comprehension of classroom interactions. Whereas these protocols offer teachers specific feedback on their teaching practices, the manual coding by human raters is resource-intensive and often unreliable. This has sparked interest in developing AI-driven, cost-effective methods for automating such holistic coding. Our work explores a multimodal approach to automatically estimating encouragement and warmth in classrooms, a key component of the Global Teaching Insights (GTI) study's observation protocol. To this end, we employed facial and speech emotion recognition with sentiment analysis to extract interpretable features from video, audio, and transcript data. The prediction task involved both classification and regression methods. Additionally, in light of recent large language models' remarkable text annotation capabilities, we evaluated ChatGPT's zero-shot performance on this scoring task based on transcripts. We demonstrated our approach on the GTI dataset, comprising 367 16-minute video segments from 92 authentic lesson recordings. The inferences of GPT-4 and the best-trained model yielded correlations of r = .341 and r = .441 with human ratings, respectively. Combining estimates from both models through averaging, an ensemble approach achieved a correlation of r = .513, comparable to human inter-rater reliability. Our model explanation analysis indicated that text sentiment features were the primary contributors to the trained model's decisions. Moreover, GPT-4 could deliver logical and concrete reasoning as potential teacher guidelines. Our findings provide insights into using advanced, multimodal techniques for automated classroom observation, aiming to foster teacher training through frequent and valuable feedback. ",https://doi.org/10.1007/978-3-031-64302-6_5,2404.15310v1,Yes,potent(1)
0000-0002-7044-7532,Marc Scheffler,Universität Stuttgart,Tuning the superconducting dome in granular aluminum thin films,1970,"  Granular aluminum, which consists of nanometer-sized aluminum grains separated by aluminum oxide, is a peculiar superconductor. Its phase diagram as function of normal-state resistivity features a superconducting dome with a maximum critical temperature Tc well above the Tc = 1.2 K of pure aluminum. Here we show how the maximum Tc of this superconducting dome grows if the substrate temperature during deposition is lowered from 300 K to cooling with liquid nitrogen (150 K and 100 K) and liquid helium (25 K). The highest Tc we observe is 3.27 K. These results highlight that granular aluminum is a model system for complex phase diagrams of superconductors and demonstrate its potential in the context of high kinetic inductance applications. This is augmented by our observation of comparably sharp superconducting transitions of high-resistivity samples grown at cryogenic temperatures and by a thickness dependence even for films substantially thicker than the grain size. ",Kein DOI-Link verfügbar,2408.15477v1,Yes,potent(1)
0000-0002-7044-7532,Marc Scheffler,Universität Stuttgart,Observing electron spin resonance between 0.1 and 67 GHz at temperatures   between 50 mK and 300 K using broadband metallic coplanar waveguides,1970,"  We describe a fully broadband approach for electron spin resonance (ESR) experiments where it is possible to not only tune the magnetic field but also the frequency continuously over wide ranges. Here a metallic coplanar transmission line acts as compact and versatile microwave probe that can easily be implemented in different cryogenic setups. We perform ESR measurements at frequencies between 0.1 and 67 GHz and at temperatures between 50 mK and room temperature. Three different types of samples (Cr3+ ions in ruby, organic radicals of the nitronyl-nitroxide family, and the doped semiconductor Si:P) represent different possible fields of application for the technique. We demonstrate that an extremely large phase space in temperature, magnetic field, and frequency for ESR measurements, substantially exceeding the range of conventional ESR setups, is accessible with metallic coplanar lines. ",https://doi.org/10.1063/1.4921231,1505.06105v1,Yes,versatile(1)
0000-0002-7044-7532,Marc Scheffler,Universität Stuttgart,Gapped magnetic ground state in quantum-spin-liquid candidate   $κ$-(BEDT-TTF)$_2$-Cu$_2$(CN)$_3$,1970,"  Geometrical frustration, quantum entanglement and disorder may prevent long-range order of localized spins with strong exchange interactions, resulting in a novel state of matter. $\kappa$-(BEDT-TTF)$_2$-Cu$_2$(CN)$_3$ is considered the best approximation of this elusive quantum-spin-liquid state, but its ground-state properties remain puzzling. Here we present a multi-frequency electron-spin resonance study down to millikelvin temperatures, revealing a rapid drop of the spin susceptibility at $T^*=6\,\mathrm{K}$. This opening of a spin gap, accompanied by structural modifications, suggests the enigmatic `$6\,\mathrm{K}$-anomaly' as the transition to a valence-bond-solid ground state. We identify an impurity contribution that becomes dominant when the intrinsic spins form singlets. Only probing the electrons directly manifests the pivotal role of defects for the low-energy properties of quantum-spin systems without magnetic order. ",https://doi.org/10.1126/science.abc6363,2010.16155v1,Yes,pivotal(1)
0000-0002-7078-3472,Xiaoli Ma,Eberhard Karls Universität Tübingen,Channel Estimation for Extremely Large-Scale Massive MIMO Systems,1970,"  Extremely large-scale massive multiple-input multiple-output (MIMO) has shown considerable potential in future mobile communications. However, the use of extremely large aperture arrays has led to near-field and spatial non-stationary channel conditions, which result in changes to transceiver design and channel state information that should be acquired. This letter focuses on the channel estimation problem and describes the non-stationary channel through mapping between subarrays and scatterers. We propose subarray-wise and scatterer-wise channel estimation methods to estimate the near-field non-stationary channel from the view of subarray and scatterer, respectively. Numerical results demonstrate that subarray-wise method can derive accurate channel estimation results with low complexity, whereas the scatterer-wise method can accurately position the scatterers and identify almost all the mappings between subarrays and scatterers. ",Kein DOI-Link verfügbar,1910.05432v1,Yes,potent(1)
0000-0002-7078-3472,Xiaoli Ma,Eberhard Karls Universität Tübingen,Observation of Emergent Superconductivity in the Quantum Spin Hall   Insulator Ta2Pd3Te5 via Pressure Manipulation,1970,"  Quantum Spin Hall (QSH) insulators possess distinct helical in-gap states, enabling their edge states to act as one-dimensional conducting channels when backscattering is prohibited by time-reversal symmetry. However, it remains challenging to achieve high-performance combinations of nontrivial topological QSH states with superconductivity for applications and requires understanding of the complicated underlying mechanisms. Here, our experimental observations for a novel superconducting phase in the pressurized QSH insulator Ta2Pd3Te5 is reported, and the high-pressure phase maintains its original ambient pressure lattice symmetry up to 45 GPa. Our in-situ high-pressure synchrotron X-ray diffraction, electrical transport, infrared reflectance, and Raman spectroscopy measurements, in combination with rigorous theoretical calculations, provide compelling evidence for the association between the superconducting behavior and the abnormal densified phase. The isostructural transition was found to modify the topology of the Fermi surface directly, accompanied by a fivefold amplification of the density of states at 20 GPa compared to ambient pressure, which synergistically fosters the emergence of robust superconductivity. A profound comprehension of the fascinating properties exhibited by the compressed Ta2Pd3Te5 phase is achieved, highlighting the extraordinary potential of van der Waals (vdW) QSH insulators for exploring and investigating high-performance electronic advanced devices under extreme conditions. ",Kein DOI-Link verfügbar,2310.05532v1,Yes,potent(1)
0000-0002-7183-9239,Philipp Bach,Universität Hamburg,Valid Simultaneous Inference in High-Dimensional Settings (with the hdm   package for R),1970,"  Due to the increasing availability of high-dimensional empirical applications in many research disciplines, valid simultaneous inference becomes more and more important. For instance, high-dimensional settings might arise in economic studies due to very rich data sets with many potential covariates or in the analysis of treatment heterogeneities. Also the evaluation of potentially more complicated (non-linear) functional forms of the regression relationship leads to many potential variables for which simultaneous inferential statements might be of interest. Here we provide a review of classical and modern methods for simultaneous inference in (high-dimensional) settings and illustrate their use by a case study using the R package hdm. The R package hdm implements valid joint powerful and efficient hypothesis tests for a potentially large number of coeffcients as well as the construction of simultaneous confidence intervals and, therefore, provides useful methods to perform valid post-selection inference based on the LASSO. ",Kein DOI-Link verfügbar,1809.04951v1,Yes,potent(4)
0000-0002-7183-9239,Philipp Bach,Universität Hamburg,DoubleMLDeep: Estimation of Causal Effects with Multimodal Data,1970,"  This paper explores the use of unstructured, multimodal data, namely text and images, in causal inference and treatment effect estimation. We propose a neural network architecture that is adapted to the double machine learning (DML) framework, specifically the partially linear model. An additional contribution of our paper is a new method to generate a semi-synthetic dataset which can be used to evaluate the performance of causal effect estimation in the presence of text and images as confounders. The proposed methods and architectures are evaluated on the semi-synthetic dataset and compared to standard approaches, highlighting the potential benefit of using text and images directly in causal studies. Our findings have implications for researchers and practitioners in economics, marketing, finance, medicine and data science in general who are interested in estimating causal quantities using non-traditional data. ",Kein DOI-Link verfügbar,2402.01785v1,Yes,potent(1)
0000-0002-7187-9126,Randolf Klein,Friedrich-Schiller-Universität Jena,Massive star formation around I05345+3157 -- I. The dense gas,1970,"  We present observations of the intermediate to massive star-forming region I05345+3157 using the molecular line tracer CS(2-1) with CARMA to reveal the properties of the dense gas cores. Seven gas cores are identified in the integrated intensity map of CS(2-1). Among these, core 1 and core 3 have counterparts in the 2.7 millimeter continuum data. We suggest that core 1 and core 3 are star-forming cores that may already or will very soon harbor young massive protostars. The total masses of core 1 estimated from the LTE method and dust emission by assuming a gas-to-dust ratio are 5 +- 1 solar masses and 18 +- 6 solar masses, and that of core 3 are 15 +- 7 solar masses and 11 +- 3 solar masses. The spectrum of core 3 shows blue-skewed self-absorption, which suggests gas infall -- a collapsing core. The observed broad linewidths of the seven gas cores indicate non-thermal motions. These non-thermal motions can be interactions with nearby outflows or due to the initial turbulence; the former is observed, while the role of initial turbulence is less certain. Finally, the virial masses of the gas cores are larger than the LTE masses, which for a bound core implies a requirement on the external pressure of ~ 10^8 K/cm^3. The cores have the potential to further form massive stars. ",https://doi.org/10.1111/j.1365-2966.2011.18897.x,1107.1224v1,Yes,potent(1)
0000-0002-7269-5433,Katja Steiger,Technische Universität München,Deep Learning Under the Microscope: Improving the Interpretability of   Medical Imaging Neural Networks,1970,"  In this paper, we propose a novel interpretation method tailored to histological Whole Slide Image (WSI) processing. A Deep Neural Network (DNN), inspired by Bag-of-Features models is equipped with a Multiple Instance Learning (MIL) branch and trained with weak supervision for WSI classification. MIL avoids label ambiguity and enhances our model's expressive power without guiding its attention. We utilize a fine-grained logit heatmap of the models activations to interpret its decision-making process. The proposed method is quantitatively and qualitatively evaluated on two challenging histology datasets, outperforming a variety of baselines. In addition, two expert pathologists were consulted regarding the interpretability provided by our method and acknowledged its potential for integration into several clinical applications. ",Kein DOI-Link verfügbar,1904.03127v2,Yes,potent(1)
0000-0002-7297-0845,Tatjana Legler,"Rheinland-Pfälzische Technische Universität Kaiserslautern-Landau, Technische Universität Kaiserslautern",Seamless Integration: Sampling Strategies in Federated Learning Systems,1970,"  Federated Learning (FL) represents a paradigm shift in the field of machine learning, offering an approach for a decentralized training of models across a multitude of devices while maintaining the privacy of local data. However, the dynamic nature of FL systems, characterized by the ongoing incorporation of new clients with potentially diverse data distributions and computational capabilities, poses a significant challenge to the stability and efficiency of these distributed learning networks. The seamless integration of new clients is imperative to sustain and enhance the performance and robustness of FL systems. This paper looks into the complexities of integrating new clients into existing FL systems and explores how data heterogeneity and varying data distribution (not independent and identically distributed) among them can affect model training, system efficiency, scalability and stability. Despite these challenges, the integration of new clients into FL systems presents opportunities to enhance data diversity, improve learning performance, and leverage distributed computational power. In contrast to other fields of application such as the distributed optimization of word predictions on Gboard (where federated learning once originated), there are usually only a few clients in the production environment, which is why information from each new client becomes all the more valuable. This paper outlines strategies for effective client selection strategies and solutions for ensuring system scalability and stability. Using the example of images from optical quality inspection, it offers insights into practical approaches. In conclusion, this paper proposes that addressing the challenges presented by new client integration is crucial to the advancement and efficiency of distributed learning networks, thus paving the way for the adoption of Federated Learning in production environments. ",Kein DOI-Link verfügbar,2408.09545v2,Yes,potent(1)
0000-0002-7297-0845,Tatjana Legler,"Rheinland-Pfälzische Technische Universität Kaiserslautern-Landau, Technische Universität Kaiserslautern",Federated Object Detection for Quality Inspection in Shared Production,1970,"  Federated learning (FL) has emerged as a promising approach for training machine learning models on decentralized data without compromising data privacy. In this paper, we propose a FL algorithm for object detection in quality inspection tasks using YOLOv5 as the object detection algorithm and Federated Averaging (FedAvg) as the FL algorithm. We apply this approach to a manufacturing use-case where multiple factories/clients contribute data for training a global object detection model while preserving data privacy on a non-IID dataset. Our experiments demonstrate that our FL approach achieves better generalization performance on the overall clients' test dataset and generates improved bounding boxes around the objects compared to models trained using local clients' datasets. This work showcases the potential of FL for quality inspection tasks in the manufacturing industry and provides valuable insights into the performance and feasibility of utilizing YOLOv5 and FedAvg for federated object detection. ",Kein DOI-Link verfügbar,2306.17645v2,Yes,potent(1)
0000-0002-7297-0845,Tatjana Legler,"Rheinland-Pfälzische Technische Universität Kaiserslautern-Landau, Technische Universität Kaiserslautern",Towards Robust Federated Image Classification: An Empirical Study of   Weight Selection Strategies in Manufacturing,1970,"  In the realm of Federated Learning (FL), particularly within the manufacturing sector, the strategy for selecting client weights for server aggregation is pivotal for model performance. This study investigates the comparative effectiveness of two weight selection strategies: Final Epoch Weight Selection (FEWS) and Optimal Epoch Weight Selection (OEWS). Designed for manufacturing contexts where collaboration typically involves a limited number of partners (two to four clients), our research focuses on federated image classification tasks. We employ various neural network architectures, including EfficientNet, ResNet, and VGG, to assess the impact of these weight selection strategies on model convergence and robustness. Our research aims to determine whether FEWS or OEWS enhances the global FL model's performance across communication rounds (CRs). Through empirical analysis and rigorous experimentation, we seek to provide valuable insights for optimizing FL implementations in manufacturing, ensuring that collaborative efforts yield the most effective and reliable models with a limited number of participating clients. The findings from this study are expected to refine FL practices significantly in manufacturing, thereby enhancing the efficiency and performance of collaborative machine learning endeavors in this vital sector. ",Kein DOI-Link verfügbar,2408.10024v2,Yes,pivotal(1)
0000-0002-7297-0845,Tatjana Legler,"Rheinland-Pfälzische Technische Universität Kaiserslautern-Landau, Technische Universität Kaiserslautern",Enhancing Object Detection with Hybrid dataset in Manufacturing   Environments: Comparing Federated Learning to Conventional Techniques,1970,"  Federated Learning (FL) has garnered significant attention in manufacturing for its robust model development and privacy-preserving capabilities. This paper contributes to research focused on the robustness of FL models in object detection, hereby presenting a comparative study with conventional techniques using a hybrid dataset for small object detection. Our findings demonstrate the superior performance of FL over centralized training models and different deep learning techniques when tested on test data recorded in a different environment with a variety of object viewpoints, lighting conditions, cluttered backgrounds, etc. These results highlight the potential of FL in achieving robust global models that perform efficiently even in unseen environments. The study provides valuable insights for deploying resilient object detection models in manufacturing environments. ",Kein DOI-Link verfügbar,2408.08974v1,Yes,potent(1)
0000-0002-7305-7126,Eva Schmidt,Technische Universität Dortmund,What Do We Want From Explainable Artificial Intelligence (XAI)? -- A   Stakeholder Perspective on XAI and a Conceptual Model Guiding   Interdisciplinary XAI Research,1970,"  Previous research in Explainable Artificial Intelligence (XAI) suggests that a main aim of explainability approaches is to satisfy specific interests, goals, expectations, needs, and demands regarding artificial systems (we call these stakeholders' desiderata) in a variety of contexts. However, the literature on XAI is vast, spreads out across multiple largely disconnected disciplines, and it often remains unclear how explainability approaches are supposed to achieve the goal of satisfying stakeholders' desiderata. This paper discusses the main classes of stakeholders calling for explainability of artificial systems and reviews their desiderata. We provide a model that explicitly spells out the main concepts and relations necessary to consider and investigate when evaluating, adjusting, choosing, and developing explainability approaches that aim to satisfy stakeholders' desiderata. This model can serve researchers from the variety of different disciplines involved in XAI as a common ground. It emphasizes where there is interdisciplinary potential in the evaluation and the development of explainability approaches. ",https://doi.org/10.1016/j.artint.2021.103473,2102.07817v1,Yes,potent(1)
0000-0002-7305-7126,Eva Schmidt,Technische Universität Dortmund,An Asymmetric Double-Degenerate Type Ia Supernova Explosion with a   Surviving Companion Star,1970,"  We present nebular spectroscopy of SN 2020hvf, a Type Ia supernova (SN Ia) with an early bump in its light curve. SN 2020hvf shares many spectroscopic and photometric similarities to the carbon-rich high-luminosity ""03fg-like"" SNe Ia. At $>$240 days after peak brightness, we detect unambiguous emission from [Ca II] $\lambda\lambda$7291, 7324 which is never observed in normal-SNe Ia and only seen in peculiar subclasses. SN 2020hvf displays ""saw-tooth"" emission profiles near 7300 A that cannot be explained with single symmetric velocity components of [Fe II], [Ni II], and [Ca II], indicating an asymmetric explosion. The broad [Ca II] emission is best modeled by two velocity components offset by 1,220 km s$^{-1}$, which could be caused by ejecta associated with each star in the progenitor system, separated by their orbital velocity. For the first time in a SN Ia, we identify narrow (${\rm FWHM} = 180\pm40$ km s$^{-1}$) [Ca II] emission, which we associate with a wind from a surviving, puffed-up companion star. Few published spectra have sufficient resolution and signal-to-noise ratio necessary to detect similar narrow [Ca II] emission, however, we have detected similar line profiles in other 03fg-like SNe Ia. The extremely narrow velocity width of [Ca II] has only otherwise been observed in SNe Iax at late times. Since this event likely had a double-degenerate ""super-Chandrasekhar"" mass progenitor system, we suggest that a single white dwarf (WD) was fully disrupted and a wind from a surviving companion WD is producing the observed narrow emission. It is unclear if this unique progenitor and explosion scenario can explain the diversity of 03fg-like SNe Ia, potentially indicating that multiple progenitor channels contribute to this subclass. ",Kein DOI-Link verfügbar,2306.11788v2,Yes,potent(1)
0000-0002-7328-1427,Karin Schwarz,Universität des Saarlandes,Microbiome and metabolome insights into the role of the   gastrointestinal-brain axis in neurodegenerative diseases: unveiling   potential therapeutic targets,1970,"  Due to the aging of the world population and westernization of lifestyles, the prevalence of neurodegenerative diseases such as Alzheimer's disease (AD) and Parkinson's disease (PD) is rapidly rising and is expected to put a strong socioeconomic burden on health systems worldwide. Due to the limited success of clinical trials of therapies against neurodegenerative diseases, research has extended its scope to a systems medicine point of view, with a particular focus on the gastrointestinal-brain axis as a potential main actor in disease development and progression. Microbiome as well as metabolome studies along the gastrointestinal-brain axis have already revealed important insights into disease pathomechanisms. Both the microbiome and metabolome can be easily manipulated by dietary and lifestyle interventions, and might thus offer novel, readily available therapeutic options to prevent the onset as well as the progression of PD and AD. This review summarizes our current knowledge on the association between microbiota, metabolites, and neurodegeneration in light of the gastrointestinal-brain axis. In this context, we also illustrate state-of-the art methods of microbiome and metabolome research as well as metabolic modeling that facilitate the identification of disease pathomechanisms. We conclude our review with therapeutic options to modulate microbiome composition to prevent or delay neurodegeneration and illustrate potential future research directions to fight PD and AD. ",Kein DOI-Link verfügbar,2208.09338v1,Yes,potent(2)
0000-0002-7360-1849,Martin Meyer,Universität Duisburg-Essen,Extended Tully-Fisher Relations using HI Stacking,1970,"  We present a new technique for the statistical evaluation of the Tully-Fisher relation (TFR) using spectral line stacking. This technique has the potential to extend TFR observations to lower masses and higher redshifts than possible through a galaxy-by-galaxy analysis. It further avoids the need for individual galaxy inclination measurements.   To quantify the properties of stacked HI emission lines, we consider a simplistic model of galactic disks with analytically expressible line profiles. Using this model, we compare the widths of stacked profiles with those of individual galaxies. We then follow the same procedure using more realistic mock galaxies drawn from the S3-SAX model (a derivative of the Millennium simulation). Remarkably, when stacking the apparent HI lines of galaxies with similar absolute magnitude and random inclinations, the width of the stack is very similar to the width of the deprojected (= corrected for inclination) and dedispersed (= after removal of velocity dispersion) input lines. Therefore, the ratio between the widths of the stack and the deprojected/dedispersed input lines is approximately constant - about 0.93 - with very little dependence on the gas dispersion, galaxy mass, galaxy morphology, and shape of the rotation curve.   Finally, we apply our technique to construct a stacked TFR using HIPASS data which already has a well defined TFR based on individual detections. We obtain a B-band TFR with a slope of $-8.5\pm0.4$ and a K-band relation with a slope of $-11.7\pm0.6$ for the HIPASS data set which is consistent with the existing results. ",https://doi.org/10.1093/mnras/stv2458,1510.07785v1,Yes,potent(1)
0000-0002-7360-1849,Martin Meyer,Universität Duisburg-Essen,Confronting Cold Dark Matter Predictions with Observed Galaxy Rotations,1970,"  The rich statistics of galaxy rotations as captured by the velocity function (VF) provides invaluable constraints on galactic baryon physics and the nature of dark matter (DM). However, the comparison of observed galaxy rotations against cosmological models is prone to subtle caveats that can easily lead to misinterpretations. Our analysis reveals full statistical consistency between ~5000 galaxy rotations, observed in line-of-sight projection, and predictions based on the standard cosmological model (LCDM) at the mass-resolution of the Millennium simulation (HI line-based circular velocities above ~50 km/s). Explicitly, the HI linewidths in the HI Parkes All Sky Survey (HIPASS) are found consistent with those in S3-SAX, a post-processed semi-analytic model for the Millennium simulation. Previously found anomalies in the VF can be plausibly attributed to (1) the mass-limit of the Millennium simulation, (2) confused sources in HIPASS, (3) inaccurate inclination measurements for optically faint sources, and (4) the non-detectability of gas-poor early-type galaxies. These issues can be bypassed by comparing observations and models using linewidth source counts rather than VFs. We investigate if and how well such source counts can constrain the temperature of DM. ",https://doi.org/10.1088/0004-637X/766/2/137,1302.3687v3,Yes,invaluable(1)
0000-0002-7373-7260,Wenli Zhang,Albert-Ludwigs-Universität Freiburg,Depression Detection Using Digital Traces on Social Media: A   Knowledge-aware Deep Learning Approach,1970,"  Depression is a common disease worldwide. It is difficult to diagnose and continues to be underdiagnosed. Because depressed patients constantly share their symptoms, major life events, and treatments on social media, researchers are turning to user-generated digital traces on social media for depression detection. Such methods have distinct advantages in combating depression because they can facilitate innovative approaches to fight depression and alleviate its social and economic burden. However, most existing studies lack effective means to incorporate established medical domain knowledge in depression detection or suffer from feature extraction difficulties that impede greater performance. Following the design science research paradigm, we propose a Deep Knowledge-aware Depression Detection (DKDD) framework to accurately detect social media users at risk of depression and explain the critical factors that contribute to such detection. Extensive empirical studies with real-world data demonstrate that, by incorporating domain knowledge, our method outperforms existing state-of-the-art methods. Our work has significant implications for IS research in knowledge-aware machine learning, digital traces utilization, and NLP research in IS. Practically, by providing early detection and explaining the critical factors, DKDD can supplement clinical depression screening and enable large-scale evaluations of a population's mental health status. ",https://doi.org/10.1080/07421222.2024.2340822,2303.05389v2,Yes,innovative(1)
0000-0002-7373-7260,Wenli Zhang,Albert-Ludwigs-Universität Freiburg,MD-Manifold: A Medical-Distance-Based Representation Learning Approach   for Medical Concept and Patient Representation,1970,"  Effectively representing medical concepts and patients is important for healthcare analytical applications. Representing medical concepts for healthcare analytical tasks requires incorporating medical domain knowledge and prior information from patient description data. Current methods, such as feature engineering and mapping medical concepts to standardized terminologies, have limitations in capturing the dynamic patterns from patient description data. Other embedding-based methods have difficulties in incorporating important medical domain knowledge and often require a large amount of training data, which may not be feasible for most healthcare systems. Our proposed framework, MD-Manifold, introduces a novel approach to medical concept and patient representation. It includes a new data augmentation approach, concept distance metric, and patient-patient network to incorporate crucial medical domain knowledge and prior data information. It then adapts manifold learning methods to generate medical concept-level representations that accurately reflect medical knowledge and patient-level representations that clearly identify heterogeneous patient cohorts. MD-Manifold also outperforms other state-of-the-art techniques in various downstream healthcare analytical tasks. Our work has significant implications in information systems research in representation learning, knowledge-driven machine learning, and using design science as middle-ground frameworks for downstream explorative and predictive analyses. Practically, MD-Manifold has the potential to create effective and generalizable representations of medical concepts and patients by incorporating medical domain knowledge and prior data information. It enables deeper insights into medical data and facilitates the development of new analytical applications for better healthcare outcomes. ",Kein DOI-Link verfügbar,2305.00553v1,Yes,potent(1)
0000-0002-7373-7260,Wenli Zhang,Albert-Ludwigs-Universität Freiburg,DreamScene: 3D Gaussian-based Text-to-3D Scene Generation via Formation   Pattern Sampling,1970,"  Text-to-3D scene generation holds immense potential for the gaming, film, and architecture sectors. Despite significant progress, existing methods struggle with maintaining high quality, consistency, and editing flexibility. In this paper, we propose DreamScene, a 3D Gaussian-based novel text-to-3D scene generation framework, to tackle the aforementioned three challenges mainly via two strategies. First, DreamScene employs Formation Pattern Sampling (FPS), a multi-timestep sampling strategy guided by the formation patterns of 3D objects, to form fast, semantically rich, and high-quality representations. FPS uses 3D Gaussian filtering for optimization stability, and leverages reconstruction techniques to generate plausible textures. Second, DreamScene employs a progressive three-stage camera sampling strategy, specifically designed for both indoor and outdoor settings, to effectively ensure object-environment integration and scene-wide 3D consistency. Last, DreamScene enhances scene editing flexibility by integrating objects and environments, enabling targeted adjustments. Extensive experiments validate DreamScene's superiority over current state-of-the-art techniques, heralding its wide-ranging potential for diverse applications. Code and demos will be released at https://dreamscene-project.github.io . ",Kein DOI-Link verfügbar,2404.03575v2,Yes,potent(2)
0000-0002-7373-7260,Wenli Zhang,Albert-Ludwigs-Universität Freiburg,"High fusion computers: The IoTs, edges, data centers, and   humans-in-the-loop as a computer",1970,"  Emerging and future applications rely heavily upon systems consisting of Internet of Things (IoT), edges, data centers, and humans-in-the-loop. Significantly different from warehouse-scale computers that serve independent concurrent user requests, this new class of computer systems directly interacts with the physical world, considering humans an essential part and performing safety-critical and mission-critical operations; their computations have intertwined dependencies between not only adjacent execution loops but also actions or decisions triggered by IoTs, edge, datacenters, or humans-in-the-loop; the systems must first satisfy the accuracy metric in predicting, interpreting, or taking action before meeting the performance goal under different cases. This article argues we need a paradigm shift to reconstruct the IoTs, edges, data centers, and humans-in-the-loop as a computer rather than a distributed system. We coin a new term, high fusion computers (HFCs), to describe this class of systems. The fusion in the term has two implications: fusing IoTs, edges, data centers, and humans-in-the-loop as a computer, fusing the physical and digital worlds through HFC systems. HFC is a pivotal case of the open-source computer systems initiative. We laid out the challenges, plan, and call for uniting our community's wisdom and actions to address the HFC challenges. Everything, including the source code, will be publicly available from the project homepage: https://www.computercouncil.org/HFC/. ",Kein DOI-Link verfügbar,2212.00721v1,Yes,pivotal(1)
0000-0002-7388-7680,Michael Schubert,Universität Bayreuth,Receiver Bandwidth Extension Beyond Nyquist Using Channel Bonding,1970,"  Current and upcoming communication and sensing technologies require ever larger bandwidths. Channel bonding can be utilized to extend a receiver's instantaneous bandwidth beyond a single converter's Nyquist limit. Two potential joint front-end and converter design approaches are theoretically introduced, realized and evaluated in this paper. The Xilinx RFSoC platform with its 5 GSa/s analog to digital converters (ADCs) is used to implement both a hybrid coupler based in-phase/quadrature (I/Q) sampling and a time-interleaved sampling approach along with channel bonding. Both realizations are demonstrated to be able to reconstruct instantaneous bandwidths of 5 GHz with up to 49 dB image rejection ratio (IRR) typically within 4 to 8 dB the front-ends' theoretical limits. ",https://doi.org/10.23919/EuCAP57121.2023.10133262,2210.07821v3,Yes,potent(1)
0000-0002-7429-0667,Andreas Vogel,Ruhr Universität Bochum,Wave modes of collective vortex gyration in dipolar-coupled-dot-array   magnonic crystals,1970,"  Lattice vibration modes are collective excitations in periodic arrays of atoms or molecules. These modes determine novel transport properties in solid crystals. Analogously, in periodical arrangements of magnetic vortex-state disks, collective vortex motions have been predicted. Here, we experimentally observe wave modes of collective vortex gyration in one-dimensional (1D) chains of periodic disks using time-resolved scanning transmission x-ray microscopy. The observed modes are interpreted based on micromagnetic simulation and numerical calculation of coupled Thiele equations. Dispersion of the modes is found to be strongly affected by both vortex polarization and chirality ordering, as revealed by the explicit analytical form of 1D infinite chains. A thorough understanding thereof is fundamental both for lattice vibrations and vortex dynamics, which we demonstrate for 1D magnonic crystals. Such magnetic disk arrays with vortex-state ordering, referred to as magnetic metastructure, offer potential implementation into information processing devices. ",Kein DOI-Link verfügbar,1303.4170v1,Yes,potent(1)
0000-0002-7476-3508,Tom Russ,Heidelberg Universität,Experimental verification of stopping-power prediction from single- and   dual-energy computed tomography in biological tissues,1970,"  An experimental setup for consecutive measurement of ion and x-ray absorption in tissue or other materials is introduced. With this setup using a 3D-printed sample container, the reference stopping-power ratio (SPR) of materials can be measured with an uncertainty of below 0.1%. A total of 65 porcine and bovine tissue samples were prepared for measurement, comprising five samples each of 13 tissue types representing about 80% of the total body mass (three different muscle and fatty tissues, liver, kidney, brain, heart, blood, lung and bone). Using a standard stoichiometric calibration for single-energy CT (SECT) as well as a state-of-the-art dual-energy CT (DECT) approach, SPR was predicted for all tissues and then compared to the measured reference. With the SECT approach, the SPRs of all tissues were predicted with a mean error of (-0.84 $\pm$ 0.12)% and a mean absolute error of (1.27 $\pm$ 0.12)%. In contrast, the DECT-based SPR predictions were overall consistent with the measured reference with a mean error of (-0.02 $\pm$ 0.15)% and a mean absolute error of (0.10 $\pm$ 0.15)%. Thus, in this study, the potential of DECT to decrease range uncertainty could be confirmed in biological tissue. ",https://doi.org/10.1088/1361-6560/aaa1c9,1708.07368v2,Yes,potent(1)
0000-0002-7537-1047,Mahsa Noroozi,Leibniz Universität Hannover,Performance Analysis of Universal Robot Control System Using Networked   Predictive Control,1970,"  Networked control systems are feedback control systems with system components distributed at different locations connected through a communication network. Since the communication network is carried out through the internet and there are bandwidth and packet size limitations, network constraints appear. Some of these constraints are time delay and packet loss. These network limitations can degrade the performance and even destabilize the system. To overcome the adverse effect of these communication constraints, various approaches have been developed, among which a representative one is networked predictive control. This approach proposes a controller, which compensates for the network time delay and packet loss actively. This paper aims at implementing a networked predictive control system for controlling a robot arm through a computer network. The network delay is accounted for by a predictor, while the potential of packet loss is mitigated using redundant control packets. The results will show the stability of the system despite a high delay and a considerable packet loss. Additionally, improvements to previous networked predictive control systems will be suggested and an increase in performance can be shown. Lastly, the effects of different system and environment parameters on the control loop will be investigated. ",https://doi.org/10.1109/ICRAE56463.2022.10056165,2207.08450v2,Yes,potent(1)
0000-0002-7537-1047,Mahsa Noroozi,Leibniz Universität Hannover,Performance Evaluation of a New Scheduling Model Using Congestion Window   Reservation,1970,"  Multipath QUIC is a transport protocol that allows for the use of multiple network interfaces for a single connection. It thereby offers, on the one hand, the possibility to gather a higher throughput, while, on the other hand, multiple paths can also be used to transmit data redundantly. Selective redundancy combines these two applications and thereby offers the potential to transmit time-critical data. This paper considers scenarios where data with real-time requirements are transmitted redundantly while at the same time, non-critical data should make use of the aggregated throughput. A new model called congestion window reservation is proposed, which enables an immediate transmission of time-critical data. The performance of this method and its combination with selective redundancy is evaluated using emulab with real data. The results show that this technique leads to a smaller end-to-end latency and reliability for periodically generated priority data. ",Kein DOI-Link verfügbar,2305.03684v1,Yes,potent(1)
0000-0002-7537-1047,Mahsa Noroozi,Leibniz Universität Hannover,Age- and Deviation-of-Information of Time-Triggered and Event-Triggered   Systems,1970,"  Age-of-information is a metric that quantifies the freshness of information obtained by sampling a remote sensor. In signal-agnostic sampling, sensor updates are triggered at certain times without being conditioned on the actual sensor signal. Optimal update policies have been researched and it is accepted that periodic updates achieve smaller age-of-information than random updates. We contribute a study of a signal-aware policy, where updates are triggered by a random sensor event. By definition, this implies random updates and as a consequence inferior age-of-information. Considering a notion of deviation-of-information as a signal-aware metric, our results show, however, that event-triggered systems can perform equally well as time-triggered systems while causing smaller mean network utilization. ",Kein DOI-Link verfügbar,2206.01428v1,Yes,fresh(1)
0000-0002-7537-1047,Mahsa Noroozi,Leibniz Universität Hannover,Statistical Age-of-Information Bounds for Parallel Systems: When Do   Independent Channels Make a Difference?,1970,"  This paper contributes tail bounds of the age-of-information of a general class of parallel systems and explores their potential. Parallel systems arise in relevant cases, such as in multi-band mobile networks, multi-technology wireless access, or multi-path protocols, just to name a few. Typically, control over each communication channel is limited and random service outages and congestion cause buffering that impairs the age-of-information. The parallel use of independent channels promises a remedy, since outages on one channel may be compensated for by another. Surprisingly, for the well-known case of M$\mid$M$\mid$1 queues we find the opposite: pooling capacity in one channel performs better than a parallel system with the same total capacity. A generalization is not possible since there are no solutions for other types of parallel queues at hand. In this work, we prove a dual representation of age-of-information in min-plus algebra that connects to queueing models known from the theory of effective bandwidth/capacity and the stochastic network calculus. Exploiting these methods, we derive tail bounds of the age-of-information of parallel G$\mid$G$\mid$1 queues. In addition to parallel classical queues, we investigate Markov channels where, depending on the memory of the channel, we show the true advantage of parallel systems. We continue to investigate this new finding and provide insight into when capacity should be pooled in one channel or when independent parallel channels perform better. We complement our analysis with simulation results and evaluate different update policies, scheduling policies, and the use of heterogeneous channels that is most relevant for latest multi-band networks. ",Kein DOI-Link verfügbar,2303.14035v1,Yes,potent(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,MultifacetEval: Multifaceted Evaluation to Probe LLMs in Mastering   Medical Knowledge,1970,"  Large language models (LLMs) have excelled across domains, also delivering notable performance on the medical evaluation benchmarks, such as MedQA. However, there still exists a significant gap between the reported performance and the practical effectiveness in real-world medical scenarios. In this paper, we aim to explore the causes of this gap by employing a multifaceted examination schema to systematically probe the actual mastery of medical knowledge by current LLMs. Specifically, we develop a novel evaluation framework MultifacetEval to examine the degree and coverage of LLMs in encoding and mastering medical knowledge at multiple facets (comparison, rectification, discrimination, and verification) concurrently. Based on the MultifacetEval framework, we construct two multifaceted evaluation datasets: MultiDiseK (by producing questions from a clinical disease knowledge base) and MultiMedQA (by rephrasing each question from a medical benchmark MedQA into multifaceted questions). The experimental results on these multifaceted datasets demonstrate that the extent of current LLMs in mastering medical knowledge is far below their performance on existing medical benchmarks, suggesting that they lack depth, precision, and comprehensiveness in mastering medical knowledge. Consequently, current LLMs are not yet ready for application in real-world medical tasks. The codes and datasets are available at https://github.com/THUMLP/MultifacetEval. ",Kein DOI-Link verfügbar,2406.02919v1,Yes,notable(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,Generative Action Description Prompts for Skeleton-based Action   Recognition,1970,"  Skeleton-based action recognition has recently received considerable attention. Current approaches to skeleton-based action recognition are typically formulated as one-hot classification tasks and do not fully exploit the semantic relations between actions. For example, ""make victory sign"" and ""thumb up"" are two actions of hand gestures, whose major difference lies in the movement of hands. This information is agnostic from the categorical one-hot encoding of action classes but could be unveiled from the action description. Therefore, utilizing action description in training could potentially benefit representation learning. In this work, we propose a Generative Action-description Prompts (GAP) approach for skeleton-based action recognition. More specifically, we employ a pre-trained large-scale language model as the knowledge engine to automatically generate text descriptions for body parts movements of actions, and propose a multi-modal training scheme by utilizing the text encoder to generate feature vectors for different body parts and supervise the skeleton encoder for action representation learning. Experiments show that our proposed GAP method achieves noticeable improvements over various baseline models without extra computation cost at inference. GAP achieves new state-of-the-arts on popular skeleton-based action recognition benchmarks, including NTU RGB+D, NTU RGB+D 120 and NW-UCLA. The source code is available at https://github.com/MartinXM/GAP. ",Kein DOI-Link verfügbar,2208.05318v2,Yes,potent(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,SP-ViT: Learning 2D Spatial Priors for Vision Transformers,1970,"  Recently, transformers have shown great potential in image classification and established state-of-the-art results on the ImageNet benchmark. However, compared to CNNs, transformers converge slowly and are prone to overfitting in low-data regimes due to the lack of spatial inductive biases. Such spatial inductive biases can be especially beneficial since the 2D structure of an input image is not well preserved in transformers. In this work, we present Spatial Prior-enhanced Self-Attention (SP-SA), a novel variant of vanilla Self-Attention (SA) tailored for vision transformers. Spatial Priors (SPs) are our proposed family of inductive biases that highlight certain groups of spatial relations. Unlike convolutional inductive biases, which are forced to focus exclusively on hard-coded local regions, our proposed SPs are learned by the model itself and take a variety of spatial relations into account. Specifically, the attention score is calculated with emphasis on certain kinds of spatial relations at each head, and such learned spatial foci can be complementary to each other. Based on SP-SA we propose the SP-ViT family, which consistently outperforms other ViT models with similar GFlops or parameters. Our largest model SP-ViT-L achieves a record-breaking 86.3% Top-1 accuracy with a reduction in the number of parameters by almost 50% compared to previous state-of-the-art model (150M for SP-ViT-L vs 271M for CaiT-M-36) among all ImageNet-1K models trained on 224x224 and fine-tuned on 384x384 resolution w/o extra data. ",Kein DOI-Link verfügbar,2206.07662v1,Yes,potent(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,Overcoming Topology Agnosticism: Enhancing Skeleton-Based Action   Recognition through Redefined Skeletal Topology Awareness,1970,"  Graph Convolutional Networks (GCNs) have long defined the state-of-the-art in skeleton-based action recognition, leveraging their ability to unravel the complex dynamics of human joint topology through the graph's adjacency matrix. However, an inherent flaw has come to light in these cutting-edge models: they tend to optimize the adjacency matrix jointly with the model weights. This process, while seemingly efficient, causes a gradual decay of bone connectivity data, culminating in a model indifferent to the very topology it sought to map. As a remedy, we propose a threefold strategy: (1) We forge an innovative pathway that encodes bone connectivity by harnessing the power of graph distances. This approach preserves the vital topological nuances often lost in conventional GCNs. (2) We highlight an oft-overlooked feature - the temporal mean of a skeletal sequence, which, despite its modest guise, carries highly action-specific information. (3) Our investigation revealed strong variations in joint-to-joint relationships across different actions. This finding exposes the limitations of a single adjacency matrix in capturing the variations of relational configurations emblematic of human movement, which we remedy by proposing an efficient refinement to Graph Convolutions (GC) - the BlockGC. This evolution slashes parameters by a substantial margin (above 40%), while elevating performance beyond original GCNs. Our full model, the BlockGCN, establishes new standards in skeleton-based action recognition for small model sizes. Its high accuracy, notably on the large-scale NTU RGB+D 120 dataset, stand as compelling proof of the efficacy of BlockGCN. ",Kein DOI-Link verfügbar,2305.11468v3,Yes,innovative(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,Magnetic frustration in the cubic double perovskite Ba2NiIrO6,1970,"  Hybrid transition metal oxides continue to attract attention due to their multiple degrees of freedom ($e.g.$, lattice, charge, spin, and orbital) and versatile properties. Here we investigate the magnetic and electronic properties of the newly synthesized double perovskite Ba$_2$NiIrO$_6$, using crystal field theory, superexchange model analysis, density functional calculations, and parallel tempering Monte Carlo (PTMC) simulations. Our results indicate that Ba$_2$NiIrO$_6$ has the Ni$^{2+}$ ($t_{2g}^{6}e_{g}^{2}$)-Ir$^{6+}$ ($t_{2g}^{3}$) charge states. The first nearest-neighboring (1NN) Ni$^{2+}$-Ir$^{6+}$ ions prefer a ferromagnetic (FM) coupling as expected from the Goodenough-Kanamori-Anderson rules, which contradicts the experimental antiferromagnetic (AF) order in Ba$_2$NiIrO$_6$. We find that the strong 2NN AF couplings are frustrated in the fcc sublattices, and they play a major role in determining the observed AF ground state. We also prove that the $J_{\rm eff}$ = 3/2 and $J_{\rm eff}$ = 1/2 states induced by spin-orbit coupling, which would be manifested in low-dimensional (e.g., layered) iridates, are however not the case for cubic Ba$_2$NiIrO$_6$. Our PTMC simulations show that when the long-range (2NN and 3NN) AF interactions are included, an AF transition with $T_{\rm N}$ = 66 K would be obtained and it is well comparable with the experimental 51 K. Meanwhile, we propose a possible 2$\times$2$\times$2 noncollinear AF structure for Ba$_2$NiIrO$_6$. ",https://doi.org/10.1103/PhysRevB.105.184413,2205.03049v1,Yes,versatile(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,Robust Quantum Gates against Correlated Noise in Integrated Quantum   Chips,1970,"  As quantum circuits become more integrated and complex, additional error sources that were previously insignificant start to emerge. Consequently, the fidelity of quantum gates benchmarked under pristine conditions falls short of predicting their performance in realistic circuits. To overcome this problem, we must improve their robustness against pertinent error models besides isolated fidelity. Here we report the experimental realization of robust quantum gates in superconducting quantum circuits based on a geometric framework for diagnosing and correcting various gate errors. Using quantum process tomography and randomized benchmarking, we demonstrate robust single-qubit gates against quasi-static noise and spatially-correlated noise in a broad range of strengths, which are common sources of coherent errors in large-scale quantum circuit. We also apply our method to non-static noises and to realize robust two-qubit gates. Our work provides a versatile toolbox for achieving noise-resilient complex quantum circuits. ",https://doi.org/10.1103/PhysRevLett.132.250604,2401.01810v3,Yes,versatile(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,Noise-induced quantum synchronization and maximally entangled mixed   states in superconducting circuits,1970,"  Random fluctuations can lead to cooperative effects in complex systems. We here report the experimental observation of noise-induced quantum synchronization in a chain of superconducting transmon qubits with nearest-neighbor interactions. The application of Gaussian white noise to a single site leads to synchronous oscillations in the entire chain. We show that the two synchronized end qubits are entangled, with nonzero concurrence, and that they belong to a class of generalized Bell states known as maximally entangled mixed states, whose entanglement cannot be increased by any global unitary. We further demonstrate the stability against frequency detuning of both synchronization and entanglement by determining the corresponding generalized Arnold tongue diagrams. Our results highlight the constructive influence of noise in a quantum many-body system and uncover the potential role of synchronization for mixed-state quantum information science. ",Kein DOI-Link verfügbar,2406.10457v1,Yes,potent(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,Native Conditional $i$SWAP Operation with Superconducting Artificial   Atoms,1970,"  Controlling the flow of quantum information is a fundamental task for quantum computers, which is unfeasible to realize on classical devices. Coherent devices which can process quantum states are thus required to route the quantum states that encode information. In this paper we demonstrate experimentally the smallest quantum transistor with a superconducting quantum processor which is composed of a collector qubit, an emitter qubit, and a coupler (transistor gate). The interaction strength between the collector and emitter qubits is controlled by the frequency and state of the coupler, effectively implementing a quantum switch. Through the coupler-state-dependent Heisenberg (inherent) interaction between the qubits, a single-step (native) conditional $i$SWAP operation can be applied. To this end, we find that it is important to take into consideration higher energy level for achieving a native and high-fidelity transistor operation. By reconstructing the Quantum Process Tomography, we obtain an operation fidelity of $92.36\%$ when the transistor gate is open ($i$SWAP implementation) and $95.23 \%$ in the case of closed gate (identity gate implementation). The architecture has strong potential in quantum information processing applications with superconducting qubits. ",https://doi.org/10.1103/PhysRevApplied.20.034072,2203.09791v2,Yes,potent(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,Multi-Level Variational Spectroscopy using a Programmable Quantum   Simulator,1970,"  Energy spectroscopy is a powerful tool with diverse applications across various disciplines. The advent of programmable digital quantum simulators opens new possibilities for conducting spectroscopy on various models using a single device. Variational quantum-classical algorithms have emerged as a promising approach for achieving such tasks on near-term quantum simulators, despite facing significant quantum and classical resource overheads. Here, we experimentally demonstrate multi-level variational spectroscopy for fundamental many-body Hamiltonians using a superconducting programmable digital quantum simulator. By exploiting symmetries, we effectively reduce circuit depth and optimization parameters allowing us to go beyond the ground state. Combined with the subspace search method, we achieve full spectroscopy for a 4-qubit Heisenberg spin chain, yielding an average deviation of 0.13 between experimental and theoretical energies, assuming unity coupling strength. Our method, when extended to 8-qubit Heisenberg and transverse-field Ising Hamiltonians, successfully determines the three lowest energy levels. In achieving the above, we introduce a circuit-agnostic waveform compilation method that enhances the robustness of our simulator against signal crosstalk. Our study highlights symmetry-assisted resource efficiency in variational quantum algorithms and lays the foundation for practical spectroscopy on near-term quantum simulators, with potential applications in quantum chemistry and condensed matter physics. ",https://doi.org/10.1103/PhysRevResearch.6.013015,2306.02110v1,Yes,potent(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,Coupler-Assisted Leakage Reduction for Scalable Quantum Error Correction   with Superconducting Qubits,1970,"  Superconducting qubits are a promising platform for building fault-tolerant quantum computers, with recent achievement showing the suppression of logical error with increasing code size. However, leakage into non-computational states, a common issue in practical quantum systems including superconducting circuits, introduces correlated errors that undermine QEC scalability. Here, we propose and demonstrate a leakage reduction scheme utilizing tunable couplers, a widely adopted ingredient in large-scale superconducting quantum processors. Leveraging the strong frequency tunability of the couplers and stray interaction between the couplers and readout resonators, we eliminate state leakage on the couplers, thus suppressing space-correlated errors caused by population propagation among the couplers. Assisted by the couplers, we further reduce leakage to higher qubit levels with high efficiency (98.1%) and low error rate on the computational subspace (0.58%), suppressing time-correlated errors during QEC cycles. The performance of our scheme demonstrates its potential as an indispensable building block for scalable QEC with superconducting qubits. ",Kein DOI-Link verfügbar,2403.16155v1,Yes,potent(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,Interaction-induced topological pumping in a solid-state quantum system,1970,"  As the basis for generating multi-particle quantum correlations, inter-particle interaction plays a crucial role in collective quantum phenomena, quantum phase transitions, and quantum information processing. It can profoundly alter the band structure of quantum many-body systems and give rise to exotic topological phenomena. Conventional topological pumping, which has been well demonstrated in driven linear or noninteracting systems, may break down in the presence of strong interaction. However, the interplay between band topology and interaction could also induce emergent topological pumping of interacting particles, but its experimental realization has proven challenging. Here we demonstrate interaction-induced topological pumping in a solid-state quantum system comprising an array of 36 superconducting qubits. With strong interaction inherent in the qubits and site-resolved controllability of the lattice potential and hopping strength, we realize the topological Thouless pumping of single and two bounded particles. Beyond these topological phenomena with linear or noninteracting counterparts, we also observe topologically resonant tunneling and asymmetric edge-state transport of interacting particles. Our work creates a paradigm for multi-particle topological effects, and provides a new pathway to the study of exotic topological phenomena, many-body quantum transport, and quantum information transfer. ",Kein DOI-Link verfügbar,2303.04582v1,Yes,potent(1)
0000-0002-7688-803X,Yuxuan Zhou,Universität Mannheim,Scalable algorithm simplification using quantum AND logic,1970,"  Implementing quantum algorithms on realistic hardware requires translating high-level global operations into sequences of native elementary gates, a process known as quantum compiling. Physical limitations, such as constraints in connectivity and gate alphabets, often result in unacceptable implementation costs. To enable successful near-term applications, it is crucial to optimize compilation by exploiting the potential capabilities of existing hardware. Here, we implement a resource-efficient construction for a quantum version of AND logic that can reduce the cost, enabling the execution of key quantum circuits. On a high-scalability superconducting quantum processor, we demonstrate low-depth synthesis of high-fidelity generalized Toffoli gates with up to 8 qubits and Grover's search algorithm in a search space of up to 64 entries; both are the largest such implementations in scale to date. Our experimental demonstration illustrates a scalable implementation of simplifying quantum algorithms, paving the way for larger, more meaningful quantum applications on noisy devices. ",https://doi.org/10.1038/s41567-022-01813-7,2112.14922v1,Yes,potent(1)
0000-0002-7700-9113,Orestis Loukas,Philipps-Universität Marburg,Abelian scalar theory at large global charge,1970,"  We elaborate on Abelian complex scalar models, which are dictated by natural actions (all couplings are of order one), at fixed and large global $U(1)$ charge in an arbitrary number of dimensions. The ground state $| \upsilon\rangle$ is coherently constructed by the zero modes and the appearance of a centrifugal potential is quantum mechanically verified. Using the path integral formulation we systematically analyze the quantum fluctuations around $| \upsilon\rangle$ in order to derive an effective action for the Goldstone mode, which becomes perturbatively meaningful when the charge is large. In this regime we explicitly show that the whole construction is stable against quantum corrections, in the sense that any higher derivative couplings to Goldstone's tree-level action are suppressed by appropriate powers of the large charge. ",https://doi.org/10.1002/prop.201700028,1612.08985v1,Yes,potent(1)
0000-0002-7700-9113,Orestis Loukas,Philipps-Universität Marburg,Self-regularizing restricted Boltzmann machines,1970,"  Focusing on the grand-canonical extension of the ordinary restricted Boltzmann machine, we suggest an energy-based model for feature extraction that uses a layer of hidden units with varying size. By an appropriate choice of the chemical potential and given a sufficiently large number of hidden resources the generative model is able to efficiently deduce the optimal number of hidden units required to learn the target data with exceedingly small generalization error. The formal simplicity of the grand-canonical ensemble combined with a rapidly converging ansatz in mean-field theory enable us to recycle well-established numerical algothhtims during training, like contrastive divergence, with only minor changes. As a proof of principle and to demonstrate the novel features of grand-canonical Boltzmann machines, we train our generative models on data from the Ising theory and MNIST. ",Kein DOI-Link verfügbar,1912.05634v1,Yes,potent(1)
0000-0002-7700-9113,Orestis Loukas,Philipps-Universität Marburg,Entropy-based Characterization of Modeling Constraints,1970,"  In most data-scientific approaches, the principle of Maximum Entropy (MaxEnt) is used to a posteriori justify some parametric model which has been already chosen based on experience, prior knowledge or computational simplicity. In a perpendicular formulation to conventional model building, we start from the linear system of phenomenological constraints and asymptotically derive the distribution over all viable distributions that satisfy the provided set of constraints. The MaxEnt distribution plays a special role, as it is the most typical among all phenomenologically viable distributions representing a good expansion point for large-N techniques. This enables us to consistently formulate hypothesis testing in a fully-data driven manner. The appropriate parametric model which is supported by the data can be always deduced at the end of model selection. In the MaxEnt framework, we recover major scores and selection procedures used in multiple applications and assess their ability to capture associations in the data-generating process and identify the most generalizable model. This data-driven counterpart of standard model selection demonstrates the unifying prospective of the deductive logic advocated by MaxEnt principle, while potentially shedding new insights to the inverse problem. ",Kein DOI-Link verfügbar,2206.14105v1,Yes,potent(1)
0000-0002-7700-9113,Orestis Loukas,Philipps-Universität Marburg,(MS)SM-like models on smooth Calabi-Yau manifolds from all three   heterotic string theories,1970,"  We perform model searches on smooth Calabi-Yau compactifications for both the supersymmetric E8xE8 and SO(32) as well as for the non-supersymmetric SO(16)xSO(16) heterotic strings simultaneously. We consider line bundle backgrounds on both favorable CICYs with relatively small h_11 and the Schoen manifold. Using Gram matrices we systematically analyze the combined consequences of the Bianchi identities and the tree-level Donaldson-Uhlenbeck-Yau equations inside the Kahler cone. In order to evaluate the model building potential of the three heterotic theories on the various geometries, we perform computer-aided scans. We have generated a large number of GUT-like models (up to over a few hundred thousand on the various geometries for the three heterotic theories) which become (MS)SM-like upon using a freely acting Wilson line. For all three heterotic theories we present tables and figures summarizing the potentially phenomenologically interesting models which were obtained during our model scans. ",https://doi.org/10.1002/prop.201500041,1507.07559v3,Yes,potent(2)
0000-0002-7741-5816,Vincent Pohl,Freie Universität Berlin,Adiabatic electronic flux density: a Born-Oppenheimer Broken Symmetry   ansatz,1970,"  The Born-Oppenheimer approximation leads to the counterintuitive result of a vanishing electronic flux density upon vibrational dynamics in the electronic ground state. To circumvent this long known issue, we propose using pairwise anti-symmetrically translated vibronic densities to generate a symmetric electronic density that can be forced to satisfy the continuity equation approximately. The so-called Born-Oppenheimer broken symmetry ansatz yields all components of the flux density simultaneously while requiring only knowledge about the nuclear quantum dynamics on the electronic adiabatic ground state potential energy surface. The underlying minimization procedure is transparent and computationally inexpensive, and the solution can be computed from the standard output of any quantum chemistry program. Taylor series expansion reveals that the implicit electron dynamics originates from non-adiabatic coupling to the explicit Born-Oppenheimer nuclear dynamics. The new approach is applied to the ${\rm H}_2^+$ molecular ion vibrating in its ${}^2\Sigma^+_g$ ground state. The electronic flux density is found to have the correct nodal structure and symmetry properties at all times. ",https://doi.org/10.1103/PhysRevA.93.012504,1510.05785v2,Yes,potent(1)
0000-0002-7741-5816,Vincent Pohl,Freie Universität Berlin,Cyanographone and Isocyanographone $-$ two asymmetrically functionalized   graphene pseudohalides and their potential use in chemical sensing,1970,"  Graphene pseudohalides are natural candidates for use in molecular sensing due to their greater chemical activity as compared to both graphene halides and pristine graphene. Though their study is still in its infancy, being hindered until recently by the unavailability of both selective and efficient procedures for their synthesis, they promise to considerably widen the application potential of chemically modified graphenes. Herein, we employ vdW-DFT to study the structural and electronic properties of two selected graphene pseudohalides namely cyanographone and isocyanographone and investigate the potential use of the latter as a chemical sensor via electron transport calculations. ",Kein DOI-Link verfügbar,1703.08582v2,Yes,potent(2)
0000-0002-7741-5816,Vincent Pohl,Freie Universität Berlin,Electronic Flux Density Maps Reveal Unique Current Patterns in a   Single-Molecule-Graphene-Nanoribbon Junction,1970,"  To assist the design of novel, highly efficient molecular junctions, a deep understanding of the precise charge transport mechanisms through these devices is of prime importance. In the present contribution, we describe a procedure to investigate spatially-resolved electron transport through a nanojunction from first principles, at the example of a nitro-substituted oligo-(phenylene ethynylene) covalently bound to graphene nanoribbon leads. Recently, we demonstrated that the conductivity of this single-molecule-graphene-nanoribbon junction can be switched quantitatively and reversibly upon application of a static electric field in a top gate position, in the spirit of a traditional field effect transistor [J. Phys. Chem. C, 2016, 120, 28808-28819]. The propensity of the central oligomer unit to align with the external field was found to induce a damped rotational motion and to cause an interruption of the conjugated $\pi$-system, thereby drastically reducing the conductance through the nanojunction. In the current work, we use the driven Liouville-von-Neumann (DLvN) approach for time-dependent electronic transport calculations to simulate the electronic current dynamics under time-dependent potential biases for the two logical states of the nanojunction. Our quantum dynamical simulations rely on a novel localization procedure using an orthonormal set of molecular orbitals obtained from a standard density functional theory calculation to generate a localized representation for the different parts of the molecular junction. The transparent DLvN formalism allows us to directly access the density matrix and to reconstruct the time-dependent electronic current density, unraveling unique mechanistic details of the electron transport. ",https://doi.org/10.1021/acs.jpclett.9b01732,1707.07635v2,Yes,potent(1)
0000-0002-7780-6374,Markus Reischl,Karlsruher Institut für Technologie,Assessing Political Bias in Large Language Models,1970,"  The assessment of bias within Large Language Models (LLMs) has emerged as a critical concern in the contemporary discourse surrounding Artificial Intelligence (AI) in the context of their potential impact on societal dynamics. Recognizing and considering political bias within LLM applications is especially important when closing in on the tipping point toward performative prediction. Then, being educated about potential effects and the societal behavior LLMs can drive at scale due to their interplay with human operators. In this way, the upcoming elections of the European Parliament will not remain unaffected by LLMs. We evaluate the political bias of the currently most popular open-source LLMs (instruct or assistant models) concerning political issues within the European Union (EU) from a German voter's perspective. To do so, we use the ""Wahl-O-Mat,"" a voting advice application used in Germany. From the voting advice of the ""Wahl-O-Mat"" we quantize the degree of alignment of LLMs with German political parties. We show that larger models, such as Llama3-70B, tend to align more closely with left-leaning political parties, while smaller models often remain neutral, particularly when prompted in English. The central finding is that LLMs are similarly biased, with low variances in the alignment concerning a specific party. Our findings underline the importance of rigorously assessing and making bias transparent in LLMs to safeguard the integrity and trustworthiness of applications that employ the capabilities of performative prediction and the invisible hand of machine learning prediction and language generation. ",Kein DOI-Link verfügbar,2405.13041v3,Yes,potent(2)
0000-0002-7780-6374,Markus Reischl,Karlsruher Institut für Technologie,Improving 3D deep learning segmentation with biophysically motivated   cell synthesis,1970,"  Biomedical research increasingly relies on 3D cell culture models and AI-based analysis can potentially facilitate a detailed and accurate feature extraction on a single-cell level. However, this requires for a precise segmentation of 3D cell datasets, which in turn demands high-quality ground truth for training. Manual annotation, the gold standard for ground truth data, is too time-consuming and thus not feasible for the generation of large 3D training datasets. To address this, we present a novel framework for generating 3D training data, which integrates biophysical modeling for realistic cell shape and alignment. Our approach allows the in silico generation of coherent membrane and nuclei signals, that enable the training of segmentation models utilizing both channels for improved performance. Furthermore, we present a new GAN training scheme that generates not only image data but also matching labels. Quantitative evaluation shows superior performance of biophysical motivated synthetic training data, even outperforming manual annotation and pretrained models. This underscores the potential of incorporating biophysical modeling for enhancing synthetic training data quality. ",Kein DOI-Link verfügbar,2408.16471v1,Yes,potent(2)
0000-0002-7780-6374,Markus Reischl,Karlsruher Institut für Technologie,Towards DeepSpray: Using Convolutional Neural Network to post-process   Shadowgraphy Images of Liquid Atomization,1970,"  This technical report investigates the potential of Convolutional Neural Networks to post-process images from primary atomization. Three tasks are investigated. First, the detection and segmentation of liquid droplets in degraded optical conditions. Second, the detection of overlapping ellipses and the prediction of their geometrical characteristics. This task corresponds to extrapolate the hidden contour of an ellipse with reduced visual information. Third, several features of the liquid surface during primary breakup (ligaments, bags, rims) are manually annotated on 15 experimental images. The detector is trained on this minimal database using simple data augmentation and then applied to other images from numerical simulation and from other experiment. In these three tasks, models from the literature based on Convolutional Neural Networks showed very promising results, thus demonstrating the high potential of Deep Learning to post-process liquid atomization. The next step is to embed these models into a unified framework DeepSpray. ",https://doi.org/10.5445/IR/1000097897/v3,1910.11073v1,Yes,potent(2)
0000-0002-7795-3905,Sven Sickert,Friedrich Schiller Universität Jena,Facial Behavior Analysis using 4D Curvature Statistics for Presentation   Attack Detection,1970,"  The human face has a high potential for biometric identification due to its many individual traits. At the same time, such identification is vulnerable to biometric copies. These presentation attacks pose a great challenge in unsupervised authentication settings. As a countermeasure, we propose a method that automatically analyzes the plausibility of facial behavior based on a sequence of 3D face scans. A compact feature representation measures facial behavior using the temporal curvature change. Finally, we train our method only on genuine faces in an anomaly detection scenario. Our method can detect presentation attacks using elastic 3D masks, bent photographs with eye holes, and monitor replay-attacks. For evaluation, we recorded a challenging database containing such cases using a high-quality 3D sensor. It features 109 4D face scans including eleven different types of presentation attacks. We achieve error rates of 11% and 6% for APCER and BPCER, respectively. ",Kein DOI-Link verfügbar,1910.06056v4,Yes,potent(1)
0000-0002-7808-6743,Daniel Schleich,Universität Bonn,Predictive Angular Potential Field-based Obstacle Avoidance for Dynamic   UAV Flights,1970,"  In recent years, unmanned aerial vehicles (UAVs) are used for numerous inspection and video capture tasks. Manually controlling UAVs in the vicinity of obstacles is challenging, however, and poses a high risk of collisions. Even for autonomous flight, global navigation planning might be too slow to react to newly perceived obstacles. Disturbances such as wind might lead to deviations from the planned trajectories.   In this work, we present a fast predictive obstacle avoidance method that does not depend on higher-level localization or mapping and maintains the dynamic flight capabilities of UAVs. It directly operates on LiDAR range images in real time and adjusts the current flight direction by computing angular potential fields within the range image. The velocity magnitude is subsequently determined based on a trajectory prediction and time-to-contact estimation.   Our method is evaluated using Hardware-in-the-Loop simulations. It keeps the UAV at a safe distance to obstacles, while allowing higher flight velocities than previous reactive obstacle avoidance methods that directly operate on sensor data. ",Kein DOI-Link verfügbar,2208.05873v1,Yes,potent(1)
0000-0002-7808-6743,Daniel Schleich,Universität Bonn,Autonomous Flight in Unknown GNSS-denied Environments for Disaster   Examination,1970,"  Micro aerial vehicles (MAVs) have high potential for information gathering tasks to support situation awareness in search and rescue scenarios. Manually controlling MAVs in such scenarios requires experienced pilots and is error-prone, especially in stressful situations of real emergencies. The conditions of disaster scenarios are also challenging for autonomous MAV systems. The environment is usually not known in advance and GNSS might not always be available.   We present a system for autonomous MAV flights in unknown environments which does not rely on global positioning systems. The method is evaluated in multiple search and rescue scenarios and allows for safe autonomous flights, even when transitioning between indoor and outdoor areas. ",https://doi.org/10.1109/ICUAS51884.2021.9476790,2103.11742v2,Yes,potent(1)
0000-0002-7808-6743,Daniel Schleich,Universität Bonn,Autonomous Fire Fighting with a UAV-UGV Team at MBZIRC 2020,1970,"  Every day, burning buildings threaten the lives of occupants and first responders trying to save them. Quick action is of essence, but some areas might not be accessible or too dangerous to enter. Robotic systems have become a promising addition to firefighting, but at this stage, they are mostly manually controlled, which is error-prone and requires specially trained personal.   We present two systems for autonomous firefighting from air and ground we developed for the Mohamed Bin Zayed International Robotics Challenge (MBZIRC) 2020. The systems use LiDAR for reliable localization within narrow, potentially GNSS-restricted environments while maneuvering close to obstacles. Measurements from LiDAR and thermal cameras are fused to track fires, while relative navigation ensures successful extinguishing.   We analyze and discuss our successful participation during the MBZIRC 2020, present further experiments, and provide insights into our lessons learned from the competition. ",Kein DOI-Link verfügbar,2106.06444v1,Yes,potent(1)
0000-0002-7820-1393,Michael Mayer,Universität Regensburg,Real-time shape approximation and 5-D fingerprinting of single proteins,1970,"  This work exploits the zeptoliter sensing volume of electrolyte-filled nanopores to determine, simultaneously and in real time, the approximate shape, volume, charge, rotational diffusion coefficient, and dipole moment of individual proteins. We have developed the theory for a quantitative understanding and analysis of modulations in ionic current that arise from rotational dynamics of single proteins as they move through the electric field inside a nanopore. The resulting multi-parametric information raises the possibility to characterize, identify, and quantify individual proteins and protein complexes in a mixture. This approach interrogates single proteins in solution and determines parameters such as the approximate shape and dipole moment, which are excellent protein descriptors and cannot be obtained otherwise from single protein molecules in solution. Taken together, this five-dimensional characterization of biomolecules at the single particle level has the potential for instantaneous protein identification, quantification, and possibly sorting with implications for structural biology, proteomics, biomarker detection, and routine protein analysis. ",https://doi.org/10.1038/nnano.2016.267,1510.01935v1,Yes,potent(1)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,NCoRE: Neural Counterfactual Representation Learning for Combinations of   Treatments,1970,"  Estimating an individual's potential response to interventions from observational data is of high practical relevance for many domains, such as healthcare, public policy or economics. In this setting, it is often the case that combinations of interventions may be applied simultaneously, for example, multiple prescriptions in healthcare or different fiscal and monetary measures in economics. However, existing methods for counterfactual inference are limited to settings in which actions are not used simultaneously. Here, we present Neural Counterfactual Relation Estimation (NCoRE), a new method for learning counterfactual representations in the combination treatment setting that explicitly models cross-treatment interactions. NCoRE is based on a novel branched conditional neural representation that includes learnt treatment interaction modulators to infer the potential causal generative process underlying the combination of multiple treatments. Our experiments show that NCoRE significantly outperforms existing state-of-the-art methods for counterfactual treatment effect estimation that do not account for the effects of combining multiple treatments across several synthetic, semi-synthetic and real-world benchmarks. ",Kein DOI-Link verfügbar,2103.11175v1,Yes,potent(2)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,Physical Derivatives: Computing policy gradients by physical   forward-propagation,1970,"  Model-free and model-based reinforcement learning are two ends of a spectrum. Learning a good policy without a dynamic model can be prohibitively expensive. Learning the dynamic model of a system can reduce the cost of learning the policy, but it can also introduce bias if it is not accurate. We propose a middle ground where instead of the transition model, the sensitivity of the trajectories with respect to the perturbation of the parameters is learned. This allows us to predict the local behavior of the physical system around a set of nominal policies without knowing the actual model. We assay our method on a custom-built physical robot in extensive experiments and show the feasibility of the approach in practice. We investigate potential challenges when applying our method to physical systems and propose solutions to each of them. ",Kein DOI-Link verfügbar,2201.05830v1,Yes,potent(1)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,Doubly Robust Structure Identification from Temporal Data,1970,"  Learning the causes of time-series data is a fundamental task in many applications, spanning from finance to earth sciences or bio-medical applications. Common approaches for this task are based on vector auto-regression, and they do not take into account unknown confounding between potential causes. However, in settings with many potential causes and noisy data, these approaches may be substantially biased. Furthermore, potential causes may be correlated in practical applications. Moreover, existing algorithms often do not work with cyclic data. To address these challenges, we propose a new doubly robust method for Structure Identification from Temporal Data ( SITD ). We provide theoretical guarantees, showing that our method asymptotically recovers the true underlying causal structure. Our analysis extends to cases where the potential causes have cycles and they may be confounded. We further perform extensive experiments to showcase the superior performance of our method. ",Kein DOI-Link verfügbar,2311.06012v1,Yes,potent(4)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,Clinical Predictive Models for COVID-19: Systematic Study,1970,"  Coronavirus Disease 2019 (COVID-19) is a rapidly emerging respiratory disease caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Due to the rapid human-to-human transmission of SARS-CoV-2, many healthcare systems are at risk of exceeding their healthcare capacities, in particular in terms of SARS-CoV-2 tests, hospital and intensive care unit (ICU) beds and mechanical ventilators. Predictive algorithms could potentially ease the strain on healthcare systems by identifying those who are most likely to receive a positive SARS-CoV-2 test, be hospitalised or admitted to the ICU. Here, we study clinical predictive models that estimate, using machine learning and based on routinely collected clinical data, which patients are likely to receive a positive SARS-CoV-2 test, require hospitalisation or intensive care. To evaluate the predictive performance of our models, we perform a retrospective evaluation on clinical and blood analysis data from a cohort of 5644 patients. Our experimental results indicate that our predictive models identify (i) patients that test positive for SARS-CoV-2 a priori at a sensitivity of 75% (95% CI: 67%, 81%) and a specificity of 49% (95% CI: 46%, 51%), (ii) SARS-CoV-2 positive patients that require hospitalisation with 0.92 AUC (95% CI: 0.81, 0.98), and (iii) SARS-CoV-2 positive patients that require critical care with 0.98 AUC (95% CI: 0.95, 1.00). In addition, we determine which clinical features are predictive to what degree for each of the aforementioned clinical tasks. Our results indicate that predictive models trained on routinely collected clinical data could be used to predict clinical pathways for COVID-19, and therefore help inform care and prioritise resources. ",Kein DOI-Link verfügbar,2005.08302v2,Yes,potent(1)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,Learning Counterfactual Representations for Estimating Individual   Dose-Response Curves,1970,"  Estimating what would be an individual's potential response to varying levels of exposure to a treatment is of high practical relevance for several important fields, such as healthcare, economics and public policy. However, existing methods for learning to estimate counterfactual outcomes from observational data are either focused on estimating average dose-response curves, or limited to settings with only two treatments that do not have an associated dosage parameter. Here, we present a novel machine-learning approach towards learning counterfactual representations for estimating individual dose-response curves for any number of treatments with continuous dosage parameters with neural networks. Building on the established potential outcomes framework, we introduce performance metrics, model selection criteria, model architectures, and open benchmarks for estimating individual dose-response curves. Our experiments show that the methods developed in this work set a new state-of-the-art in estimating individual dose-response. ",https://doi.org/10.1609/aaai.v34i04.6014,1902.00981v3,Yes,potent(2)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,Disentangling Factors of Variation Using Few Labels,1970,"  Learning disentangled representations is considered a cornerstone problem in representation learning. Recently, Locatello et al. (2019) demonstrated that unsupervised disentanglement learning without inductive biases is theoretically impossible and that existing inductive biases and unsupervised methods do not allow to consistently learn disentangled representations. However, in many practical settings, one might have access to a limited amount of supervision, for example through manual labeling of (some) factors of variation in a few training examples. In this paper, we investigate the impact of such supervision on state-of-the-art disentanglement methods and perform a large scale study, training over 52000 models under well-defined and reproducible experimental conditions. We observe that a small number of labeled examples (0.01--0.5\% of the data set), with potentially imprecise and incomplete labels, is sufficient to perform model selection on state-of-the-art unsupervised models. Further, we investigate the benefit of incorporating supervision into the training process. Overall, we empirically validate that with little and imprecise supervision it is possible to reliably learn disentangled representations. ",Kein DOI-Link verfügbar,1905.01258v2,Yes,potent(1)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,Federated Causal Discovery From Interventions,1970,"  Causal discovery serves a pivotal role in mitigating model uncertainty through recovering the underlying causal mechanisms among variables. In many practical domains, such as healthcare, access to the data gathered by individual entities is limited, primarily for privacy and regulatory constraints. However, the majority of existing causal discovery methods require the data to be available in a centralized location. In response, researchers have introduced federated causal discovery. While previous federated methods consider distributed observational data, the integration of interventional data remains largely unexplored. We propose FedCDI, a federated framework for inferring causal structures from distributed data containing interventional samples. In line with the federated learning framework, FedCDI improves privacy by exchanging belief updates rather than raw samples. Additionally, it introduces a novel intervention-aware method for aggregating individual updates. We analyze scenarios with shared or disjoint intervened covariates, and mitigate the adverse effects of interventional data heterogeneity. The performance and scalability of FedCDI is rigorously tested across a variety of synthetic and real-world graphs. ",Kein DOI-Link verfügbar,2211.03846v4,Yes,pivotal(1)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,Benchmarking Bayesian Causal Discovery Methods for Downstream Treatment   Effect Estimation,1970,"  The practical utility of causality in decision-making is widespread and brought about by the intertwining of causal discovery and causal inference. Nevertheless, a notable gap exists in the evaluation of causal discovery methods, where insufficient emphasis is placed on downstream inference. To address this gap, we evaluate seven established baseline causal discovery methods including a newly proposed method based on GFlowNets, on the downstream task of treatment effect estimation. Through the implementation of a distribution-level evaluation, we offer valuable and unique insights into the efficacy of these causal discovery methods for treatment effect estimation, considering both synthetic and real-world scenarios, as well as low-data scenarios. The results of our study demonstrate that some of the algorithms studied are able to effectively capture a wide range of useful and diverse ATE modes, while some tend to learn many low-probability modes which impacts the (unrelaxed) recall and precision. ",Kein DOI-Link verfügbar,2307.04988v3,Yes,notable(1)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,DiscoBAX: Discovery of Optimal Intervention Sets in Genomic Experiment   Design,1970,"  The discovery of therapeutics to treat genetically-driven pathologies relies on identifying genes involved in the underlying disease mechanisms. Existing approaches search over the billions of potential interventions to maximize the expected influence on the target phenotype. However, to reduce the risk of failure in future stages of trials, practical experiment design aims to find a set of interventions that maximally change a target phenotype via diverse mechanisms. We propose DiscoBAX, a sample-efficient method for maximizing the rate of significant discoveries per experiment while simultaneously probing for a wide range of diverse mechanisms during a genomic experiment campaign. We provide theoretical guarantees of approximate optimality under standard assumptions, and conduct a comprehensive experimental evaluation covering both synthetic as well as real-world experimental design tasks. DiscoBAX outperforms existing state-of-the-art methods for experimental design, selecting effective and diverse perturbations in biological systems. ",Kein DOI-Link verfügbar,2312.04064v1,Yes,potent(1)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,GeneDisco: A Benchmark for Experimental Design in Drug Discovery,1970,"  In vitro cellular experimentation with genetic interventions, using for example CRISPR technologies, is an essential step in early-stage drug discovery and target validation that serves to assess initial hypotheses about causal associations between biological mechanisms and disease pathologies. With billions of potential hypotheses to test, the experimental design space for in vitro genetic experiments is extremely vast, and the available experimental capacity - even at the largest research institutions in the world - pales in relation to the size of this biological hypothesis space. Machine learning methods, such as active and reinforcement learning, could aid in optimally exploring the vast biological space by integrating prior knowledge from various information sources as well as extrapolating to yet unexplored areas of the experimental design space based on available data. However, there exist no standardised benchmarks and data sets for this challenging task and little research has been conducted in this area to date. Here, we introduce GeneDisco, a benchmark suite for evaluating active learning algorithms for experimental design in drug discovery. GeneDisco contains a curated set of multiple publicly available experimental data sets as well as open-source implementations of state-of-the-art active learning policies for experimental design and exploration. ",Kein DOI-Link verfügbar,2110.11875v1,Yes,potent(1)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,Causal machine learning for single-cell genomics,1970,"  Advances in single-cell omics allow for unprecedented insights into the transcription profiles of individual cells. When combined with large-scale perturbation screens, through which specific biological mechanisms can be targeted, these technologies allow for measuring the effect of targeted perturbations on the whole transcriptome. These advances provide an opportunity to better understand the causative role of genes in complex biological processes such as gene regulation, disease progression or cellular development. However, the high-dimensional nature of the data, coupled with the intricate complexity of biological systems renders this task nontrivial. Within the machine learning community, there has been a recent increase of interest in causality, with a focus on adapting established causal techniques and algorithms to handle high-dimensional data. In this perspective, we delineate the application of these methodologies within the realm of single-cell genomics and their challenges. We first present the model that underlies most of current causal approaches to single-cell biology and discuss and challenge the assumptions it entails from the biological point of view. We then identify open problems in the application of causal approaches to single-cell data: generalising to unseen environments, learning interpretable models, and learning causal models of dynamics. For each problem, we discuss how various research directions - including the development of computational approaches and the adaptation of experimental protocols - may offer ways forward, or on the contrary pose some difficulties. With the advent of single cell atlases and increasing perturbation data, we expect causal models to become a crucial tool for informed experimental design. ",Kein DOI-Link verfügbar,2310.14935v1,Yes,intricate(1)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,Pyfectious: An individual-level simulator to discover optimal   containment polices for epidemic diseases,1970,"  Simulating the spread of infectious diseases in human communities is critical for predicting the trajectory of an epidemic and verifying various policies to control the devastating impacts of the outbreak. Many existing simulators are based on compartment models that divide people into a few subsets and simulate the dynamics among those subsets using hypothesized differential equations. However, these models lack the requisite granularity to study the effect of intelligent policies that influence every individual in a particular way. In this work, we introduce a simulator software capable of modeling a population structure and controlling the disease's propagation at an individualistic level. In order to estimate the confidence of the conclusions drawn from the simulator, we employ a comprehensive probabilistic approach where the entire population is constructed as a hierarchical random variable. This approach makes the inferred conclusions more robust against sampling artifacts and gives confidence bounds for decisions based on the simulation results. To showcase potential applications, the simulator parameters are set based on the formal statistics of the COVID-19 pandemic, and the outcome of a wide range of control measures is investigated. Furthermore, the simulator is used as the environment of a reinforcement learning problem to find the optimal policies to control the pandemic. The obtained experimental results indicate the simulator's adaptability and capacity in making sound predictions and a successful policy derivation example based on real-world data. As an exemplary application, our results show that the proposed policy discovery method can lead to control measures that produce significantly fewer infected individuals in the population and protect the health system against saturation. ",Kein DOI-Link verfügbar,2103.15561v2,Yes,potent(1)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,Benchmarking Offline Reinforcement Learning on Real-Robot Hardware,1970,"  Learning policies from previously recorded data is a promising direction for real-world robotics tasks, as online learning is often infeasible. Dexterous manipulation in particular remains an open problem in its general form. The combination of offline reinforcement learning with large diverse datasets, however, has the potential to lead to a breakthrough in this challenging domain analogously to the rapid progress made in supervised learning in recent years. To coordinate the efforts of the research community toward tackling this problem, we propose a benchmark including: i) a large collection of data for offline learning from a dexterous manipulation platform on two tasks, obtained with capable RL agents trained in simulation; ii) the option to execute learned policies on a real-world robotic system and a simulation for efficient debugging. We evaluate prominent open-sourced offline reinforcement learning algorithms on the datasets and provide a reproducible experimental setup for offline reinforcement learning on real systems. ",Kein DOI-Link verfügbar,2307.15690v1,Yes,potent(1)
0000-0002-7836-5961,Stefan Bauer,Universität Bielefeld,Exploring the Effectiveness of Object-Centric Representations in Visual   Question Answering: Comparative Insights with Foundation Models,1970,"  Object-centric (OC) representations, which represent the state of a visual scene by modeling it as a composition of objects, have the potential to be used in various downstream tasks to achieve systematic compositional generalization and facilitate reasoning. However, these claims have not been thoroughly analyzed yet. Recently, foundation models have demonstrated unparalleled capabilities across diverse domains from language to computer vision, marking them as a potential cornerstone of future research for a multitude of computational tasks. In this paper, we conduct an extensive empirical study on representation learning for downstream Visual Question Answering (VQA), which requires an accurate compositional understanding of the scene. We thoroughly investigate the benefits and trade-offs of OC models and alternative approaches including large pre-trained foundation models on both synthetic and real-world data, and demonstrate a viable way to achieve the best of both worlds. The extensiveness of our study, encompassing over 800 downstream VQA models and 15 different types of upstream representations, also provides several additional insights that we believe will be of interest to the community at large. ",Kein DOI-Link verfügbar,2407.15589v1,Yes,potent(2)
0000-0002-7836-7000,Faisal Ahmed,Universität Siegen,FedAuxHMTL: Federated Auxiliary Hard-Parameter Sharing Multi-Task   Learning for Network Edge Traffic Classification,1970,"  Federated Learning (FL) has garnered significant interest recently due to its potential as an effective solution for tackling many challenges in diverse application scenarios, for example, data privacy in network edge traffic classification. Despite its recognized advantages, FL encounters obstacles linked to statistical data heterogeneity and labeled data scarcity during the training of single-task models for machine learning-based traffic classification, leading to hindered learning performance. In response to these challenges, adopting a hard-parameter sharing multi-task learning model with auxiliary tasks proves to be a suitable approach. Such a model has the capability to reduce communication and computation costs, navigate statistical complexities inherent in FL contexts, and overcome labeled data scarcity by leveraging knowledge derived from interconnected auxiliary tasks. This paper introduces a new framework for federated auxiliary hard-parameter sharing multi-task learning, namely, FedAuxHMTL. The introduced framework incorporates model parameter exchanges between edge server and base stations, enabling base stations from distributed areas to participate in the FedAuxHMTL process and enhance the learning performance of the main task-network edge traffic classification. Empirical experiments are conducted to validate and demonstrate the FedAuxHMTL's effectiveness in terms of accuracy, total global loss, communication costs, computing time, and energy consumption compared to its counterparts. ",Kein DOI-Link verfügbar,2404.08028v1,Yes,potent(1)
0000-0002-7836-7000,Faisal Ahmed,Universität Siegen,MM-VID: Advancing Video Understanding with GPT-4V(ision),1970,"  We present MM-VID, an integrated system that harnesses the capabilities of GPT-4V, combined with specialized tools in vision, audio, and speech, to facilitate advanced video understanding. MM-VID is designed to address the challenges posed by long-form videos and intricate tasks such as reasoning within hour-long content and grasping storylines spanning multiple episodes. MM-VID uses a video-to-script generation with GPT-4V to transcribe multimodal elements into a long textual script. The generated script details character movements, actions, expressions, and dialogues, paving the way for large language models (LLMs) to achieve video understanding. This enables advanced capabilities, including audio description, character identification, and multimodal high-level comprehension. Experimental results demonstrate the effectiveness of MM-VID in handling distinct video genres with various video lengths. Additionally, we showcase its potential when applied to interactive environments, such as video games and graphic user interfaces. ",Kein DOI-Link verfügbar,2310.19773v1,Yes,"intricate(1), potent(1)"
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,An Effective Potential for Composite Operators,1970,"  We study the effective potential for composite operators. Introducing a source coupled to the composite operator, we define the effective potential by a Legendre transformation. We find that in three or fewer dimensions, one can use the conventionally defined renormalized operator to couple to the source. However, in four dimensions, the effective potential for the conventional renormalized composite operator is divergent. We overcome this difficulty by adding additional counterterms to the operator and adjusting these order by order in perturbation theory. These counterterms are found to be non-polynomial. We find that, because of the extra counterterms, the composite effective potential is gauge dependent. We display this gauge-dependence explicitly at two-loop order. ",https://doi.org/10.1103/PhysRevD.54.1614,hep-ph/9602435v1,Yes,potent(4)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Probing Three-Dimensional Magnetic Fields: I -- Polarized Dust Emission,1970,"  Polarized dust emission is widely used to trace the plane-of-the-sky (POS) component of interstellar magnetic fields in two dimensions. Its potential to access three-dimensional magnetic fields, including the inclination angle of the magnetic fields relative to the line-of-sight (LOS), is crucial for a variety of astrophysical problems. Based on the statistical features of observed polarization fraction and POS Alfv\'en Mach number $\overline{M_{\rm A}}_{,\bot}$ distribution, we present a new method for estimating the inclination angle. The magnetic field fluctuations raised by anisotropic magnetohydrodynamic (MHD) turbulence are taken into account in our method. By using synthetic dust emission generated from 3D compressible MHD turbulence simulations, we show that the fluctuations are preferentially perpendicular to the mean magnetic field. We find the inclination angle is the major agent for depolarization, while fluctuations of magnetic field strength and density have an insignificant contribution. We propose and demonstrate that the mean inclination angle over a region of interest can be calculated from the polarization fraction in a strongly magnetized reference position, where $\overline{M_{\rm A}}_{,\bot}^2\ll1$. We test and show that the new method can trace the 3D magnetic fields in sub-Alfv\'enic, trans-Alfv\'enic, and moderately super-Alfv\'enic conditions ($0.4\lesssim M_{\rm A}\lesssim1.2$). We numerically quantify that the difference between the estimated inclination angle and actual inclination angle ranges from 0 to $20^\circ$ with a median value of $\le10^\circ$. ",https://doi.org/10.1093/mnras/stac3744,2203.09745v4,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Mapping the Galactic Magnetic Field Orientation and Strength in Three   Dimensions,1970,"  The mapping of the Galactic Magnetic Field (GMF) in three dimensions is essential to comprehend various astrophysical processes that occur within the Milky Way. This study endeavors to map the GMF by utilizing the latest MM2 technique, the Velocity Gradient Technique (VGT), the Column Density Variance Approach, and the GALFA-H I survey of Neutral Hydrogen (H I) emission. The MM2 and VGT methods rely on an advanced understanding of magnetohydrodynamics turbulence to determine the magnetic field strength and orientation respectively. The H I emission data, combined with the Galactic rotational curve, gives us the distribution of H I gas throughout the Milky Way. By combining these two techniques, we map the GMF orientation and strength, as well as the Alfv\'en Mach number $M_{\rm A}$ in 3D for a low galactic latitude ($b<30^{\rm o}$) region close to the Perseus Arm. The analysis of column density variance gives the sonic Mach number $M_{\rm s}$ distribution, The results of this study reveal the sub-Alfv\'enic and subsonic (or trans-sonic) nature of the H I gas. The variation of mean $M_{\rm A}$ along the line-of-sight approximately ranges from 0.6 to 0.9, while that of mean $M_{\rm s}$ is from 0.2 to 1.5. The mean magnetic field strength varies from ~0.5 $\mu$G to ~2.5 $\mu$G exhibiting a decreasing trend towards the Galaxy's outskirt. This work provides a new avenue for mapping the GMF, especially the magnetic field strength, in 3D. We discuss potential synergetic applications with other approaches. ",https://doi.org/10.1093/mnras/stad1996,2302.05047v2,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,"Characterizing three-dimensional magnetic field, turbulence, and   self-gravity in the star-forming region L1688",1970,"  Interaction of three-dimensional magnetic fields, turbulence, and self-gravity in the molecular cloud is crucial in understanding star formation but has not been addressed so far. In this work, we target the low-mass star-forming region L1688 and use the spectral emissions of $^{12}$CO, $^{13}$CO, C$^{18}$O, and H I, as well as polarized dust emissions. To obtain the 3D direction of the magnetic field, we employ the novel polarization fraction analysis. In combining with the plane-of-the-sky (POS) magnetic field strength derived from the Davis-Chandrasekhar-Fermi (DCF) method and the new Differential Measure Analysis (DMA) technique, we present the first measurement of L1688's three-dimensional magnetic field, including its orientation and strength. We find that L1688's magnetic field has two statistically different inclination angles. The low-intensity tail has an inclination angle $\approx55^\circ$ on average, while that of the central dense clump is $\approx30^\circ$. We find the global mean value of total magnetic field strength is $B_{\rm tot}\approx135$ uG from DCF and $B_{\rm tot}\approx75$ uG from DMA. We use the velocity gradient technique (VGT) to separate the magnetic fields' POS orientation associated with L1688 and its foreground/background. The magnetic fields' orientations are statistically coherent. The probability density function of H$_2$ column density and VGT reveal that L1688 is potentially undergoing gravitational contraction at large scale $\approx1.0$ pc and gravitational collapse at small scale $\approx0.2$ pc. The gravitational contraction mainly along the magnetic field results in an approximate power-law relation $B_{\rm tot}\propto n_{\rm H}^{1/2}$ when volume density $n_{\rm H}$ is less than approximately $6.0\times10^3$ cm$^{-3}$. ",https://doi.org/10.1093/mnras/stad2158,2210.11023v2,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,RoboSync: Efficient Real-Time Operating System for Social Robots with   Customizable Behaviour,1970,"  Traditional robotic systems require complex implementations that are not always accessible or easy to use for Human-Robot Interaction (HRI) application developers. With the aim of simplifying the implementation of HRI applications, this paper introduces a novel real-time operating system (RTOS) designed for customizable HRI - RoboSync. By creating multi-level abstraction layers, the system enables users to define complex emotional and behavioral models without needing deep technical expertise. The system's modular architecture comprises a behavior modeling layer, a machine learning plugin configuration layer, a sensor checks customization layer, a scheduler that fits the need of HRI, and a communication and synchronization layer. This approach not only promotes ease of use without highly specialized skills but also ensures real-time responsiveness and adaptability. The primary functionality of the RTOS has been implemented for proof of concept and was tested on a CortexM4 microcontroller, demonstrating its potential for a wide range of lightweight simple-to-implement social robotics applications. ",https://doi.org/10.1007/978-981-99-8718-4_18,2312.00265v2,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Graph Convolutional Networks for traffic anomaly,1970,"  Event detection has been an important task in transportation, whose task is to detect points in time when large events disrupts a large portion of the urban traffic network. Travel information {Origin-Destination} (OD) matrix data by map service vendors has large potential to give us insights to discover historic patterns and distinguish anomalies. However, to fully capture the spatial and temporal traffic patterns remains a challenge, yet serves a crucial role for effective anomaly detection. Meanwhile, existing anomaly detection methods have not well-addressed the extreme data sparsity and high-dimension challenges, which are common in OD matrix datasets. To tackle these challenges, we formulate the problem in a novel way, as detecting anomalies in a set of directed weighted graphs representing the traffic conditions at each time interval. We further propose \textit{Context augmented Graph Autoencoder} (\textbf{Con-GAE }), that leverages graph embedding and context embedding techniques to capture the spatial traffic network patterns while working around the data sparsity and high-dimensionality issue. Con-GAE adopts an autoencoder framework and detect anomalies via semi-supervised learning. Extensive experiments show that our method can achieve up can achieve a 0.1-0.4 improvements of the area under the curve (AUC) score over state-of-art anomaly detection baselines, when applied on several real-world large scale OD matrix datasets. ",Kein DOI-Link verfügbar,2012.13637v1,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Decomposing Magnetic Fields in Three Dimensions over the Central   Molecular Zone,1970,"  Measuring magnetic fields in the interstellar medium and obtaining their distribution along line-of-sight is very challenging with the traditional techniques. The Velocity Gradient Technique (VGT), which utilizes anisotropy of magnetohydrodynamic (MHD) turbulence, provides an attractive solution. Targeting the central molecular zone (CMZ), we test this approach by applying the VGT to $\rm ^{12}CO$ and $\rm ^{13}CO$ (J = 1-0) data cubes. We first used the SCOUSEPY algorithm to decompose the CO line emissions into separate velocity components, and then we constructed pseudo-Stokes parameters via the VGT to map the plane-of-the-sky magnetic fields in three-dimension. We present the decomposed magnetic field maps and investigate their significance. While the line-of-sight integrated magnetic field orientation is shown to be consistent with the polarized dust emission from the Planck survey at 353 GHz, individual velocity components may exhibit different magnetic fields. We present a scheme of magnetic field configuration in the CMZ based on the decomposed magnetic fields. In particular, we observe a nearly vertical magnetic field orientation in the dense clump near the Sgr B2 and a change in the outflow regions around the Sgr A*. Two high-velocity structures associated with an expanding ring in the CMZ show distinct swirling magnetic field structures. These results demonstrate the potential power of the VGT to decompose velocity or density-dependent magnetic structures. ",https://doi.org/10.1093/mnras/stac1060,2201.07970v2,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Magnetic Fields and Velocity Gradients in L1551: The Role of Stellar   Feedback,1970,"  Magnetic fields play a crucial role in star formation, yet tracing them becomes particularly challenging, especially in the presence of outflow feedback in protostellar systems. We targeted the star-forming region L1551, notable for its apparent outflows, to investigate the magnetic fields. These fields were probed using polarimetry observations from the Planck satellite at 353 GHZ/849 $\mu$m, the SOFIA/HAWC+ measurement at 214 $\mu$m, and the JCMT/SCUPOL 850 $\mu$m survey. Consistently, all three measurements show that the magnetic fields twist towards the protostar IRS 5. Additionally, we utilized the Velocity Gradients Technique (VGT) on the $^{12}$CO (J = 1-0) emission data to distinguish the magnetic fields directly associated with the protostellar outflows. These were then compared with the polarization results. Notably, in the outskirts of the region, these measurements generally align. However, as one approaches the center of IRS 5, the measurements tend to yield mostly perpendicular relative orientations. This suggests that the outflows might be dynamically significant from a scale of approximately $\sim0.2$~pc, causing the velocity gradient to change direction by 90 degrees. Furthermore, we discovered that the polarization fraction $p$ and the total intensity $I$ correlate as $p \propto I^{-\alpha}$. Specifically, $\alpha$ is approximately $1.044\pm0.06$ for SCUPOL and around $0.858\pm0.15$ for HAWC+. This indicates that the outflows could significantly impact the alignment of dust grains and magnetic fields in the L1551 region. ",Kein DOI-Link verfügbar,2309.04173v2,Yes,notable(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Velocity Gradient and Stellar Polarization: Magnetic Field Tomography   towards the L1688 Cloud,1970,"  Magnetic fields are a defining yet enigmatic aspect of the interstellar medium (ISM), with their three-dimensional mapping posing a substantial challenge. In this study, we harness the innovative Velocity Gradient Technique (VGT), underpinned by magnetohydrodynamic (MHD) turbulence theories, to elucidate the magnetic field structure by applying it to the atomic neutral hydrogen (HI) emission line and the molecular tracer $^{12}$CO. We construct the tomography of the magnetic field in the low-mass star-forming region L1688, utilizing two approaches: (1) VGT-HI combined with the Galactic rotational curve, and (2) stellar polarization paired with precise star parallax measurements. Our analysis reveals that the magnetic field orientations deduced from stellar polarization undergo a distinct directional change in the vicinity of L1688, providing evidence that the misalignment between VGT-HI and stellar polarization stems from the influence of the molecular cloud's magnetic field on the polarization of starlight. When comparing VGT-$^{12}$CO to stellar polarization and Planck polarization data, we observe that VGT-$^{12}$CO effectively reconciles the misalignment noted with VGT-HI, showing statistical alignment with Planck polarization measurements. This indicates that VGT-$^{12}$CO could be integrated with VGT-HI, offering vital insights into the magnetic fields of molecular clouds, thereby enhancing the accuracy of our 3D magnetic field reconstructions. ",Kein DOI-Link verfügbar,2311.08681v2,Yes,innovative(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,On the Feasibility of Fingerprinting Collaborative Robot Traffic,1970,"  This study examines privacy risks in collaborative robotics, focusing on the potential for traffic analysis in encrypted robot communications. While previous research has explored low-level command recovery, our work investigates high-level motion recovery from command message sequences. We evaluate the efficacy of traditional website fingerprinting techniques (k-FP, KNN, and CUMUL) and their limitations in accurately identifying robotic actions due to their inability to capture detailed temporal relationships. To address this, we introduce a traffic classification approach using signal processing techniques, demonstrating high accuracy in action identification and highlighting the vulnerability of encrypted communications to privacy breaches. Additionally, we explore defenses such as packet padding and timing manipulation, revealing the challenges in balancing traffic analysis resistance with network efficiency. Our findings emphasize the need for continued development of practical defenses in robotic privacy and security. ",Kein DOI-Link verfügbar,2312.06802v1,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Mutagenesis screen to map the functionals of parameters of Large   Language Models,1970,"  Large Language Models (LLMs) have significantly advanced artificial intelligence, excelling in numerous tasks. Although the functionality of a model is inherently tied to its parameters, a systematic method for exploring the connections between the parameters and the functionality are lacking. Models sharing similar structure and parameter counts exhibit significant performance disparities across various tasks, prompting investigations into the varying patterns that govern their performance. We adopted a mutagenesis screen approach inspired by the methods used in biological studies, to investigate Llama2-7b and Zephyr. This technique involved mutating elements within the models' matrices to their maximum or minimum values to examine the relationship between model parameters and their functionalities. Our research uncovered multiple levels of fine structures within both models. Many matrices showed a mixture of maximum and minimum mutations following mutagenesis, but others were predominantly sensitive to one type. Notably, mutations that produced phenotypes, especially those with severe outcomes, tended to cluster along axes. Additionally, the location of maximum and minimum mutations often displayed a complementary pattern on matrix in both models, with the Gate matrix showing a unique two-dimensional asymmetry after rearrangement. In Zephyr, certain mutations consistently resulted in poetic or conversational rather than descriptive outputs. These ""writer"" mutations grouped according to the high-frequency initial word of the output, with a marked tendency to share the row coordinate even when they are in different matrices. Our findings affirm that the mutagenesis screen is an effective tool for deciphering the complexities of large language models and identifying unexpected ways to expand their potential, providing deeper insights into the foundational aspects of AI systems. ",Kein DOI-Link verfügbar,2408.11494v1,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Impacts of Covid-19 mode shift on road traffic,1970,"  This work considers the sensitivity of commute travel times in US metro areas due to potential changes in commute patterns, for example caused by events such as pandemics. Permanent shifts away from transit and carpooling can add vehicles to congested road networks, increasing travel times. Growth in the number of workers who avoid commuting and work from home instead can offset travel time increases. To estimate these potential impacts, 6-9 years of American Community Survey commute data for 118 metropolitan statistical areas are investigated. For 74 of the metro areas, the average commute travel time is shown to be explainable using only the number of passenger vehicles used for commuting. A universal Bureau of Public Roads model characterizes the sensitivity of each metro area with respect to additional vehicles. The resulting models are then used to determine the change in average travel time for each metro area in scenarios when 25\% or 50\% of transit and carpool users switch to single occupancy vehicles. Under a 25\% mode shift, areas such as San Francisco and New York that are already congested and have high transit ridership may experience round trip travel time increases of 12 minutes (New York) to 20 minutes (San Francisco), costing individual commuters \$1065 and \$1601 annually in lost time. The travel time increases and corresponding costs can be avoided with an increase in working from home. The main contribution of this work is to provide a model to quantify the potential increase in commute travel times under various behavior changes, that can aid policy making for more efficient commuting. ",Kein DOI-Link verfügbar,2005.01610v2,Yes,potent(3)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Collaboration Helps Camera Overtake LiDAR in 3D Detection,1970,"  Camera-only 3D detection provides an economical solution with a simple configuration for localizing objects in 3D space compared to LiDAR-based detection systems. However, a major challenge lies in precise depth estimation due to the lack of direct 3D measurements in the input. Many previous methods attempt to improve depth estimation through network designs, e.g., deformable layers and larger receptive fields. This work proposes an orthogonal direction, improving the camera-only 3D detection by introducing multi-agent collaborations. Our proposed collaborative camera-only 3D detection (CoCa3D) enables agents to share complementary information with each other through communication. Meanwhile, we optimize communication efficiency by selecting the most informative cues. The shared messages from multiple viewpoints disambiguate the single-agent estimated depth and complement the occluded and long-range regions in the single-agent view. We evaluate CoCa3D in one real-world dataset and two new simulation datasets. Results show that CoCa3D improves previous SOTA performances by 44.21% on DAIR-V2X, 30.60% on OPV2V+, 12.59% on CoPerception-UAVs+ for AP@70. Our preliminary results show a potential that with sufficient collaboration, the camera might overtake LiDAR in some practical scenarios. We released the dataset and code at https://siheng-chen.github.io/dataset/CoPerception+ and https://github.com/MediaBrain-SJTU/CoCa3D. ",Kein DOI-Link verfügbar,2303.13560v1,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Synchrotron Intensity Gradient Revealing Magnetic Fields in Galaxy   Clusters,1970,"  Magnetic fields and their dynamical interplay with matter in galaxy clusters contribute to the physical properties and evolution of the intracluster medium. However, the current understanding of the origin and properties of cluster magnetic fields is still limited by observational challenges. In this article, we map the magnetic fields at hundreds-kpc scales of five clusters RXC J1314.4 -2515, Abell 2345, Abell 3376, MCXC J0352.4 -7401, and El Gordo using the innovative synchrotron intensity gradient technique in conjunction with high-resolution radio observations from JVLA and MeerKAT. We demonstrate that magnetic field orientation of radio relics derived from synchrotron intensity gradients is in very good agreement with that obtained with synchrotron polarization. Most important, synchrotron intensity gradients is not limited by Faraday depolarization in the cluster central regions and allows us to map magnetic fields in the radio halos of RXC J1314.4 -2515 and El Gordo. We find that magnetic fields in radio halos exihibit a preferential direction along the major merger axis and show turbulent structures at higher angular resolution. Results are consistent with expectations from numerical simulations which predict turbulent magnetic fields in cluster mergers that are stirred and amplified by matter motions. ",https://doi.org/10.1038/s41467-024-45164-8,2306.10011v2,Yes,innovative(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Do You Know My Emotion? Emotion-Aware Strategy Recognition towards a   Persuasive Dialogue System,1970,"  Persuasive strategy recognition task requires the system to recognize the adopted strategy of the persuader according to the conversation. However, previous methods mainly focus on the contextual information, little is known about incorporating the psychological feedback, i.e. emotion of the persuadee, to predict the strategy. In this paper, we propose a Cross-channel Feedback memOry Network (CFO-Net) to leverage the emotional feedback to iteratively measure the potential benefits of strategies and incorporate them into the contextual-aware dialogue information. Specifically, CFO-Net designs a feedback memory module, including strategy pool and feedback pool, to obtain emotion-aware strategy representation. The strategy pool aims to store historical strategies and the feedback pool is to obtain updated strategy weight based on feedback emotional information. Furthermore, a cross-channel fusion predictor is developed to make a mutual interaction between the emotion-aware strategy representation and the contextual-aware dialogue information for strategy recognition. Experimental results on \textsc{PersuasionForGood} confirm that the proposed model CFO-Net is effective to improve the performance on M-F1 from 61.74 to 65.41. ",Kein DOI-Link verfügbar,2206.12101v1,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Latency-Aware Collaborative Perception,1970,"  Collaborative perception has recently shown great potential to improve perception capabilities over single-agent perception. Existing collaborative perception methods usually consider an ideal communication environment. However, in practice, the communication system inevitably suffers from latency issues, causing potential performance degradation and high risks in safety-critical applications, such as autonomous driving. To mitigate the effect caused by the inevitable latency, from a machine learning perspective, we present the first latency-aware collaborative perception system, which actively adapts asynchronous perceptual features from multiple agents to the same time stamp, promoting the robustness and effectiveness of collaboration. To achieve such a feature-level synchronization, we propose a novel latency compensation module, called SyncNet, which leverages feature-attention symbiotic estimation and time modulation techniques. Experiments results show that the proposed latency aware collaborative perception system with SyncNet can outperforms the state-of-the-art collaborative perception method by 15.6% in the communication latency scenario and keep collaborative perception being superior to single agent perception under severe latency. ",Kein DOI-Link verfügbar,2207.08560v4,Yes,potent(2)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,AtomGS: Atomizing Gaussian Splatting for High-Fidelity Radiance Field,1970,"  3D Gaussian Splatting (3DGS) has recently advanced radiance field reconstruction by offering superior capabilities for novel view synthesis and real-time rendering speed. However, its strategy of blending optimization and adaptive density control might lead to sub-optimal results; it can sometimes yield noisy geometry and blurry artifacts due to prioritizing optimizing large Gaussians at the cost of adequately densifying smaller ones. To address this, we introduce AtomGS, consisting of Atomized Proliferation and Geometry-Guided Optimization. The Atomized Proliferation constrains ellipsoid Gaussians of various sizes into more uniform-sized Atom Gaussians. The strategy enhances the representation of areas with fine features by placing greater emphasis on densification in accordance with scene details. In addition, we proposed a Geometry-Guided Optimization approach that incorporates an Edge-Aware Normal Loss. This optimization method effectively smooths flat surfaces while preserving intricate details. Our evaluation shows that AtomGS outperforms existing state-of-the-art methods in rendering quality. Additionally, it achieves competitive accuracy in geometry reconstruction and offers a significant improvement in training speed over other SDF-based methods. More interactive demos can be found in our website (https://rongliu-leo.github.io/AtomGS/). ",Kein DOI-Link verfügbar,2405.12369v2,Yes,intricate(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,MCR-Net: A Multi-Step Co-Interactive Relation Network for Unanswerable   Questions on Machine Reading Comprehension,1970,"  Question answering systems usually use keyword searches to retrieve potential passages related to a question, and then extract the answer from passages with the machine reading comprehension methods. However, many questions tend to be unanswerable in the real world. In this case, it is significant and challenging how the model determines when no answer is supported by the passage and abstains from answering. Most of the existing systems design a simple classifier to determine answerability implicitly without explicitly modeling mutual interaction and relation between the question and passage, leading to the poor performance for determining the unanswerable questions. To tackle this problem, we propose a Multi-Step Co-Interactive Relation Network (MCR-Net) to explicitly model the mutual interaction and locate key clues from coarse to fine by introducing a co-interactive relation module. The co-interactive relation module contains a stack of interaction and fusion blocks to continuously integrate and fuse history-guided and current-query-guided clues in an explicit way. Experiments on the SQuAD 2.0 and DuReader datasets show that our model achieves a remarkable improvement, outperforming the BERT-style baselines in literature. Visualization analysis also verifies the importance of the mutual interaction between the question and passage. ",Kein DOI-Link verfügbar,2103.04567v2,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,An Extensible Framework for Open Heterogeneous Collaborative Perception,1970,"  Collaborative perception aims to mitigate the limitations of single-agent perception, such as occlusions, by facilitating data exchange among multiple agents. However, most current works consider a homogeneous scenario where all agents use identity sensors and perception models. In reality, heterogeneous agent types may continually emerge and inevitably face a domain gap when collaborating with existing agents. In this paper, we introduce a new open heterogeneous problem: how to accommodate continually emerging new heterogeneous agent types into collaborative perception, while ensuring high perception performance and low integration cost? To address this problem, we propose HEterogeneous ALliance (HEAL), a novel extensible collaborative perception framework. HEAL first establishes a unified feature space with initial agents via a novel multi-scale foreground-aware Pyramid Fusion network. When heterogeneous new agents emerge with previously unseen modalities or models, we align them to the established unified space with an innovative backward alignment. This step only involves individual training on the new agent type, thus presenting extremely low training costs and high extensibility. To enrich agents' data heterogeneity, we bring OPV2V-H, a new large-scale dataset with more diverse sensor types. Extensive experiments on OPV2V-H and DAIR-V2X datasets show that HEAL surpasses SOTA methods in performance while reducing the training parameters by 91.5% when integrating 3 new agent types. We further implement a comprehensive codebase at: https://github.com/yifanlu0227/HEAL ",Kein DOI-Link verfügbar,2401.13964v3,Yes,innovative(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Explore of exfoliable multifunctional high-k two-dimensional oxides,1970,"  As the continuing down-scaling of field-effect transistors (FETs) in more-than-Moore integrated circuits, finding new functional two-dimensional (2D) materials with a higher dielectric constant (high-k) serve as gate dielectrics is critical. Here, we identify dozens of binary 2D oxides by screening potentially exfoliable bulk metal oxides despite of their non-layered structures followed by simulation of the exfoliation process. For dynamically stable materials, we fully characterize their static dielectric constants and electronic structures, among which GeO2(011)/(101)/(1-11) 2D oxides exhibit unusually high k values (85-99), being much higher than the k of the currently highly regarded 2D dielectrics CaF2 (k ~6) and \b{eta}-Bi2SeO5 (k ~22), together with band gap of 3.3 eV. We further design 2D high-k oxides/2D semiconductors (such as MoS2) heterostructures, and determine by DFT calculations whether they can form Van der Waals interfaces to evaluate their compatibility as gate dielectrics in 2D FETs. In addition to dielectric properties, we also explore magnetic and mechanical properties of potentially exfoliable 2D oxides, revealing a number of functional materials that can be studied experimentally, notably including ferromagnetic half semiconductors, non-magnetic spintronic materials, flexible high-k 2D oxides, and auxetic monolayers. ",Kein DOI-Link verfügbar,2212.01731v1,Yes,potent(2)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Learning User Representations with Hypercuboids for Recommender Systems,1970,"  Modeling user interests is crucial in real-world recommender systems. In this paper, we present a new user interest representation model for personalized recommendation. Specifically, the key novelty behind our model is that it explicitly models user interests as a hypercuboid instead of a point in the space. In our approach, the recommendation score is learned by calculating a compositional distance between the user hypercuboid and the item. This helps to alleviate the potential geometric inflexibility of existing collaborative filtering approaches, enabling a greater extent of modeling capability. Furthermore, we present two variants of hypercuboids to enhance the capability in capturing the diversities of user interests. A neural architecture is also proposed to facilitate user hypercuboid learning by capturing the activity sequences (e.g., buy and rate) of users. We demonstrate the effectiveness of our proposed model via extensive experiments on both public and commercial datasets. Empirical results show that our approach achieves very promising results, outperforming existing state-of-the-art. ",Kein DOI-Link verfügbar,2011.05742v1,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Charged vacancy in graphene: interplay between Landau levels and atomic   collapse resonances,1970,"  The interplay between a magnetic field and the Coulomb potential from a charged vacancy on the electron states in graphene is investigated within the tight-binding model. The Coulomb potential removes locally Landau level degeneracy, while the vacancy introduces a satellite level next to the normal Landau level. These satellite levels are found throughout the positive energy region, but in the negative energy region they turn into atomic collapse resonances. Crossings between Landau levels with different angular quantum number $m$ are found. Unlike the point impurity system in which an anticrossing occurs between Landau levels of the same $m$, in this work anticrossing is found between the normal Landau level and the vacancy induced level. The atomic collapse resonance hybridize with the Landau levels. The charge at which the lowest Landau level $m = -1, N = 1$ crosses increases $E = 0$ with enhancing magnetic field. Landau level scaling anomaly occurs when the charge is larger than the critical charge $\beta\approx0.6$ and this critical charge is independent of the magnetic field. ",Kein DOI-Link verfügbar,2311.08064v1,Yes,potent(2)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Influence of Boundaries and Thermostatting on Nonequilibrium Molecular   Dynamics Simulations of Heat Conduction in Solids,1970,"  Nonequilibrium molecular dynamics (NEMD) has been extensively used to study thermal transport at various length scales in many materials. In this method, two local thermostats at different temperatures are used to generate a nonequilibrium steady state with a constant heat flux. Conventionally, the thermal conductivity of a finite system is calculated as the ratio between the heat flux and the temperature gradient extracted from the linear part of the temperature profile away from the local thermostats. Here we show that, with a proper choice of the thermostat, the nonlinear part of the temperature profile should actually not be excluded in thermal transport calculations. We compare NEMD results against those from the atomistic Green's function method in the ballistic regime, and those from the homogeneous nonequilibrium molecular dynamics method in the ballistic-to-diffusive regime. These comparisons suggest that in all the transport regimes, one should directly calculate the thermal conductance from the temperature difference between the heat source and sink and, if needed, convert it to the thermal conductivity by multiplying it with the system length. Furthermore, we find that the Langevin thermostat outperforms the Nos\'{e}-Hoover (chain) thermostat in NEMD simulations because of its stochastic and local nature. We show that this is particularly important for studying asymmetric carbon-based nanostructures, for which the Nos\'{e}-Hoover thermostat can produce artifacts leading to unphysical thermal rectification. Our findings are important to obtain correct results from molecular dynamics simulations of nanoscale heat transport as the accuracy of the interatomic potentials is rapidly improving. ",https://doi.org/10.1063/1.5132543,1905.11024v1,Yes,potent(1)
0000-0002-7985-5145,Yue Hu,Heinrich-Heine-Universität Düsseldorf,Towards Collaborative Autonomous Driving: Simulation Platform and   End-to-End System,1970,"  Vehicle-to-everything-aided autonomous driving (V2X-AD) has a huge potential to provide a safer driving solution. Despite extensive researches in transportation and communication to support V2X-AD, the actual utilization of these infrastructures and communication resources in enhancing driving performances remains largely unexplored. This highlights the necessity of collaborative autonomous driving: a machine learning approach that optimizes the information sharing strategy to improve the driving performance of each vehicle. This effort necessitates two key foundations: a platform capable of generating data to facilitate the training and testing of V2X-AD, and a comprehensive system that integrates full driving-related functionalities with mechanisms for information sharing. From the platform perspective, we present V2Xverse, a comprehensive simulation platform for collaborative autonomous driving. This platform provides a complete pipeline for collaborative driving. From the system perspective, we introduce CoDriving, a novel end-to-end collaborative driving system that properly integrates V2X communication over the entire autonomous pipeline, promoting driving with shared perceptual information. The core idea is a novel driving-oriented communication strategy. Leveraging this strategy, CoDriving improves driving performance while optimizing communication efficiency. We make comprehensive benchmarks with V2Xverse, analyzing both modular performance and closed-loop driving performance. Experimental results show that CoDriving: i) significantly improves the driving score by 62.49% and drastically reduces the pedestrian collision rate by 53.50% compared to the SOTA end-to-end driving method, and ii) achieves sustaining driving performance superiority over dynamic constraint communication conditions. ",Kein DOI-Link verfügbar,2404.09496v1,Yes,potent(1)
0000-0002-8025-4742,Jürgen Barnstedt,Universität Tübingen,Stratospheric Balloons as a Complement to the Next Generation of   Astronomy Missions,1970,"  Observations that require large physical instrument dimensions and/or a considerable amount of cryogens, as it is for example the case for high spatial resolution far infrared astronomy, currently still face technological limits for their execution from space. The high cost and finality of space missions furthermore call for a very low risk approach and entail long development times. For certain spectral regions, prominently including the mid- to far-infrared as well as parts of the ultraviolet, stratospheric balloons offer a flexible and affordable complement to space telescopes, with short development times and comparatively good observing conditions. Yet, the entry burden to use balloon-borne telescopes is high, with research groups typically having to shoulder part of the infrastructure development as well. Aiming to ease access to balloon-based observations, we present the efforts towards a community-accessible balloon-based observatory, the European Stratospheric Balloon Observatory (ESBO). ESBO aims at complementing space-based and airborne capabilities over the next 10-15 years and at adding to the current landscape of scientific ballooning activities by providing a service-centered infrastructure for broader astronomical use, performing regular flights and offering an operations concept that provides researchers with a similar proposal-based access to observation time as practiced on ground-based observatories. We present details on the activities planned towards the goal of ESBO, the current status of the STUDIO (Stratospheric UV Demonstrator of an Imaging Observatory) prototype platform and mission, as well as selected technology developments with extensibility potential to space missions undertaken for STUDIO. ",Kein DOI-Link verfügbar,2202.04651v1,Yes,potent(1)
0000-0002-8053-0284,Fabian Gabel,Technische Universität Hamburg,Spectral approximation of generalized Schrödinger operators via   approximation of subwords,1970,"  We demonstrate criteria, purely based on finite subwords of the potential, to guarantee spectral inclusion as well as Hausdorff approximation of pseudospectra or even spectra of generalized Schr\""odinger operators on the discrete line or half-line. In fact, our results are neither limited to Schr\""odinger or self-adjoint operators, nor to Hilbert space or 1D. ",Kein DOI-Link verfügbar,2209.11613v2,Yes,potent(1)
0000-0002-8053-0284,Fabian Gabel,Technische Universität Hamburg,Finite Sections of Periodic Schrödinger Operators,1970,"  We study discrete Schr\""odinger operators $H$ with periodic potentials as they are typically used to approximate aperiodic Schr\""odinger operators like the Fibonacci Hamiltonian. We prove an efficient test for applicability of the finite section method, a procedure that approximates $H$ by growing finite square submatrices $H_n$. For integer-valued potentials, we show that the finite section method is applicable as soon as $H$ is invertible. This statement remains true for $\{0, \lambda\}$-valued potentials with fixed rational $\lambda$ and period less than nine as well as for arbitrary real-valued potentials of period two. ",Kein DOI-Link verfügbar,2110.09339v2,Yes,potent(4)
0000-0002-8053-0284,Fabian Gabel,Technische Universität Hamburg,Finite section method for aperiodic Schrödinger operators,1970,"  We consider 1D discrete Schr\""odinger operators with aperiodic potentials given by a Sturmian word, which is a natural generalisation of the Fibonacci Hamiltonian. Via a standard approximation by periodic potentials, we establish Hausdorff convergence of the corresponding spectra for the Schr\""odinger operators on the axis as well as for their compressions to the half-axis. Based on the half-axis results, we study the finite section method, which is another operator approximation, now by compressions to finite but growing intervals, that is often used to solve operator equations approximately. We find that, also for this purpose, the aperiodic case can be studied via its periodic approximants. Our results on the finite section method of the aperiodic operator are illustrated by confirming a result on the finite sections of the special case of the Fibonacci Hamiltonian. ",https://doi.org/10.7153/oam-2023-17-29,2104.00711v3,Yes,potent(2)
0000-0002-8122-6778,Markus Schartel,Universität Ulm,An Experimental Study on Airborne Landmine Detection Using a Circular   Synthetic Aperture Radar,1970,"  Many countries in the world are contaminated with landmines. Several thousand casualties occur every year. Although there are certain types of mines that can be detected from a safe stand-off position with tools, humanitarian demining is still mostly done by hand. As a new approach, an unmanned aerial system (UAS) equipped with a ground penetrating synthetic aperture radar (GPSAR) was developed, which is used to detect landmines, cluster munition, grenades, and improvised explosive devices (IEDs). The measurement system consists of a multicopter, a total station, an inertial measurement unit (IMU), and a frequency-modulated continuous-wave (FMCW) radar operating from 1 GHz to 4 GHz. The highly accurate localization of the measurement system and the full flexibility of the UAS are used to generate 3D-repeat-pass circular SAR images of buried antipersonnel landmines. In order to demonstrate the functionality of the system, 15 different dummy landmines were buried in a sandbox. The measurement results show the high potential of circular SAR for the detection of minimum metal mines. 11 out of 15 different test objects could be detected unambiguously with cm-level accuracy by examining depth profiles showing the amplitude of the targets response over the processing depth. ",Kein DOI-Link verfügbar,2005.02600v1,Yes,potent(1)
0000-0002-8256-5675,Natalia Dubrovinskaia,Universität Bayreuth,High-Pressure Synthesis of Seven Lanthanum Hydrides with a Significant   Variability of Hydrogen Content,1970,"  The lanthanum-hydrogen system has attracted significant attention following the report of superconductivity in LaH10 at near-ambient temperatures and high pressures. Here, we present the results of our single-crystal X-ray diffraction studies on this system, supported by density functional theory calculations, which reveal an unexpected chemical and structural diversity of lanthanum hydrides synthesized in the range of 50 to 180 GPa. Seven lanthanum hydrides were produced, LaH3, LaH~4, LaH4+{\delta}, La4H23, LaH6+{\delta}, LaH9+{\delta}, and LaH10+{\delta}, and the atomic coordinates of lanthanum in their structures determined. The regularities in rare-earth element hydrides unveiled here provide clues to guide the search for other synthesizable hydrides and candidate high-temperature superconductors. The hydrogen content variability in lanthanum hydrides and the samples' phase heterogeneity underline the challenges related to assessing potentially superconducting phase(s) and the nature of electronic transitions in high-pressure hydrides. ",https://doi.org/10.1038/s41467-022-34755-y,2208.10418v1,Yes,potent(1)
0000-0002-8256-5675,Natalia Dubrovinskaia,Universität Bayreuth,High-pressure synthesis of ultraincompressible hard rhenium nitride   pernitride Re$_{2}$(N$_{2}$)N$_{2}$ stable at ambient conditions,1970,"  Here we report the synthesis of metallic, ultraincompressible (bulk modulus $K_{0}$ = 428(10) GPa) and very hard (nanoindentation hardness 36.7(8) GPa) rhenium (V) nitride pernitride Re$_{2}$(N$_{2}$)N$_{2}$. While the empirical chemical formula of the compound, ReN$_{2}$, is the same as for other known transition metals pernitrides, e.g. IrN$_{2}$, PtN$_{2}$, PdN$_{2}$ and OsN$_{2}$, its crystal chemistry is unique. The known pernitrides of transition metals consist of a metal in the oxidation state +IV and pernitride anions N$_{2}^{4-}$. ReN$_{2}$ contains both pernitride N$_{2}^{4-}$ and discrete N$^{3-}$ anions, which explains its exceptional properties. Moreover, in the original experimental synthesis of Re$_{2}$(N$_{2}$)N$_{2}$ performed in a laser-heated diamond anvil cell via a direct reaction between rhenium and nitrogen at pressures from 40 to 90 GPa we observed that the material was recoverable at ambient conditions. Consequently, we developed a route to scale up its synthesis through a reaction between rhenium and ammonium azide, NH$_{4}$N$_{3}$, in a large-volume press at 33 GPa. Our work resulted not only in a discovery of a novel material with unusual crystal chemistry and a set of properties attractive for potential applications, but also demonstrated a feasibility of surmounting conceptions common in material sciences. ",https://doi.org/10.1038/s41467-019-10995-3,1902.09249v1,Yes,potent(1)
0000-0002-8350-6925,Adrian Weindl,Universität Regensburg,Tracing Dirac points of topological surface states by ferromagnetic   resonance,1970,"  Ferromagnetic resonance is used to reveal features of the buried electronic band structure at interfaces between ferromagnetic metals and topological insulators. By monitoring the evolution of magnetic damping, the application of this method to a hybrid structure consisting of a ferromagnetic layer and a 3D topological insulator reveals a clear fingerprint of the Dirac point and exhibits additional features of the interfacial band structure not otherwise observable. The underlying spin-pumping mechanism is discussed in the framework of dissipation of angular momentum by topological surface states (TSSs). Tuning of the Fermi level within the TSS was verified both by varying the stoichiometry of the topological insulator layer and by electrostatic backgating and the damping values obtained in both cases show a remarkable agreement. The high energy resolution of this method additionally allows us to resolve the energetic shift of the local Dirac points generated by local variations of the electrostatic potential. Calculations based on the chiral tunneling process naturally occurring in TSS agree well with the experimental results. ",https://doi.org/10.1103/PhysRevB.109.064424,2403.03518v2,Yes,potent(1)
0000-0002-8362-4083,Julia Harz,Johannes Gutenberg Universität Mainz,Higgs-mediated bound states in dark-matter models,1970,"  It has been recently demonstrated that the 125 GeV Higgs boson can mediate a long-range force between TeV-scale particles, that can impact considerably their annihilation due to the Sommerfeld effect, and hence the density of thermal relic dark matter. In the presence of long-range interactions, the formation and decay of particle-antiparticle bound states can also deplete dark matter significantly. We consider the Higgs boson as mediator in the formation of bound states, and compute the effect on the dark matter abundance. To this end, we consider a simplified model in which dark matter co-annihilates with coloured particles that have a sizeable coupling to the Higgs. The Higgs-mediated force affects the dark matter depletion via bound state formation in several ways. It enhances the capture cross-sections due to the attraction it mediates between the incoming particles, it increases the binding energy of the bound states, hence rendering their ionisation inefficient sooner in the early universe, and for large enough couplings, it can overcome the gluon repulsion of certain colour representations and give rise to additional bound states. Because it alters the momentum exchange in the bound states, the Higgs-mediated force also affects the gluon-mediated potential via the running of the strong coupling. We comment on the experimental implications and conclude that the Higgs-mediated potential must be taken into account when circumscribing the viable parameter space of related models. ",https://doi.org/10.1007/JHEP04(2019)130,1901.10030v2,Yes,potent(2)
0000-0002-8362-4083,Julia Harz,Johannes Gutenberg Universität Mainz,Impact of Neutrinoless Double Beta Decay on Models of Baryogenesis,1970,"  Interactions that manifest themselves as lepton number violating processes at low energies in combination with sphaleron transitions typically erase any pre-existing baryon asymmetry of the Universe. We demonstrate in a model independent approach that the observation of neutrinoless double beta decay would impose a stringent constraint on mechanisms of high-scale baryogenesis, including leptogenesis scenarios. Further, we discuss the potential of the LHC to model independently exclude high-scale leptogenesis scenarios when observing lepton number violating processes. In combination with the observation of lepton flavor violating processes, we can further strengthen this argument, closing the loophole of asymmetries being stored in different lepton flavors. ",Kein DOI-Link verfügbar,1510.06305v1,Yes,potent(1)
0000-0002-8362-4083,Julia Harz,Johannes Gutenberg Universität Mainz,Confronting Dark Matter Freeze-In during Reheating with Constraints from   Inflation,1970,"  We investigate the production of particle Dark Matter (DM) in a minimal freeze-in model considering a non-instantaneous reheating phase after inflation. We demonstrate that for low reheating temperatures, bosonic or fermionic reheating from monomial potentials can lead to a different evolution in the DM production and hence to distinct predictions for the parent particle lifetime and mass, constrained by long-lived particle (LLP) searches. We highlight that such scenario predicts parent particle decay lengths larger compared to using the instantaneous reheating approximation. Moreover, we demonstrate the importance of an accurate definition of the reheating temperature and emphasize its relevance for the correct interpretation of experimental constraints. We explore different models of inflation, which can lead to the considered reheating potential. We find that the extent to which the standard DM freeze-in production can be modified crucially depends on the underlying inflationary model. Based on the latest CMB constraints, we derive lower limits on the decay length of the parent particle and confront these results with the corresponding reach of LLP searches. Our findings underscore the impact of the specific dynamics of inflation on DM freeze-in production and highlight their importance for the interpretation of collider signatures. At the same time, our results indicate the potential for LLP searches to shed light on the underlying dynamics of reheating. ",https://doi.org/10.1088/1475-7516/2024/01/053,2306.17238v2,Yes,potent(3)
0000-0002-8362-4083,Julia Harz,Johannes Gutenberg Universität Mainz,Probing Active-Sterile Neutrino Transition Magnetic Moments with Photon   Emission from CE$ν$NS,1970,"  In the presence of transition magnetic moments between active and sterile neutrinos, the search for a Primakoff upscattering process at coherent elastic neutrino-nucleus scattering (CE$\nu$NS) experiments can provide stringent constraints on the neutrino magnetic moment. We show that a radiative upscattering process with an emitted photon in the final state can induce a novel coincidence signal at CE$\nu$NS experiments that can also probe neutrino transition magnetic moments beyond existing limits. Furthermore, the differential distributions for such a radiative mode can also potentially be sensitive to the Dirac vs. Majorana nature of the sterile state mediating the process. This can provide valuable insights into the nature and mass generation mechanism of the light active neutrinos. ",https://doi.org/10.1103/PhysRevD.106.035036,2110.02233v2,Yes,potent(1)
0000-0002-8441-8935,Haoran Wu,Universität des Saarlandes,Mutation Testing for Ethereum Smart Contract,1970,"  Smart contract is a special program that manages digital assets on blockchain. It is difficult to recover the loss if users make transactions through buggy smart contracts, which cannot be directly fixed. Hence, it is important to ensure the correctness of smart contracts before deploying them. This paper proposes a systematic framework to mutation testing for smart contracts on Ethereum, which is currently the most popular open blockchain for deploying and running smart contracts. Fifteen novel mutation operators have been designed for Ethereum Smart Contracts (ESC), in terms of keyword, global variable/function, variable unit, and error handling. An empirical study on 26 smart contracts in four Ethereum DApps has been conducted to evaluate the effectiveness of mutation testing. The experimental results show that our approach can outperform the coverage-based approach on defect detection rate (96.01% vs. 55.68%). The ESC mutation operators are effective to reveal real defects and we found 117 out of 729 real bug reports are related to our operators. These show the great potential of using mutation testing for quality assurance of ESC. ",Kein DOI-Link verfügbar,1908.03707v1,Yes,potent(1)
0000-0002-8441-8935,Haoran Wu,Universität des Saarlandes,FREA: Feasibility-Guided Generation of Safety-Critical Scenarios with   Reasonable Adversariality,1970,"  Generating safety-critical scenarios, which are essential yet difficult to collect at scale, offers an effective method to evaluate the robustness of autonomous vehicles (AVs). Existing methods focus on optimizing adversariality while preserving the naturalness of scenarios, aiming to achieve a balance through data-driven approaches. However, without an appropriate upper bound for adversariality, the scenarios might exhibit excessive adversariality, potentially leading to unavoidable collisions. In this paper, we introduce FREA, a novel safety-critical scenarios generation method that incorporates the Largest Feasible Region (LFR) of AV as guidance to ensure the reasonableness of the adversarial scenarios. Concretely, FREA initially pre-calculates the LFR of AV from offline datasets. Subsequently, it learns a reasonable adversarial policy that controls critical background vehicles (CBVs) in the scene to generate adversarial yet AV-feasible scenarios by maximizing a novel feasibility-dependent objective function. Extensive experiments illustrate that FREA can effectively generate safety-critical scenarios, yielding considerable near-miss events while ensuring AV's feasibility. Generalization analysis also confirms the robustness of FREA in AV testing across various surrogate AV methods and traffic environments. ",Kein DOI-Link verfügbar,2406.02983v1,Yes,potent(1)
0000-0002-8441-8935,Haoran Wu,Universität des Saarlandes,SparseDrive: End-to-End Autonomous Driving via Sparse Scene   Representation,1970,"  The well-established modular autonomous driving system is decoupled into different standalone tasks, e.g. perception, prediction and planning, suffering from information loss and error accumulation across modules. In contrast, end-to-end paradigms unify multi-tasks into a fully differentiable framework, allowing for optimization in a planning-oriented spirit. Despite the great potential of end-to-end paradigms, both the performance and efficiency of existing methods are not satisfactory, particularly in terms of planning safety. We attribute this to the computationally expensive BEV (bird's eye view) features and the straightforward design for prediction and planning. To this end, we explore the sparse representation and review the task design for end-to-end autonomous driving, proposing a new paradigm named SparseDrive. Concretely, SparseDrive consists of a symmetric sparse perception module and a parallel motion planner. The sparse perception module unifies detection, tracking and online mapping with a symmetric model architecture, learning a fully sparse representation of the driving scene. For motion prediction and planning, we review the great similarity between these two tasks, leading to a parallel design for motion planner. Based on this parallel design, which models planning as a multi-modal problem, we propose a hierarchical planning selection strategy , which incorporates a collision-aware rescore module, to select a rational and safe trajectory as the final planning output. With such effective designs, SparseDrive surpasses previous state-of-the-arts by a large margin in performance of all tasks, while achieving much higher training and inference efficiency. Code will be avaliable at https://github.com/swc-17/SparseDrive for facilitating future research. ",Kein DOI-Link verfügbar,2405.19620v2,Yes,potent(1)
0000-0002-8441-8935,Haoran Wu,Universität des Saarlandes,PepHarmony: A Multi-View Contrastive Learning Framework for Integrated   Sequence and Structure-Based Peptide Encoding,1970,"  Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or http://www.healthinformaticslab.org/supp/. ",Kein DOI-Link verfügbar,2401.11360v1,Yes,"innovative(1), intricate(1), notable(1), innovatively(1)"
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Evading the sign problem in random matrix simulations,1970,"  We show how the sign problem occurring in dynamical simulations of random matrices at nonzero chemical potential can be avoided by judiciously combining matrices into subsets. For each subset the sum of fermionic determinants is real and positive such that importance sampling can be used in Monte Carlo simulations. The number of matrices per subset is proportional to the matrix dimension. We measure the chiral condensate and observe that the statistical error is independent of the chemical potential and grows linearly with the matrix dimension, which contrasts strongly with its exponential growth in reweighting methods. ",https://doi.org/10.1103/PhysRevLett.107.132002,1103.3467v2,Yes,potent(2)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,A subset solution to the sign problem in random matrix simulations,1970,"  We present a solution to the sign problem in dynamical random matrix simulations of a two-matrix model at nonzero chemical potential. The sign problem, caused by the complex fermion determinants, is solved by gathering the matrices into subsets, whose sums of determinants are real and positive even though their cardinality only grows linearly with the matrix size. A detailed proof of this positivity theorem is given for an arbitrary number of fermion flavors. We performed importance sampling Monte Carlo simulations to compute the chiral condensate and the quark number density for varying chemical potential and volume. The statistical errors on the results only show a mild dependence on the matrix size and chemical potential, which confirms the absence of sign problem in the subset method. This strongly contrasts with the exponential growth of the statistical error in standard reweighting methods, which was also analyzed quantitatively using the subset method. Finally, we show how the method elegantly resolves the Silver Blaze puzzle in the microscopic limit of the matrix model, where it is equivalent to QCD. ",https://doi.org/10.1103/PhysRevD.86.074505,1205.5500v2,Yes,potent(3)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Nonzero chemical potential in the overlap Dirac operator and comparison   to random matrix theory,1970,"  In this talk we present the results published recently in Ref. [1], where we showed how to introduce a quark chemical potential in the overlap Dirac operator. The resulting operator satisfies a Ginsparg-Wilson relation and has exact zero modes. It is no longer gamma_5-Hermitian, but its nonreal eigenvalues still occur in pairs. We compute the spectral density of the operator on the lattice and show that, for small eigenvalues, the data agree with analytical predictions of non-Hermitian chiral random matrix theory for both trivial and nontrivial topology. We also explain an observed change in the number of zero modes as a function of chemical potential. ",Kein DOI-Link verfügbar,hep-lat/0609020v1,Yes,potent(2)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Random matrix analysis of the QCD sign problem for general topology,1970,"  Motivated by the important role played by the phase of the fermion determinant in the investigation of the sign problem in lattice QCD at nonzero baryon density, we derive an analytical formula for the average phase factor of the fermion determinant for general topology in the microscopic limit of chiral random matrix theory at nonzero chemical potential, for both the quenched and the unquenched case. The formula is a nontrivial extension of the expression for zero topology derived earlier by Splittorff and Verbaarschot. Our analytical predictions are verified by detailed numerical random matrix simulations of the quenched theory. ",https://doi.org/10.1088/1126-6708/2009/03/100,0812.0324v2,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,The QCD sign problem and dynamical simulations of random matrices,1970,"  At nonzero quark chemical potential dynamical lattice simulations of QCD are hindered by the sign problem caused by the complex fermion determinant. The severity of the sign problem can be assessed by the average phase of the fermion determinant. In an earlier paper we derived a formula for the microscopic limit of the average phase for general topology using chiral random matrix theory. In the current paper we present an alternative derivation of the same quantity, leading to a simpler expression which is also calculable for finite-sized matrices, away from the microscopic limit. We explicitly prove the equivalence of the old and new results in the microscopic limit. The results for finite-sized matrices illustrate the convergence towards the microscopic limit. We compare the analytical results with dynamical random matrix simulations, where various reweighting methods are used to circumvent the sign problem. We discuss the pros and cons of these reweighting methods. ",https://doi.org/10.1007/JHEP05(2011)048,1102.3715v2,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Positivity of center subsets for QCD,1970,"  We further pursue an approach to the sign problem of quantum chromodynamics at nonzero chemical potential, in which configurations of the lattice path integral are gathered into subsets. In the subset construction we multiply each temporal link by center elements independently and in a first step neglect the gauge action. The positivity of the subset weights -- shown for 0+1 dimensions in an earlier study -- extends to larger lattices: for two sites in the temporal direction and arbitrary spatial extent we give a proof of the positivity by decomposing the subset weight in positive summands. From numerical evidence we conjecture that the positivity persists on larger lattices and that the gauge action can be reintroduced through mild reweighting. First results on the quark number obtained with this method in two dimensions are shown as well. ",https://doi.org/10.1103/PhysRevD.93.014508,1508.03522v2,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Selected inversion as key to a stable Langevin evolution across the QCD   phase boundary,1970,"  We present new results of full QCD at nonzero chemical potential. In PRD 92, 094516 (2015) the complex Langevin method was shown to break down when the inverse coupling decreases and enters the transition region from the deconfined to the confined phase. We found that the stochastic technique used to estimate the drift term can be very unstable for indefinite matrices. This may be avoided by using the full inverse of the Dirac operator, which is, however, too costly for four-dimensional lattices. The major breakthrough in this work was achieved by realizing that the inverse elements necessary for the drift term can be computed efficiently using the selected inversion technique provided by the parallel sparse direct solver package PARDISO. In our new study we show that no breakdown of the complex Langevin method is encountered and that simulations can be performed across the phase boundary. ",https://doi.org/10.1051/epjconf/201817507003,1707.08874v1,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Grassmann tensor-network method for strong-coupling QCD,1970,"  We present a tensor-network method for strong-coupling QCD with staggered quarks at nonzero chemical potential. After integrating out the gauge fields at infinite coupling, the partition function can be written as a full contraction of a tensor network consisting of coupled local numeric and Grassmann tensors. To evaluate the partition function and to compute observables, we develop a Grassmann higher-order tensor renormalization group method, specifically tailored for this model. We apply the method to the two-dimensional case and validate it by comparing results for the partition function, the chiral condensate and the baryon density with exact analytical expressions on small lattices up to volumes of $4\times4$. For larger two-dimensional volumes, we present tensor results for the chiral condensate as a function of the mass and volume, and observe that the chiral symmetry is not broken dynamically in two dimensions. Furthermore, our results for the number density as a function of the chemical potential hint at a first-order phase transition. Finally, we present some preliminary tensor results for three-dimensional strong-coupling QCD. ",https://doi.org/10.22323/1.430.0004,2210.08935v2,Yes,potent(2)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Overlap Dirac operator at nonzero chemical potential and random matrix   theory,1970,"  We show how to introduce a quark chemical potential in the overlap Dirac operator. The resulting operator satisfies a Ginsparg-Wilson relation and has exact zero modes. It is no longer gamma_5-hermitian, but its nonreal eigenvalues still occur in pairs. We compute the spectral density of the operator on the lattice and show that, for small eigenvalues, the data agree with analytical predictions of nonhermitian chiral random matrix theory for both trivial and nontrivial topology. ",https://doi.org/10.1103/PhysRevLett.97.012003,hep-lat/0604020v1,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Domain-wall and overlap fermions at nonzero quark chemical potential,1970,"  We have recently given a construction of the overlap Dirac operator at nonzero quark chemical potential. Here, we introduce a quark chemical potential in the domain-wall fermion formalism and show that our earlier result is reproduced if the extent of the fifth dimension is taken to infinity and its lattice spacing is taken to zero. We also extend this result to include a bare quark mass, consider its continuum limit, and prove a number of properties of the overlap operator at nonzero quark chemical potential. In particular, we show that the relation between the anomaly and the index of the overlap operator remains valid. ",https://doi.org/10.1103/PhysRevD.76.114511,0709.4630v1,Yes,potent(3)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Random matrix analysis of the QCD sign problem,1970,"  The severity of the sign problem in lattice QCD at nonzero baryon density is measured by the average phase of the fermion determinant. Motivated by the equivalence of chiral random matrix theory and QCD to leading order in the epsilon regime, we compute the phase of the fermion determinant for general topology in random matrix theory as a function of the quark chemical potential and the quark mass. We find that the sign problem becomes milder with increasing topological charge. The analytic predictions are verified by detailed numerical random matrix simulations. ",Kein DOI-Link verfügbar,0910.1206v2,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Complex Langevin Dynamics in 1+1d QCD at Non-Zero Densities,1970,  We present our results obtained from gauge cooled complex Langevin simulations in 1+1d QCD at non-zero densities in the strong coupling regime with unrooted staggered fermions. For small quark masses there are regions of the chemical potential where this method fails to reproduce correct results. In these parameter ranges we studied the effect of different gauge cooling schemes on the distributions of the fermion determinant as well as of observables. ,Kein DOI-Link verfügbar,1611.00702v1,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Grassmann higher-order tensor renormalization group approach for   two-dimensional strong-coupling QCD,1970,"  We present a tensor-network approach for two-dimensional strong-coupling QCD with staggered quarks at nonzero chemical potential. After integrating out the gauge fields at infinite coupling, the partition function can be written as a full contraction of a tensor network consisting of coupled local numeric and Grassmann tensors. To evaluate the partition function and to compute observables, we develop a Grassmann higher-order tensor renormalization group method, specifically tailored for this model. During the coarsening procedure, the blocking of adjacent Grassmann tensors is performed analytically, and the total number of Grassmann variables in the tensor network is reduced by a factor of two at each coarsening step. The coarse-site numeric tensors are truncated using higher-order singular value decompositions. The method is validated by comparing the partition function, the chiral condensate and the baryon density computed with the tensor method with exact analytical results on small lattices up to volumes of $4\times4$. For larger volumes, we present first tensor results for the chiral condensate as a function of the mass and volume, and observe that the chiral symmetry is not broken dynamically in two dimensions. We also present tensor results for the number density as a function of the chemical potential, which hint at a first-order phase transition. ",https://doi.org/10.1016/j.nuclphysb.2022.116032,2206.00545v1,Yes,potent(2)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Comparing iterative methods to compute the overlap Dirac operator at   nonzero chemical potential,1970,"  The overlap Dirac operator at nonzero quark chemical potential involves the computation of the sign function of a non-Hermitian matrix. In this talk we present iterative Krylov subspace approximations, with deflation of critical eigenvalues, which we developed to compute the operator on large lattices. We compare the accuracy and efficiency of two alternative approximations based on the Arnoldi and on the two-sided Lanczos method. The short recurrences used in the latter method make it faster and more effective for realistic lattice simulations. ",Kein DOI-Link verfügbar,0810.4228v1,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Subset method for one-dimensional QCD,1970,  We present a subset method which solves the sign problem for QCD at nonzero quark chemical potential in 0+1 dimensions. The subsets gather gauge configurations based on the center symmetry of the SU(3) group. We show that the sign problem is solved for one to five quark flavors and that it slowly reappears for a larger number of flavors. We formulate an extension of the center subsets that solves the sign problem for a larger number of flavors as well. We also derive some new analytical results for this toy model. ,https://doi.org/10.1007/JHEP10(2013)140,1307.1416v2,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Reweighted complex Langevin and its application to two-dimensional QCD,1970,"  We present the reweighted complex Langevin method, which enlarges the applicability range of the complex Langevin method by reweighting the complex trajectories. In this reweighting procedure both the auxiliary and target ensembles have a complex action. We validate the method by applying it to two-dimensional strong-coupling QCD at nonzero chemical potential, and observe that it gives access to parameter regions that could otherwise not be reached with the complex Langevin method. ",Kein DOI-Link verfügbar,1701.01298v1,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Level spacings for weakly asymmetric real random matrices and   application to two-color QCD with chemical potential,1970,"  We consider antisymmetric perturbations of real symmetric matrices in the context of random matrix theory and two-color quantum chromodynamics. We investigate the level spacing distributions of eigenvalues that remain real or become complex conjugate pairs under the perturbation. We work out analytical surmises from small matrices and show that they describe the level spacings of large random matrices. As expected from symmetry arguments, these level spacings also apply to the overlap Dirac operator for two-color QCD with chemical potential. ",https://doi.org/10.1007/JHEP08(2012)066,1204.6259v2,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Sign problem and subsets in one-dimensional QCD,1970,"  We present a subset method that solves the sign problem for QCD at nonzero quark chemical potential in 0+1 dimensions. The subsets of gauge configurations are constructed using the center symmetry of the SU(3) group. These subsets completely solve the sign problem for up to five flavors. For a larger number of flavors the sign problem slowly reappears, and we propose an extension of the subsets that also solves the sign problem for these cases. The subset method allows for numerical simulations of the model at nonzero chemical potential. We also present some preliminary results on subsets for QCD in two, three, and four dimensions. ",Kein DOI-Link verfügbar,1310.6645v2,Yes,potent(2)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Tensor-network study of the 3d $O(2)$ model at non-zero chemical   potential and temperature,1970,"  We present results of tensor-network simulations of the three-dimensional $O(2)$ model at non-zero chemical potential and temperature, which were computed using the higher-order tensor-renormalization-group method (HOTRG). This necessitated enhancements to the HOTRG blocking procedure to reduce the truncation error in the case of anisotropic tensors. Moreover, the construction of the truncated vector spaces was adapted to strongly reduce the effect of systematic errors in the computation of observables using the finite-difference method. Our (improved) HOTRG results for the evolution of the number density with the chemical potential are in agreement with results obtained with the worm algorithm, and both the Silver Blaze phenomenon at zero temperature and the temperature dependence of the number density can be adequately reproduced. ",Kein DOI-Link verfügbar,2112.01414v1,Yes,potent(2)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,An iterative method to compute the overlap Dirac operator at nonzero   chemical potential,1970,"  The overlap Dirac operator at nonzero quark chemical potential involves the computation of the sign function of a non-Hermitian matrix. In this talk we present an iterative method, first proposed by us in Ref. [1], which allows for an efficient computation of the operator, even on large lattices. The starting point is a Krylov subspace approximation, based on the Arnoldi algorithm, for the evaluation of a generic matrix function. The efficiency of this method is spoiled when the matrix has eigenvalues close to a function discontinuity. To cure this, a small number of critical eigenvectors are added to the Krylov subspace, and two different deflation schemes are proposed in this augmented subspace. The ensuing method is then applied to the sign function of the overlap Dirac operator, for two different lattice sizes. The sign function has a discontinuity along the imaginary axis, and the numerical results show how deflation dramatically improves the efficiency of the method. ",https://doi.org/10.1016/j.cpc.2007.07.012,0710.0341v1,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Distributions of individual Dirac eigenvalues for QCD at non-zero   chemical potential: RMT predictions and lattice results,1970,"  For QCD at non-zero chemical potential $\mu$, the Dirac eigenvalues are scattered in the complex plane. We define a notion of ordering for individual eigenvalues in this case and derive the distributions of individual eigenvalues from random matrix theory (RMT). We distinguish two cases depending on the parameter $\alpha=\mu^2 F^2 V$, where $V$ is the volume and $F$ is the familiar low-energy constant of chiral perturbation theory. For small $\alpha$, we use a Fredholm determinant expansion and observe that already the first few terms give an excellent approximation. For large $\alpha$, all spectral correlations are rotationally invariant, and exact results can be derived. We compare the RMT predictions to lattice data and in both cases find excellent agreement in the topological sectors $\nu=0,1,2$. ",Kein DOI-Link verfügbar,0711.0629v1,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Complex Langevin simulations of a finite density matrix model for QCD,1970,"  We study a random matrix model for QCD at finite density via complex Langevin dynamics. This model has a phase transition to a phase with nonzero baryon density. We study the convergence of the algorithm as a function of the quark mass and the chemical potential and focus on two main observables: the baryon density and the chiral condensate. For simulations close to the chiral limit, the algorithm has wrong convergence properties when the quark mass is in the spectral domain of the Dirac operator. A possible solution of this problem is discussed. ",https://doi.org/10.1051/epjconf/201713707030,1612.04621v1,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Progress on Complex Langevin simulations of a finite density matrix   model for QCD,1970,"  We study the Stephanov model, which is an RMT model for QCD at finite density, using the Complex Langevin algorithm. Naive implementation of the algorithm shows convergence towards the phase quenched or quenched theory rather than to intended theory with dynamical quarks. A detailed analysis of this issue and a potential resolution of the failure of this algorithm are discussed. We study the effect of gauge cooling on the Dirac eigenvalue distribution and time evolution of the norm for various cooling norms, which were specifically designed to remove the pathologies of the complex Langevin evolution. The cooling is further supplemented with a shifted representation for the random matrices. Unfortunately, none of these modifications generate a substantial improvement on the complex Langevin evolution and the final results still do not agree with the analytical predictions. ",https://doi.org/10.1051/epjconf/201817507034,1801.06456v1,Yes,potent(1)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Tensor renormalization group study of the 3d $O(2)$ model,1970,"  We calculate thermodynamic potentials and their derivatives for the three-dimensional $O(2)$ model using tensor-network methods to investigate the well-known second-order phase transition. We also consider the model at non-zero chemical potential to study the Silver Blaze phenomenon, which is related to the particle number density at zero temperature. Furthermore, the temperature dependence of the number density is explored using asymmetric lattices. Our results for both zero and non-zero magnetic field, temperature, and chemical potential are consistent with those obtained using other methods. ",https://doi.org/10.1103/PhysRevD.104.094517,2105.08066v2,Yes,potent(3)
0000-0002-8443-4804,Jacques Bloch,Universität Regensburg,Subsets and the canonical partition functions,1970,"  We explain the physical nature of the subset solution to the sign problem in chiral random matrix theory: The subset sum is shown to project out the canonical determinant with zero quark charge from a given configuration. As the grand canonical chiral random matrix partition function is independent of the chemical potential, the zero quark charge sector provides the full result. ",https://doi.org/10.1103/PhysRevD.87.034510,1211.3990v1,Yes,potent(1)
0000-0002-8448-4510,Kay Hansel,TU Darmstadt,Machine Learning with Physics Knowledge for Prediction: A Survey,1970,"  This survey examines the broad suite of methods and models for combining machine learning with physics knowledge for prediction and forecast, with a focus on partial differential equations. These methods have attracted significant interest due to their potential impact on advancing scientific research and industrial practices by improving predictive models with small- or large-scale datasets and expressive predictive models with useful inductive biases. The survey has two parts. The first considers incorporating physics knowledge on an architectural level through objective functions, structured predictive models, and data augmentation. The second considers data as physics knowledge, which motivates looking at multi-task, meta, and contextual learning as an alternative approach to incorporating physics knowledge in a data-driven fashion. Finally, we also provide an industrial perspective on the application of these methods and a survey of the open-source ecosystem for physics-informed machine learning. ",Kein DOI-Link verfügbar,2408.09840v1,Yes,potent(1)
0000-0002-8494-0045,Joachim Weickert,Saarland Universität,Object Segmentation Tracking from Generic Video Cues,1970,"  We propose a light-weight variational framework for online tracking of object segmentations in videos based on optical flow and image boundaries. While high-end computer vision methods on this task rely on sequence specific training of dedicated CNN architectures, we show the potential of a variational model, based on generic video information from motion and color. Such cues are usually required for tasks such as robot navigation or grasp estimation. We leverage them directly for video object segmentation and thus provide accurate segmentations at potentially very low extra cost. Our simple method can provide competitive results compared to the costly CNN-based methods with parameter tuning. Furthermore, we show that our approach can be combined with state-of-the-art CNN-based segmentations in order to improve over their respective results. We evaluate our method on the datasets DAVIS 16,17 and SegTrack v2. ",Kein DOI-Link verfügbar,1910.02258v3,Yes,potent(2)
0000-0002-8494-0045,Joachim Weickert,Saarland Universität,"The circular SiZer, inferred persistence of shape parameters and   application to early stem cell differentiation",1970,"  We generalize the SiZer of Chaudhuri and Marron (J. Amer. Statist. Assoc. 94 (1999) 807-823, Ann. Statist. 28 (2000) 408-428) for the detection of shape parameters of densities on the real line to the case of circular data. It turns out that only the wrapped Gaussian kernel gives a symmetric, strongly Lipschitz semi-group satisfying ""circular"" causality, that is, not introducing possibly artificial modes with increasing levels of smoothing. Some notable differences between Euclidean and circular scale space theory are highlighted. Based on this, we provide an asymptotic theory to make inference about the persistence of shape features. The resulting circular mode persistence diagram is applied to the analysis of early mechanically-induced differentiation in adult human stem cells from their actin-myosin filament structure. As a consequence, the circular SiZer based on the wrapped Gaussian kernel (WiZer) allows the verification at a controlled error level of the observation reported by Zemel et al. (Nat. Phys. 6 (2010) 468-473): Within early stem cell differentiation, polarizations of stem cells exhibit preferred directions in three different micro-environments. ",https://doi.org/10.3150/15-BEJ722,1404.3300v2,Yes,notable(1)
0000-0002-8593-5811,Noah Hoffmann,Martin Luther Universität Halle-Wittenberg,Searching for ductile superconducting Heusler X2YZ compounds,1970,"  Heusler compounds have always attracted a great deal of attention from researchers thanks to a wealth of interesting properties for technological applications. They are intermetallic ductile compounds, and some of them have been found to be superconducting. With this in mind, we perform an extensive study of the superconducting and elastic properties of the cubic (full-)Heusler family. Starting from thermodynamically stable compounds, we use ab initio methods for the calculation of the phonon spectra, electron-phonon couplings, superconducting critical temperatures and elastic tensors. By analyzing the statistical distributions of these properties and comparing them to anti-perovskites we recognize universal behaviors that should be common to all conventional superconductors while others turn out to be specific to the material family. The resulting data is used to train interpretable and predictive machine learning models, that are used to extend our knowledge of superconductivity in Heuslers and to provide an interpretation of our results. In total, we discover a total of 8 hypothetical materials with critical temperatures above 10 K, to be compared with the current record of Tc = 4.7 K in this family. Furthermore, we expect most of these materials to be highly ductile, making them potential candidates for the manufacture of wires and tapes for superconducting magnets. ",Kein DOI-Link verfügbar,2306.04439v1,Yes,potent(1)
0000-0002-8593-5811,Noah Hoffmann,Martin Luther Universität Halle-Wittenberg,Large-scale machine-learning-assisted exploration of the whole materials   space,1970,"  Crystal-graph attention networks have emerged recently as remarkable tools for the prediction of thermodynamic stability and materials properties from unrelaxed crystal structures. Previous networks trained on two million materials exhibited, however, strong biases originating from underrepresented chemical elements and structural prototypes in the available data. We tackled this issue computing additional data to provide better balance across both chemical and crystal-symmetry space. Crystal-graph networks trained with this new data show unprecedented generalization accuracy, and allow for reliable, accelerated exploration of the whole space of inorganic compounds. We applied this universal network to perform machine-learning assisted high-throughput materials searches including 2500 binary and ternary structure prototypes and spanning about 1 billion compounds. After validation using density-functional theory, we uncover in total 19512 additional materials on the convex hull of thermodynamic stability and ~150000 compounds with a distance of less than 50 meV/atom from the hull. Combining again machine learning and ab-initio methods, we finally evaluate the discovered materials for applications as superconductors, superhard materials, and we look for candidates with large gap deformation potentials, finding several compounds with extreme values of these properties. ",Kein DOI-Link verfügbar,2210.00579v1,Yes,potent(1)
0000-0002-8603-6682,Swanhild Bernstein,Technische Universität Bergakademie Freiberg,Paley-Wiener Type Theorems associated to Dirac Operators of Riesz-Feller   type,1970,"  This paper systematically investigates Paley-Wiener-type theorems in the context of hypercomplex variables. To this end, we introduce and study the so-called generalized Bernstein spaces endowed by the fractional Dirac operator $D_{\alpha}^{\theta}$ - a space-fractional operator of order $\alpha$ and skewness $\theta$, encompassing the Dirac operator $D$. We will show that such family of function spaces seamlessly characterizes the interplay between Clifford-valued $L^p-$functions satisfying the support condition $\mathrm{supp}\ \widehat{f}\subseteq B(0,R)$, and the solutions of the Cauchy problems endowed by the space-time operator $\partial_{x_0}+D_\theta^\alpha$ that are of exponential type $R^\alpha$. Such construction allows us to generalize, in a meaningful way, the results obtained by Kou and Qian (2002) and Franklin, Hogan and Larkin (2017). Noteworthy, the exploitation of the well-known Kolmogorov-Stein inequalities to hypercomplex variables permits us to make the computation of the maximal radius $R$ for which $\mathrm{supp}\ \widehat{f}$ is compactly supported in $B(0,R)$ rather explicit. ",Kein DOI-Link verfügbar,2405.04989v1,Yes,noteworthy(1)
0000-0002-8665-777X,Markus Koch,Technische Universität Dresden,Bayesian Analysis of Femtosecond Pump-Probe Photoelectron-Photoion   Coincidence Spectra with Fluctuating Laser Intensities,1970,"  This paper employs Bayesian probability theory for analyzing data generated in femtosecond pump-probe photoelectron-photoion coincidence (PEPICO) experiments. These experiments allow investigating ultrafast dynamical processes in photoexcited molecules. Bayesian probability theory is consistently applied to data analysis problems occurring in these types of experiments such as background subtraction and false coincidences. We previously demonstrated that the Bayesian formalism has many advantages, amongst which are compensation of false coincidences, no overestimation of pump-only contributions, significantly increased signal-to-noise ratio, and applicability to any experimental situation and noise statistics. Most importantly, by accounting for false coincidences, our approach allows running experiments at higher ionization rates, resulting in an appreciable reduction of data acquisition times. In addition to our previous paper, we include fluctuating laser intensities, of which the straightforward implementation highlights yet another advantage of the Bayesian formalism. Our method is thoroughly scrutinized by challenging mock data, where we find a minor impact of laser fluctuations on false coincidences, yet a noteworthy influence on background subtraction. We apply our algorithm to data obtained in experiments and discuss the impact of laser fluctuations on the data analysis. ",https://doi.org/10.3390/e21010093,1901.06933v1,Yes,noteworthy(1)
0000-0002-8689-0782,Kumar Gaurav,Friedrich Schiller Universität Jena,Quantitative Analysis of Social Influence & Digital Piracy Contagion   with Differential Equations on Networks,1970,"  Though the studies of social contagions are regularly borrowing network models to study the propagation of social influences and opinions to include social heterogeneity. Such studies provide valuable insights regarding these, but the social network structures cannot be well explored in their study. In this research, we methodically study the trends in online piracy with a continuous ODE approach and differential equations on graphs, to have a clear comparative view. We first formulate a compartmental model to mathematically study bifurcations and thresholds, and later move on with a network-based analysis to illustrate the proliferation of online piracy dynamic with an epidemiological approach over a social network. We figure out a solution for this online piracy problem by developing awareness among individuals by introducing media campaigns which could be a useful factor for the eradication and control of online piracy. Next, using degree-block approximation, network analysis has been performed to investigate the phenomena from a heterogeneous approach and to derive the threshold condition for the persistence of piracy in the population in a steady state. Based on the behavioral responses of individuals in a society due to the effect of media, we examine the system through the aid of realistic parameter selection to better understand the complexity of the dynamics and propose control strategies. ",Kein DOI-Link verfügbar,2309.15425v1,Yes,methodically(1)
0000-0002-8689-0782,Kumar Gaurav,Friedrich Schiller Universität Jena,SHS: Scorpion Hunting Strategy Swarm Algorithm,1970,"  We introduced the Scorpion Hunting Strategy (SHS), a novel population-based, nature-inspired optimisation algorithm. This algorithm draws inspiration from the hunting strategy of scorpions, which identify, locate, and capture their prey using the alpha and beta vibration operators. These operators control the SHS algorithm's exploitation and exploration abilities. To formulate an optimisation method, we mathematically simulate these dynamic events and behaviors. We evaluate the effectiveness of the SHS algorithm by employing 20 benchmark functions (including 10 conventional and 10 CEC2020 functions), using both qualitative and quantitative analyses. Through a comparative analysis with 12 state-of-the-art meta-heuristic algorithms, we demonstrate that the proposed SHS algorithm yields exceptionally promising results. These findings are further supported by statistically significant results obtained through the Wilcoxon rank sum test. Additionally, the ranking of SHS, as determined by the average rank derived from the Friedman test, positions it at the forefront when compared to other algorithms. Going beyond theoretical validation, we showcase the practical utility of the SHS algorithm by applying it to six distinct real-world optimisation tasks. These applications illustrate the algorithm's potential in addressing complex optimisation challenges. In summary, this work not only introduces the innovative SHS algorithm but also substantiates its effectiveness and versatility through rigorous benchmarking and real-world problem-solving scenarios. ",Kein DOI-Link verfügbar,2407.14202v2,Yes,"innovative(1), potent(1)"
0000-0002-8689-0782,Kumar Gaurav,Friedrich Schiller Universität Jena,Pioneers of Influence Propagation in Social Networks,1970,"  With the growing importance of corporate viral marketing campaigns on online social networks, the interest in studies of influence propagation through networks is higher than ever. In a viral marketing campaign, a firm initially targets a small set of pioneers and hopes that they would influence a sizeable fraction of the population by diffusion of influence through the network. In general, any marketing campaign might fail to go viral in the first try. As such, it would be useful to have some guide to evaluate the effectiveness of the campaign and judge whether it is worthy of further resources, and in case the campaign has potential, how to hit upon a good pioneer who can make the campaign go viral. In this paper, we present a diffusion model developed by enriching the generalized random graph (a.k.a. configuration model) to provide insight into these questions. We offer the intuition behind the results on this model, rigorously proved in Blaszczyszyn & Gaurav(2013), and illustrate them here by taking examples of random networks having prototypical degree distributions - Poisson degree distribution, which is commonly used as a kind of benchmark, and Power Law degree distribution, which is normally used to approximate the real-world networks. On these networks, the members are assumed to have varying attitudes towards propagating the information. We analyze three cases, in particular - (1) Bernoulli transmissions, when a member influences each of its friend with probability p; (2) Node percolation, when a member influences all its friends with probability p and none with probability 1-p; (3) Coupon-collector transmissions, when a member randomly selects one of his friends K times with replacement. We assume that the configuration model is the closest approximation of a large online social network, when the information available about the network is very limited. The key insight offered by this study from a firm's perspective is regarding how to evaluate the effectiveness of a marketing campaign and do cost-benefit analysis by collecting relevant statistical data from the pioneers it selects. The campaign evaluation criterion is informed by the observation that if the parameters of the underlying network and the campaign effectiveness are such that the campaign can indeed reach a significant fraction of the population, then the set of good pioneers also forms a significant fraction of the population. Therefore, in such a case, the firms can even adopt the naive strategy of repeatedly picking and targeting some number of pioneers at random from the population. With this strategy, the probability of them picking a good pioneer will increase geometrically fast with the number of tries. ",Kein DOI-Link verfügbar,1310.2441v1,Yes,potent(1)
0000-0002-8705-7063,Christian Bauer,Universität Würzburg,Introduction to the GiNaC Framework for Symbolic Computation within the   C++ Programming Language,1970,"  The traditional split-up into a low level language and a high level language in the design of computer algebra systems may become obsolete with the advent of more versatile computer languages. We describe GiNaC, a special-purpose system that deliberately denies the need for such a distinction. It is entirely written in C++ and the user can interact with it directly in that language. It was designed to provide efficient handling of multivariate polynomials, algebras and special functions that are needed for loop calculations in theoretical quantum field theory. It also bears some potential to become a more general purpose symbolic package. ",Kein DOI-Link verfügbar,cs/0004015v2,Yes,"versatile(1), potent(1)"
0000-0002-8705-7063,Christian Bauer,Universität Würzburg,Optical nanoscopy of transient states in condensed matter,1970,"  Recently, the fundamental and nanoscale understanding of complex phenomena in materials research and the life sciences, witnessed considerable progress. However, elucidating the underlying mechanisms, governed by entangled degrees of freedom such as lattice, spin, orbit, and charge for solids or conformation, electric potentials, and ligands for proteins, has remained challenging. Techniques that allow for distinguishing between different contributions to these processes are hence urgently required. In this paper we demonstrate the application of scattering-type scanning near-field optical microscopy (s-SNOM) as a novel type of nano-probe for tracking transient states of matter. We introduce a sideband-demodulation technique that allows for probing exclusively the stimuli-induced change of near-field optical properties. We exemplify this development by inspecting the decay of an electron-hole plasma generated in SiGe thin films through near-infrared laser pulses. Our approach can universally be applied to optically track ultrafast/-slow processes over the whole spectral range from UV to THz frequencies. ",https://doi.org/10.1038/srep12582,1508.00358v1,Yes,potent(1)
0000-0002-8735-6960,Riad Akrour,TU Darmstadt,An Upper Bound of the Bias of Nadaraya-Watson Kernel Regression under   Lipschitz Assumptions,1970,"  The Nadaraya-Watson kernel estimator is among the most popular nonparameteric regression technique thanks to its simplicity. Its asymptotic bias has been studied by Rosenblatt in 1969 and has been reported in a number of related literature. However, Rosenblatt's analysis is only valid for infinitesimal bandwidth. In contrast, we propose in this paper an upper bound of the bias which holds for finite bandwidths. Moreover, contrarily to the classic analysis we allow for discontinuous first order derivative of the regression function, we extend our bounds for multidimensional domains and we include the knowledge of the bound of the regression function when it exists and if it is known, to obtain a tighter bound. We believe that this work has potential applications in those fields where some hard guarantees on the error are needed ",Kein DOI-Link verfügbar,2001.10972v2,Yes,potent(1)
0000-0002-8739-9530,Nico Krais,Universität Stuttgart,FLEXI: A high order discontinuous Galerkin framework for   hyperbolic-parabolic conservation laws,1970,"  High order (HO) schemes are attractive candidates for the numerical solution of multiscale problems occurring in fluid dynamics and related disciplines. Among the HO discretization variants, discontinuous Galerkin schemes offer a collection of advantageous features which have lead to a strong increase in interest in them and related formulations in the last decade. The methods have matured sufficiently to be of practical use for a range of problems, for example in direct numerical and large eddy simulation of turbulence. However, in order to take full advantage of the potential benefits of these methods, all steps in the simulation chain must be designed and executed with HO in mind. Especially in this area, many commercially available closed-source solutions fall short. In this work, we therefor present the FLEXI framework, a HO consistent, open-source simulation tool chain for solving the compressible Navier-Stokes equations in a high performance computing setting. We describe the numerical algorithms and implementation details and give an overview of the features and capabilities of all parts of the framework. Beyond these technical details, we also discuss the important, but often overlooked issues of code stability, reproducibility and user-friendliness. The benefits gained by developing an open-source framework are discussed, with a particular focus on usability for the open-source community. We close with sample applications that demonstrate the wide range of use cases and the expandability of FLEXI and an overview of current and future developments. ",Kein DOI-Link verfügbar,1910.02858v1,Yes,potent(1)
0000-0002-8744-4960,Ekta Singh,Technische Universität Dresden,Tuning the domain wall conductivity in bulk lithium niobate by uniaxial   stress,1970,"  Conductive domain walls (CDWs) in insulating ferroelectrics have recently attracted considerable attention due to their unique topological, optical, and electronic properties, and offer potential applications such as in memory devices or re-writable circuitry. The electronic properties of domain walls (DWs) can be tuned by the application of strain, hence controlling the charge carrier density at DWs. In this work, we study the influence of uniaxial stress on the conductivity of DWs in the bulk single crystal lithium niobate (LiNbO$_3$). Using conductive atomic force microscopy (cAFM), we observe a large asymmetry in the conductivity of DWs, where only negatively screened walls, so called head-to-head DWs, are becoming increasingly conductive, while positively screened, tail-to-tails DWs, show a decrease in conductivity. This asymmetry of DW conductivity agrees with our theoretical model based on the piezoelectric effect. In addition, we observed that the current in the DW increases up to an order of magnitude for smaller compressive stresses of 100 MPa. This response of DWs remained intact for multiple stress cycles over 2 months, opening a path for future applications. ",Kein DOI-Link verfügbar,2205.00959v2,Yes,potent(1)
0000-0002-8764-9456,Joel Diaz Maier,Universität Rostock,Rescaled Mode-Coupling Scheme for the Quantitative Description of   Experimentally Observed Colloid Dynamics,1970,"  We describe experimentally observed collective dynamics in colloidal suspensions of model hard-sphere particles using a modified mode coupling theory (MCT). This rescaled MCT is capable to describe quantitatively the wave-vector and time-dependent diffusion in these systems. Intermediate scattering functions of liquid-like structured dispersions are determined by means of static and dynamic light scattering experiments. The structure and short-time dynamics of the systems can be described quantitatively employing a multi-component Percus-Yevick ansatz for the partial structure factors and an effective, one-component description of hydrodynamic interactions based on the semi-analytical $\delta\gamma$-expansion. Combined with a recently proposed empirical modification of MCT in which memory functions are calculated using effective structure factors at rescaled number densities, the scheme is able to model the collective dynamics over the entire accessible time and wave-vector range and predicts the volume-fraction-dependence of long-time self-diffusion coefficients and the zero-shear viscosity quantitatively. This highlights the potential of MCT as a practical tool for the quantitative analysis and prediction of experimental observations. ",Kein DOI-Link verfügbar,2403.04556v1,Yes,potent(1)
0000-0002-8833-4384,Olga Soloveva,Goethe-Universität Frankfurt am Main,Transport coefficients for the hot quark-gluon plasma at finite chemical   potential $μ_B$,1970,"  We calculate transport coefficients of the quark-gluon plasma (QGP) within the dynamical quasiparticle model (DQPM) by explicitly computing the parton interaction rates as a function of temperature $T$ and baryon chemical potential $\mu_B$ on the basis of the DQPM couplings and partonic propagators. The latter are extracted from lattice QCD by matching the equation of state, entropy density and energy density at $\mu_B$= 0. For baryon chemical potentials $0 \leq \mu_B \leq 500 MeV$ we employ a scaling Ansatz for the effective coupling which was shown before to lead to thermodynamic consistent results in this range. We compute the ratio of the shear and bulk viscosities to the entropy density, i.e. $\eta/s$ and $\zeta/s$, the electric conductivity $\sigma_0/T$ as well as the baryon diffusion coefficient $\kappa_B$ and compare to related approaches from the literature. We find that the ratios $\eta/s$ and $\zeta/s$ as well as $\sigma_0/T$ are in accord with the results from lattice QCD at $\mu_B$=0 and only weakly depend on the ratio $T/T_c(\mu_B)$ where $T_c(\mu_B)$ denotes the critical temperature at finite baryon chemical potential. ",https://doi.org/10.1103/PhysRevC.101.045203,1911.08547v1,Yes,potent(3)
0000-0002-8833-4384,Olga Soloveva,Goethe-Universität Frankfurt am Main,QCD at finite chemical potential in and out-of equilibrium,1970,"  We review the transport properties of the strongly interacting quark-gluon plasma (QGP) created in heavy-ion collisions at ultrarelativistic energies, i.e. out-of equilibrium, and compare them to the equilibrium properties. The description of the strongly interacting (non-perturbative) QGP in equilibrium is based on the effective propagators and couplings from the Dynamical QuasiParticle Model (DQPM) that is matched to reproduce the equation-of-state of the partonic system above the deconfinement temperature $T_c$ from lattice QCD. We study the transport coefficients such as the ratio of shear viscosity and bulk viscosity over entropy density, diffusion coefficients, electric conductivity etc. versus temperature and baryon chemical potential. Based on a microscopic transport description of heavy-ion collisions we, furthermore, discuss which observables are sensitive to the QGP formation and its properties. ",https://doi.org/10.1088/1402-4896/ac3c10,2103.15417v1,Yes,potent(1)
0000-0002-8833-4384,Olga Soloveva,Goethe-Universität Frankfurt am Main,Shear viscosity and electric conductivity of a hot and dense QGP with a   chiral phase transition,1970,"  We calculate two transport coefficients -- the shear viscosity over entropy ratio $\eta/s$ and the ratio of the electric conductivity to the temperature $\sigma_0/T$ -- of strongly interacting quark matter within the extended $N_f=3$ Polyakov Nambu-Jona-Lasinio (PNJL) model along the crossover transition line for moderate values of baryon chemical potential $0 \leq \mu_B \leq 0.9$ GeV as well as in the vicinity of the critical endpoint (CEP) and at large baryon chemical potential $\mu_B=1.2$ GeV, where the first-order phase transition takes place. The evaluation of the transport coefficients is performed on the basis of the effective Boltzmann equation in the relaxation time approximation. We employ two different methods for the calculation of the quark relaxation times: i) using the averaged transition rate defined via thermal averaged quark-quark and quark-antiquark PNJL cross sections and ii) using the 'weighted' thermal averaged quark-quark and quark-antiquark PNJL cross sections. The $\eta/s$ and $\sigma_0/T$ transport coefficients have a similar temperature and chemical potential behavior when approaching the chiral phase transition for the both methods for the quark relaxation time, however, the differences grow with increasing temperature. We demonstrate the effect of the first-order phase transition and of the CEP on the transport coefficients in the deconfined QCD medium. ",https://doi.org/10.1103/PhysRevC.103.054901,2011.03505v2,Yes,potent(3)
0000-0002-8833-4384,Olga Soloveva,Goethe-Universität Frankfurt am Main,Transport properties and equation-of-state of hot and dense QGP matter   near the critical end-point in the phenomenological dynamical quasi-particle   model,1970,"  We extend the effective dynamical quasiparticle model (DQPM) - constructed for the description of non-perturbative QCD phenomena of the strongly interacting quark-gluon plasma (QGP) - to large baryon chemical potentials, $\mu_B$, including a critical end-point and a 1st order phase transition. The DQPM description of quarks and gluons is based on partonic propagators with complex selfenergies where the real part of the selfenergies is related to the quasiparticle mass and the imaginary part to a finite width of their spectral functions. In DQPM the determination of complex selfenergies for the partonic degrees of freedom at zero and finite $\mu_B$ has been performed by adjusting the entropy density to the lQCD data. The temperature-dependent effective coupling (squared) $g^2(T/T_c)$, as well as the parton effective masses and widths are based on this adjustment. The novel extended dynamical quasiparticle model, named ""DQPM-CP"", makes it possible to describe thermodynamical and transport properties of quarks and gluons in a wide range of $T$ and $\mu_B$, and reproduces the equation-of-state (EoS) of lQCD calculations in the crossover region of finite $T, \mu_B$. We apply a scaling ansatz for the strong coupling constant near the CEP, located at ($T^{CEP}$, $\mu^{CEP}_B) = (0.100, 0.960)$ GeV. We show the EoS as well as the speed of sound for $T>T_c$ and for a wide range of $\mu_B$, which can be of interest for hydrodynamical simulations. Furthermore, we consider two settings for the strange quark chemical potentials (I) $\mu_s=\mu_B/3$ and (II) $\mu_s=0$. The isentropic trajectories of the QGP matter are compared for these two cases. The phase diagram of DQPM-CP is close to PNJL calculations. The leading order pQCD transport coefficients of both approaches differ. This elucidates that the knowledge of the phase diagram alone is not sufficient to describe the dynamical evolution of QGP. ",https://doi.org/10.1103/PhysRevD.105.054011,2108.08561v3,Yes,potent(2)
0000-0002-8833-4384,Olga Soloveva,Goethe-Universität Frankfurt am Main,Soft gluon emission from heavy quark scattering in strongly interacting   quark-gluon plasma,1970,"  We apply the Low's theorem to soft gluon emission from heavy quark scattering in the nonperturbative strongly interacting quark-gluon plasma (sQGP). The sQGP is described in terms of the dynamical quasi-particles and adjusted to reproduce the EoS from lQCD at finite temperature and chemical potential. Since the emitted gluon is soft and of long wavelength, it does not provide information on the detailed structure of the scattering, and only the emission from incoming and outgoing partons is enough. It simplifies the calculations making the scattering amplitude factorizable into the elastic scattering and the emission of soft gluon. Imposing a proper upper limit on the emitted gluon energy, we obtain the guage-invariant scattering cross sections of heavy quarks with the massive partons of the medium as well as their transport coefficients (momentum drag and diffusion) in the QGP and compare with those from the elastic scattering without gluon emission. ",https://doi.org/10.1103/PhysRevD.107.036009,2210.04010v2,Yes,potent(1)
0000-0002-8833-4384,Olga Soloveva,Goethe-Universität Frankfurt am Main,Radiative energy loss of heavy quark through soft gluon emission in QGP,1970,"  The Low's theorem is applied to the soft gluon emission from heavy quark scattering in quark-gluon plasma (QGP). The QGP is described by the dynamical quasi-particle model (DQPM) which reproduces the EoS from lQCD at finite temperature and chemical potential. We show that if the emitted gluon is soft and of long wavelength, the scattering amplitude can be factorized into the scattering part and the emission part and the Slavnov-Taylor identities are satisfied in the leading order. Imposing a proper upper limit on the emitted gluon energy, we obtain the scattering cross sections of charm quark as well as the transport coefficients (momentum drag and diffusion) in the QGP with and without gluon emission. ",Kein DOI-Link verfügbar,2307.09124v1,Yes,potent(1)
0000-0002-8833-4384,Olga Soloveva,Goethe-Universität Frankfurt am Main,Exploring jet transport coefficients by elastic and radiative   scatterings in the strongly interacting quark-gluon plasma,1970,"  We investigate the interaction of leading jet partons within a strongly interacting quark-gluon plasma (sQGP) medium, using the effective dynamical quasiparticle model (DQPM). The DQPM offers a description of the sQGP's non-perturbative nature at finite temperature $T$ and baryon chemical potential $\mu_B$ through a propagator representation of massive off-shell partons (quarks and gluons). These partons are characterized by spectral functions with $T,\mu_B$ dependent masses and widths, adjusted to reproduce the lattice Quantum Chromodynamics (lQCD) equation-of-state (EoS) for the QGP in thermodynamic equilibrium. Our focus lies on examining the jet transport coefficients by elastic scattering in sQGP, specifically the transverse momentum transfer squared per unit length denoted as $\hat{q}$, within the QGP. Furthermore, we investigate the dependence of these coefficients on both the medium temperature $T$ and the jet parton energy. By studying the jet transport coefficients and their relationship to temperature and parton energy, we aim to gain insights into the dynamics of jet propagation in the strongly interacting quark-gluon plasma medium. ",Kein DOI-Link verfügbar,2309.08296v1,Yes,potent(1)
0000-0002-8833-4384,Olga Soloveva,Goethe-Universität Frankfurt am Main,Exploring jet transport coefficients by elastic scattering in the   strongly interacting quark-gluon plasma,1970,"  We study the interaction of leading jet partons in a strongly interacting quark-gluon plasma (sQGP) medium based on the effective dynamical quasi-particle model (DQPM). The DQPM describes the non-perturbative nature of the sQGP at finite temperature $T$ and baryon chemical potential $\mu_B$ based on a propagator representation of massive off-shell partons (quarks and gluons) whose properties (characterized by spectral functions with $T,\mu_B$ dependent masses and widths) are adjusted to reproduce the lQCD EoS for the QGP in thermodynamic equilibrium. We present the results for the jet transport coefficients, i.e. the transverse momentum transfer squared per unit length $\hat{q}$ as well as the energy loss per unit length $\Delta E =dE/dx$, in the QGP and investigate their dependence on the temperature $T$ and baryon chemical potential $\mu_B$ as well as on jet properties such as the leading jet parton momentum, mass, flavor, and the choice of the strong coupling constant. In this first study only elastic scattering processes of a leading jet parton with the sQGP partons are explored discarding presently the radiative processes (such as gluon Bremsstrahlung). We present a comparison of our results for the elastic energy loss in the sQGP medium with the pQCD results obtained by the BAMPS and LBT models as well as with other theoretical approaches such as lattice QCD and the LO-HTL and also with estimates of $\hat{q}/T^3$ by the color string percolation model (CSPM) and the JET and JETSCAPE Collaborations based on a comparison of hydrodynamical calculations with experimental heavy-ion data. ",https://doi.org/10.1103/PhysRevC.106.014903,2204.01561v2,Yes,potent(2)
0000-0002-8833-4384,Olga Soloveva,Goethe-Universität Frankfurt am Main,Diffusion coefficient matrix of the strongly interacting quark-gluon   plasma,1970,"  We study the diffusion properties of the strongly interacting quark-gluon plasma (sQGP) and evaluate the diffusion coefficient matrix for the baryon ($B$), strange ($S$) and electric ($Q$) charges - $\kappa_{qq'}$ ($q,q' = B, S, Q$) and show their dependence on temperature $T$ and baryon chemical potential $\mu_B$. The non-perturbative nature of the sQGP is evaluated within the Dynamical Quasi-Particle Model (DQPM) which is matched to reproduce the equation of state of the partonic matter above the deconfinement temperature $T_c$ from lattice QCD. The calculation of diffusion coefficients is based on two methods: i) the Chapman-Enskog method for the linearized Boltzmann equation, which allows to explore non-equilibrium corrections for the phase-space distribution function in leading order of the Knudsen numbers as well as ii) the relaxation time approximation (RTA). In this work we explore the differences between the two methods. We find a good agreement with the available lattice QCD data in case of the electric charge diffusion coefficient (or electric conductivity) at vanishing baryon chemical potential as well as a qualitative agreement with the recent predictions from the holographic approach for all diagonal components of the diffusion coefficient matrix. The knowledge of the diffusion coefficient matrix is also of special interest for more accurate hydrodynamic simulations. ",https://doi.org/10.1103/PhysRevD.104.034014,2102.08140v1,Yes,potent(2)
0000-0002-8833-4384,Olga Soloveva,Goethe-Universität Frankfurt am Main,Inelastic and elastic parton scatterings in the strongly interacting   quark-gluon plasma,1970,"  We investigate the role of inelastic processes in the strongly interacting quark-gluon plasma (sQGP) based on the effective dynamical quasi-particle model (DQPM). In the DQPM the non-perturbative properties of the sQGP at finite temperature $T$ and baryon chemical potential $\mu_B$ are described in terms of strongly interacting off-shell partons (quarks and gluons) with dynamically generated spectral functions whose properties are adjusted to reproduce the lQCD EoS for the QGP in thermodynamic equilibrium. For the first time the massive gluon radiation processes from the off-shell quark-quark ($q+q$) and quark-gluon ($q+g$) scatterings are calculated explicitly within leading order Feynman diagrams with effective propagators and vertices from the DQPM without any further approximations. We present the results for the energy and temperature dependencies of the total and differential radiative cross sections and compare them to the corresponding elastic cross sections. We show that our results reproduce the pQCD calculations in the limit of zero masses and widths of quasiparticles. Also we study the $\mu_B$ dependence of the inelastic cross sections. Moreover, we present estimates for the transition rate and relaxation time of radiative versus elastic scatterings in the sQGP. ",Kein DOI-Link verfügbar,2308.03105v2,Yes,potent(1)
0000-0002-8833-4384,Olga Soloveva,Goethe-Universität Frankfurt am Main,Exploring the partonic phase at finite chemical potential within an   extended off-shell transport approach,1970,"  We extend the Parton-Hadron-String Dynamics (PHSD) transport approach in the partonic sector by explicitly calculating the total and differential partonic scattering cross sections as a function of temperature $T$ and baryon chemical potential $\mu_B$ on the basis of the effective propagators and couplings from the Dynamical QuasiParticle Model (DQPM) that is matched to reproduce the equation of state of the partonic system above the deconfinement temperature $T_c$ from lattice QCD. The ratio of shear viscosity $\eta$ over entropy density $s$, i.e. $\eta/s$, is evaluated using the collisional widths and compared to lQCD calculations for $\mu_B$ = 0 as well. We find only a very modest change of $\eta/s$ with the baryon chemical $\mu_B$. This also holds for a variety of hadronic observables from central A+A and C+Au collisions in the energy range 5 GeV $\leq \sqrt{s_{NN}} \leq$ 200 GeV when implementing the differential cross sections into the PHSD approach. We only observe small differences in the strangeness and antibaryon sector with practically no sensitivity of rapidity and $p_T$ distributions to the $\mu_B$ dependence of the partonic cross sections. Since we find only small traces of a $\mu_B$-dependence in heavy-ion observables - although the effective partonic masses and widths as well as their partonic cross sections clearly depend on $\mu_B$ - this implies that one needs a sizable partonic density and large space-time QGP volume to explore the dynamics in the partonic phase. These conditions are only fulfilled at high bombarding energies where $\mu_B$ is, however, rather low. On the other hand, when decreasing the bombarding energy and thus increasing $\mu_B$, the hadronic phase becomes dominant and accordingly, it will be difficult to extract signals from the partonic dynamics based on ""bulk"" observables. ",https://doi.org/10.1103/PhysRevC.100.014911,1903.10257v3,Yes,potent(1)
0000-0002-8868-2397,Laura Hansel,Georg-August-Universität Göttingen,Self-Supervised Graph Representation Learning for Neuronal Morphologies,1970,"  Unsupervised graph representation learning has recently gained interest in several application domains such as neuroscience, where modeling the diverse morphology of cell types in the brain is one of the key challenges. It is currently unknown how many excitatory cortical cell types exist and what their defining morphological features are. Here we present GraphDINO, a purely data-driven approach to learn low-dimensional representations of 3D neuronal morphologies from unlabeled large-scale datasets. GraphDINO is a novel transformer-based representation learning method for spatially-embedded graphs. To enable self-supervised learning on transformers, we (1) developed data augmentation strategies for spatially-embedded graphs, (2) adapted the positional encoding and (3) introduced a novel attention mechanism, AC-Attention, which combines attention-based global interaction between nodes and classic graph convolutional processing. We show, in two different species and across multiple brain areas, that this method yields morphological cell type clusterings that are on par with manual feature-based classification by experts, but without using prior knowledge about the structural features of neurons. Moreover, it outperforms previous approaches on quantitative benchmarks predicting expert labels. Our method could potentially enable data-driven discovery of novel morphological features and cell types in large-scale datasets. It is applicable beyond neuroscience in settings where samples in a dataset are graphs and graph-level embeddings are desired. ",Kein DOI-Link verfügbar,2112.12482v3,Yes,potent(1)
0000-0002-8878-7375,Stefan Schubert,Universität Leipzig,What makes visual place recognition easy or hard?,1970,"  Visual place recognition is a fundamental capability for the localization of mobile robots. It places image retrieval in the practical context of physical agents operating in a physical world. It is an active field of research and many different approaches have been proposed and evaluated in many different experiments. In the following, we argue that due to variations of this practical context and individual design decisions, place recognition experiments are barely comparable across different papers and that there is a variety of properties that can change from one experiment to another. We provide an extensive list of such properties and give examples how they can be used to setup a place recognition experiment easier or harder. This might be interesting for different involved parties: (1) people who just want to select a place recognition approach that is suitable for the properties of their particular task at hand, (2) researchers that look for open research questions and are interested in particularly difficult instances, (3) authors that want to create reproducible papers on this topic, and (4) also reviewers that have the task to identify potential problems in papers under review. ",Kein DOI-Link verfügbar,2106.12671v1,Yes,potent(1)
0000-0002-8878-7375,Stefan Schubert,Universität Leipzig,Hyperdimensional computing as a framework for systematic aggregation of   image descriptors,1970,"  Image and video descriptors are an omnipresent tool in computer vision and its application fields like mobile robotics. Many hand-crafted and in particular learned image descriptors are numerical vectors with a potentially (very) large number of dimensions. Practical considerations like memory consumption or time for comparisons call for the creation of compact representations. In this paper, we use hyperdimensional computing (HDC) as an approach to systematically combine information from a set of vectors in a single vector of the same dimensionality. HDC is a known technique to perform symbolic processing with distributed representation in numerical vectors with thousands of dimensions. We present a HDC implementation that is suitable for processing the output of existing and future (deep-learning based) image descriptors. We discuss how this can be used as a framework to process descriptors together with additional knowledge by simple and fast vector operations. A concrete outcome is a novel HDC-based approach to aggregate a set of local image descriptors together with their image positions in a single holistic descriptor. The comparison to available holistic descriptors and aggregation methods on a series of standard mobile robotics place recognition experiments shows a 20% improvement in average performance compared to runner-up and 3.6x better worst-case performance. ",Kein DOI-Link verfügbar,2101.07720v1,Yes,potent(1)
0000-0002-8878-7375,Stefan Schubert,Universität Leipzig,Beyond ANN: Exploiting Structural Knowledge for Efficient Place   Recognition,1970,"  Visual place recognition is the task of recognizing same places of query images in a set of database images, despite potential condition changes due to time of day, weather or seasons. It is important for loop closure detection in SLAM and candidate selection for global localization. Many approaches in the literature perform computationally inefficient full image comparisons between queries and all database images. There is still a lack of suited methods for efficient place recognition that allow a fast, sparse comparison of only the most promising image pairs without any loss in performance. While this is partially given by ANN-based methods, they trade speed for precision and additional memory consumption, and many cannot find arbitrary numbers of matching database images in case of loops in the database. In this paper, we propose a novel fast sequence-based method for efficient place recognition that can be applied online. It uses relocalization to recover from sequence losses, and exploits usually available but often unused intra-database similarities for a potential detection of all matching database images for each query in case of loops or stops in the database. We performed extensive experimental evaluations over five datasets and 21 sequence combinations, and show that our method outperforms two state-of-the-art approaches and even full image comparisons in many cases, while providing a good tradeoff between performance and percentage of evaluated image pairs. Source code for Matlab will be provided with publication of this paper. ",https://doi.org/10.1109/ICRA48506.2021.9561006,2103.08366v1,Yes,potent(2)
0000-0002-8878-7375,Stefan Schubert,Universität Leipzig,Towards Revisiting Visual Place Recognition for Joining Submaps in   Multimap SLAM,1970,"  Visual SLAM is a key technology for many autonomous systems. However, tracking loss can lead to the creation of disjoint submaps in multimap SLAM systems like ORB-SLAM3. Because of that, these systems employ submap merging strategies. As we show, these strategies are not always successful. In this paper, we investigate the impact of using modern VPR approaches for submap merging in visual SLAM. We argue that classical evaluation metrics are not sufficient to estimate the impact of a modern VPR component on the overall system. We show that naively replacing the VPR component does not leverage its full potential without requiring substantial interference in the original system. Because of that, we present a post-processing pipeline along with a set of metrics that allow us to estimate the impact of modern VPR components. We evaluate our approach on the NCLT and Newer College datasets using ORB-SLAM3 with NetVLAD and HDC-DELF as VPR components. Additionally, we present a simple approach for combining VPR with temporal consistency for map merging. We show that the map merging performance of ORB-SLAM3 can be improved. Building on these results, researchers in VPR can assess the potential of their approaches for SLAM systems. ",Kein DOI-Link verfügbar,2407.12408v1,Yes,potent(2)
0000-0002-8992-444X,Stefan Gerlach,Technische Universität Hamburg,Fooling the Crowd with Deep Learning-based Methods,1970,"  Modern, state-of-the-art deep learning approaches yield human like performance in numerous object detection and classification tasks. The foundation for their success is the availability of training datasets of substantially high quantity, which are expensive to create, especially in the field of medical imaging. Recently, crowdsourcing has been applied to create large datasets for a broad range of disciplines. This study aims to explore the challenges and opportunities of crowd-algorithm collaboration for the object detection task of grading cytology whole slide images. We compared the classical crowdsourcing performance of twenty participants with their results from crowd-algorithm collaboration. All participants performed both modes in random order on the same twenty images. Additionally, we introduced artificial systematic flaws into the precomputed annotations to estimate a bias towards accepting precomputed annotations. We gathered 9524 annotations on 800 images from twenty participants organised into four groups in concordance to their level of expertise with cytology. The crowd-algorithm mode improved on average the participants' classification accuracy by 7%, the mean average precision by 8% and the inter-observer Fleiss' kappa score by 20%, and reduced the time spent by 31%. However, two thirds of the artificially modified false labels were not recognised as such by the contributors. This study shows that crowd-algorithm collaboration is a promising new approach to generate large datasets when it is ensured that a carefully designed setup eliminates potential biases. ",Kein DOI-Link verfügbar,1912.00142v1,Yes,potent(1)
0000-0002-9070-6933,Andreas Haselsteiner,Universität Bremen,Could mass eccentricity explain the formation of orbits in wind   turbines?,1970,"  The kinematics of offshore wind turbines are of great importance when installing the turbines, as the motions of the components during craning operations are a limiting factor. Most critical is the installation of the blades: the blade's bolts need to be inserted into the rotor flange, an operation that requires great precision. Both the blade and the turbine undergo environmental loading, leading to relative motions between the blade root and the hub during installation. Results from an offshore wind farm installation measurement campaign showed, that the partially installed turbines show intricate patterns of motion (orbits) in the horizontal plane. The mechanism behind the formation of these orbits remains elusive so far.   In this paper, we present a novel torsional coupling mechanism linking motions in the fore-aft and side-side direction. It can explain the formation of orbits that change direction. ",Kein DOI-Link verfügbar,2110.12802v1,Yes,intricate(1)
0000-0002-9072-8278,Zhiyuan Jia,Universität Siegen,Small-Sample Inferred Adaptive Recoding for Batched Network Coding,1970,"  Batched network coding is a low-complexity network coding solution to feedbackless multi-hop wireless packet network transmission with packet loss. The data to be transmitted is encoded into batches where each of which consists of a few coded packets. Unlike the traditional forwarding strategy, the intermediate network nodes have to perform recoding, which generates recoded packets by network coding operations restricted within the same batch. Adaptive recoding is a technique to adapt the fluctuation of packet loss by optimizing the number of recoded packets per batch to enhance the throughput. The input rank distribution, which is a piece of information regarding the batches arriving at the node, is required to apply adaptive recoding. However, this distribution is not known in advance in practice as the incoming link's channel condition may change from time to time. On the other hand, to fully utilize the potential of adaptive recoding, we need to have a good estimation of this distribution. In other words, we need to guess this distribution from a few samples so that we can apply adaptive recoding as soon as possible. In this paper, we propose a distributionally robust optimization for adaptive recoding with a small-sample inferred prediction of the input rank distribution. We develop an algorithm to efficiently solve this optimization with the support of theoretical guarantees that our optimization's performance would constitute as a confidence lower bound of the optimal throughput with high probability. ",https://doi.org/10.1109/ISIT45174.2021.9518091,2105.01370v3,Yes,potent(1)
0000-0002-9111-8981,Markus Guehr,Universität Potsdam,Unsupervised real-world knowledge extraction via disentangled   variational autoencoders for photon diagnostics,1970,"  We present real-world data processing on measured electron time-of-flight data via neural networks. Specifically, the use of disentangled variational autoencoders on data from a diagnostic instrument for online wavelength monitoring at the free electron laser FLASH in Hamburg. Without a-priori knowledge the network is able to find representations of single-shot FEL spectra, which have a low signal-to-noise ratio. This reveals, in a directly human-interpretable way, crucial information about the photon properties. The central photon energy and the intensity as well as very detector-specific features are identified. The network is also capable of data cleaning, i.e. denoising, as well as the removal of artefacts. In the reconstruction, this allows for identification of signatures with very low intensity which are hardly recognisable in the raw data. In this particular case, the network enhances the quality of the diagnostic analysis at FLASH. However, this unsupervised method also has the potential to improve the analysis of other similar types of spectroscopy data. ",Kein DOI-Link verfügbar,2206.11559v2,Yes,potent(1)
0000-0002-9181-8435,Manuel Rieger,Technische Universität München,Fast optoelectronic charge state conversion of silicon vacancies in   diamond,1970,"  Group IV vacancy color centers in diamond are promising spin-photon interfaces with strong potential for applications for photonic quantum technologies. Reliable methods for controlling and stabilizing their charge state are urgently needed for scaling to multi-qubit devices. Here, we manipulate the charge state of silicon vacancy (SiV) ensembles by combining luminescence and photo-current spectroscopy. We controllably convert the charge state between the optically active SiV$^-$ and dark SiV$^{2-}$ with MHz rates and 90% contrast by judiciously choosing the local potential applied to in-plane surface electrodes and the laser excitation wavelength. We observe intense SiV$^-$ photoluminescence under hole-capture, measure the intrinsic conversion time from the dark SiV$^{2-}$ to the bright SiV$^-$ to be 36.4(6.7)ms and demonstrate how it can be enhanced by a factor of $10^5$ via optical pumping. Moreover, we obtain new information on the defects that contribute to photo-conductivity, indicating the presence of substitutional nitrogen and divacancies. ",https://doi.org/10.1126/sciadv.adl4265,2310.12288v1,Yes,potent(2)
0000-0002-9215-7720,Elkin A. Santos,Friedrich-Schiller-Universität Jena,Experimental analysis on image resolution of quantum imaging with   undetected light through position correlations,1970,"  Image resolution of quantum imaging with undetected photons is governed by the spatial correlations existing between the photons of a photon pair that has been generated in a nonlinear process. These correlations allow for obtaining an image of an object with light that never interacted with that object. Depending on the imaging configuration, either position or momentum correlations are exploited. We hereby experimentally analyse how the crystal length and pump waist affect the image resolution when using position correlations of photons that have been generated via spontaneous parametric down conversion in a nonlinear interferometer. Our results support existing theoretical models for the dependency of the resolution on the crystal length. In addition, we probe the resolution of our quantum imaging scheme for varying pump waists over one order of magnitude. This analysis reveals the intricate dependency of the resolution on the strength of the correlations within the biphoton states for parameter combinations in which the crystal lengths are much larger than the involved photon wavelengths. We extend the existing models in this parameter regime to properly take nontrivial effects of finite pump waists into account and demonstrate that they match the experimental results. ",https://doi.org/10.1103/PhysRevA.108.052610,2306.01884v1,Yes,intricate(1)
0000-0002-9305-1768,Alexander Hahn,Universität Duisburg-Essen,Strong Error Bounds for Trotter & Strang-Splittings and Their   Implications for Quantum Chemistry,1970,"  Efficient error estimates for the Trotter product formula are central in quantum computing, mathematical physics, and numerical simulations. However, the Trotter error's dependency on the input state and its application to unbounded operators remains unclear. Here, we present a general theory for error estimation, including higher-order product formulas, with explicit input state dependency. Our approach overcomes two limitations of the existing operator-norm estimates in the literature. First, previous bounds are too pessimistic as they quantify the worst-case scenario. Second, previous bounds become trivial for unbounded operators and cannot be applied to a wide class of Trotter scenarios, including atomic and molecular Hamiltonians. Our method enables analytical treatment of Trotter errors in chemistry simulations, illustrated through a case study on the hydrogen atom. Our findings reveal: (i) for states with fat-tailed energy distribution, such as low-angular-momentum states of the hydrogen atom, the Trotter error scales worse than expected (sublinearly) in the number of Trotter steps; (ii) certain states do not admit an advantage in the scaling from higher-order Trotterization, and thus, the higher-order Trotter hierarchy breaks down for these states, including the hydrogen atom's ground state; (iii) the scaling of higher-order Trotter bounds might depend on the order of the Hamiltonians in the Trotter product for states with fat-tailed energy distribution. Physically, the enlarged Trotter error is caused by the atom's ionization due to the Trotter dynamics. Mathematically, we find that certain domain conditions are not satisfied by some states so higher moments of the potential and kinetic energies diverge. Our analytical error analysis agrees with numerical simulations, indicating that we can estimate the state-dependent Trotter error scaling genuinely. ",Kein DOI-Link verfügbar,2312.08044v1,Yes,potent(1)
0000-0002-9310-8533,Oliver Rheinbach,Technische Universität Bergakademie Freiberg,Monolithic parallel overlapping Schwarz methods in fully-coupled   nonlinear chemo-mechanics problems,1970,"  We consider the swelling of hydrogels as an example of a chemo-mechanical problem with strong coupling between the mechanical balance relations and the mass diffusion. The problem is cast into a minimization formulation using a time-explicit approach for the dependency of the dissipation potential on the deformation and the swelling volume fraction to obtain symmetric matrices, which are typically better suited for iterative solvers. The MPI-parallel implementation uses the software libraries deal.II, p4est and FROSch (Fast of Robust Overlapping Schwarz). FROSch is part of the Trilinos library and is used in fully algebraic mode, i.e., the preconditioner is constructed from the monolithic system matrix without making explicit use of the problem structure. Strong and weak parallel scalability is studied using up to 512 cores, considering the standard GDSW (Generalized Dryja-Smith-Widlund) coarse space and the newer coarse space with reduced dimension. The FROSch solver is applicable to the coupled problems within in the range of processor cores considered here, although numerical scalablity cannot be expected (and is not observed) for the fully algebraic mode. In our strong scalability study, the average number of Krylov iterations per Newton iteration is higher by a factor of up to six compared to a linear elasticity problem. However, making mild use of the problem structure in the preconditioner, this number can be reduced to a factor of two and, importantly, also numerical scalability can then be achieved experimentally. Nevertheless, the fully algebraic mode is still preferable since a faster time to solution is achieved. ",Kein DOI-Link verfügbar,2212.00801v1,Yes,potent(1)
0000-0002-9370-1038,Anurag Singh,Universität Tübingen,Malaria Cell Detection Using Deep Neural Networks,1970,"  Malaria remains one of the most pressing public health concerns globally, causing significant morbidity and mortality, especially in sub-Saharan Africa. Rapid and accurate diagnosis is crucial for effective treatment and disease management. Traditional diagnostic methods, such as microscopic examination of blood smears, are labor-intensive and require significant expertise, which may not be readily available in resource-limited settings. This project aims to automate the detection of malaria-infected cells using a deep learning approach. We employed a convolutional neural network (CNN) based on the ResNet50 architecture, leveraging transfer learning to enhance performance. The Malaria Cell Images Dataset from Kaggle, containing 27,558 images categorized into infected and uninfected cells, was used for training and evaluation. Our model demonstrated high accuracy, precision, and recall, indicating its potential as a reliable tool for assisting in malaria diagnosis. Additionally, a web application was developed using Streamlit to allow users to upload cell images and receive predictions about malaria infection, making the technology accessible and user-friendly. This paper provides a comprehensive overview of the methodology, experiments, and results, highlighting the effectiveness of deep learning in medical image analysis. ",Kein DOI-Link verfügbar,2406.20005v1,Yes,potent(1)
0000-0002-9370-1038,Anurag Singh,Universität Tübingen,Optimal Reservoir Operations using Long Short-Term Memory Network,1970,"  A reliable forecast of inflows to the reservoir is a key factor in the optimal operation of reservoirs. Real-time operation of the reservoir based on forecasts of inflows can lead to substantial economic gains. However, the forecast of inflow is an intricate task as it has to incorporate the impacts of climate and hydrological changes. Therefore, the major objective of the present work is to develop a novel approach based on long short-term memory (LSTM) for the forecast of inflows. Real-time inflow forecast, in other words, daily inflow at the reservoir helps in efficient operation of water resources. Also, daily variations in the release can be monitored efficiently and the reliability of operation is improved. This work proposes a naive anomaly detection algorithm baseline based on LSTM. In other words, a strong baseline to forecast flood and drought for any deep learning-based prediction model. The practicality of the approach has been demonstrated using the observed daily data of the past 20 years from Bhakra Dam in India. The results of the simulations conducted herein clearly indicate the supremacy of the LSTM approach over the traditional methods of forecasting. Although, experiments are run on data from Bhakra Dam Reservoir in India, LSTM model, and anomaly detection algorithm are general purpose and can be applied to any basin with minimal changes. A distinct practical advantage of the LSTM method presented herein is that it can adequately simulate non-stationarity and non-linearity in the historical data. ",Kein DOI-Link verfügbar,2109.04255v1,Yes,intricate(1)
0000-0002-9370-1038,Anurag Singh,Universität Tübingen,Modelling Competitive marketing strategies in Social Networks,1970,"  In a competitive marketing, there are a large number of players which produce the same product. Each firm aims to diffuse its product information widely so that it's product will become popular among potential buyers. The more popular is a product of a firm, the higher is the revenue for the firm. A model is developed in which two players compete to spread information in the large network. Players choose their initial seed nodes simultaneously and the information is diffused according to Independent Cascade model (ICM). The main aim of the player is to choose the seed nodes such that they will spread its information to as many nodes as possible in a social network. The rate of spreading of information also plays a very important role in information diffusion process. Any node in a social network will get influenced by none or one or more than one information. We also analyzed how much fraction of nodes in different compartment changes by changing the rate of spreading of information. Finally, a game theory model is developed to obtain the Nash equilibrium based on best response function of the players. This model is based on Hotelling's model of electoral competition. ",https://doi.org/10.1016/j.physa.2018.11.035,1805.02081v1,Yes,potent(1)
0000-0002-9370-1038,Anurag Singh,Universität Tübingen,Locating transition path region in the free energy landscape of protein   folding,1970,"  Protein folding processes are generally described statistically with the help of multidimensional free energy landscape, typically reduced to a 1-D free energy profile along good reaction co-ordinate. There are many physical parameters which are responsible for protein molecule to hop between the native and unfolded states. The transition path region across the barrier is the region corresponding to the minimum fluctuation. The extent to which this transition region can extend beyond the obvious 1/2 kBT region has been a question of interest for a long time. We propose a new method to locate this transition path region and to study its dependence on the asymmetry of the transition state for a given free energy landscape. We have performed Brownian dynamics simulations with Gaussian white noise and Monte-Carlo simulation by sampling ten thousand successful transitions across the barrier for three different energy landscape having fixed barrier height with asymmetry in their curvatures. It was found that the transition path region increases with the increase in the asymmetry of the energy landscape in the transition region. The rate limiting parameter diffusion constant over the diffusive barrier, rate constant at particular force and transition path time for different potentials were estimated directly from the landscape profile using Kramers theory for diffusive barrier crossing. It was also found that the average diffusion in the native state increases with the increase in the asymmetry of the transition state towards the non-native state. ",Kein DOI-Link verfügbar,1705.01246v1,Yes,potent(1)
0000-0002-9379-2048,Alexander Brinkmann,Universität Mannheim,Product Information Extraction using ChatGPT,1970,"  Structured product data in the form of attribute/value pairs is the foundation of many e-commerce applications such as faceted product search, product comparison, and product recommendation. Product offers often only contain textual descriptions of the product attributes in the form of titles or free text. Hence, extracting attribute/value pairs from textual product descriptions is an essential enabler for e-commerce applications. In order to excel, state-of-the-art product information extraction methods require large quantities of task-specific training data. The methods also struggle with generalizing to out-of-distribution attributes and attribute values that were not a part of the training data. Due to being pre-trained on huge amounts of text as well as due to emergent effects resulting from the model size, Large Language Models like ChatGPT have the potential to address both of these shortcomings. This paper explores the potential of ChatGPT for extracting attribute/value pairs from product descriptions. We experiment with different zero-shot and few-shot prompt designs. Our results show that ChatGPT achieves a performance similar to a pre-trained language model but requires much smaller amounts of training data and computation for fine-tuning. ",Kein DOI-Link verfügbar,2306.14921v1,Yes,potent(2)
0000-0002-9379-2048,Alexander Brinkmann,Universität Mannheim,Using LLMs for the Extraction and Normalization of Product Attribute   Values,1970,"  Product offers on e-commerce websites often consist of a product title and a textual product description. In order to enable features such as faceted product search or to generate product comparison tables, it is necessary to extract structured attribute-value pairs from the unstructured product titles and descriptions and to normalize the extracted values to a single, unified scale for each attribute. This paper explores the potential of using large language models (LLMs), such as GPT-3.5 and GPT-4, to extract and normalize attribute values from product titles and descriptions. We experiment with different zero-shot and few-shot prompt templates for instructing LLMs to extract and normalize attribute-value pairs. We introduce the Web Data Commons - Product Attribute Value Extraction (WDC-PAVE) benchmark dataset for our experiments. WDC-PAVE consists of product offers from 59 different websites which provide schema.org annotations. The offers belong to five different product categories, each with a specific set of attributes. The dataset provides manually verified attribute-value pairs in two forms: (i) directly extracted values and (ii) normalized attribute values. The normalization of the attribute values requires systems to perform the following types of operations: name expansion, generalization, unit of measurement conversion, and string wrangling. Our experiments demonstrate that GPT-4 outperforms the PLM-based extraction methods SU-OpenTag, AVEQA, and MAVEQA by 10%, achieving an F1-score of 91%. For the extraction and normalization of product attribute values, GPT-4 achieves a similar performance to the extraction scenario, while being particularly strong at string wrangling and name expansion. ",https://doi.org/10.1007/978-3-031-70626-4_15,2403.02130v4,Yes,potent(1)
0000-0002-9379-2048,Alexander Brinkmann,Universität Mannheim,ExtractGPT: Exploring the Potential of Large Language Models for Product   Attribute Value Extraction,1970,"  In order to facilitate features such as faceted product search and product comparison, e-commerce platforms require accurately structured product data, including precise attribute/value pairs. Vendors often times provide unstructured product descriptions consisting only of an offer title and a textual description. Consequently, extracting attribute values from titles and descriptions is vital for e-commerce platforms. State-of-the-art attribute value extraction methods based on pre-trained language models, such as BERT, face two drawbacks (i) the methods require significant amounts of task-specific training data and (ii) the fine-tuned models have problems with generalising to unseen attribute values that were not part of the training data. This paper explores the potential of using large language models as a more training data-efficient and more robust alternative to existing AVE methods. We propose prompt templates for describing the target attributes of the extraction to the LLM, covering both zero-shot and few-shot scenarios. In the zero-shot scenario, textual and JSON-based target schema representations of the attributes are compared. In the few-shot scenario, we investigate (i) the provision of example attribute values, (ii) the selection of in-context demonstrations, (iii) shuffled ensembling to prevent position bias, and (iv) fine-tuning the LLM. We evaluate the prompt templates in combination with hosted LLMs, such as GPT-3.5 and GPT-4, and open-source LLMs which can be run locally. We compare the performance of the LLMs to the PLM-based methods SU-OpenTag, AVEQA, and MAVEQA. The highest average F1-score of 86% was achieved by GPT-4. Llama-3-70B performs only 3% worse than GPT-4, making it a competitive open-source alternative. Given the same training data, this prompt/GPT-4 combination outperforms the best PLM baseline by an average of 6% F1-score. ",Kein DOI-Link verfügbar,2310.12537v3,Yes,potent(1)
0000-0002-9475-3593,Simone Frintrop,Universität Hamburg,Occlusion Resistant Object Rotation Regression from Point Cloud Segments,1970,"  Rotation estimation of known rigid objects is important for robotic applications such as dexterous manipulation. Most existing methods for rotation estimation use intermediate representations such as templates, global or local feature descriptors, or object coordinates, which require multiple steps in order to infer the object pose. We propose to directly regress a pose vector from raw point cloud segments using a convolutional neural network. Experimental results show that our method can potentially achieve competitive performance compared to a state-of-the-art method, while also showing more robustness against occlusion. Our method does not require any post processing such as refinement with the iterative closest point algorithm. ",Kein DOI-Link verfügbar,1808.05498v2,Yes,potent(1)
0000-0002-9475-3593,Simone Frintrop,Universität Hamburg,Immersive Neural Graphics Primitives,1970,"  Neural radiance field (NeRF), in particular its extension by instant neural graphics primitives, is a novel rendering method for view synthesis that uses real-world images to build photo-realistic immersive virtual scenes. Despite its potential, research on the combination of NeRF and virtual reality (VR) remains sparse. Currently, there is no integration into typical VR systems available, and the performance and suitability of NeRF implementations for VR have not been evaluated, for instance, for different scene complexities or screen resolutions. In this paper, we present and evaluate a NeRF-based framework that is capable of rendering scenes in immersive VR allowing users to freely move their heads to explore complex real-world scenes. We evaluate our framework by benchmarking three different NeRF scenes concerning their rendering performance at different scene complexities and resolutions. Utilizing super-resolution, our approach can yield a frame rate of 30 frames per second with a resolution of 1280x720 pixels per eye. We discuss potential applications of our framework and provide an open source implementation online. ",Kein DOI-Link verfügbar,2211.13494v1,Yes,potent(2)
0000-0002-9475-3593,Simone Frintrop,Universität Hamburg,Select High-Level Features: Efficient Experts from a Hierarchical   Classification Network,1970,"  This study introduces a novel expert generation method that dynamically reduces task and computational complexity without compromising predictive performance. It is based on a new hierarchical classification network topology that combines sequential processing of generic low-level features with parallelism and nesting of high-level features. This structure allows for the innovative extraction technique: the ability to select only high-level features of task-relevant categories. In certain cases, it is possible to skip almost all unneeded high-level features, which can significantly reduce the inference cost and is highly beneficial in resource-constrained conditions. We believe this method paves the way for future network designs that are lightweight and adaptable, making them suitable for a wide range of applications, from compact edge devices to large-scale clouds. In terms of dynamic inference our methodology can achieve an exclusion of up to 88.7\,\% of parameters and 73.4\,\% fewer giga-multiply accumulate (GMAC) operations, analysis against comparative baselines showing an average reduction of 47.6\,\% in parameters and 5.8\,\% in GMACs across the cases we evaluated. ",Kein DOI-Link verfügbar,2403.05601v1,Yes,innovative(1)
0000-0002-9586-2265,Mingfeng Wang,Kiel Universität,"Bioinspired molecular qubits and nanoparticle ensembles that could be   initialized, manipulated and readout under mild conditions",1970,"  Quantum computation and quantum information processing are emerging technologies that have potential to overcome the physical limitation of traditional computation systems. Present quantum systems based on photons, atoms and molecules, however, all face challenges such as short coherence time, requirement of ultralow temperature and/or high vacuum, and lack of scalability. We report a new type of molecular qubits and nanoparticle ensembles based on thermally controllable transformation between J-aggregation and monomeric states of molecular chromophores, using pyrrolopyrrole cyanine tethered with polymeric chains such as polycaprolactones as an example. Such supramolecular quantum systems, resembling some feature of light harvesting complexes in photosynthesis, provide new opportunities for manipulating quantum in-formation under mild conditions, which do not require complicated ultra-cooling and/or high vacuum often involved in present superconducting qubits or Rydberg atoms for quantum computation and information processing. ",Kein DOI-Link verfügbar,2107.06682v1,Yes,potent(1)
0000-0002-9586-2265,Mingfeng Wang,Kiel Universität,"Design, Modelling and Validation of a Novel Extra Slender Continuum   Robot for In-situ Inspection and Repair in Aeroengine",1970,"  In-situ aeroengine maintenance works are highly beneficial as it can significantly reduce the current maintenance cycle which is extensive and costly due to the disassembly requirement of engines from aircrafts. However, navigating in/out via inspection ports and performing multi-axis movements with end-effectors in constrained environments (e.g. combustion chamber) are fairly challenging. A novel extra-slender (diameter-to-length ratio <0.02) dual-stage continuum robot (16 degree-of-freedom) is proposed to navigate in/out confined environments and perform required configuration shapes for further repair operations. Firstly, the robot design presents several innovative mechatronic solutions: (i) dual-stage tendon-driven structure with bevelled disks to perform required shapes and to provide selective stiffness for carrying high payloads; (ii) various rigid-compliant combined joints to enable different flexibility and stiffness in each stage; (iii) three commanding cables for each 2-DoF section to minimise the number of actuators with precise actuations. Secondly, a segment-scaled piecewise-constant-curvature-theory based kinematic model and a Kirchhoff-elastic-rod-theory based static model are established by considering the applied forces/moments (friction, actuation, gravity and external load), where the friction coefficient is modelled as a function of bending angle. Finally, experiments were carried out to validate the proposed static modelling and to evaluate the robot capabilities of performing the predefined shape and stiffness. ",Kein DOI-Link verfügbar,1910.04572v1,Yes,innovative(1)
0000-0002-9586-2265,Mingfeng Wang,Kiel Universität,Higher-order exceptional point in a pseudo-Hermitian cavity   optomechanical system,1970,"  Higher-order exceptional points (EPs), resulting from non-Hermitian degeneracies, have shown greater advantages in sensitive enhancement than second-order EPs (EP2s). Therefore, seeking higher-order EPs in various quantum systems is important for quantum information science. Here we propose a benchmark cavity optomechanical (COM) system consisting of a mechanical resonator (MR) coupled to two cavities via radiation pressure for predicting the third-order exceptional point (EP3). We first give the pseudo-Hermitian condition for the non-Hermitian COM system by taking the bath effects into account. Then we consider the mechanical gain effect and we find that the pseudo-Hermitian COM system without $\mathcal{PT}$ symmetry can host both the EP3 and EP2 for symmetric and asymmetric cavities. In the symmetric case, only the EP3 or EP2 can be predicted in the parameter space, but the EP3 and EP2 can be transformed into each other by tuning the COM coupling strength in the asymmetric case. We further consider the case of one cavity with gain. For this case, the pseudo-Hermitian COM system is $\mathcal{PT}$-symmetric and can also host the EP3 or EP2. The influence of system parameters on them are discussed. Our proposal provides a potential way to realize sensitive detection and study other physical phenomena {around} higher-order EP3 in non-Hermitian COM systems. ",https://doi.org/10.1103/PhysRevA.104.063508,2109.12232v3,Yes,potent(1)
0000-0002-9586-2265,Mingfeng Wang,Kiel Universität,Unitary and efficient spin squeezing in cavity optomechanics,1970,"  We propose an approach to produce spin squeezed states of a large number of nitrogen-vacancy centers in diamond nanostructures coupled to an optical cavity. Unlike the previous squeezing method proposed by Bennett et al. [Phys. Rev. Lett. 110, 156402 (2013)], which is limited by phonon number fluctuations due to the existence of phonon-spin entanglement, our proposal can completely erase the entanglement between spins and hybrid phonon-photon mode mediating the effective spin-spin interaction, and thus achieves unitary one-axis-twisting interactions between nitrogen-vacancy centres, yielding a squeezing scaling $J^{-2/3}$, where J is the total angular momentum. We found that, under certain conditions, our method has the potential to enhance the spin-spin nonlinear interactions. We also proposed a scheme utilizing repeatedly applying the one-axis-twisting evolution to two orthogonal spin directions, which enables the transformation of the one-axis-twisting interactions into two-axis-twisting type, and therefore leads to the spin squeezing with Heisenberg-limited scaling $J^{-1}$. Taking into account the noise effects of spin dephasing and relaxtion, we found that the proposed approaches are robust against imperfections. ",Kein DOI-Link verfügbar,2401.15553v1,Yes,potent(1)
0000-0002-9586-2265,Mingfeng Wang,Kiel Universität,Higher-order exceptional point in a blue-detuned non-Hermitian cavity   optomechanical system,1970,"  Higher-order exceptional points (EPs) in non-Hermitian systems have attracted great interest due to their advantages in sensitive enhancement and distinct topological features. However, realization of such EPs is still challenged because more fine-tuning parameters is generically required in quantum systems, compared to the second-order EP (EP2). Here, we propose a non-Hermitian three-mode optomechanical system in the blue-sideband regime for predicting the third-order EP (EP3). By deriving the pseudo-Hermitian condition for the proposed system, one cavity with loss and the other one with gain must be required. Then we show EP3 or EP2 can be observed when the mechanical resonator (MR) is neutral, loss or gain. For the neutral MR, we find both two degenerate or two non-degenerate EP3s can be predicted by tuning system parameters in the parameter space, while four non-degenerate EP2s can be observed when the system parameters derivate from EP3s, which is distinguished from the previous study in the red-detuned optomechanical system. For the gain (loss) MR, we find only two degenerate EP3s or EP2s can be predicted by tuning enhanced coupling strength. Our proposal provides a potential way to predict higher-order EPs or multiple EP2s and study multimode quantum squeezing around EPs using the blue-detuned non-Hermitian optomechanical systems. ",https://doi.org/10.1103/PhysRevA.106.033518,2205.07184v4,Yes,potent(1)
0000-0002-9600-1854,Fabian Hofmann,Universität Ulm,Enhancing the German Transmission Grid Through Dynamic Line Rating,1970,"  The German government recently announced that 80\% of the power supply should come from renewable energy by 2030. One key task lies in reorganizing the transmission system such that power can be transported from sites with good renewable potentials to the load centers. Dynamic Line Rating (DLR), which allows the dynamic calculation of transmission line capacities based on prevailing weather conditions rather than conservative invariant ratings, offers the potential to exploit existing grid capacities better. In this paper, we analyze the effect of DLR on behalf of a detailed power system model of Germany including all of today's extra high voltage transmission lines and substations. The evolving synergies between DLR and an increased wind power generation lead to savings of around 400 million euro per year in the short term and 900 million per year in a scenario for 2030. ",Kein DOI-Link verfügbar,2208.04716v1,Yes,potent(2)
0000-0002-9600-1854,Fabian Hofmann,Universität Ulm,H$_2$ and CO$_2$ Network Strategies for the European Energy System,1970,"  Hydrogen and carbon dioxide transport can both play an essential role in climate-neutral energy systems. Hydrogen networks help serve regions with high energy demand, while excess emissions are transported away in carbon dioxide networks. For the synthesis of carbonaceous fuels, it is less clear which input should be transported: hydrogen to carbon point sources or carbon to low-cost hydrogen. We explore both networks' potential synergies and competition in a cost-optimal carbon-neutral European energy system. In direct comparison, a hydrogen network is more cost-effective than a carbon network, since it serves to transport hydrogen to demand and to point source of carbon for utilization. However, in a hybrid scenario where both networks are present, the carbon network effectively complements the hydrogen network, promoting carbon capture from biomass and reducing reliance on direct air capture. Our analysis suggests integrating hydrogen and carbon dioxide networks into European energy policy for a robust, carbon-neutral or carbon-negative future energy system. ",Kein DOI-Link verfügbar,2402.19042v1,Yes,potent(1)
0000-0002-9600-1854,Fabian Hofmann,Universität Ulm,Leveraging the Existing German Transmission Grid with Dynamic Line   Rating,1970,"  The integration of large shares of wind and solar power into the power system benefits from transmission network expansion. However, the construction of new power lines requires long planning phases and is often delayed by citizen protests. As a non-invasive alternative, Dynamic Line Rating (DLR) offers the potential to leverage the existing grid by dynamically adjusting the transmission line capacities to the prevailing weather conditions. In this study, we present the first investment model that includes DLR in a large-scale power system with real-world network data and a high temporal resolution. Using Germany as an example, we show that a system-wide integration of DLR improves the integration of existing and additional renewables while reducing grid congestion. The evolving synergies between DLR and increased wind generation result in total cost savings of about 3% of all system costs for a scenario with 80% renewable power production, mainly due to reduced storage and solar capacity needs. If considering a fully decarbonized electricity system, the cost savings from DLR amount to up to 5.5% of the system costs, i.e. 4 billion Euro per year. Our results underscore the importance of a rapid implementation of DLR in power systems to support the energy transition and relieve grid congestion. ",Kein DOI-Link verfügbar,2303.02987v1,Yes,potent(1)
0000-0002-9600-1854,Fabian Hofmann,Universität Ulm,PyPSA-Eur: An Open Optimisation Model of the European Transmission   System,1970,"  PyPSA-Eur, the first open model dataset of the European power system at the transmission network level to cover the full ENTSO-E area, is presented. It contains 6001 lines (alternating current lines at and above 220 kV voltage level and all high voltage direct current lines), 3657 substations, a new open database of conventional power plants, time series for electrical demand and variable renewable generator availability, and geographic potentials for the expansion of wind and solar power. The model is suitable both for operational studies and generation and transmission expansion planning studies. The continental scope and highly resolved spatial scale enables a proper description of the long-range smoothing effects for renewable power generation and their varying resource availability. The restriction to freely available and open data encourages the open exchange of model data developments and eases the comparison of model results. A further novelty of the dataset is the publication of the full, automated software pipeline to assemble the load-flow-ready model from the original datasets, which enables easy replacement and improvement of the individual parts. This paper focuses on the description of the network topology, the compilation of a European power plant database and a top-down load time-series regionalisation. It summarises the derivation of renewable wind and solar availability time-series from re-analysis weather datasets and the estimation of renewable capacity potentials restricted by land-use. Finally, validations of the dataset are presented, including a new methodology to compare geo-referenced network datasets to one another. ",https://doi.org/10.1016/j.esr.2018.08.012,1806.01613v3,Yes,potent(2)
0000-0002-9600-1854,Fabian Hofmann,Universität Ulm,Carbon Leakage in a European Power System with Inhomogeneous Carbon   Prices,1970,"  Global warming is one of the main threats to the future of humanity and extensive emissions of greenhouse gases are found to be the main cause of global temperature rise as well as climate change. During the last decades international attention has focused on this issue, as well as on searching for viable solutions to mitigate global warming. In this context, the pricing of greenhouse gas emissions turned out to be the most prominent mechanism: First, to lower the emissions, and second, to capture their external costs. By now, various carbon dioxide taxes have been adopted by several countries in Europe and around the world; moreover, the list of these countries is growing. However, there is no standardized approach and the price for carbon varies significantly from one country to another. Regionally diversified carbon prices in turn lead to carbon leakage, which will offset the climate protection goals. In this paper, a simplified European power system with flexible carbon prices regarding the Gross Domestic Product (GDP) is investigated. A distribution parameter that quantifies carbon leakage is defined and varied together with the base carbon price, where the combination of both parameters describes the spatially resolved price distribution, i.e. the effective carbon pricing among the European regions. It is shown that inhomogeneous carbon prices will indeed lead to significant carbon leakage across the continent, and that coal-fired electricity generation will remain a cheap and therefore major source of power in Eastern and South-Eastern Europe - representing a potential risk for the long term decarbonization targets within the European Union. ",Kein DOI-Link verfügbar,2105.05669v1,Yes,potent(1)
0000-0002-9620-1469,Qiang Yu,Martin Luther Universität Halle-Wittenberg,Synaptic Learning with Augmented Spikes,1970,"  Traditional neuron models use analog values for information representation and computation, while all-or-nothing spikes are employed in the spiking ones. With a more brain-like processing paradigm, spiking neurons are more promising for improvements on efficiency and computational capability. They extend the computation of traditional neurons with an additional dimension of time carried by all-or-nothing spikes. Could one benefit from both the accuracy of analog values and the time-processing capability of spikes? In this paper, we introduce a concept of augmented spikes to carry complementary information with spike coefficients in addition to spike latencies. New augmented spiking neuron model and synaptic learning rules are proposed to process and learn patterns of augmented spikes. We provide systematic insight into the properties and characteristics of our methods, including classification of augmented spike patterns, learning capacity, construction of causality, feature detection, robustness and applicability to practical tasks such as acoustic and visual pattern recognition. The remarkable results highlight the effectiveness and potential merits of our methods. Importantly, our augmented approaches are versatile and can be easily generalized to other spike-based systems, contributing to a potential development for them including neuromorphic computing. ",https://doi.org/10.1109/TNNLS.2020.3040969,2005.04820v1,Yes,"versatile(1), potent(2)"
0000-0002-9620-1469,Qiang Yu,Martin Luther Universität Halle-Wittenberg,Towards Efficient Processing and Learning with Spikes: New Approaches   for Multi-Spike Learning,1970,"  Spikes are the currency in central nervous systems for information transmission and processing. They are also believed to play an essential role in low-power consumption of the biological systems, whose efficiency attracts increasing attentions to the field of neuromorphic computing. However, efficient processing and learning of discrete spikes still remains as a challenging problem. In this paper, we make our contributions towards this direction. A simplified spiking neuron model is firstly introduced with effects of both synaptic input and firing output on membrane potential being modeled with an impulse function. An event-driven scheme is then presented to further improve the processing efficiency. Based on the neuron model, we propose two new multi-spike learning rules which demonstrate better performance over other baselines on various tasks including association, classification, feature detection. In addition to efficiency, our learning rules demonstrate a high robustness against strong noise of different types. They can also be generalized to different spike coding schemes for the classification task, and notably single neuron is capable of solving multi-category classifications with our learning rules. In the feature detection task, we re-examine the ability of unsupervised STDP with its limitations being presented, and find a new phenomenon of losing selectivity. In contrast, our proposed learning rules can reliably solve the task over a wide range of conditions without specific constraints being applied. Moreover, our rules can not only detect features but also discriminate them. The improved performance of our methods would contribute to neuromorphic computing as a preferable choice. ",https://doi.org/10.1109/TCYB.2020.2984888,2005.00723v1,Yes,potent(1)
0000-0002-9620-1469,Qiang Yu,Martin Luther Universität Halle-Wittenberg,Constructing Accurate and Efficient Deep Spiking Neural Networks with   Double-threshold and Augmented Schemes,1970,"  Spiking neural networks (SNNs) are considered as a potential candidate to overcome current challenges such as the high-power consumption encountered by artificial neural networks (ANNs), however there is still a gap between them with respect to the recognition accuracy on practical tasks. A conversion strategy was thus introduced recently to bridge this gap by mapping a trained ANN to an SNN. However, it is still unclear that to what extent this obtained SNN can benefit both the accuracy advantage from ANN and high efficiency from the spike-based paradigm of computation. In this paper, we propose two new conversion methods, namely TerMapping and AugMapping. The TerMapping is a straightforward extension of a typical threshold-balancing method with a double-threshold scheme, while the AugMapping additionally incorporates a new scheme of augmented spike that employs a spike coefficient to carry the number of typical all-or-nothing spikes occurring at a time step. We examine the performance of our methods based on MNIST, Fashion-MNIST and CIFAR10 datasets. The results show that the proposed double-threshold scheme can effectively improve accuracies of the converted SNNs. More importantly, the proposed AugMapping is more advantageous for constructing accurate, fast and efficient deep SNNs as compared to other state-of-the-art approaches. Our study therefore provides new approaches for further integration of advanced techniques in ANNs to improve the performance of SNNs, which could be of great merit to applied developments with spike-based neuromorphic computing. ",https://doi.org/10.1109/TNNLS.2020.3043415,2005.03231v1,Yes,potent(1)
0000-0002-9620-1469,Qiang Yu,Martin Luther Universität Halle-Wittenberg,Robust Environmental Sound Recognition with Sparse Key-point Encoding   and Efficient Multi-spike Learning,1970,"  The capability for environmental sound recognition (ESR) can determine the fitness of individuals in a way to avoid dangers or pursue opportunities when critical sound events occur. It still remains mysterious about the fundamental principles of biological systems that result in such a remarkable ability. Additionally, the practical importance of ESR has attracted an increasing amount of research attention, but the chaotic and non-stationary difficulties continue to make it a challenging task. In this study, we propose a spike-based framework from a more brain-like perspective for the ESR task. Our framework is a unifying system with a consistent integration of three major functional parts which are sparse encoding, efficient learning and robust readout. We first introduce a simple sparse encoding where key-points are used for feature representation, and demonstrate its generalization to both spike and non-spike based systems. Then, we evaluate the learning properties of different learning rules in details with our contributions being added for improvements. Our results highlight the advantages of the multi-spike learning, providing a selection reference for various spike-based developments. Finally, we combine the multi-spike readout with the other parts to form a system for ESR. Experimental results show that our framework performs the best as compared to other baseline approaches. In addition, we show that our spike-based framework has several advantageous characteristics including early decision making, small dataset acquiring and ongoing dynamic processing. Our framework is the first attempt to apply the multi-spike characteristic of nervous neurons to ESR. The outstanding performance of our approach would potentially contribute to draw more research efforts to push the boundaries of spike-based paradigm to a new horizon. ",Kein DOI-Link verfügbar,1902.01094v1,Yes,potent(1)
0000-0002-9620-1469,Qiang Yu,Martin Luther Universität Halle-Wittenberg,Prompt Tuning with Soft Context Sharing for Vision-Language Models,1970,"  Vision-language models have recently shown great potential on many tasks in computer vision. Meanwhile, prior work demonstrates prompt tuning designed for vision-language models could acquire superior performance on few-shot image recognition compared to linear probe, a strong baseline. In practice, many few-shot tasks are inherently correlated, particularly within specialized domains. However, such information is overlooked previously. Inspired by the fact that modeling task relationship by multi-task learning can usually boost performance, we propose a novel method SoftCPT (Soft Context Sharing for Prompt Tuning) to tune pre-trained vision-language models on multiple target few-shot tasks jointly. Specifically, we design a task-shared meta network to generate prompt context for each task using task name together with a learnable task context as input. The parameters of this meta network as well as the task context are tuned on the joint training set of all tasks. As such, the prompt context of all tasks will be shared in a soft manner. Extensive experiments across four multi-task few-shot datasets covering 44 tasks and 1593 categories demonstrate that SoftCPT significantly outperforms single-task prompt tuning methods, highlighting the effectiveness of multi-task learning for vision-language prompt tuning. Code is available at https://github.com/kding1225/softcpt. ",Kein DOI-Link verfügbar,2208.13474v2,Yes,potent(1)
0000-0002-9641-9492,Jin Li,Universität Duisburg-Essen,Prospects of constraining on the polarizations of gravitational waves   from binary black holes using space- and ground-based detectors,1970,"  In general relativity, gravitational waves (GWs) exhibit two tensor modes, while alternative theories predict up to six polarization modes. We investigate GW polarization constraints using a model-independent parametrized post-Einsteinian framework with space- and ground-based detectors. Evaluating LISA, Taiji, TianQin, LIGO, Virgo, KAGRA, and Einstein Telescope (ET), we analyze their capabilities and network performance. Taiji provides the best constraints among space-based detectors, with LISA outperforming TianQin. Among ground-based detectors, LIGO excels in vector modes, while ET offers the most comprehensive constraints. In network scenarios, LISA+TJm performs best, and ET surpasses second-generation detector combinations. Multiband observations alleviate scalar mode degeneracies, significantly enhancing ground-based detector performance. Combined space- and ground-based observations yield robust constraints on GW polarization, advancing tests of deviations from general relativity. Our findings highlight the potential of future GW missions to refine our understanding of gravitational physics through precise polarization measurements. ",Kein DOI-Link verfügbar,2407.13590v1,Yes,potent(1)
0000-0002-9646-7136,Tommy Hofmann,Martin-Luther-Universität Halle-Wittenberg,Ionic liquid dynamics in nanoporous carbon: A pore-size- and   temperature-dependent neutron spectroscopy study on supercapacitor materials,1970,"  The influence of spatial confinement on the thermally excited stochastic cation dynamics of the room-temperature ionic liquid 1-N-butylpyridinium bis-((trifluoromethyl)sulfonyl)imide ([BuPy][Tf_2N]) inside porous carbide-derived carbons with various pore sizes in the sub- to a few nanometer range are investigated by quasi-elastic neutron spectroscopy. Using the potential of fixed window scans, i.e. scanning a sample parameter, while observing solely one specific energy transfer value, an overview of the dynamic landscape within a wide temperature range is obtained. It is shown that already these data provide a quite comprehensive understanding of the confinement-induced alteration of the molecular mobility in comparison to the bulk. A complementary, more detailed analysis of full energy transfer spectra at selected temperatures reveals two translational diffusive processes on different time scales. Both are considerably slower than in the bulk liquid and show a decrease of the respective self-diffusion coefficients with decreasing nanopore size. Different thermal activation energies for molecular self-diffusion in nanoporous carbons with similar pore size indicate the importance of pore morphology on the molecular mobility, beyond the pure degree of confinement. In spite of the dynamic slowing down we can show that the temperature range of the liquid state upon nanoconfinement is remarkably extended to much lower temperatures, which is beneficial for potential technical applications of such systems. ",https://doi.org/10.1103/PhysRevMaterials.4.055401,2005.02851v1,Yes,potent(2)
0000-0002-9646-7136,Tommy Hofmann,Martin-Luther-Universität Halle-Wittenberg,Self-Assembly of Liquid Crystals in Nanoporous Solids for Adaptive   Photonic Metamaterials,1970,"  Nanoporous media exhibit structures significantly smaller than the wavelengths of visible light and can thus act as photonic metamaterials. Their optical functionality is not determined by the properties of the base materials, but rather by tailored, multiscale structures, in terms of precise pore shape, geometry, and orientation. Embedding liquid crystals in pore space provides additional opportunities to control light-matter interactions at the single-pore, meta-atomic scale. Here, we present temperature-dependent 3D reciprocal space mapping using synchrotron-based X-ray diffraction in combination with high-resolution birefringence experiments on disk-like mesogens (HAT6) imbibed in self-ordered arrays of parallel cylindrical pores 17 to 160 nm across in monolithic anodic aluminium oxide (AAO). In agreement with Monte Carlo computer simulations we observe a remarkably rich self-assembly behaviour, unknown from the bulk state. It encompasses transitions between the isotropic liquid state and discotic stacking in linear columns as well as circular concentric ring formation perpendicular and parallel to the pore axis. These textural transitions underpin an optical birefringence functionality, tuneable in magnitude and in sign from positive to negative via pore size, pore surface-grafting and temperature. Our study demonstrates that the advent of large-scale, self-organised nanoporosity in monolithic solids along with confinement-controllable phase behaviour of liquid-crystalline matter at the single-pore scale provides a reliable and accessible tool to design materials with adjustable optical anisotropy, and thus offers versatile pathways to fine-tune polarisation-dependent light propagation speeds in materials. Such a tailorability is at the core of the emerging field of transformative optics, allowing, e.g., adjustable light absorbers and extremely thin metalenses. ",https://doi.org/10.1039/C9NR07143A,1911.10052v1,Yes,versatile(1)
0000-0002-9698-2453,Patrick Linker,Universität Stuttgart,Reduced Quantum General Relativity in Higher Dimensions,1970,"  The higher dimensional Quantum General Relativity of a Riemannian manifold being an embedded space in a space-time being a Lorentzian manifold is investigated. The model of quantum geometrodynamics, based on the Wheeler-DeWitt equation reduced to a first order functional quantum evolution supplemented through an additional eigenequation for the scalar curvature, is formulated. Furthermore, making use of the objective quantum gravity and global one-dimensional conjecture, the general wave function beyond the Feynman path integral technique is derived. The resulting quantum gravity model creates the opportunity of potentially new theoretical and phenomenological applications for astrophysics, cosmology, and physics. ",Kein DOI-Link verfügbar,1605.02546v1,Yes,potent(1)
0000-0002-9744-3419,Benjamin Butz,Universität Siegen,Highly Integrated Organic-Inorganic Hybrid Architectures by Non-Covalent   Exfoliation of Graphite and Assembly with Zinc Oxide Nanoparticles,1970,"  Herein, we report an easy, straight forward, and versatile approach to build 0D/2D hybrid nanoparticle/graphene architectures by means of non-covalent chemistry and a modified Layer-by-Layer assembly. Three water soluble perylene diimides were employed to efficiently exfoliate pristine graphite into positively charged few- and multilayer graphene flakes. Further combination of these cationic building blocks with anionic zinc oxide nanoparticles led to the formation of tailor-made hybrid films via electrostatic and van der Waals interactions. These supramolecular hybrid nano-structures were thoroughly characterized by UV/Vis and Raman spectroscopy, AFM as well as electron microscopy, showing outstanding long-range homogeneity and high integrity in the centimetre-scale, uniform nanometric thickness between 60-100 nm and a close contact between the different building blocks. Due to their straightforward assembly. These architectures can be considered as promising candidates for numerous advanced applications especially in the field of energy storage and conversion. ",https://doi.org/10.1002/admi.201600365,1805.09129v1,Yes,versatile(1)
0000-0002-9787-5975,Onur Ayan,Technische Universität München,Optimal Scheduling for Discounted Age Penalty Minimization in Multi-Loop   Networked Control,1970,"  Age-of-information (AoI) is a metric quantifying information freshness at the receiver. Since AoI combines packet generation frequency, packet loss, and delay into a single metric, it has received a lot of research attention as an interface between communication network and application. In this work, we apply AoI to the problem of wireless scheduling for multi-loop networked control systems (NCS), i.e., feedback control loops closed over a shared wireless network. We model the scheduling problem as a Markov decision process (MDP) with AoI as its observable states and derive a relation of control system error and AoI. We further derive a stationary scheduling policy to minimize control error over an infinite horizon. We show that our scheduler outperforms the state-of-the-art scheduling policies for NCS. To the best of our knowledge, this is the first work proposing an AoI-based wireless scheduling policy that minimizes the control error over an infinite horizon for multi-loop NCS. ",Kein DOI-Link verfügbar,1908.01503v3,Yes,fresh(1)
0000-0002-9787-5975,Onur Ayan,Technische Universität München,Probability Analysis of Age of Information in Multi-hop Networks,1970,"  Age-of-information (AoI) is a metric quantifying information freshness at the receiver. It captures the delay together with packet loss and packet generation rate. However, the existing literature focuses on average or peak AoI and neglects the complete distribution. In this work, we consider a N-hop network with time-invariant packet loss probabilities on each link. We derive closed form equations for the probability mass function of AoI. We verify our findings with simulations. Our results show that the performance indicators considered in the literature such as average or peak AoI may give misleading insights into the real AoI performance. ",Kein DOI-Link verfügbar,1911.09957v2,Yes,fresh(1)
0000-0002-9787-5975,Onur Ayan,Technische Universität München,AoI-based Finite Horizon Scheduling for Heterogeneous Networked Control   Systems,1970,"  Age of information (AoI) measures information freshness at the receiver. AoI may provide insights into quality of service in communication systems. For this reason, it has been used as a cross-layer metric for wireless communication protocols. In this work, we employ AoI to calculate penalty functions for a centralized resource scheduling problem. We consider a single wireless link shared by multiple, heterogeneous control systems where each sub-system has a time-varying packet loss probability. Sub-systems are competing for network resources to improve the accuracy of their remote estimation process. In order to cope with the dynamically changing conditions of the wireless link, we define a finite horizon age-penalty minimization problem and propose a scheduler that takes optimal decisions by looking $H$ slots into the future. The proposed algorithm has a worst-case complexity that grows exponentially with $H$. However, by narrowing down our search space within the constrained set of actions, we are able to decrease the complexity significantly without losing optimality. On the contrary, we show by simulations that the benefit of increasing $H$ w.r.t. remote state estimation performance diminishes after a certain $H$ value. ",Kein DOI-Link verfügbar,2005.02037v1,Yes,fresh(1)
0000-0002-9787-5975,Onur Ayan,Technische Universität München,Task-oriented Scheduling for Networked Control Systems: An Age of   Information-Aware Implementation on Software-defined Radios,1970,"  Networked control systems (NCSs) are feedback control loops that are closed over a communication network. Emerging applications, such as telerobotics, drones and autonomous driving are the most prominent examples of such systems. Regular and timely information sharing between the components of NCSs is essential to fulfill the desired control tasks, as stale information can lead to performance degradation or even physical damage. In this work, we consider multiple heterogeneous NCSs that transmit their system state over a shared physical wireless channel towards a gateway node. We conduct a comprehensive experimental study on selected MAC protocols using software-defined radios with state-of-the-art (SotA) solutions that have been designed to increase information freshness and control performance. As a significant improvement over the SotA, we propose a novel contention-free algorithm that is able to outperform the existing solutions by combining their strengths in one protocol. In addition, we propose a new metric called normalized mean squared error that maps the age of information to a dimensionless quantity that captures the expected value of a control system's next transmission. We demonstrate its adoption and effectiveness for wireless resource scheduling in a case study involving multiple inverted pendulums. From our experimental study and results, we observe that value-aware prioritization of the sub-systems contributes to minimizing the negative effects of information staleness on control performance. In particular, as the number of devices increases, the benefit of control-awareness to the quality of control stands out when compared to protocols that focus solely on maximizing information freshness. ",Kein DOI-Link verfügbar,2202.09189v3,Yes,fresh(2)
0000-0002-9787-5975,Onur Ayan,Technische Universität München,Age-of-Information vs. Value-of-Information Scheduling for Cellular   Networked Control Systems,1970,"  Age-of-Information (AoI) is a recently introduced metric for network operation with sensor applications which quantifies the freshness of data. In the context of networked control systems (NCSs), we compare the worth of the AoI metric with the value-of-information (VoI) metric, which is related to the uncertainty reduction in stochastic processes. First, we show that the uncertainty propagates non-linearly over time depending on system dynamics. Next, we define the value of a new update of the process of interest as a function of AoI and system parameters of the NCSs. We use the aggregated update value as a utility for the centralized scheduling problem in a cellular NCS composed of multiple heterogeneous control loops. By conducting a simulative analysis, we show that prioritizing transmissions with higher VoI improves performance of the NCSs compared with providing fair data freshness to all sub-systems equally. ",Kein DOI-Link verfügbar,1903.05356v1,Yes,fresh(2)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Cosmology with a time-varying speed of light,1970,  Cosmic inflation is the only known mechanism with the potential to explain the very special initial conditions which are required at the early stages of the evolution of our universe. This article outlines my work with Joao Magueijo which attempts to construct an alternative mechanism based on a time-varying speed of light. ,https://doi.org/10.1063/1.59450,astro-ph/9904185v1,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,The Theory of Everything vs the Theory of Anything,1970,"  To what extent can our limited set of observations be used to pin down the specifics of a ``Theory of Everything''? In the limit where the links are arbitrarily tenuous, a ``Theory of Everything'' might become a ``Theory of Anything''. A clear understanding of what we can and can not expect to learn about the universe is particularly important in the field of particle cosmology. The aim of this article is to draw attention to some key issues which arise in this context, in the hopes of fostering further discussion. In particular, I explore the idea that a variety of different inflaton potentials may contribute to worlds ``like ours''. A careful examination of the conditional probability questions we can ask might give a physical measure of what is ``natural'' for an inflation potential which is quite different from those previously used. ",https://doi.org/10.1007/3-540-60024-8_126,gr-qc/9408023v2,Yes,potent(2)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Cosmic curvature from de Sitter equilibrium cosmology,1970,"  I show that the de Sitter Equilibrium cosmology generically predicts observable levels of curvature in the Universe today. The predicted value of the curvature depends only on the ratio of the density of non-relativistic matter to energy density in cosmological constant, and the value of the curvature from the initial bubble that starts the inflation. The result is independent of the scale of inflation, the shape of the potential during inflation, and many other details of the cosmology. Future cosmological measurements of the matter density, cosmological constant and curvature will open up a window on the very beginning of our Universe and offer an opportunity to support or falsify the de Sitter Equilibrium cosmology. ",https://doi.org/10.1103/PhysRevLett.107.151102,1104.3315v2,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Opportunities for future supernova studies of cosmic acceleration,1970,"  We investigate the potential of a future supernova dataset, as might be obtained by the proposed SNAP satellite, to discriminate among different ``dark energy'' theories that describe an accelerating Universe. We find that many such models can be distinguished with a fit to the effective pressure-to-density ratio, $w$, of this energy. More models can be distinguished when the effective slope, $dw/dz$, of a changing $w$ is also fit, but only if our knowledge of the current mass density, $\Omega_m$, is improved. We investigate the use of ``fitting functions'' to interpret luminosity distance data from supernova searches, and argue in favor of a particular preferred method, which we use in our analysis. ",https://doi.org/10.1103/PhysRevLett.86.1939,astro-ph/0008314v3,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Transients in finite inflation,1970,  We test a model of inflation with a fast-rolling kinetic-dominated initial condition against data from Planck using Markov chain Monte Carlo parameter estimation. We test both an $m^2 \phi^2$ potential and the $R+R^2$ gravity model and perform a full numerical calculation of both the scalar and tensor primordial power spectra. We find a slight (though not significant) improvement in fit for this model over the standard eternal slow-roll case. ,https://doi.org/10.1103/PhysRevD.92.083506,1503.04872v2,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Phenomenology of a realistic accelerating universe using only   Planck-scale physics,1970,"  Modern data is showing increasing evidence that the Universe is accelerating. So far, all attempts to account for the acceleration have required some fundamental dimensionless quantities to be extremely small. We show how a class of scalar field models (which may emerge naturally from superstring theory) can account for acceleration which starts in the present epoch with all the potential parameters O(1) in Planck units. ",https://doi.org/10.1103/PhysRevLett.84.2076,astro-ph/9908085v2,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Creating universes with thick walls,1970,"  We study the dynamics of a spherically symmetric false vacuum bubble embedded in a true vacuum region separated by a ""thick wall"", which is generated by a scalar field in a quartic potential. We study the ""Farhi-Guth-Guven"" (FGG) quantum tunneling process by constructing numerical solutions relevant to this process. The ADM mass of the spacetime is calculated, and we show that there is a lower bound that is a significant fraction of the scalar field mass. We argue that the zero mass solutions used to by some to argue against the physicality of the FGG process are artifacts of the thin wall approximation used in earlier work. We argue that the zero mass solutions should not be used to question the viability of the FGG process. ",https://doi.org/10.1103/PhysRevD.85.103527,1202.5936v1,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Holographic bounds and finite inflation,1970,"  We compare two holographic arguments that impose especially strong bounds on the amount of inflation. One comes from the de Sitter Equilibrium cosmology and the other from the work of Banks and Fischler. We find that simple versions of these two approaches yield the same bound on the number of e-foldings. A careful examination reveals that while these pictures are similar in spirit, they are not necessarily identical prescriptions. We apply the two pictures to specific cosmologies which expose potentially important differences and which also demonstrate ways these seemingly simple proposals can be tricky to implement in practice. ",https://doi.org/10.1103/PhysRevD.91.043513,1410.6065v1,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Testing quantum gravity by nanodiamond interferometry with   nitrogen-vacancy centers,1970,"  Interferometry with massive particles may have the potential to explore the limitations of standard quantum mechanics in particular where it concerns its boundary with general relativity and the yet to be developed theory of quantum gravity. This development is hindered considerably by the lack of experimental evidence and testable predictions. Analyzing effects that appear to be common to many of such theories, such as a modification of the energy dispersion and of the canonical commutation relation within the standard framework of quantum mechanics, has been proposed as a possible way forward. Here we analyze in some detail the impact of a modified energy-momentum dispersion in a Ramsey-Bord\'e setup and provide achievable bounds of these correcting terms when operating such an interferometer with nanodiamonds. Thus, taking thermal and gravitational disturbances into account will show that without specific prerequisites, quantum gravity modifications may in general be suppressed requiring a revision of previously estimated bounds. As a possible solution we propose a stable setup that is rather insensitive to these effects. Finally, we address the problems of decoherence and pulse errors in such setups and discuss the scalings and advantages with increasing particle mass. ",https://doi.org/10.1103/PhysRevA.90.033834,1403.6038v2,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Quintessential Cosmological Tensions,1970,"  Several cosmological tensions have emerged in light of recent data, most notably in the inferences of the parameters $H_0$ and $\sigma_8$. We explore the possibility of alleviating both these tensions {\it simultaneously} by means of the Albrecht-Skordis ``quintessence'' potential. The field can reduce the size of the sound horizon $r_s^*$ while concurrently suppressing the power in matter density fluctuations before it comes to dominate the energy density budget today. Interestingly, this rich set of dynamics is governed entirely by one free parameter that is of $\mathcal{O}(10)$ in Planck units. We find that the inferred value of $H_0$ can be increased, while that of $\sigma_8$ can be decreased, both by $\approx 1\sigma$ compared to the $\Lambda$CDM case. However, ultimately the model is disfavored by Planck and BAO data alone, compared to the standard $\Lambda$CDM model, with a $\Delta \chi^2 \approx +6$. When including large scale structure and supernova data $\Delta \chi^2 \approx +1$. We note that historically much attention has been focused on preserving the three angular scales $\theta_D$, $\theta_{EQ}$, and $\theta_s^*$ to their $\Lambda$CDM values. Our work presents an example of how, while doing so indeed maintains a relatively good fit to the CMB data for an increased number of ultra-relativistic species, it is a-priori insufficient in maintaining such a fit in more general model spaces. ",https://doi.org/10.1103/PhysRevD.107.063521,2207.10235v1,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Spinodal Instabilities and Super-Planckian Excursions in Natural   Inflation,1970,"  Models such as Natural Inflation that use Pseudo-Nambu-Goldstone bosons (PNGB's) as the inflaton are attractive for many reasons. However, they typically require trans-Planckian field excursions $\Delta \Phi>M_{\rm Pl}$, due to the need for an axion decay constant $f>M_{\rm Pl}$ to have both a sufficient number of e-folds {\em and} values of $n_s,\ r$ consistent with data. Such excursions would in general require the addition of all other higher dimension operators consistent with symmetries, thus disrupting the required flatness of the potential and rendering the theory non-predictive. We show that in the case of Natural Inflation, the existence of spinodal instabilities (modes with tachyonic masses) can modify the inflaton equations of motion to the point that versions of the model with $f<M_{\rm Pl}$ can still inflate for the required number of e-folds. The instabilities naturally give rise to two separate phases of inflation with different values of the Hubble parameter $H$ one driven by the zero mode, the other by the unstable fluctuation modes. The values of $n_s$ and $r$ typically depend on the initial conditions for the zero mode, and, at least for those examined here, the values of $r$ tend to be unobservably small. ",https://doi.org/10.1103/PhysRevLett.114.171301,1412.6879v2,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Exploring Parameter Constraints on Quintessential Dark Energy: The   Exponential Model,1970,"  We present an analysis of a scalar field model of dark energy with an exponential potential using the Dark Energy Task Force (DETF) simulated data models. Using Markov Chain Monte Carlo sampling techniques we examine the ability of each simulated data set to constrain the parameter space of the exponential potential for data sets based on a cosmological constant and a specific exponential scalar field model. We compare our results with the constraining power calculated by the DETF using their ``$w_0-w_a$'' parametrization of the dark energy. We find that respective increases in constraining power from one stage to the next produced by our analysis give results consistent with DETF results. To further investigate the potential impact of future experiments, we also generate simulated data for an exponential model background cosmology which can not be distinguished from a cosmological constant at DETF ``Stage 2'', and show that for this cosmology good DETF Stage 4 data would exclude a cosmological constant by better than 3$\sigma$. ",https://doi.org/10.1103/PhysRevD.77.103504,0712.2884v1,Yes,potent(3)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Future Supernovae observations as a probe of dark energy,1970,"  We study the potential impact of improved future supernovae data on our understanding of the dark energy problem. We carefully examine the relative utility of different fitting functions that can be used to parameterize the dark energy models, and provide concrete reasons why a particular choice (based on a parameterization of the equation of state) is better in almost all cases. We discuss the details of a representative sample of dark energy models and show how future supernova observations could distinguish among these. As a specific example, we consider the proposed ``SNAP'' satellite which is planned to observe around 2000 supernovae. We show how a SNAP-class data set taken alone would be a powerful discriminator among a family of models that would be approximated by a constant equation of state for the most recent epoch of cosmic expansion. We show how this family includes most of the dark energy models proposed so far. We then show how an independent measurement of $\Omega_{\rm m}$ can allow SNAP to probe the evolution of the equation of state as well, allowing further discrimination among a larger class of proposed dark energy models. We study the impact of the satellite design parameters on this method to distinguish the models and compare SNAP to alternative measurements. We establish that if we exploit the full precision of SNAP it provides a very powerful probe. ",https://doi.org/10.1103/PhysRevD.65.103512,astro-ph/0106079v2,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,A Search for Classical Subsystems in Quantum Worlds,1970,"  Decoherence and einselection have been effective in explaining several features of an emergent classical world from an underlying quantum theory. However, the theory assumes a particular factorization of the global Hilbert space into constituent system and environment subsystems, as well as specially constructed Hamiltonians. In this work, we take a systematic approach to discover, given a fixed Hamiltonian, (potentially) several factorizations (or tensor product structures) of a global Hilbert space that admit a quasi-classical description of subsystems in the sense that certain states (the ""pointer states"") are robust to entanglement. We show that every Hamiltonian admits a pointer basis in the factorization where the energy eigenvectors are separable. Furthermore, we implement an algorithm that allows us to discover a multitude of factorizations that admit pointer states and use it to explore these quasi-classical ""realms"" for both random and structured Hamiltonians. We also derive several analytical forms that the Hamiltonian may take in such factorizations, each with its unique set of features. Our approach has several implications: it enables us to derive the division into quasi-classical subsystems, demonstrates that decohering subsystems do not necessarily align with our classical notion of locality, and challenges ideas expressed by some authors that the propensity of a system to exhibit classical dynamics relies on minimizing the interaction between subsystems. From a quantum foundations perspective, these results lead to interesting ramifications for relative-state interpretations. From a quantum engineering perspective, these results may be useful in characterizing decoherence free subspaces and other passive error avoidance protocols. ",Kein DOI-Link verfügbar,2403.10895v2,Yes,potent(1)
0000-0002-9813-4319,Andreas Albrecht,Technische Universität München,Entanglement masquerading in the CMB,1970,"  The simplest single-field inflation models capture all the relevant contributions to the patterns in the Cosmic Microwave Background (CMB) observed today. A key assumption in these models is that the quantum inflationary fluctuations that source such patterns are generated by a particular quantum state -- the Bunch-Davies (BD) state. While this is a well-motivated choice from a theoretical perspective, the question arises of whether current data can rule out other, also well motivated, choices of states. In particular, as we previously demonstrated in arXiv:2104.13410 [hep-th], entanglement is naturally and inevitably dynamically generated during inflation given the presence of a ""rolling"" spectator scalar field -- and the resulting entangled state will yield a primordial power spectrum with potentially measurable deviations compared to the canonical BD result. For this work we developed a perturbative framework to allow a systematic exploration of constraints on (or detection of) entangled states with Planck CMB data using Monte Carlo techniques. We have found that most entangled states accessible with our framework are consistent with the data. One would have to expand the framework to allow a greater variety of entangled states in order to saturate the Planck constraints and more systematically explore any preferences the data may have among the different possibilities. ",https://doi.org/10.1088/1475-7516/2023/06/024,2211.11079v2,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,How Many Events do You Need? Event-based Visual Place Recognition Using   Sparse But Varying Pixels,1970,"  Event cameras continue to attract interest due to desirable characteristics such as high dynamic range, low latency, virtually no motion blur, and high energy efficiency. One of the potential applications that would benefit from these characteristics lies in visual place recognition for robot localization, i.e. matching a query observation to the corresponding reference place in the database. In this letter, we explore the distinctiveness of event streams from a small subset of pixels (in the tens or hundreds). We demonstrate that the absolute difference in the number of events at those pixel locations accumulated into event frames can be sufficient for the place recognition task, when pixels that display large variations in the reference set are used. Using such sparse (over image coordinates) but varying (variance over the number of events per pixel location) pixels enables frequent and computationally cheap updates of the location estimates. Furthermore, when event frames contain a constant number of events, our method takes full advantage of the event-driven nature of the sensory stream and displays promising robustness to changes in velocity. We evaluate our proposed approach on the Brisbane-Event-VPR dataset in an outdoor driving scenario, as well as the newly contributed indoor QCR-Event-VPR dataset that was captured with a DAVIS346 camera mounted on a mobile robotic platform. Our results show that our approach achieves competitive performance when compared to several baseline methods on those datasets, and is particularly well suited for compute- and energy-constrained platforms such as interplanetary rovers. ",Kein DOI-Link verfügbar,2206.13673v3,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Fast and Robust Bio-inspired Teach and Repeat Navigation,1970,"  Fully autonomous mobile robots have a multitude of potential applications, but guaranteeing robust navigation performance remains an open research problem. For many tasks such as repeated infrastructure inspection, item delivery, or inventory transport, a route repeating capability can be sufficient and offers potential practical advantages over a full navigation stack. Previous teach and repeat research has achieved high performance in difficult conditions predominantly by using sophisticated, expensive sensors, and has often had high computational requirements. Biological systems, such as small animals and insects like seeing ants, offer a proof of concept that robust and generalisable navigation can be achieved with extremely limited visual systems and computing power. In this work we create a novel asynchronous formulation for teach and repeat navigation that fully utilises odometry information, paired with a correction signal driven by much more computationally lightweight visual processing than is typically required. This correction signal is also decoupled from the robot's motor control, allowing its rate to be modulated by the available computing capacity. We evaluate this approach with extensive experimentation on two different robotic platforms, the Consequential Robotics Miro and the Clearpath Jackal robots, across navigation trials totalling more than 6000 metres in a range of challenging indoor and outdoor environments. Our approach continues to succeed when multiple state-of-the-art systems fail due to low resolution images, unreliable odometry, or lighting change, while requiring significantly less compute. We also - for the first time - demonstrate versatile cross-platform teach and repeat without changing parameters, in which we learn to navigate a route with one robot and repeat that route using a completely different robot. ",Kein DOI-Link verfügbar,2010.11326v3,Yes,"versatile(1), potent(2)"
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,"Effects of a strong phase transition on supernova explosions, compact   stars and their mergers",1970,"  We outline a theoretical approach supporting strong phase transitions from normal nuclear matter to the deconfined quark-gluon plasma, in the equation of state (EOS) for compact star matter. Implications of this hypothesis are discussed for astrophysical applications. Special emphasis is devoted to potentially detectable signatures, which can be directly related with the occurrence of a sufficiently strong phase transition. Therefore, simulations of core-collapse supernovae and binary compact star mergers are considered, including the subsequent emission of gravitational waves and, in the case of supernova, in addition the neutrinos play the role of messengers. ",https://doi.org/10.1142/9789811220944_0008,2203.17188v1,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Applications of Spiking Neural Networks in Visual Place Recognition,1970,"  In robotics, Spiking Neural Networks (SNNs) are increasingly recognized for their largely-unrealized potential energy efficiency and low latency particularly when implemented on neuromorphic hardware. Our paper highlights three advancements for SNNs in Visual Place Recognition (VPR). Firstly, we propose Modular SNNs, where each SNN represents a set of non-overlapping geographically distinct places, enabling scalable networks for large environments. Secondly, we present Ensembles of Modular SNNs, where multiple networks represent the same place, significantly enhancing accuracy compared to single-network models. Each of our Modular SNN modules is compact, comprising only 1500 neurons and 474k synapses, making them ideally suited for ensembling due to their small size. Lastly, we investigate the role of sequence matching in SNN-based VPR, a technique where consecutive images are used to refine place recognition. We analyze the responsiveness of SNNs to ensembling and sequence matching compared to other VPR techniques. Our contributions highlight the viability of SNNs for VPR, offering scalable and robust solutions, and paving the way for their application in various energy-sensitive robotic tasks. ",Kein DOI-Link verfügbar,2311.13186v2,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,RMMI: Enhanced Obstacle Avoidance for Reactive Mobile Manipulation using   an Implicit Neural Map,1970,"  We introduce RMMI, a novel reactive control framework for mobile manipulators operating in complex, static environments. Our approach leverages a neural Signed Distance Field (SDF) to model intricate environment details and incorporates this representation as inequality constraints within a Quadratic Program (QP) to coordinate robot joint and base motion. A key contribution is the introduction of an active collision avoidance cost term that maximises the total robot distance to obstacles during the motion. We first evaluate our approach in a simulated reaching task, outperforming previous methods that rely on representing both the robot and the scene as a set of primitive geometries. Compared with the baseline, we improved the task success rate by 25% in total, which includes increases of 10% by using the active collision cost. We also demonstrate our approach on a real-world platform, showing its effectiveness in reaching target poses in cluttered and confined spaces using environment models built directly from sensor data. For additional details and experiment videos, visit https://rmmi.github.io/. ",Kein DOI-Link verfügbar,2408.16206v1,Yes,intricate(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,"A compact neuromorphic system for ultra energy-efficient, on-device   robot localization",1970,"  Neuromorphic computing offers a transformative pathway to overcome the computational and energy challenges faced in deploying robotic localization and navigation systems at the edge. Visual place recognition, a critical component for navigation, is often hampered by the high resource demands of conventional systems, making them unsuitable for small-scale robotic platforms which still require to perform complex, long-range tasks. Although neuromorphic approaches offer potential for greater efficiency, real-time edge deployment remains constrained by the complexity and limited scalability of bio-realistic networks. Here, we demonstrate a neuromorphic localization system that performs accurate place recognition in up to 8km of traversal using models as small as 180 KB with 44k parameters, while consuming less than 1% of the energy required by conventional methods. Our Locational Encoding with Neuromorphic Systems (LENS) integrates spiking neural networks, an event-based dynamic vision sensor, and a neuromorphic processor within a single SPECK(TM) chip, enabling real-time, energy-efficient localization on a hexapod robot. LENS represents the first fully neuromorphic localization system capable of large-scale, on-device deployment, setting a new benchmark for energy efficient robotic place recognition. ",Kein DOI-Link verfügbar,2408.16754v1,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Spiking Neural Networks for Visual Place Recognition via Weighted   Neuronal Assignments,1970,"  Spiking neural networks (SNNs) offer both compelling potential advantages, including energy efficiency and low latencies and challenges including the non-differentiable nature of event spikes. Much of the initial research in this area has converted deep neural networks to equivalent SNNs, but this conversion approach potentially negates some of the advantages of SNN-based approaches developed from scratch. One promising area for high-performance SNNs is template matching and image recognition. This research introduces the first high-performance SNN for the Visual Place Recognition (VPR) task: given a query image, the SNN has to find the closest match out of a list of reference images. At the core of this new system is a novel assignment scheme that implements a form of ambiguity-informed salience, by up-weighting single-place-encoding neurons and down-weighting ""ambiguous"" neurons that respond to multiple different reference places. In a range of experiments on the challenging Nordland, Oxford RobotCar, SPEDTest, Synthia, and St Lucia datasets, we show that our SNN achieves comparable VPR performance to state-of-the-art and classical techniques, and degrades gracefully in performance with an increasing number of reference places. Our results provide a significant milestone towards SNNs that can provide robust, energy-efficient, and low latency robot localization. ",https://doi.org/10.1109/LRA.2022.3149030,2109.06452v2,Yes,potent(2)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,"Ensembles of Compact, Region-specific & Regularized Spiking Neural   Networks for Scalable Place Recognition",1970,"  Spiking neural networks have significant potential utility in robotics due to their high energy efficiency on specialized hardware, but proof-of-concept implementations have not yet typically achieved competitive performance or capability with conventional approaches. In this paper, we tackle one of the key practical challenges of scalability by introducing a novel modular ensemble network approach, where compact, localized spiking networks each learn and are solely responsible for recognizing places in a local region of the environment only. This modular approach creates a highly scalable system. However, it comes with a high-performance cost where a lack of global regularization at deployment time leads to hyperactive neurons that erroneously respond to places outside their learned region. Our second contribution introduces a regularization approach that detects and removes these problematic hyperactive neurons during the initial environmental learning phase. We evaluate this new scalable modular system on benchmark localization datasets Nordland and Oxford RobotCar, with comparisons to standard techniques NetVLAD, DenseVLAD, and SAD, and a previous spiking neural network system. Our system substantially outperforms the previous SNN system on its small dataset, but also maintains performance on 27 times larger benchmark datasets where the operation of the previous system is computationally infeasible, and performs competitively with the conventional localization systems. ",Kein DOI-Link verfügbar,2209.08723v3,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Boosting Performance of a Baseline Visual Place Recognition Technique by   Predicting the Maximally Complementary Technique,1970,"  One recent promising approach to the Visual Place Recognition (VPR) problem has been to fuse the place recognition estimates of multiple complementary VPR techniques using methods such as SRAL and multi-process fusion. These approaches come with a substantial practical limitation: they require all potential VPR methods to be brute-force run before they are selectively fused. The obvious solution to this limitation is to predict the viable subset of methods ahead of time, but this is challenging because it requires a predictive signal within the imagery itself that is indicative of high performance methods. Here we propose an alternative approach that instead starts with a known single base VPR technique, and learns to predict the most complementary additional VPR technique to fuse with it, that results in the largest improvement in performance. The key innovation here is to use a dimensionally reduced difference vector between the query image and the top-retrieved reference image using this baseline technique as the predictive signal of the most complementary additional technique, both during training and inference. We demonstrate that our approach can train a single network to select performant, complementary technique pairs across datasets which span multiple modes of transportation (train, car, walking) as well as to generalise to unseen datasets, outperforming multiple baseline strategies for manually selecting the best technique pairs based on the same training data. ",https://doi.org/10.1109/ICRA48891.2023.10161561,2210.07509v1,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Early quark deconfinement in compact star astrophysics and heavy-ion   collisions,1970,"  Based on a recently developed relativistic density functional approach to color-superconducting quark matter and a novel quark-hadron transition construction which phenomenologically accounts for the effects of inhomogeneous pasta phases and quark-hadron continuity, we construct a class of hybrid equations of state applicable at the regimes typical for compact star astrophysics and heavy ion collisions. We outline that early quark deconfinement is a notable consequence of strong diquark pairing providing a good agreement with the observational data and driving the trajectories of the matter evolution during the supernovae explosions toward the regimes typical for the compact star mergers and heavy-ion collisions. ",https://doi.org/10.5506/APhysPolBSupp.16.1-A104,2208.09085v2,Yes,notable(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Detecting the QCD phase transition in the next Galactic supernova   neutrino burst,1970,"  Predictions of the thermodynamic conditions for phase transitions at high baryon densities and large chemical potentials are currently uncertain and largely phenomenological. Neutrino observations of core-collapse supernovae can be used to constrain the situation. Recent simulations of stellar core collapse that include a description of quark matter predict a sharp burst of anti \nu_e several hundred milliseconds after the prompt \nu_e neutronization burst. We study the observational signatures of that anti \nu_e burst at current neutrino detectors - IceCube and Super-Kamiokande. For a Galactic core-collapse supernova, we find that signatures of the QCD phase transition can be detected, regardless of the neutrino oscillation scenario. The detection would constitute strong evidence of a phase transition in the stellar core, with implications for the equation of state at high matter density and the supernova explosion mechanism. ",https://doi.org/10.1103/PhysRevD.81.103005,0912.2568v2,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,VPRTempo: A Fast Temporally Encoded Spiking Neural Network for Visual   Place Recognition,1970,"  Spiking Neural Networks (SNNs) are at the forefront of neuromorphic computing thanks to their potential energy-efficiency, low latencies, and capacity for continual learning. While these capabilities are well suited for robotics tasks, SNNs have seen limited adaptation in this field thus far. This work introduces a SNN for Visual Place Recognition (VPR) that is both trainable within minutes and queryable in milliseconds, making it well suited for deployment on compute-constrained robotic systems. Our proposed system, VPRTempo, overcomes slow training and inference times using an abstracted SNN that trades biological realism for efficiency. VPRTempo employs a temporal code that determines the timing of a single spike based on a pixel's intensity, as opposed to prior SNNs relying on rate coding that determined the number of spikes; improving spike efficiency by over 100%. VPRTempo is trained using Spike-Timing Dependent Plasticity and a supervised delta learning rule enforcing that each output spiking neuron responds to just a single place. We evaluate our system on the Nordland and Oxford RobotCar benchmark localization datasets, which include up to 27k places. We found that VPRTempo's accuracy is comparable to prior SNNs and the popular NetVLAD place recognition algorithm, while being several orders of magnitude faster and suitable for real-time deployment -- with inference speeds over 50 Hz on CPU. VPRTempo could be integrated as a loop closure component for online SLAM on resource-constrained systems such as space and underwater robots. ",Kein DOI-Link verfügbar,2309.10225v2,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,A new quark-hadron hybrid equation of state for astrophysics - I.   High-mass twin compact stars,1970,"  Aims: We present a new microscopic hadron-quark hybrid equation of state model for astrophysical applications, from which compact hybrid star configurations are constructed. These are composed of a quark core and a hadronic shell with a first-order phase transition at their interface. The resulting mass-radius relations are in accordance with the latest astrophysical constraints. Methods: The quark matter description is based on a quantum chromodynamics (QCD) motivated chiral approach with higher-order quark interactions in the Dirac scalar and vector coupling channels. For hadronic matter we select a relativistic mean-field equation of state with density-dependent couplings. Since the nucleons are treated in the quasi-particle framework, an excluded volume correction has been included for the nuclear equation of state at suprasaturation density which takes into account the finite size of the nucleons. Results: These novel aspects, excluded volume in the hadronic phase and the higher-order repulsive interactions in the quark phase, lead to a strong first-order phase transition with large latent heat, i.e. the energy-density jump at the phase transition, which fulfils a criterion for a disconnected third-family branch of compact stars in the mass-radius relationship. These twin stars appear at high masses ($\sim$ 2 M$_\odot$) that are relevant for current observations of high-mass pulsars. Conclusions: This analysis offers a unique possibility by radius observations of compact stars to probe the QCD phase diagram at zero temperature and large chemical potential and even to support the existence of a critical point in the QCD phase diagram. ",https://doi.org/10.1051/0004-6361/201425318,1411.2856v2,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Constraining the onset density for the QCD phase transition with the   neutrino signal from core-collapse supernovae,1970,"  The occurrence of a first-order hadron-quark matter phase transition at high baryon densities is investigated in astrophysical simulations of core-collapse supernovae, to decipher yet incompletely understood properties of the dense matter equation of state (EOS) using neutrinos from such cosmic events. It is found that the emission of a nonstandard second neutrino burst, dominated by electron antineutrinos, is not only a measurable signal for the appearance of deconfined quark matter but also reveals information about the state of matter at extreme conditions encountered at the supernova (SN) interior. To this end, a large set of spherically symmetric SN models is investigated, studying the dependence on the EOS and the stellar progenitor. General relativistic neutrino-radiation hydrodynamics is employed featuring three-flavor Boltzmann neutrino transport and a microscopic hadron-quark hybrid matter EOS class. Therefore, the DD2 relativistic mean-field hadronic model is employed, and several variations of it, and the string-flip model for the description of deconfined quark matter. The resulting hybrid model covers a representative range of onset densities for the phase transition and latent heats. This facilitates the direct connection between intrinsic signatures of the neutrino signal and properties of the EOS. In particular, a set of linear relations has been found empirically. These potentially provide a constraint for the onset density of a possible QCD phase transition from the future neutrino observation of the next galactic core-collapse SN, if a millisecond electron anti-neutrino burst is present around or less than 1s. ",https://doi.org/10.3847/1538-4357/ad24f2,2304.12316v2,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Neutron stars in accreting systems -- signatures of the QCD phase   transition,1970,"  Neutron stars (NS) that are born in binary systems with a main-sequence star companion can experience mass transfer, resulting in the accumulation of material at the surface of the NS. This, in turn, leads to the continuous growth of the NS mass and the associated steepening of the gravitational potential. Supposing the central density surpasses the onset for the phase transition from nuclear, generally hadronic matter to deconfined quark-gluon plasma, which is a quantity currently constrained solely from an upper limit by asymptotic freedom in quantum chromodynamics (QCD), the system may experience a dynamic response due to the appearance of additional degrees of freedom in the equation of state (EOS). This dynamical response might give rise to a rapid softening of the EOS during the transition in the hadron-quark matter co-existence region. While this phenomenon has long been studied in the context of hydrostatic configurations, the dynamical implications of this problem are still incompletely understood. It is the purpose of the present paper to simulate the dynamics of NSs with previously accreted envelopes caused by the presence of a first-order QCD phase transition. Therefore, we employed the neutrino radiation hydrodynamics treatment based on the fully general relativistic approach in spherical symmetry, implementing a three-flavor Boltzmann neutrino transport and a microscopic model EOS that contains a first-order hadron-quark phase transition. The associated neutrino signal shows a sudden rise in the neutrino fluxes and average energies, becoming observable for the present generation of neutrino detectors for a galactic event, and a gravitational wave mode analysis revealed the behaviors of the dominant $f$ mode and the first and the second gravity $g$ modes that are excited during the NS evolution across the QCD phase transition. ",https://doi.org/10.1051/0004-6361/202348742,2311.15992v2,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Astrophysical Implications of the QCD phase transition,1970,"  The possible role of a first order QCD phase transition at nonvanishing quark chemical potential and temperature for cold neutron stars and for supernovae is delineated. For cold neutron stars, we use the NJL model with nonvanishing color superconducting pairing gaps, which describes the phase transition to the 2SC and the CFL quark matter phases at high baryon densities. We demonstrate that these two phase transitions can both be present in the core of neutron stars and that they lead to the appearance of a third family of solution for compact stars. In particular, a core of CFL quark matter can be present in stable compact star configurations when slightly adjusting the vacuum pressure to the onset of the chiral phase transition from the hadronic model to the NJL model. We show that a strong first order phase transition can have strong impact on the dynamics of core collapse supernovae. If the QCD phase transition sets in shortly after the first bounce, a second outgoing shock wave can be generated which leads to an explosion. The presence of the QCD phase transition can be read off from the neutrino and antineutrino signal of the supernova. ",Kein DOI-Link verfügbar,0903.0991v1,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Frequency-Division Multiplexing in Magnonic Logic Networks Based on   Caustic-Like Spin-Wave Beams,1970,"  Wave-based data processing by spin waves and their quanta, magnons, is a promising technique to overcome the challenges which CMOS-based logic networks are facing nowadays. The advantage of these quasi-particles lies in their potential for the realization of energy efficient devices on the micro- to nanometer scale due to their charge-less propagation in magnetic materials. In this paper, the frequency dependence of the propagation direction of caustic-like spin-wave beams in microstructured ferromagnets is studied by micromagnetic simulations. Based on the observed alteration of the propagation angle, an approach to spatially combine and separate spin-wave signals of different frequencies is demonstrated. The presented magnetic structure constitutes a prototype design of a passive circuit enabling frequency-division multiplexing in magnonic logic networks. It is verified that spin-wave signals of different frequencies can be transmitted through the device simultaneously without any interaction or creation of spurious signals. Due to the wave-based approach of computing in magnonic networks, the technique of frequency-division multiplexing can be the basis for parallel data processing in single magnonic devices, enabling the multiplication of the data throughput. ",https://doi.org/10.1002/pssr.201800409,1906.04993v2,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Evolution of collisional neutrino flavor instabilities in spherically   symmetric supernova models,1970,"  We implement a multi-group and discrete-ordinate neutrino transport model in spherical symmetry which allows to simulate collective neutrino oscillations by including realistic collisional rates in a self-consistent way. We utilize this innovative model, based on strategic parameter rescaling, to study a recently proposed collisional flavor instability caused by the asymmetry of emission and absorption rates between $\nu_e$ and $\bar\nu_e$ for four different static backgrounds taken from different stages in a core-collapse supernova simulation. Our results confirm that collisional instabilities generally exist around the neutrinosphere during the SN accretion and post-accretion phase, as suggested by [arXiv:2104.11369]. However, the growth and transport of flavor instabilities can only be fully captured by models with global simulations as done in this work. With minimal ingredient to trigger collisional instabilities, we find that the flavor oscillations and transport mainly affect (anti)neutrinos of heavy lepton flavors around their decoupling sphere, which then leave imprints on their energy spectra in the free-streaming regime. For electron (anti)neutrinos, their properties remain nearly intact. We also explore various effects due to the decoherence from neutrino-nucleon scattering, artificially enhanced decoherence from emission and absorption, neutrino vacuum mixing, and inhomogeneous matter profile, and discuss the implication of our work. ",https://doi.org/10.1103/PhysRevD.107.083016,2210.08254v2,Yes,innovative(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Neutrinos and nucleosynthesis of elements,1970,"  Neutrinos are known to play important roles in many astrophysical scenarios from the early period of the big bang to current stellar evolution being a unique messenger of the fusion reactions occurring in the center of our sun. In particular, neutrinos are crucial in determining the dynamics and the composition evolution in explosive events such as core-collapse supernovae and the merger of two neutron stars. In this paper, we review the current understanding of supernovae and binary neutron star mergers by focusing on the role of neutrinos therein. Several recent improvements on the theoretical modeling of neutrino interaction rates in nuclear matter as well as their impact on the heavy element nucleosynthesis in the supernova neutrino-driven wind are discussed, including the neutrino-nucleon opacity at the mean field level taking into account the relativistic kinematics of nucleons, the effect due to the nucleon-nucleon correlation, and the nucleon-nucleon bremsstrahlung. We also review the framework used to compute the neutrino-nucleus interactions and the up-to-date yield prediction for isotopes from neutrino nucleosynthesis occurring in the outer envelope of the supernova progenitor star during the explosion. Here improved predictions of energy spectra of supernova neutrinos of all flavors have had significant impact on the nucleosynthesis yields. Rapid progresses in modeling the flavor oscillations of neutrinos in these environments, including several novel mechanisms for collective neutrino oscillations and their potential impacts on various nucleosynthesis processes are summarized. ",https://doi.org/10.1016/j.ppnp.2024.104107,2308.03962v2,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,CR3DT: Camera-RADAR Fusion for 3D Detection and Tracking,1970,"  To enable self-driving vehicles accurate detection and tracking of surrounding objects is essential. While Light Detection and Ranging (LiDAR) sensors have set the benchmark for high-performance systems, the appeal of camera-only solutions lies in their cost-effectiveness. Notably, despite the prevalent use of Radio Detection and Ranging (RADAR) sensors in automotive systems, their potential in 3D detection and tracking has been largely disregarded due to data sparsity and measurement noise. As a recent development, the combination of RADARs and cameras is emerging as a promising solution. This paper presents Camera-RADAR 3D Detection and Tracking (CR3DT), a camera-RADAR fusion model for 3D object detection, and Multi-Object Tracking (MOT). Building upon the foundations of the State-of-the-Art (SotA) camera-only BEVDet architecture, CR3DT demonstrates substantial improvements in both detection and tracking capabilities, by incorporating the spatial and velocity information of the RADAR sensor. Experimental results demonstrate an absolute improvement in detection performance of 5.3% in mean Average Precision (mAP) and a 14.9% increase in Average Multi-Object Tracking Accuracy (AMOTA) on the nuScenes dataset when leveraging both modalities. CR3DT bridges the gap between high-performance and cost-effective perception systems in autonomous driving, by capitalizing on the ubiquitous presence of RADAR in automotive applications. The code is available at: https://github.com/ETH-PBL/CR3DT. ",Kein DOI-Link verfügbar,2403.15313v2,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,MICDrop: Masking Image and Depth Features via Complementary Dropout for   Domain-Adaptive Semantic Segmentation,1970,"  Unsupervised Domain Adaptation (UDA) is the task of bridging the domain gap between a labeled source domain, e.g., synthetic data, and an unlabeled target domain. We observe that current UDA methods show inferior results on fine structures and tend to oversegment objects with ambiguous appearance. To address these shortcomings, we propose to leverage geometric information, i.e., depth predictions, as depth discontinuities often coincide with segmentation boundaries. We show that naively incorporating depth into current UDA methods does not fully exploit the potential of this complementary information. To this end, we present MICDrop, which learns a joint feature representation by masking image encoder features while inversely masking depth encoder features. With this simple yet effective complementary masking strategy, we enforce the use of both modalities when learning the joint feature representation. To aid this process, we propose a feature fusion module to improve both global as well as local information sharing while being robust to errors in the depth predictions. We show that our method can be plugged into various recent UDA methods and consistently improve results across standard UDA benchmarks, obtaining new state-of-the-art performances. ",Kein DOI-Link verfügbar,2408.16478v1,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Axion emission and detection from a Galactic supernova,1970,"  A Galactic supernova (SN) axion signal would be detected in a future neutrino Mton-class water Cherenkov detector, such as the proposed Hyper-Kamiokande in Japan. The main detection channel for axions is absorption on the oxygen nuclei in the water. The subsequent oxygen de-excitation leads to a potentially detectable gamma signal. In this contribution we present a calculation of the SN axion signal and discuss its detectability in Hyper-Kamiokande. ",https://doi.org/10.3204/PUBDB-2018-02580,1808.04101v1,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Improved axion emissivity from a supernova via nucleon-nucleon   bremsstrahlung,1970,"  The most efficient axion production mechanism in a supernova (SN) core is the nucleon-nucleon bremsstrahlung. This process has been often modeled at the level of the vacuum one-pion exchange (OPE) approximation. Starting from this naive recipe, we revise the calculation including systematically different effects, namely a non-vanishing mass for the exchanged pion, the contribution from the two-pions exchange, effective in-medium nucleon masses and multiple nucleon scatterings. Moreover, we allow for an arbitrary degree of nucleon degeneracy. A self consistent treatment of the axion emission rate including all these effects is currently missing. The aim of this work is to provide such an analysis. Furthermore, we demonstrate that the OPE potential with all the previous corrections gives rise to similar results as the on-shell T-matrix, and is therefore well justified for our and similar studies. We find that the axion emissivity is reduced by over an order of magnitude with respect to the basic OPE calculation, after all these effects are accounted for. The implications for the axion mass bound and the impact for the next generation experimental axion searches is also discussed. ",https://doi.org/10.1088/1475-7516/2019/10/016,1906.11844v3,Yes,potent(1)
0000-0002-9825-5655,Tobias Fischer,Leipzig Universität,Equation-of-state Constraints and the QCD Phase Transition in the Era of   Gravitational-Wave Astronomy,1970,"  We describe a multi-messenger interpretation of GW170817, which yields a robust lower limit on NS radii. This excludes NSs with radii smaller than about 10.7 km and thus rules out very soft nuclear matter. We stress the potential of this type of constraints when future detections become available. A very similar argumentation may yield an upper bound on the maximum mass of nonrotating NSs. We also discuss simulations of NS mergers, which undergo a first-order phase transition to quark matter. We point out a different dynamical behavior. Considering the gravitational-wave signal, we identify an unambiguous signature of the QCD phase transition in NS mergers. The occurrence of quark matter through a strong first-order phase transition during merging leads to a characteristic shift of the dominant postmerger frequency. The frequency shift is indicative for a phase transition if it is compared to the postmerger frequency which is expected for purely hadronic EoS models. A very strong deviation of several 100 Hz is observed for hybrid EoSs in an otherwise tight relation between the tidal deformability and the postmerger frequency. We address the potential impact of a first-order phase transition on the electromagnetic counterpart of NS mergers. Our simulations suggest that there would be no significant qualitative differences between a system undergoing a phase transition to quark matter and purely hadronic mergers. The quantitative differences are within the spread which is found between different hadronic EoS models. This implies on the one hand that GW170817 is compatible with a possible transition to quark matter. On the other hand these considerations show that it may not be easy to identify quantitative differences between purely hadronic mergers and events in which quark matter occurs considering solely their electromagnetic counterpart or their nucleosynthesis products. (abridged) ",https://doi.org/10.1063/1.5117803,1904.01306v1,Yes,potent(2)
0000-0002-9841-3676,Christian Uhl,Philipps Universität Marburg,Mind the GAP: Security & Privacy Risks of Contact Tracing Apps,1970,"  Google and Apple have jointly provided an API for exposure notification in order to implement decentralized contract tracing apps using Bluetooth Low Energy, the so-called ""Google/Apple Proposal"", which we abbreviate by ""GAP"". We demonstrate that in real-world scenarios the current GAP design is vulnerable to (i) profiling and possibly de-anonymizing infected persons, and (ii) relay-based wormhole attacks that basically can generate fake contacts with the potential of affecting the accuracy of an app-based contact tracing system. For both types of attack, we have built tools that can easily be used on mobile phones or Raspberry Pis (e.g., Bluetooth sniffers). The goal of our work is to perform a reality check towards possibly providing empirical real-world evidence for these two privacy and security risks. We hope that our findings provide valuable input for developing secure and privacy-preserving digital contact tracing systems. ",Kein DOI-Link verfügbar,2006.05914v2,Yes,potent(1)
0000-0002-9847-257X,Alfred Leitenstorfer,Universität Konstanz,Subcycle Quantum Electrodynamics,1970,"  Besides their stunning physical properties which are unmatched in a classical world, squeezed states of electromagnetic radiation bear advanced application potentials in quantum information systems and precision metrology, including gravitational wave detectors with unprecedented sensitivity. Since the first experiments on such nonclassical light, quantum analysis has been based on homodyning techniques and photon correlation measurements. These methods require a well-defined carrier frequency and photons contained in a quantum state need to be absorbed or amplified. They currently function in the visible to near-infrared and microwave spectral ranges. Quantum nondemolition experiments may be performed at the expense of excess fluctuations in another quadrature. Here we generate mid-infrared time-locked patterns of squeezed vacuum noise. After propagation through free space, the quantum fluctuations of the electric field are studied in the time domain by electro-optic sampling with few-femtosecond laser pulses. We directly compare the local noise amplitude to the level of bare vacuum fluctuations. This nonlinear approach operates off resonance without absorption or amplification of the field that is investigated. Subcycle intervals with noise level significantly below the pure quantum vacuum are found. Enhanced fluctuations in adjacent time segments manifest generation of highly correlated quantum radiation as a consequence of the uncertainty principle. Together with efforts in the far infrared, this work opens a window to the elementary quantum dynamics of light and matter in an energy range at the boundary between vacuum and thermal background conditions. ",https://doi.org/10.1038/nature21024,1611.06773v1,Yes,potent(1)
0000-0002-9847-257X,Alfred Leitenstorfer,Universität Konstanz,Ultrafast spontaneous spin switching in an antiferromagnet,1970,"  Owing to their high magnon frequencies, antiferromagnets are key materials for future high-speed spintronics. Picosecond switching of antiferromagnetic order has been viewed a milestone for decades and pursued only by using ultrafast external perturbations. Here, we show that picosecond spin switching occurs spontaneously due to thermal fluctuations in the antiferromagnetic orthoferrite Sm0.7Er0.3FeO3. By analysing the correlation between the pulse-to-pulse polarisation fluctuations of two femtosecond optical probes, we extract the autocorrelation of incoherent magnon fluctuations. We observe a strong enhancement of the magnon fluctuation amplitude and the coherence time around the critical temperature of the spin reorientation transition. The spectrum shows two distinct modes, one corresponding to the quasi-ferromagnetic mode and another one which has not been previously reported in pump-probe experiments. Comparison to a stochastic spin dynamics simulation reveals this new mode as smoking gun of ultrafast spontaneous spin switching within the double-well anisotropy potential. ",https://doi.org/10.1038/s41467-023-43318-8,2301.02006v1,Yes,potent(1)
0000-0002-9910-1287,Yan Zhu,Julius-Maximilians-Universität Würzburg,RawlsGCN: Towards Rawlsian Difference Principle on Graph Convolutional   Network,1970,"  Graph Convolutional Network (GCN) plays pivotal roles in many real-world applications. Despite the successes of GCN deployment, GCN often exhibits performance disparity with respect to node degrees, resulting in worse predictive accuracy for low-degree nodes. We formulate the problem of mitigating the degree-related performance disparity in GCN from the perspective of the Rawlsian difference principle, which is originated from the theory of distributive justice. Mathematically, we aim to balance the utility between low-degree nodes and high-degree nodes while minimizing the task-specific loss. Specifically, we reveal the root cause of this degree-related unfairness by analyzing the gradients of weight matrices in GCN. Guided by the gradients of weight matrices, we further propose a pre-processing method RawlsGCN-Graph and an in-processing method RawlsGCN-Grad that achieves fair predictive accuracy in low-degree nodes without modification on the GCN architecture or introduction of additional parameters. Extensive experiments on real-world graphs demonstrate the effectiveness of our proposed RawlsGCN methods in significantly reducing degree-related bias while retaining comparable overall performance. ",https://doi.org/10.1145/3485447.3512169,2202.13547v1,Yes,pivotal(1)
0000-0002-9910-1287,Yan Zhu,Julius-Maximilians-Universität Würzburg,User-Controllable Recommendation via Counterfactual Retrospective and   Prospective Explanations,1970,"  Modern recommender systems utilize users' historical behaviors to generate personalized recommendations. However, these systems often lack user controllability, leading to diminished user satisfaction and trust in the systems. Acknowledging the recent advancements in explainable recommender systems that enhance users' understanding of recommendation mechanisms, we propose leveraging these advancements to improve user controllability. In this paper, we present a user-controllable recommender system that seamlessly integrates explainability and controllability within a unified framework. By providing both retrospective and prospective explanations through counterfactual reasoning, users can customize their control over the system by interacting with these explanations.   Furthermore, we introduce and assess two attributes of controllability in recommendation systems: the complexity of controllability and the accuracy of controllability. Experimental evaluations on MovieLens and Yelp datasets substantiate the effectiveness of our proposed framework. Additionally, our experiments demonstrate that offering users control options can potentially enhance recommendation accuracy in the future. Source code and data are available at \url{https://github.com/chrisjtan/ucr}. ",Kein DOI-Link verfügbar,2308.00894v1,Yes,potent(1)
0000-0002-9910-1287,Yan Zhu,Julius-Maximilians-Universität Würzburg,Evidence of Kitaev interaction in the monolayer 1T-CrTe$_2$,1970,"  The two-dimensional 1T-CrTe$_2$ has been an attractive room-temperature van der Waals magnet which has a potential application in spintronic devices. Although it was recognized as a ferromagnetism in the past, the monolayer 1T-CrTe$_2$ was recently found to exhibit zigzag antiferromagnetism with the easy axis oriented at $70^\circ$ to the perpendicular direction of the plane. Therefore, the origin of the intricate anisotropic magnetic behavior therein is well worthy of thorough exploration. Here, by applying density functional theory with spin spiral method, we demonstrate that the Kitaev interaction, together with the single-ion anisotropy and other off-diagonal exchanges, is amenable to explain the magnetic orientation in the metallic 1T-CrTe$_2$. Moreover, the Ruderman-Kittle-Kasuya-Yosida interaction can also be extracted from the dispersion calculations, which explains the metallic behavior of 1T-CrTe$_2$. Our results demonstrate that 1T-CrTe$_2$ is potentially a rare metallic Kitaev material. ",https://doi.org/10.1103/PhysRevB.108.094433,2305.13815v2,Yes,"intricate(1), potent(2)"
0000-0002-9910-1287,Yan Zhu,Julius-Maximilians-Universität Würzburg,Novel Chern insulators with half-metallic edge states,1970,"  The central target of spintronics research is to achieve flexible control of highly efficient and spin-polarized electronic currents. Based on first-principles calculations and k-p models, we demonstrate that Cu2S/MnSe heterostructures are a novel type of Chern insulators with half-metallic chiral edge states and a very high Fermi velocity (0.87 * 10^6 m/s). The full spin-polarization of the edge states is found to be robust against the tuning of the chemical potential. Unlike the mechanisms reported previously, this heterostructure has quadratic bands with a normal band order, that is, the p/d-like band is below the s-like band. Charge transfer between the Cu2S moiety and the substrate results in variation in the occupied bands, which together with spin-orbit coupling, triggers the appearance of the topological state in the system. These results imply that numerous ordinary semiconductors with normal band order may convert into Chern insulators with half-metallic chiral edge states through this mechanism, providing a strategy to find a rich variety of materials for dissipationless, 100% spin-polarized and high-speed spintronic devices. ",https://doi.org/10.1038/am.2017.240,1901.00629v1,Yes,potent(1)
0000-0002-9911-8468,Alejandro Perez,Universität Siegen,Rare B decays Potential of SuperB,1970,  The study of rare B-decays at SuperB provides unique opportunities to understand the Standard Model and constrain new physics. It is discussed the new physics potential of the B -> K nu nu_bar and B -> K^{\ast} nu nu_bar system from the proposed SuperB experiment with 75ab-1 of data (5 nominal years of data taking). ,Kein DOI-Link verfügbar,1011.4812v1,Yes,potent(1)
0000-0002-9911-8468,Alejandro Perez,Universität Siegen,Black Holes in Loop Quantum Gravity,1970,  This is a review of the results on black hole physics in the framework of loop quantum gravity. The key feature underlying the results is the discreteness of geometric quantities at the Planck scale predicted by this approach to quantum gravity. Quantum discreteness follows directly from the canonical quantization prescription when applied to the action of general relativity that is suitable for the coupling of gravity with gauge fields and specially with fermions. Planckian discreteness and causal considerations provide the basic structure for the understanding of the thermal properties of black holes close to equilibrium. Discreteness also provides a fresh new look at more (at the moment) speculative issues such as those concerning the fate of information in black hole evaporation. The hypothesis of discreteness leads also to interesting phenomenology with possible observational consequences. The theory of loop quantum gravity is a developing program. This review reports its achievements and open questions in a pedagogical manner with an emphasis on quantum aspects of black hole physics. ,https://doi.org/10.1088/1361-6633/aa7e14,1703.09149v2,Yes,fresh(1)
0000-0002-9911-8468,Alejandro Perez,Universität Siegen,Dark energy as the weight of violating energy conservation,1970,"  In this letter, we consider the possibility of reconciling metric theories of gravitation with violation of the conservation of energy-momentum. Under some circumstances, this can be achieved in the context of unimodular gravity, and it leads to the emergence of an effective cosmological constant in Einstein's equation. We specifically investigate two potential sources of energy non-conservation ---non-unitary modifications of quantum mechanics, and phenomenological models motivated by quantum gravity theories with spacetime discreteness at the Planck scale--- and show that such locally negligible phenomena can nevertheless become relevant at the cosmological scale. ",https://doi.org/10.1103/PhysRevLett.118.021102,1604.04183v3,Yes,potent(1)
0000-0002-9911-8468,Alejandro Perez,Universität Siegen,Cosmological constraints on unimodular gravity models with diffusion,1970,"  A discrete space-time structure lying at about the Planck scale may become manifest in the form of very small violations of the conservation of the matter energy-momentum tensor. In order to include such kind of violations, forbidden within the General Relativity framework, the theory of unimodular gravity seems as the simplest option to describe the gravitational interaction. In the cosmological context, a direct consequence of such violation of energy conservation might be heuristically viewed a ""diffusion process of matter (both dark and ordinary)"" into an effective dark energy term in Einstein's equations, which leads under natural assumptions to an adequate estimate for the value of the cosmological constant. Previous works have also indicated that these kind of models might offer a natural scenario to alleviate the Hubble tension. In this work, we consider a simple model for thecosmological history including a late time occurrence of such energy violation and study the modifications of the predictions for the anisotropy and polarization of the Cosmic Microwave Background (CMB). We compare the model's predictions with recent data from the CMB, Supernovae Type Ia, cosmic chronometers and Baryon Acoustic Oscillations. The results show the potential of this type of model to alleviate the Hubble tension. ",Kein DOI-Link verfügbar,2211.07424v1,Yes,potent(1)
0000-0002-9911-8468,Alejandro Perez,Universität Siegen,Black holes as gases of punctures with a chemical potential:   Bose-Einstein condensation and logarithmic corrections to the entropy,1970,"  We study the thermodynamical properties of black holes when described as gases of indistinguishable punctures with a chemical potential. In this picture, which arises from loop quantum gravity, the black hole microstates are defined by finite families of half-integers spins coloring the punctures, and the near-horizon energy measured by quasi-local stationary observers defines the various thermodynamical ensembles. The punctures carry excitations of quantum geometry in the form of quanta of area, and the total horizon area $a_\text{H}$ is given by the sum of these microscopic contributions. We assume here that the system satisfies the Bose-Einstein statistics, and that each microstate is degenerate with a holographic degeneracy given by $\exp\big(\lambda a_\text{H}/\ell_\text{Pl}^2\big)$ and $\lambda>0$. We analyze in detail the thermodynamical properties resulting from these inputs, and in particular compute the grand canonical entropy. We explain why the requirements that the temperature be fixed to the Unruh temperature and that the chemical potential vanishes do not specify completely the semi-classical regime of large horizon area, and classify in turn what the various regimes can be. When the degeneracy saturates the holographic bound ($\lambda=1/4$), there exists a semi-classical regime in which the subleading corrections to the entropy are logarithmic. Furthermore, this regime corresponds to a Bose-Einstein condensation, in the sense that it is dominated by punctures carrying the minimal (or ground state) spin value $1/2$. ",https://doi.org/10.1103/PhysRevD.91.084005,1412.5851v1,Yes,potent(2)
0000-0003-0088-2456,John H. Stiebel,Heinrich-Heine-Universität Düsseldorf,A closer look at the chemical potential of an ideal agent system,1970,"  Models for spin systems known from statistical physics are used in econometrics in the form of agent-based models. Econophysics research in econometrics is increasingly developing general market models that describe exchange phenomena and use the chemical potential $\mu$ known from physics in the context of particle number changes. In statistical physics, equations of state are known for the chemical potential, which take into account the respective model framework and the corresponding state variables. A simple transfer of these equations of state to problems in econophysics appears difficult. To the best of our knowledge, the equation of state for the chemical potential is currently missing even for the simplest conceivable model of an ideal agent system. In this paper, this research gap is closed and the equation of state for the chemical potential is derived from the econophysical model assumptions of the ideal agent system. An interpretation of the equation of state leads to fundamental relationships that could also have been guessed, but are shown here by the theory. ",Kein DOI-Link verfügbar,2401.09233v1,Yes,potent(4)
0000-0003-0115-2500,Corinna Maier,Universität Potsdam,Reinforcement learning and Bayesian data assimilation for model-informed   precision dosing in oncology,1970,"  Model-informed precision dosing (MIPD) using therapeutic drug/biomarker monitoring offers the opportunity to significantly improve the efficacy and safety of drug therapies. Current strategies comprise model-informed dosing tables or are based on maximum a-posteriori estimates. These approaches, however, lack a quantification of uncertainty and/or consider only part of the available patient-specific information. We propose three novel approaches for MIPD employing Bayesian data assimilation (DA) and/or reinforcement learning (RL) to control neutropenia, the major dose-limiting side effect in anticancer chemotherapy. These approaches have the potential to substantially reduce the incidence of life-threatening grade 4 and subtherapeutic grade 0 neutropenia compared to existing approaches. We further show that RL allows to gain further insights by identifying patient factors that drive dose decisions. Due to its flexibility, the proposed combined DA-RL approach can easily be extended to integrate multiple endpoints or patient-reported outcomes, thereby promising important benefits for future personalized therapies. ",Kein DOI-Link verfügbar,2006.01061v1,Yes,potent(1)
0000-0003-0242-5857,Gunnar Bali,Universität Regensburg,Static-static-light baryonic potentials,1970,"  We determine doubly heavy baryonic potentials as a function of the distance between the two static sources, coupled to a light relativistic quark, for different quantum numbers. We use the variational method to compute the ground state and the first two excitations. These can be used as an input to nonrelativistic models or to NRQCD calculations of properties of doubly heavy baryons. We compare our findings with a factorization model. We employ all-to-all propagator methods, improved by an additional hopping parameter expansion and Wuppertal smearing on QCDSF configurations with two sea quark flavors. ",Kein DOI-Link verfügbar,0910.2824v1,Yes,potent(1)
0000-0003-0242-5857,Gunnar Bali,Universität Regensburg,Static-light meson-meson potentials,1970,"  We investigate potentials between pairs of static-light mesons in Nf=2 Lattice QCD, in different spin channels. The question of attraction and repulsion is particularly interesting with respect to the X(3872) charmonium state and charged candidates such as the Z+(4430). We employ the nonperturbatively improved Sheikholeslami-Wohlert fermion and the Wilson gauge actions at a lattice spacing a approx. 0.084 fm and a pseudoscalar mass mPS approx. 760 MeV. We use stochastic all-to-all propagator techniques, improved by a hopping parameter expansion. The analysis is based on the variational method, utilizing various source and sink interpolators. ",Kein DOI-Link verfügbar,1011.0571v1,Yes,potent(1)
0000-0003-0242-5857,Gunnar Bali,Universität Regensburg,Potentials between pairs of static-light mesons,1970,"  We give an update on our ongoing investigations of potentials between pairs of static-light mesons in Nf=2 Lattice QCD, in different spin and isospin channels. The question of attraction and repulsion is particularly interesting with respect to the X(3872) charmonium state and charged candidates such as the Z+(4430). We employ the nonperturbatively improved Sheikholeslami-Wohlert fermion and the Wilson gauge actions at two lattice spacings a approx. 0.084 fm and a approx. 0.077 fm with a pseudoscalar mass of mPS approx. 770 MeV and mPS approx. 400 MeV respectively. We use stochastic all-to-all propagator techniques, improved by a hopping parameter expansion. The analysis is based on the variational method, utilizing various source and sink interpolators. ",Kein DOI-Link verfügbar,1111.2222v1,Yes,potent(1)
0000-0003-0262-2519,Robin Mieling,Technische Universität Hamburg,Diffusion Models with Ensembled Structure-Based Anomaly Scoring for   Unsupervised Anomaly Detection,1970,"  Supervised deep learning techniques show promise in medical image analysis. However, they require comprehensive annotated data sets, which poses challenges, particularly for rare diseases. Consequently, unsupervised anomaly detection (UAD) emerges as a viable alternative for pathology segmentation, as only healthy data is required for training. However, recent UAD anomaly scoring functions often focus on intensity only and neglect structural differences, which impedes the segmentation performance. This work investigates the potential of Structural Similarity (SSIM) to bridge this gap. SSIM captures both intensity and structural disparities and can be advantageous over the classical $l1$ error. However, we show that there is more than one optimal kernel size for the SSIM calculation for different pathologies. Therefore, we investigate an adaptive ensembling strategy for various kernel sizes to offer a more pathology-agnostic scoring mechanism. We demonstrate that this ensembling strategy can enhance the performance of DMs and mitigate the sensitivity to different kernel sizes across varying pathologies, highlighting its promise for brain MRI anomaly detection. ",Kein DOI-Link verfügbar,2403.14262v1,Yes,potent(1)
0000-0003-0262-2519,Robin Mieling,Technische Universität Hamburg,Guided Reconstruction with Conditioned Diffusion Models for Unsupervised   Anomaly Detection in Brain MRIs,1970,"  Unsupervised anomaly detection in Brain MRIs aims to identify abnormalities as outliers from a healthy training distribution. Reconstruction-based approaches that use generative models to learn to reconstruct healthy brain anatomy are commonly used for this task. Diffusion models are an emerging class of deep generative models that show great potential regarding reconstruction fidelity. However, they face challenges in preserving intensity characteristics in the reconstructed images, limiting their performance in anomaly detection. To address this challenge, we propose to condition the denoising mechanism of diffusion models with additional information about the image to reconstruct coming from a latent representation of the noise-free input image. This conditioning enables high-fidelity reconstruction of healthy brain structures while aligning local intensity characteristics of input-reconstruction pairs. We evaluate our method's reconstruction quality, domain adaptation features and finally segmentation performance on publicly available data sets with various pathologies. Using our proposed conditioning mechanism we can reduce the false-positive predictions and enable a more precise delineation of anomalies which significantly enhances the anomaly detection performance compared to established state-of-the-art approaches to unsupervised anomaly detection in brain MRI. Furthermore, our approach shows promise in domain adaptation across different MRI acquisitions and simulated contrasts, a crucial property of general anomaly detection methods. ",Kein DOI-Link verfügbar,2312.04215v1,Yes,potent(1)
0000-0003-0272-3088,Thomas Kupfer,Julius-Maximilians-Universität Würzburg,Detailed follow up studies of three ultracompact sdB binaries,1970,"  We present follow-up studies of three ultracompact hot subdwarf binaries. Using data from the Zwicky Transient Facility, we find orbital periods of 33.6, 37.3, and 36.9 minutes for ZTF 1946+3203, ZTF 0640+1738, and ZTF 0643+0318 respectively. The light curves show ellipsoidal variability of the hot subdwarf star with potential eclipses of an accretion disc. Phase-resolved spectroscopic observations with Keck were used to measure a radial velocity curve and atmospheric parameters of the hot subdwarf stars. ZTF J0643 shows evidence of accretion disc emission lines in the average spectrum. Combining light curve and spectroscopic fits will allow us to measure precise system properties such as masses, to determine the evolutionary history and future evolution of the system. ",Kein DOI-Link verfügbar,2303.05523v1,Yes,potent(1)
0000-0003-0272-3088,Thomas Kupfer,Julius-Maximilians-Universität Würzburg,Multi-messenger parameter inference of gravitational-wave and   electromagnetic observations of white dwarf binaries,1970,"  The upcoming Laser Interferometer Space Antenna (LISA) will detect a large gravitational-wave foreground of Galactic white dwarf binaries. These sources are exceptional for their probable detection at electromagnetic wavelengths, some long before LISA flies. Studies in both gravitational and electromagnetic waves will yield strong constraints on system parameters not achievable through measurements of one messenger alone. In this work, we present a Bayesian inference pipeline and simulation suite in which we study potential constraints on binaries in a variety of configurations. We show how using LISA detections and parameter estimation can significantly improve constraints on system parameters when used as a prior for the electromagnetic analyses. We also provide rules of thumb for how current measurements will benefit from LISA measurements in the future. ",Kein DOI-Link verfügbar,2112.00145v2,Yes,potent(1)
0000-0003-0272-3088,Thomas Kupfer,Julius-Maximilians-Universität Würzburg,The ELM Survey South. II. Two dozen new low mass white dwarf binaries,1970,"  We present the results from our ongoing spectroscopic survey targeting low mass white dwarf binaries, focusing on the southern sky. We used a Gaia DR2 and eDR3 based selection and identified 28 new binaries, including 19 new extremely low mass white dwarfs, one short period, likely eclipsing, DABZ, and two potential LISA binaries. We present orbital and atmospheric parameters for each new binary based on our spectroscopic follow-up.   Four of our new binaries show periodic photometric variability in the TESS 2-minute cadence data, including one new eclipsing double-lined spectroscopic binary. Three others show periodic photometric variability in ZTF, including one new eclipsing binary. We provide estimates for the inclinations and scaled component radii for these ZTF variables, based on light curve modeling to our high-speed photometric follow-up observations.   Our observations have increased the sample of ELM Survey binaries identified in the southern sky to 41, an increase of 64%. Future time domain surveys, such as BlackGEM and the Vera C. Rubin Observatory Legacy Survey of Space and Time, will efficiently identify the photometric variables in the southern sky and significantly increase the population of southern sky low mass white dwarf binaries, leading to a more complete all-sky population of these systems. ",https://doi.org/10.3847/1538-4357/acd187,2305.03079v1,Yes,potent(1)
0000-0003-0272-3088,Thomas Kupfer,Julius-Maximilians-Universität Würzburg,ZTFJ0038+2030: a long period eclipsing white dwarf and a substellar   companion,1970,"  In a search for eclipsing white dwarfs using the Zwicky Transient Facility lightcurves, we identified a deep eclipsing white dwarf with a dark, substellar companion. The lack of an infrared excess and an orbital period of 10 hours made this a potential exoplanet candidate. We obtained high-speed photometry and radial velocity measurements to characterize the system. The white dwarf has a mass of $0.50\pm0.02\,\mathrm{M_{\odot}}$ and a temperature of $10900\pm200\,$K. The companion has a mass of $0.059\pm0.004\,\mathrm{M_{\odot}}$ and a small radius of $0.0783\pm0.0013\,\mathrm{R_{\odot}}$. It is one of the smallest transiting brown dwarfs known and likely old, $\gtrsim 8\,$Gyr. The ZTF discovery efficiency of substellar objects transiting white dwarfs is limited by the number of epochs and as ZTF continues to collect data we expect to find more of these systems. This will allow us to measure period and mass distributions and allows us to understand the formation channels of white dwarfs with substellar companions. ",https://doi.org/10.3847/2041-8213/ac22b7,2105.08687v1,Yes,potent(1)
0000-0003-0272-3088,Thomas Kupfer,Julius-Maximilians-Universität Würzburg,EVR-CB-004: An Inflated Hot Subdwarf O star + Unseen WD Companion in a   Compact Binary Discovered with the Evryscope,1970,"  We present the discovery of EVR-CB-004, a close binary with a remnant stellar core and an unseen white dwarf companion. The analysis in this work reveals the primary is potentially an inflated hot subdwarf (sdO) and more likely is a rarer post-blue horizontal branch (post-BHB) star. Post-BHBs are the short-lived shell-burning final stage of a blue horizontal star or hot subdwarf before transitioning to a WD. This object was discovered using Evryscope photometric data in a southern-all-sky hot subdwarf variability survey. The photometric light curve for EVR-CB-004 shows multi-component variability from ellipsoidal deformation of the primary and from Doppler boosting as well as gravitational limb darkening. EVR-CB-004 is one of just a handful of known systems, and has a long period (6.08426 hours) and large amplitude ellipsoidal modulation (16.0 $\%$ change in brightness from maximum to minimum) for these extremely close binary systems, while the properties of the primary make it a truly unique system. EVR-CB-004 also shows a peculiar low-amplitude (less than $1\%$) sinusoidal light curve variation with a period that is a 1/3 resonance of the binary period. We tentatively identify this additional variation source as a tidally-induced resonant pulsation, and we suggest followup observations that could verify this interpretation. From the evolutionary state of the system, its components, and its mass fraction, EVR-CB-004 is a strong merger candidate to form a single high-mass ($\approx1.2M_{\odot}$) WD. EVR-CB-004 offers a glimpse into a brief phase of a remnant core evolution and secondary variation, not seen before in a compact binary. ",https://doi.org/10.3847/1538-4357/abb5b2,2009.06074v1,Yes,potent(1)
0000-0003-0272-3088,Thomas Kupfer,Julius-Maximilians-Universität Würzburg,"EVR-CB-001: An evolving, progenitor, white dwarf compact binary   discovered with the Evryscope",1970,"  We present EVR-CB-001, the discovery of a compact binary with an extremely low mass ($.21 \pm 0.05 M_{\odot}$) helium core white dwarf progenitor (pre-He WD) and an unseen low mass ($.32 \pm 0.06 M_{\odot}$) helium white dwarf (He WD) companion. He WDs are thought to evolve from the remnant helium-rich core of a main-sequence star stripped during the giant phase by a close companion. Low mass He WDs are exotic objects (only about .2$\%$ of WDs are thought to be less than .3 $M_{\odot}$), and are expected to be found in compact binaries. Pre-He WDs are even rarer, and occupy the intermediate phase after the core is stripped, but before the star becomes a fully degenerate WD and with a larger radius ($\approx .2 R_{\odot}$) than a typical WD. The primary component of EVR-CB-001 (the pre-He WD) was originally thought to be a hot subdwarf (sdB) star from its blue color and under-luminous magnitude, characteristic of sdBs. The mass, temperature ($T_{\rm eff}=18,500 \pm 500 K$), and surface gravity ($\log(g)=4.96 \pm 0.04$) solutions from this work are lower than values for typical hot subdwarfs. The primary is likely to be a post-RGB, pre-He WD contracting into a He WD, and at a stage that places it nearest to sdBs on color-magnitude and $T_{\rm eff}$-$\log(g)$ diagrams. EVR-CB-001 is expected to evolve into a fully double degenerate, compact system that should spin down and potentially evolve into a single hot subdwarf star. Single hot subdwarfs are observed, but progenitor systems have been elusive. ",Kein DOI-Link verfügbar,1909.02012v2,Yes,potent(1)
0000-0003-0289-1938,Johann Gross,Universität Stuttgart,Computational and experimental analysis of the impact of a sphere on a   beam and the resulting modal energy distribution,1970,"  We consider the common problem setting of an elastic sphere impacting on a flexible beam. In contrast to previous studies, we analyze the modal energy distribution induced by the impact, having in mind the particular application of impact vibration absorbers. Also, the beam is analyzed in the clamped-clamped configuration, in addition to the free-free configuration usually considered. We demonstrate that the designed test rig permits to obtain well-repeatable measurements. The measurements are confronted with predictions obtained using two different approaches, state-of-the-art Finite Element Analysis and a recently developed computational approach involving a reduced-order model. The innovative aspect of the latter approach is to achieve a massless contact boundary using component mode synthesis, which reduces the mathematical model order and numerical oscillations. We show that the novel computational approach reduces the numerical effort by 3-4 orders of magnitude compared to state-of-the-art Finite Element Analysis, without compromising the excellent agreement with the measurements. ",https://doi.org/10.1016/j.ymssp.2022.109407,2207.00795v1,Yes,innovative(1)
0000-0003-0302-3745,Simon Tewes,Ruhr Universität Bochum,Validating Properties of RIS Channel Models with Prototypical   Measurements,1970,"  The integration of Reconfigurable Intelligent Surfaces (RIS) holds substantial promise for revolutionizing 6G wireless networks, offering unprecedented capabilities for real-time control over communication environments. However, determining optimal RIS configurations remains a pivotal challenge, necessitating the development of accurate analytical models. While theoretically derived models provide valuable insights, their potentially idealistic assumptions do not always translate well to practical measurements. This becomes especially problematic in mobile environments, where signals arrive from various directions. This study deploys an RIS prototype on a turntable, capturing the RIS channels' dependency on the angle of incoming signals. The difference between theory and practice is bridged by refining a model with angle-dependent reflection coefficients. The improved model exhibits a significantly closer alignment with real-world measurements. Analysis of the reflect coefficients reveals that non-perpendicular receiver angles can induce an additional attenuation of up to -14.5dB. Additionally, we note significant phase shift deviations, varying for each reflect element. ",Kein DOI-Link verfügbar,2402.00003v1,Yes,"pivotal(1), potent(1)"
0000-0003-0329-5740,Lucas Rickert,Technische Universität Berlin,Tools for the Performance Optimization of Single-Photon Quantum Key   Distribution,1970,"  Quantum light sources emitting triggered single photons or entangled photon pairs have the potential to boost the performance of quantum key distribution (QKD) systems. Proof-of-principle experiments affirmed these prospects, but further efforts are necessary to push this field beyond its current status. In this work, we show that temporal filtering of single-photon pulses enables a performance optimization of QKD systems implemented with realistic quantum light sources, both in experiment and simulations. To this end, we analyze the influence of temporal filtering of sub-Poissonian single-photon pulses on the expected secret key fraction, the quantum bit error ratio, and the tolerable channel losses. For this purpose, we developed a basic QKD testbed comprising a triggered solid-state single-photon source and a receiver module designed for four-state polarization coding via the BB84 protocol. Furthermore, we demonstrate real-time security monitoring by analyzing the photon statistics, in terms of $g^{(2)}(0)$, inside the quantum channel by correlating the photon flux recorded at the four ports of our receiver. Our findings are useful for the certification of QKD and can be applied and further extended for the optimization of various implementations of quantum communication based on sub-Poissonian quantum light sources, including measurement-device-independent schemes of QKD as well as quantum repeaters. Our work represents an important contribution towards the development of QKD-secured communication networks based on quantum light sources. ",https://doi.org/10.1038/s41534-020-0262-8,1908.02672v2,Yes,potent(1)
0000-0003-0341-0446,Dieter Mueller,Universität Leipzig,Accessing GPDs from experiment --- potential of a high-luminosity EIC   ---,1970,"  We discuss modeling of generalized parton distributions (GPDs), their access from present experiments, and the phenomenological potential of an electron-ion collider. In particular, we present a comparison of phenomenological models of GPD H, extracted from hard exclusive meson and photon production. Specific emphasis is given to the utilization of evolution effects at moderate x_Bj in a future high-luminosity experiment within a larger Q^2 lever arm. ",Kein DOI-Link verfügbar,1105.0899v1,Yes,potent(1)
0000-0003-0373-9655,Henning Krause,Universität Bielefeld,The frame of smashing tensor-ideals,1970,"  Given a tensor-triangulated category $T$, we prove that every flat tensor-idempotent in the module category over $T^c$ (the compacts) comes from a unique smashing ideal in $T$. We deduce that the lattice of smashing ideals forms a frame. ",Kein DOI-Link verfügbar,1701.05937v2,Yes,potent(1)
0000-0003-0373-9655,Henning Krause,Universität Bielefeld,Stratification and duality for unipotent finite supergroup schemes,1970,"  We survey some methods developed in a series of papers, for classifying localising subcategories of tensor triangulated categories. We illustrate these methods by proving a new theorem, providing such a classification in the case of the stable module category of a unipotent finite supergroup scheme. ",Kein DOI-Link verfügbar,2010.10430v1,Yes,potent(1)
0000-0003-0373-9655,Henning Krause,Universität Bielefeld,Detecting nilpotence and projectivity over finite unipotent supergroup   schemes,1970,"  This work concerns the representation theory and cohomology of a finite unipotent supergroup scheme $G$ over a perfect field $k$ of positive characteristic $p\ge 3$. It is proved that an element $x$ in the cohomology of $G$ is nilpotent if and only if for every extension field $K$ of $k$ and every elementary sub-supergroup scheme $E\subseteq G_K$, the restriction of $x_K$ to $E$ is nilpotent. It is also shown that a $kG$-module $M$ is projective if and only if for every extension field $K$ of $k$ and every elementary sub-supergroup scheme $E\subseteq G_K$, the restriction of $M_K$ to $E$ is projective. The statements are motivated by, and are analogues of, similar results for finite groups and finite group schemes, but the structure of elementary supergroups schemes necessary for detection is more complicated than in either of these cases. One application is a detection theorem for the nilpotence of cohomology, and projectivity of modules, over finite dimensional Hopf subalgebras of the Steenrod algebra. ",Kein DOI-Link verfügbar,1901.08273v2,Yes,potent(3)
0000-0003-0433-4529,Henning Dathe,Georg-August-Universität Göttingen,Benchmarking the Impact of Noise on Deep Learning-based Classification   of Atrial Fibrillation in 12-Lead ECG,1970,"  Electrocardiography analysis is widely used in various clinical applications and Deep Learning models for classification tasks are currently in the focus of research. Due to their data-driven character, they bear the potential to handle signal noise efficiently, but its influence on the accuracy of these methods is still unclear. Therefore, we benchmark the influence of four types of noise on the accuracy of a Deep Learning-based method for atrial fibrillation detection in 12-lead electrocardiograms. We use a subset of a publicly available dataset (PTBXL) and use the metadata provided by human experts regarding noise for assigning a signal quality to each electrocardiogram. Furthermore, we compute a quantitative signal-to-noise ratio for each electrocardiogram. We analyze the accuracy of the Deep Learning model with respect to both metrics and observe that the method can robustly identify atrial fibrillation, even in cases signals are labelled by human experts as being noisy on multiple leads. False positive and false negative rates are slightly worse for data being labelled as noisy. Interestingly, data annotated as showing baseline drift noise results in an accuracy very similar to data without. We conclude that the issue of processing noisy electrocardiography data can be addressed successfully by Deep Learning methods that might not need preprocessing as many conventional methods do. ",https://doi.org/10.3233/SHTI230321,2303.13915v1,Yes,potent(1)
0000-0003-0577-8463,Martin Kasparick,Universität Rostock,Convergence of Manufacturing and Networking in Future Factories,1970,"  The roll out of 5G has been mainly characterized by its distinct support for vertical industries, especially manufacturing. Leveraging synergies among these two worlds, namely production facilities and network systems, is a fundamental aspect to enable flexibility and economic viability in future factories. This work highlights the potential for intelligent networking and advanced machine learning-based solutions in 5G-and-beyond systems in the context of Industry 4.0 and flexible manufacturing. The intersection thereof allows to create versatile machines and dynamic communication networks that can adapt to changes in the manufacturing process, factory layout and communication environment, supporting real-time interaction between humans, machines, and systems. We present a vision and corresponding framework by introducing the network-aware and production-aware principles, outlining results achieved in this context and summarizing them into three key use cases. Finally, we discuss a selection of remaining open challenges in private networks as well as give an outlook on future 6G research directions. ",Kein DOI-Link verfügbar,2312.08708v1,Yes,"versatile(1), potent(1)"
0000-0003-0577-8463,Martin Kasparick,Universität Rostock,Leveraging Machine Learning for Industrial Wireless Communications,1970,"  Two main trends characterize today's communication landscape and are finding their way into industrial facilities: the rollout of 5G with its distinct support for vertical industries and the increasing success of machine learning (ML). The combination of those two technologies open the doors to many exciting industrial applications and its impact is expected to rapidly increase in the coming years, given the abundant data growth and the availability of powerful edge computers in production facilities. Unlike most previous work that has considered the application of 5G and ML in industrial environment separately, this paper highlights the potential and synergies that result from combining them. The overall vision presented here generates from the KICK project, a collaboration of several partners from the manufacturing and communication industry as well as research institutes. This unprecedented blend of 5G and ML expertise creates a unique perspective on ML-supported industrial communications and their role in facilitating industrial automation. The paper identifies key open industrial challenges that are grouped into four use cases: wireless connectivity and edge-cloud integration, flexibility in network reconfiguration, dynamicity of heterogeneous network services, and mobility of robots and vehicles. Moreover, the paper provides insights into the advantages of ML-based industrial communications and discusses current challenges of data acquisition in real systems. ",Kein DOI-Link verfügbar,2105.02051v1,Yes,potent(1)
0000-0003-0577-8463,Martin Kasparick,Universität Rostock,Berlin V2X: A Machine Learning Dataset from Multiple Vehicles and Radio   Access Technologies,1970,"  The evolution of wireless communications into 6G and beyond is expected to rely on new machine learning (ML)-based capabilities. These can enable proactive decisions and actions from wireless-network components to sustain quality-of-service (QoS) and user experience. Moreover, new use cases in the area of vehicular and industrial communications will emerge. Specifically in the area of vehicle communication, vehicle-to-everything (V2X) schemes will benefit strongly from such advances. With this in mind, we have conducted a detailed measurement campaign that paves the way to a plethora of diverse ML-based studies. The resulting datasets offer GPS-located wireless measurements across diverse urban environments for both cellular (with two different operators) and sidelink radio access technologies, thus enabling a variety of different studies towards V2X. The datasets are labeled and sampled with a high time resolution. Furthermore, we make the data publicly available with all the necessary information to support the onboarding of new researchers. We provide an initial analysis of the data showing some of the challenges that ML needs to overcome and the features that ML can leverage, as well as some hints at potential research studies. ",https://doi.org/10.1109/VTC2023-Spring57618.2023.10200750,2212.10343v3,Yes,potent(1)
0000-0003-0588-3212,Tim Seidelmann,Universität Bayreuth,Time-dependent switching of the photon entanglement type using a driven   quantum emitter-cavity system,1970,"  The cascaded decay in a four-level quantum emitter is a well established mechanism to generate polarization entangled photon pairs, the building blocks of many applications in quantum technologies. The four most prominent maximally entangled photon pair states are the Bell states. In a typical experiment based on an undriven emitter only one type of Bell state entanglement can be observed in a given polarization basis. Other types of Bell state entanglement in the same basis can be created by continuously driving the system by an external laser. In this work we propose a protocol for time-dependent entanglement switching in a four-level quantum emitter--cavity system that can be operated by changing the external driving strength. By selecting different two-photon resonances between the laser-dressed states, we can actively switch back and forth between the different types of Bell state entanglement in the same basis as well as between entangled and nonentangled photon pairs. This remarkable feature demonstrates the possibility to achieve a controlled, time-dependent manipulation of the entanglement type that could be used in many innovative applications. ",https://doi.org/10.1063/5.0045377,2104.00643v1,Yes,innovative(1)
0000-0003-0588-3212,Tim Seidelmann,Universität Bayreuth,Swing-up of quantum emitter population using detuned pulses,1970,"  The controlled preparation of the excited state in a quantum emitter is a prerequisite for its usage as single-photon sources - a key building block for quantum technologies. In this paper we propose a coherent excitation scheme using off-resonant pulses. In the usual Rabi scheme, these pulses would not lead to a significant occupation. This is overcome by using a frequency modulated pulse to swing up the excited state population. The same effect can be obtained using two pulses with different strong detunings of the same sign. We theoretically analyze the applicability of the scheme to a semiconductor quantum dot. In this case the excitation is several meV below the band gap, i.e., far away from the detection frequency allowing for easy spectral filtering, and does not rely on any auxiliary particles such as phonons. Our scheme has the potential to lead to the generation of close-to-ideal photons. ",https://doi.org/10.1103/PRXQuantum.2.040354,2111.10236v1,Yes,potent(1)
0000-0003-0588-3212,Tim Seidelmann,Universität Bayreuth,Theory of time-bin entangled photons from quantum emitters,1970,"  Entangled photon pairs form the foundation for many applications in the realm of quantum communication. For fiber-optic transfer of entangled photon pairs, time-bin encoding can potentially offer an improved stability compared to polarization encoded qubits. Here, we lay the theoretical foundations to describe the measurement of time-bin entangled photons. We derive multi-time correlation functions of the time-bin encoded photon pairs, corresponding to quantum state tomographic measurements. Our theory can be the starting point to extend the simulations to include all kinds of loss or decoherence effects that apply in a specific quantum system for realistic simulation for time-bin entanglement from quantum emitters. ",Kein DOI-Link verfügbar,2404.08348v2,Yes,potent(1)
0000-0003-0640-1801,Kai Hebeler,TU Darmstadt,Dense matter with eXTP,1970,"  In this White Paper we present the potential of the Enhanced X-ray Timing and Polarimetry (eXTP) mission for determining the nature of dense matter; neutron star cores host an extreme density regime which cannot be replicated in a terrestrial laboratory. The tightest statistical constraints on the dense matter equation of state will come from pulse profile modelling of accretion-powered pulsars, burst oscillation sources, and rotation-powered pulsars. Additional constraints will derive from spin measurements, burst spectra, and properties of the accretion flows in the vicinity of the neutron star. Under development by an international Consortium led by the Institute of High Energy Physics of the Chinese Academy of Science, the eXTP mission is expected to be launched in the mid 2020s. ",https://doi.org/10.1007/s11433-017-9188-4,1812.04021v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Liquid Phase 3D Printing for Quickly Manufacturing Metal Objects with   Low Melting Point Alloy Ink,1970,"  Conventional 3D printings are generally time-consuming and printable metal inks are rather limited. From an alternative way, we proposed a liquid phase 3D printing for quickly making metal objects. Through introducing metal alloys whose melting point is slightly above room temperature as printing inks, several representative structures spanning from one, two and three dimension to more complex patterns were demonstrated to be quickly fabricated. Compared with the air cooling in a conventional 3D printing, the liquid-phase-manufacturing offers a much higher cooling rate and thus significantly improves the speed in fabricating metal objects. This unique strategy also efficiently prevents the liquid metal inks from air oxidation which is hard to avoid otherwise in an ordinary 3D printing. Several key physical factors (like properties of the cooling fluid, injection speed and needle diameter, types and properties of the printing ink, etc.) were disclosed which would evidently affect the printing quality. In addition, a basic route to make future liquid phase 3D printer incorporated with both syringe pump and needle arrays was also suggested. The liquid phase 3D printing method, which owns potential values not available in a conventional modality, opens an efficient way for quickly making metal objects in the coming time. ",Kein DOI-Link verfügbar,1405.0199v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Quantum parameter estimation with optimal control,1970,"  A pivotal task in quantum metrology, and quantum parameter estimation in general, is to de- sign schemes that achieve the highest precision with given resources. Standard models of quantum metrology usually assume the dynamics is fixed, the highest precision is achieved by preparing the optimal probe states and performing optimal measurements. However, in many practical experimental settings, additional controls are usually available to alter the dynamics. Here we propose to use optimal control methods for further improvement on the precision limit of quantum parameter estimation. We show that by exploring the additional degree of freedom offered by the controls higher precision limit can be achieved. In particular we show that the precision limit under the controlled schemes can go beyond the constraints put by the coherent time, which is in contrast to the standard scheme where the precision limit is always bounded by the coherent time. ",https://doi.org/10.1103/PhysRevA.96.012117,1604.04856v3,Yes,pivotal(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Operation of BGO with SiPM readout at dry ice and liquid nitrogen   temperatures,1970,"  The light yield and decay constant of BGO were measured at both dry ice and liquid nitrogen temperatures using two SiPMs directly coupled to a $6\times6\times6$ cm$^2$ cubic BGO crystal. With the measured light yield (5.2$\pm$0.3 PE/keV at dry ice temperature and 10.5$\pm$0.4 PE/keV at liquid nitrogen temperature) and decay constants, potential applications of BGO in ToF-PET and SPECT were discussed. ",Kein DOI-Link verfügbar,2403.09501v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Liquid Metal Enabled Droplet Circuits,1970,"  Conventional electrical circuits are generally rigid in their components and working styles which are not flexible and stretchable. From an alternative, liquid metal based soft electronics is offering important opportunities for innovating modern bioelectronics and electrical engineering. However, its running in wet environments such as aqueous solution, biological tissues or allied subjects still encounters many technical challenges. Here, we proposed a new conceptual electrical circuit, termed as droplet circuits, to fulfill the special needs as raised in the above mentioned areas. Such unconventional circuits are immersed in solution and composed of liquid metal droplets, conductive ions or wires such as carbon nanotubes. With specifically designed topological or directional structures/patterns, the liquid metal droplets composing the circuit can be discretely existing and disconnected from each other, while achieving the function of electron transport through conductive routes or quantum tunneling effect. The conductive wires serve as the electron transfer stations when the distance between two separate liquid metal droplets is far beyond than that quantum tunneling effects can support. The unique advantage of the current droplet circuit lies in that it allows parallel electron transport, high flexibility, self-healing, regulativity and multi-point connectivity, without needing to worry about circuit break. This would extend the category of classical electrical circuits into the newly emerging areas like realizing room temperature quantum computing, making brain-like intelligence or nerve-machine interface electronics etc. The mechanisms and potential scientific issues of the droplet circuits are interpreted. Future prospects along this direction are outlined. ",Kein DOI-Link verfügbar,1803.10511v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Tensor networks for unsupervised machine learning,1970,"  Modeling the joint distribution of high-dimensional data is a central task in unsupervised machine learning. In recent years, many interests have been attracted to developing learning models based on tensor networks, which have the advantages of a principle understanding of the expressive power using entanglement properties, and as a bridge connecting classical computation and quantum computation. Despite the great potential, however, existing tensor network models for unsupervised machine learning only work as a proof of principle, as their performance is much worse than the standard models such as restricted Boltzmann machines and neural networks. In this Letter, we present autoregressive matrix product states (AMPS), a tensor network model combining matrix product states from quantum many-body physics and autoregressive modeling from machine learning. Our model enjoys the exact calculation of normalized probability and unbiased sampling. We demonstrate the performance of our model using two applications, generative modeling on synthetic and real-world data, and reinforcement learning in statistical physics. Using extensive numerical experiments, we show that the proposed model significantly outperforms the existing tensor network models and the restricted Boltzmann machines, and is competitive with state-of-the-art neural network models. ",https://doi.org/10.1103/PhysRevE.107.L012103,2106.12974v2,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,HIRE: Distilling High-order Relational Knowledge From Heterogeneous   Graph Neural Networks,1970,"  Researchers have recently proposed plenty of heterogeneous graph neural networks (HGNNs) due to the ubiquity of heterogeneous graphs in both academic and industrial areas. Instead of pursuing a more powerful HGNN model, in this paper, we are interested in devising a versatile plug-and-play module, which accounts for distilling relational knowledge from pre-trained HGNNs.   To the best of our knowledge, we are the first to propose a HIgh-order RElational (HIRE) knowledge distillation framework on heterogeneous graphs, which can significantly boost the prediction performance regardless of model architectures of HGNNs. Concretely, our HIRE framework initially performs first-order node-level knowledge distillation, which encodes the semantics of the teacher HGNN with its prediction logits. Meanwhile, the second-order relation-level knowledge distillation imitates the relational correlation between node embeddings of different types generated by the teacher HGNN.   Extensive experiments on various popular HGNNs models and three real-world heterogeneous graphs demonstrate that our method obtains consistent and considerable performance enhancement, proving its effectiveness and generalization ability. ",Kein DOI-Link verfügbar,2207.11887v1,Yes,versatile(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Mechanical Therapy as a Potential Green Way to Attack Cancer Disease,1970,"  Mechanical force is tightly connected to human health status, and the occurrence of disease can generally be ascribed to certain loss of force balance. However, the role of mechanical approaches in tumor therapy is largely neglected, while the currently available cancer prevention and treatment methods are generally either expensive or just cause too much side effect. In this article, we present a systematic interpretation on a promising strategy which was termed here as Mechanical Therapy for the first time based on the fact that mechanical force closely accompanies the whole life (growth and death) of a cell, and plays a crucial role in biological functions. In order to mold the mechanical force as a practical tool for cancer therapy, we expound the effects of the mechanical force related to the tumors from molecule to tissue level and evaluate its feasibility for treatment purpose. It can be conceived that given enough investigations, the mechanical therapy may generate big potential to open new windows for cancer prevention, relieving or even destroying if well administrated. As an easy going and convenient method, a systematic and thorough study of mechanical therapy may clarify more options for future clinical practices. Besides, when patients encounter various forces in daily life, they can at least identify the good or bad forces for a better and healthy life style based on the mechanisms thus disclosed. ",Kein DOI-Link verfügbar,1309.4893v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,"HPGe detector field calculation methods demonstrated with an educational   program, GeFiCa",1970,"  A review of tools and methods to calculate electrostatic potentials and fields inside high-purity germanium detectors in various configurations is given. The methods are illustrated concretely with a new educational program named GeFiCa - Germanium detector Field Calculator. Demonstrated in GeFiCa are generic numerical calculations based on the successive over-relaxation method as well as analytic ones whenever simplification is possible due to highly symmetric detector geometries. GeFiCa is written in C++, and provided as an extension to the CERN ROOT libraries widely used in the particle physics community. Calculation codes for individual detectors, provided as ROOT macros and python scripts, are distributed along with the GeFiCa core library, serving as both examples showing the usage of GeFiCa and starting points for customized calculations. They can be run without compilation in a ROOT interactive session or directly from a Linux shell. The numerical results are saved in a ROOT tree, making full use of the I/O optimization and plotting functionalities in ROOT. The speed and precision of the calculation are comparable to other commonly used packages, which qualifies GeFiCa as a scientific research tool. However, the main focus of GeFiCa is to clearly explain and demonstrate the analytic and numeric methods to solve Poisson's equation, practical coding considerations and visualization methods, with intensive documentation and example macros. It serves as a one-stop resource for people who want to understand the operating mechanism of such a package under the hood. ",https://doi.org/10.1140/epjc/s10052-020-7786-0,2001.02762v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,DECN: Automated Evolutionary Algorithms via Evolution Inspired Deep   Convolution Network,1970,"  Evolutionary algorithms (EAs) have emerged as a powerful framework for optimization, especially for black-box optimization. This paper first focuses on automated EA: Automated EA exploits structure in the problem of interest to automatically generate update rules (optimization strategies) for generating and selecting potential solutions so that it can move a random population near the optimal solution. However, current EAs cannot achieve this goal due to the poor representation of the optimization strategy and the weak interaction between the optimization strategy and the target task. We design a deep evolutionary convolution network (DECN) to realize the move from hand-designed EAs to automated EAs without manual interventions. DECN has high adaptability to the target task and can obtain better solutions with less computational cost. DECN is also able to effectively utilize the low-fidelity information of the target task to form an efficient optimization strategy. The experiments on nine synthetics and two real-world cases show the advantages of learned optimization strategies over the state-of-the-art human-designed and meta-learning EA baselines. In addition, due to the tensorization of the operations, DECN is friendly to the acceleration provided by GPUs and runs 102 times faster than EA. ",Kein DOI-Link verfügbar,2304.09599v3,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Delivery of Liquid Metal to the Target Vessels as Vascular Embolic Agent   to Starve Diseased Tissues or Tumors to Death,1970,"  Tumor growth relies heavily on the continuous blood and nutrients supply. Theoretically, it is an ideal therapeutic way of killing tumor by only vascular embolization. However, most of the existing vascular embolic agents are still rather insufficient to fulfill the real clinical need due to the reasons like: incomplete filling of target vasculature, being easily washed away by blood or body solution, or just producing toxicity to tissues. Here from an alternative way, the body temperature liquid metal, a kind of soft and highly compliant material, was proposed for the first time as blood vessel embolization agent for tumor physical therapy. With its unique capability of easy phase transition between liquid and solid state and sub-cooling behavior, such material can be fluently injected into the tiny vessels including ending capillaries and fully block them. The in vitro cytotoxicity experiments were performed which showed that treating localized diseased tissues through liquid metal embolic agent is acceptable. Endowed with a high density, the liquid metal-filled vessels are highly visible under the CT scan, which offers the potential of diagnosis-treatment integration. To further demonstrate the new conceptual liquid metal vascular embolization therapy, several experiments on in vivo vasculatures of rabbit ears and mouse tails were performed to provide evidences of destroying the targeted tissues. To interpret the liquid metal starvation therapy effects, a theoretical model was established to simulate the tumor growth with zero, partial or complete filling of the metal agent inside the vessels. All the results support that, given appropriate administration, the liquid metal embolization is able to destruct the target regions and might starve the tumors to death through a relatively easy way. This study lays the foundation of a promising tumor starvation therapy in the coming time. ",Kein DOI-Link verfügbar,1408.0989v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Softening Theory of Matter Tuning Atomic Border to Make Soft Materials,1970,"  Regulation of material softness has both theoretical and practical significances due to irreplaceable applications of soft matter in rather diverse areas. This article is dedicated to draft a theoretical category on interpreting the mechanisms lying behind all soft matters, which can be termed as Softening Theory. A technical strategy with generalized purpose was proposed for softening desired matter, i.e. the melting point of matter can be significantly reduced through tuning its interior boundaries in atomic level. This theory accords well with the classical nuclear droplet model that treats the nucleus as a droplet which had successfully explained many phenomena. It also explained the experimental fact that, the material's melting point is drastically reduced as the particles become smaller enough, in which situations effects of the atomic borders become much weaker. Along this direction, many phenomena existing in nature can be well understood. For example, if keeping in mind the fact that an atom consisting of nucleus and electronics can be regarded as fluid, all the matter consisted of atoms should maintain fluidic state in their macroscopic scale, according to the consistency between macro and micro worlds. However, many substances just cannot remain their original atomic fluidic behavior due to breaking of the consistency between macro and micro states. Based on the current softening theory, it is now easy to understand that the breaking of such consistency is just caused due to generated forces from the atomic interactions. To resolve such intrinsic confinement, a group of potential technical approaches can be developed to tune the atomic borders of the matter and thus make desired soft materials. This work provides a theoretical foundation to partially address the nature of the material which will aid to make future soft matters in the coming time. ",Kein DOI-Link verfügbar,1804.01340v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,First operation of undoped CsI directly coupled with SiPMs at 77 Kelvin,1970,"  The light yield of a small undoped cesium iodide (CsI) crystal directly coupled with two silicon photomultipliers (SiPMs) at about 77~Kelvin was measured to be $43.0 \pm 1.1$~photoelectrons (PE) per keV electron-equivalent (keV$_\text{ee}$) using $X$ and $\gamma$-ray peaks from an $^{241}$Am radioactive source from 18 to 60 keV. The high light yield together with some other technical advantages illustrate the great potential of this novel combination for neutrino and low-mass dark matter detection, particularly at accelerator-based neutrino sources, where random background can be highly suppressed by requiring coincident triggers between SiPMs and beam pulse timing signals. Some potential drawbacks of using cryogenic SiPMs instead of photomultiplier tubes (PMTs) were identified, such as worse energy resolution and optical cross-talks between SiPMs. Their influence to rare-event detection was discussed and possible solutions were provided. ",https://doi.org/10.1140/epjc/s10052-022-10289-x,2201.00483v2,Yes,potent(2)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Learning nonequilibrium statistical mechanics and dynamical phase   transitions,1970,"  Nonequilibrium statistical mechanics exhibit a variety of complex phenomena far from equilibrium. It inherits challenges of equilibrium, including accurately describing the joint distribution of a large number of configurations, and also poses new challenges as the distribution evolves over time. Characterizing dynamical phase transitions as an emergent behavior further requires tracking nonequilibrium systems under a control parameter. While a number of methods have been proposed, such as tensor networks for one-dimensional lattices, we lack a method for arbitrary time beyond the steady state and for higher dimensions. Here, we develop a general computational framework to study the time evolution of nonequilibrium systems in statistical mechanics by leveraging variational autoregressive networks, which offer an efficient computation on the dynamical partition function, a central quantity for discovering the phase transition. We apply the approach to prototype models of nonequilibrium statistical mechanics, including the kinetically constrained models of structural glasses up to three dimensions. The approach uncovers the active-inactive phase transition of spin flips, the dynamical phase diagram, as well as new scaling relations. The result highlights the potential of machine learning dynamical phase transitions in nonequilibrium systems. ",Kein DOI-Link verfügbar,2208.08266v3,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,ClusterDDPM: An EM clustering framework with Denoising Diffusion   Probabilistic Models,1970,"  Variational autoencoder (VAE) and generative adversarial networks (GAN) have found widespread applications in clustering and have achieved significant success. However, the potential of these approaches may be limited due to VAE's mediocre generation capability or GAN's well-known instability during adversarial training. In contrast, denoising diffusion probabilistic models (DDPMs) represent a new and promising class of generative models that may unlock fresh dimensions in clustering. In this study, we introduce an innovative expectation-maximization (EM) framework for clustering using DDPMs. In the E-step, we aim to derive a mixture of Gaussian priors for the subsequent M-step. In the M-step, our focus lies in learning clustering-friendly latent representations for the data by employing the conditional DDPM and matching the distribution of latent representations to the mixture of Gaussian priors. We present a rigorous theoretical analysis of the optimization process in the M-step, proving that the optimizations are equivalent to maximizing the lower bound of the Q function within the vanilla EM framework under certain constraints. Comprehensive experiments validate the advantages of the proposed framework, showcasing superior performance in clustering, unsupervised conditional generation and latent representation learning. ",Kein DOI-Link verfügbar,2312.08029v1,Yes,"innovative(1), potent(1), fresh(1)"
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Signed Graph Neural Ordinary Differential Equation for Modeling   Continuous-time Dynamics,1970,"  Modeling continuous-time dynamics constitutes a foundational challenge, and uncovering inter-component correlations within complex systems holds promise for enhancing the efficacy of dynamic modeling. The prevailing approach of integrating graph neural networks with ordinary differential equations has demonstrated promising performance. However, they disregard the crucial signed information intrinsic to graphs, impeding their capacity to accurately capture real-world phenomena and leading to subpar outcomes.   In response, we introduce a novel approach: a signed graph neural ordinary differential equation, adeptly addressing the limitations of miscapturing signed information. Our proposed solution boasts both flexibility and efficiency. To substantiate its effectiveness, we seamlessly integrate our devised strategies into three preeminent graph-based dynamic modeling frameworks: graph neural ordinary differential equations, graph neural controlled differential equations, and graph recurrent neural networks. Rigorous assessments encompass three intricate dynamic scenarios from physics and biology, as well as scrutiny across four authentic real-world traffic datasets. Remarkably outperforming the trio of baselines, empirical results underscore the substantial performance enhancements facilitated by our proposed approach.Our code can be found at https://github.com/beautyonce/SGODE. ",Kein DOI-Link verfügbar,2312.11198v1,Yes,intricate(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Automated Loss function Search for Class-imbalanced Node Classification,1970,"  Class-imbalanced node classification tasks are prevalent in real-world scenarios. Due to the uneven distribution of nodes across different classes, learning high-quality node representations remains a challenging endeavor. The engineering of loss functions has shown promising potential in addressing this issue. It involves the meticulous design of loss functions, utilizing information about the quantities of nodes in different categories and the network's topology to learn unbiased node representations. However, the design of these loss functions heavily relies on human expert knowledge and exhibits limited adaptability to specific target tasks. In this paper, we introduce a high-performance, flexible, and generalizable automated loss function search framework to tackle this challenge. Across 15 combinations of graph neural networks and datasets, our framework achieves a significant improvement in performance compared to state-of-the-art methods. Additionally, we observe that homophily in graph-structured data significantly contributes to the transferability of the proposed framework. ",Kein DOI-Link verfügbar,2405.14133v1,Yes,"meticulous(1), potent(1)"
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,GPT Sonograpy: Hand Gesture Decoding from Forearm Ultrasound Images via   VLM,1970,"  Large vision-language models (LVLMs), such as the Generative Pre-trained Transformer 4-omni (GPT-4o), are emerging multi-modal foundation models which have great potential as powerful artificial-intelligence (AI) assistance tools for a myriad of applications, including healthcare, industrial, and academic sectors. Although such foundation models perform well in a wide range of general tasks, their capability without fine-tuning is often limited in specialized tasks. However, full fine-tuning of large foundation models is challenging due to enormous computation/memory/dataset requirements. We show that GPT-4o can decode hand gestures from forearm ultrasound data even with no fine-tuning, and improves with few-shot, in-context learning. ",Kein DOI-Link verfügbar,2407.10870v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,MemSeg: A semi-supervised method for image surface defect detection   using differences and commonalities,1970,"  Under the semi-supervised framework, we propose an end-to-end memory-based segmentation network (MemSeg) to detect surface defects on industrial products. Considering the small intra-class variance of products in the same production line, from the perspective of differences and commonalities, MemSeg introduces artificially simulated abnormal samples and memory samples to assist the learning of the network. In the training phase, MemSeg explicitly learns the potential differences between normal and simulated abnormal images to obtain a robust classification hyperplane. At the same time, inspired by the mechanism of human memory, MemSeg uses a memory pool to store the general patterns of normal samples. By comparing the similarities and differences between input samples and memory samples in the memory pool to give effective guesses about abnormal regions; In the inference phase, MemSeg directly determines the abnormal regions of the input image in an end-to-end manner. Through experimental validation, MemSeg achieves the state-of-the-art (SOTA) performance on MVTec AD datasets with AUC scores of 99.56% and 98.84% at the image-level and pixel-level, respectively. In addition, MemSeg also has a significant advantage in inference speed benefiting from the end-to-end and straightforward network structure, which better meets the real-time requirement in industrial scenarios. ",Kein DOI-Link verfügbar,2205.00908v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Recurrent Dynamic Message Passing with Loops for Epidemics on Networks,1970,"  Several theoretical methods have been developed to approximate prevalence and threshold of epidemics on networks. Among them, the recurrent dynamic message-passing (rDMP) theory offers a state-of-the-art performance by preventing the echo chamber effect in network edges. However, the rDMP theory was derived in an intuitive ad-hoc way, lacking a solid theoretical foundation and resulting in a probabilistic inconsistency flaw. Furthermore, real-world networks are clustered and full of local loops like triangles, whereas rDMP is based on the assumption of a locally tree-like network structure, which makes rDMP potentially inefficient on real applications. In this work, for the recurrent-state epidemics, we first demonstrate that the echo chamber effect exits not only in edges but also in local loops, which rDMP-like method can not avoid. We then correct the deficiency of rDMP in a principled manner, leading to the natural introduction of new higher-order dynamic messages, extending rDMP to handle local loops. By linearizing the extended message-passing equations, a new epidemic threshold estimation is given by the inverse of the leading eigenvalue of a matrix named triangular non-backtracking matrix. Numerical experiments conducted on synthetic and real-world networks to evaluate our method, the efficacy of which is validated in epidemic prevalence and threshold prediction tasks. In addition, our method has the potential to speed up the solution of the immunization, influence maximization, and robustness optimization problems in the networks. ",Kein DOI-Link verfügbar,2311.05823v2,Yes,potent(2)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Transformable Soft Quantum Device based on Liquid Metals with Sandwiched   Liquid Junctions,1970,"  Quantum tunneling effect has been an important issue in both fundamental science and practical applications. Classical quantum tunneling devices are generally rigid in structures which may encounter technical difficulties during fabrication, functional tuning and shape adapting. Here through introducing the room-temperature liquid metals as two conductive electrodes and a soft even liquid insulating layer sandwiched between them, we proposed a conceptually innovative all-soft or liquid quantum device which would help realize a couple of unconventional quantum capabilities such as flexibility, deformability, transformability, and reconfigurability, etc. which may not be easily offered by a rigid quantum device. Representative structural configurations to make such transformable quantum devices via sandwiching various liquid metal-insulating layer-liquid metal (LM-IL-LM) components are suggested. The feasibility for making such an all-soft quantum device is interpreted through experimental evidences and theoretical evaluations. Potential future applications of the proposed devices in a group of emerging fields including intelligent quantum systems and quantum computing are prospected. ",Kein DOI-Link verfügbar,1710.09098v1,Yes,"innovative(1), potent(1)"
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,An analytical approximation of the scalar spectrum in the   ultra-slow-roll inflationary models,1970,"  The ultra-slow-roll (USR) inflationary models predict large-amplitude scalar perturbations at small scales which can lead to the primordial black hole production and scalar-induced gravitational waves. In general scalar perturbations in the USR models can only be obtained using numerical method because the usual slow-roll approximation breaks. In this work, we propose an analytical approach to estimate the scalar spectrum which is consistent with the numerical result. We find that the USR inflationary models predict a peak with power-law slopes in the scalar spectrum and energy spectrum of gravitational waves, and we derive the expression of the spectral indexes in terms of the inflationary potential. In turn, the inflationary potential near the USR regime can be reconstructed from the negative spectral index of the gravitational wave energy spectrum. ",https://doi.org/10.1103/PhysRevD.101.083535,2003.02075v1,Yes,potent(2)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Enhancing Instructional Quality: Leveraging Computer-Assisted Textual   Analysis to Generate In-Depth Insights from Educational Artifacts,1970,"  This paper explores the transformative potential of computer-assisted textual analysis in enhancing instructional quality through in-depth insights from educational artifacts. We integrate Richard Elmore's Instructional Core Framework to examine how artificial intelligence (AI) and machine learning (ML) methods, particularly natural language processing (NLP), can analyze educational content, teacher discourse, and student responses to foster instructional improvement. Through a comprehensive review and case studies within the Instructional Core Framework, we identify key areas where AI/ML integration offers significant advantages, including teacher coaching, student support, and content development. We unveil patterns that indicate AI/ML not only streamlines administrative tasks but also introduces novel pathways for personalized learning, providing actionable feedback for educators and contributing to a richer understanding of instructional dynamics. This paper emphasizes the importance of aligning AI/ML technologies with pedagogical goals to realize their full potential in educational settings, advocating for a balanced approach that considers ethical considerations, data quality, and the integration of human expertise. ",Kein DOI-Link verfügbar,2403.03920v1,Yes,potent(2)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Cross Fusion RGB-T Tracking with Bi-directional Adapter,1970,"  Many state-of-the-art RGB-T trackers have achieved remarkable results through modality fusion. However, these trackers often either overlook temporal information or fail to fully utilize it, resulting in an ineffective balance between multi-modal and temporal information. To address this issue, we propose a novel Cross Fusion RGB-T Tracking architecture (CFBT) that ensures the full participation of multiple modalities in tracking while dynamically fusing temporal information. The effectiveness of CFBT relies on three newly designed cross spatio-temporal information fusion modules: Cross Spatio-Temporal Augmentation Fusion (CSTAF), Cross Spatio-Temporal Complementarity Fusion (CSTCF), and Dual-Stream Spatio-Temporal Adapter (DSTA). CSTAF employs a cross-attention mechanism to enhance the feature representation of the template comprehensively. CSTCF utilizes complementary information between different branches to enhance target features and suppress background features. DSTA adopts the adapter concept to adaptively fuse complementary information from multiple branches within the transformer layer, using the RGB modality as a medium. These ingenious fusions of multiple perspectives introduce only less than 0.3\% of the total modal parameters, but they indeed enable an efficient balance between multi-modal and temporal information. Extensive experiments on three popular RGB-T tracking benchmarks demonstrate that our method achieves new state-of-the-art performance. ",Kein DOI-Link verfügbar,2408.16979v1,Yes,ingenious(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Video Event Restoration Based on Keyframes for Video Anomaly Detection,1970,"  Video anomaly detection (VAD) is a significant computer vision problem. Existing deep neural network (DNN) based VAD methods mostly follow the route of frame reconstruction or frame prediction. However, the lack of mining and learning of higher-level visual features and temporal context relationships in videos limits the further performance of these two approaches. Inspired by video codec theory, we introduce a brand-new VAD paradigm to break through these limitations: First, we propose a new task of video event restoration based on keyframes. Encouraging DNN to infer missing multiple frames based on video keyframes so as to restore a video event, which can more effectively motivate DNN to mine and learn potential higher-level visual features and comprehensive temporal context relationships in the video. To this end, we propose a novel U-shaped Swin Transformer Network with Dual Skip Connections (USTN-DSC) for video event restoration, where a cross-attention and a temporal upsampling residual skip connection are introduced to further assist in restoring complex static and dynamic motion object features in the video. In addition, we propose a simple and effective adjacent frame difference loss to constrain the motion consistency of the video sequence. Extensive experiments on benchmarks demonstrate that USTN-DSC outperforms most existing methods, validating the effectiveness of our method. ",Kein DOI-Link verfügbar,2304.05112v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models,1970,"  The Diffusion model, a prevalent framework for image generation, encounters significant challenges in terms of broad applicability due to its extended inference times and substantial memory requirements. Efficient Post-training Quantization (PTQ) is pivotal for addressing these issues in traditional models. Different from traditional models, diffusion models heavily depend on the time-step $t$ to achieve satisfactory multi-round denoising. Usually, $t$ from the finite set $\{1, \ldots, T\}$ is encoded to a temporal feature by a few modules totally irrespective of the sampling data. However, existing PTQ methods do not optimize these modules separately. They adopt inappropriate reconstruction targets and complex calibration methods, resulting in a severe disturbance of the temporal feature and denoising trajectory, as well as a low compression efficiency. To solve these, we propose a Temporal Feature Maintenance Quantization (TFMQ) framework building upon a Temporal Information Block which is just related to the time-step $t$ and unrelated to the sampling data. Powered by the pioneering block design, we devise temporal information aware reconstruction (TIAR) and finite set calibration (FSC) to align the full-precision temporal features in a limited time. Equipped with the framework, we can maintain the most temporal information and ensure the end-to-end generation quality. Extensive experiments on various datasets and diffusion models prove our state-of-the-art results. Remarkably, our quantization approach, for the first time, achieves model performance nearly on par with the full-precision model under 4-bit weight quantization. Additionally, our method incurs almost no extra computational cost and accelerates quantization time by $2.0 \times$ on LSUN-Bedrooms $256 \times 256$ compared to previous works. Our code is publicly available at https://github.com/ModelTC/TFMQ-DM. ",Kein DOI-Link verfügbar,2311.16503v3,Yes,pivotal(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,March in Chat: Interactive Prompting for Remote Embodied Referring   Expression,1970,"  Many Vision-and-Language Navigation (VLN) tasks have been proposed in recent years, from room-based to object-based and indoor to outdoor. The REVERIE (Remote Embodied Referring Expression) is interesting since it only provides high-level instructions to the agent, which are closer to human commands in practice. Nevertheless, this poses more challenges than other VLN tasks since it requires agents to infer a navigation plan only based on a short instruction. Large Language Models (LLMs) show great potential in robot action planning by providing proper prompts. Still, this strategy has not been explored under the REVERIE settings. There are several new challenges. For example, the LLM should be environment-aware so that the navigation plan can be adjusted based on the current visual observation. Moreover, the LLM planned actions should be adaptable to the much larger and more complex REVERIE environment. This paper proposes a March-in-Chat (MiC) model that can talk to the LLM on the fly and plan dynamically based on a newly proposed Room-and-Object Aware Scene Perceiver (ROASP). Our MiC model outperforms the previous state-of-the-art by large margins by SPL and RGSPL metrics on the REVERIE benchmark. ",Kein DOI-Link verfügbar,2308.10141v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,A-Lamp: Adaptive Layout-Aware Multi-Patch Deep Convolutional Neural   Network for Photo Aesthetic Assessment,1970,"  Deep convolutional neural networks (CNN) have recently been shown to generate promising results for aesthetics assessment. However, the performance of these deep CNN methods is often compromised by the constraint that the neural network only takes the fixed-size input. To accommodate this requirement, input images need to be transformed via cropping, warping, or padding, which often alter image composition, reduce image resolution, or cause image distortion. Thus the aesthetics of the original images is impaired because of potential loss of fine grained details and holistic image layout. However, such fine grained details and holistic image layout is critical for evaluating an image's aesthetics. In this paper, we present an Adaptive Layout-Aware Multi-Patch Convolutional Neural Network (A-Lamp CNN) architecture for photo aesthetic assessment. This novel scheme is able to accept arbitrary sized images, and learn from both fined grained details and holistic image layout simultaneously. To enable training on these hybrid inputs, we extend the method by developing a dedicated double-subnet neural network structure, i.e. a Multi-Patch subnet and a Layout-Aware subnet. We further construct an aggregation layer to effectively combine the hybrid features from these two subnets. Extensive experiments on the large-scale aesthetics assessment benchmark (AVA) demonstrate significant performance improvement over the state-of-the-art in photo aesthetic assessment. ",Kein DOI-Link verfügbar,1704.00248v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Multiqubit matter-wave interferometry under decoherence and the   Heisenberg scaling recovery,1970,"  Most matter-wave interferometry (MWI) schemes for quantum sensing are so far evaluated in ideal situations without noises. In this work, we provide assessments of generic multiqubit MWI schemes under Markovian dephasing noises. We find that for certain classes of the MWI schemes with scale factors that are nonlinearly dependent on the interrogation time, the optimal precision of maximally entangled probes \emph{decreases} with increasing the particle number $N$, for both independent and collective dephasing situations. This result challenges the conventional wisdom found in dephasing Ramsey-type interferometers. We initiate the analyses by investigating the optimal precision of multiqubit Sagnac atom interferometry for rotation sensing. And we show that due to the competition between the unconventional interrogation-time quadratic phase accumulation and the exponential dephasing processes, the Greenberger-Horne-Zeilinger (GHZ) state, which is the optimal input state in noiseless scenarios, leads to vanishing quantum Fisher information in the large-$N$ regime. Then our assessments are further extended to generic MWI schemes for quantum sensing with entangled states and under decoherence. Finally, a quantum error-correction logical GHZ state is tentatively analyzed, which could have the potential to recover the Heisenberg scaling and improve the sensitivity. ",https://doi.org/10.1103/PhysRevA.99.033807,1808.04632v3,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,The Promises and Pitfalls of Using Language Models to Measure   Instruction Quality in Education,1970,"  Assessing instruction quality is a fundamental component of any improvement efforts in the education system. However, traditional manual assessments are expensive, subjective, and heavily dependent on observers' expertise and idiosyncratic factors, preventing teachers from getting timely and frequent feedback. Different from prior research that mostly focuses on low-inference instructional practices on a singular basis, this paper presents the first study that leverages Natural Language Processing (NLP) techniques to assess multiple high-inference instructional practices in two distinct educational settings: in-person K-12 classrooms and simulated performance tasks for pre-service teachers. This is also the first study that applies NLP to measure a teaching practice that is widely acknowledged to be particularly effective for students with special needs. We confront two challenges inherent in NLP-based instructional analysis, including noisy and long input data and highly skewed distributions of human ratings. Our results suggest that pretrained Language Models (PLMs) demonstrate performances comparable to the agreement level of human raters for variables that are more discrete and require lower inference, but their efficacy diminishes with more complex teaching practices. Interestingly, using only teachers' utterances as input yields strong results for student-centered variables, alleviating common concerns over the difficulty of collecting and transcribing high-quality student speech data in in-person teaching settings. Our findings highlight both the potential and the limitations of current NLP techniques in the education domain, opening avenues for further exploration. ",Kein DOI-Link verfügbar,2404.02444v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,EAVL: Explicitly Align Vision and Language for Referring Image   Segmentation,1970,"  Referring image segmentation aims to segment an object mentioned in natural language from an image. A main challenge is language-related localization, which means locating the object with the relevant language. Previous approaches mainly focus on the fusion of vision and language features without fully addressing language-related localization. In previous approaches, fused vision-language features are directly fed into a decoder and pass through a convolution with a fixed kernel to obtain the result, which follows a similar pattern as traditional image segmentation. This approach does not explicitly align language and vision features in the segmentation stage, resulting in a suboptimal language-related localization. Different from previous methods, we propose Explicitly Align the Vision and Language for Referring Image Segmentation (EAVL). Instead of using a fixed convolution kernel, we propose an Aligner which explicitly aligns the vision and language features in the segmentation stage. Specifically, a series of unfixed convolution kernels are generated based on the input l, and then are use to explicitly align the vision and language features. To achieve this, We generate multiple queries that represent different emphases of the language expression. These queries are transformed into a series of query-based convolution kernels. Then, we utilize these kernels to do convolutions in the segmentation stage and obtain a series of segmentation masks. The final result is obtained through the aggregation of all masks. Our method can not only fuse vision and language features effectively but also exploit their potential in the segmentation stage. And most importantly, we explicitly align language features of different emphases with the image features to achieve language-related localization. Our method surpasses previous state-of-the-art methods on RefCOCO, RefCOCO+, and G-Ref by large margins. ",Kein DOI-Link verfügbar,2308.09779v2,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Gravitational Waves from Oscillons with Cuspy Potentials,1970,"  We study the production of gravitational waves during oscillations of the inflaton around the minimum of a cuspy potential after inflation. We find that a cusp in the potential can trigger copious oscillon formation, which sources a characteristic energy spectrum of gravitational waves with double peaks. The discovery of such a double-peak spectrum could test the underlying inflationary physics. ",https://doi.org/10.1103/PhysRevLett.120.031301,1707.09841v2,Yes,potent(2)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Gravitational wave production after inflation with cuspy potentials,1970,"  We investigate the effect of the cuspiness of scalar potentials on the production of gravitational waves during oscillon formation after inflation. We consider a more general form of potentials with a mass parameter $M$, which repoduce cuspy potentials for fields much larger than $M$, and smooth potentials in the opposite limit. For cuspy potentials, nonsmooth oscillations of the inflaton induce an amplification of the inflaton fluctuations at the bottom of the potential, so that oscillons copiously form, which leads to a significant stochastic gravitational wave background with a double-peak spectrum. By varying the parameter $M$, we find that cuspy potentials yield stronger signals of gravitational waves and the generation of gravitational waves disappears for smooth potentials. Moreover, we calculate the equation of state after inflation and find the presence of a quasi matter-dominated stage right before the transition to the radiation-dominated stage. ",https://doi.org/10.1103/PhysRevD.99.103506,1812.09235v2,Yes,potent(8)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Interactive Levy Flight in Interest Space,1970,"  Compared to the well-studied topic of human mobility in real geographic space, very few studies focus on human mobility in virtual space, such as interests, knowledge, ideas, and so forth. However, it relates to the issues of management of public opinions, knowledge diffusion, and innovation. In this paper, we assume that the interests of a group of online users can span a Euclidean space which is called interest space, and the transfers of user interests can be modeled as the Levy Flight on the interest space. To consider the interaction between users, we assume that the random walkers are not independent but interact each other indirectly via the digital resources in the interest space. The model can successfully reproduce a set of scaling laws for describing the growth of the attention flow networks of real online communities, and the ranges of the exponents of the scaling are similar with the empirical data. Further, we can infer parameters for describing the individual behaviors of the users according to the scaling laws of the empirical attention flow network. Our model can not only provide theoretical understanding on human online behaviors, but also has wide potential applications, such as dissemination and management of public opinions, online recommendation, etc. ",https://doi.org/10.1088/2632-072X/ab7f4f,1705.09462v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,LGN-Net: Local-Global Normality Network for Video Anomaly Detection,1970,"  Video anomaly detection (VAD) has been intensively studied for years because of its potential applications in intelligent video systems. Existing unsupervised VAD methods tend to learn normality from training sets consisting of only normal videos and regard instances deviating from such normality as anomalies. However, they often consider only local or global normality in the temporal dimension. Some of them focus on learning local spatiotemporal representations from consecutive frames to enhance the representation for normal events. But powerful representation allows these methods to represent some anomalies and causes miss detection. In contrast, the other methods are devoted to memorizing prototypical normal patterns of whole training videos to weaken the generalization for anomalies, which also restricts them from representing diverse normal patterns and causes false alarm. To this end, we propose a two-branch model, Local-Global Normality Network (LGN-Net), to simultaneously learn local and global normality. Specifically, one branch learns the evolution regularities of appearance and motion from consecutive frames as local normality utilizing a spatiotemporal prediction network, while the other branch memorizes prototype features of the whole videos as global normality by a memory module. LGN-Net achieves a balance of representing normal and abnormal instances by fusing local and global normality. In addition, the fused normality enables LGN-Net to generalize to various scenes more than exploiting single normality. Experiments demonstrate the effectiveness and superior performance of our method. The code is available online: https://github.com/Myzhao1999/LGN-Net. ",Kein DOI-Link verfügbar,2211.07454v3,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Temporal Feature Matters: A Framework for Diffusion Model Quantization,1970,"  The Diffusion models, widely used for image generation, face significant challenges related to their broad applicability due to prolonged inference times and high memory demands. Efficient Post-Training Quantization (PTQ) is crucial to address these issues. However, unlike traditional models, diffusion models critically rely on the time-step for the multi-round denoising. Typically, each time-step is encoded into a hypersensitive temporal feature by several modules. Despite this, existing PTQ methods do not optimize these modules individually. Instead, they employ unsuitable reconstruction objectives and complex calibration methods, leading to significant disturbances in the temporal feature and denoising trajectory, as well as reduced compression efficiency. To address these challenges, we introduce a novel quantization framework that includes three strategies: 1) TIB-based Maintenance: Based on our innovative Temporal Information Block (TIB) definition, Temporal Information-aware Reconstruction (TIAR) and Finite Set Calibration (FSC) are developed to efficiently align original temporal features. 2) Cache-based Maintenance: Instead of indirect and complex optimization for the related modules, pre-computing and caching quantized counterparts of temporal features are developed to minimize errors. 3) Disturbance-aware Selection: Employ temporal feature errors to guide a fine-grained selection between the two maintenance strategies for further disturbance reduction. This framework preserves most of the temporal information and ensures high-quality end-to-end generation. Extensive testing on various datasets, diffusion models and hardware confirms our superior performance and acceleration.. ",Kein DOI-Link verfügbar,2407.19547v2,Yes,innovative(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Fluctuation-enhanced quantum metrology,1970,"  The main obstacle for practical quantum technology is the noise, which can induce the decoherence and destroy the potential quantum advantages. The fluctuation of a field, which induces the dephasing of the system, is one of the most common noises and widely regarded as detrimental to quantum technologies. Here we show, contrary to the conventional belief, the fluctuation can be used to improve the precision limits in quantum metrology for the estimation of various parameters. Specifically, we show that for the estimation of the direction and rotating frequency of a field, the achieved precisions at the presence of the fluctuation can even surpass the highest precision achievable under the unitary dynamics which have been widely taken as the ultimate limit. We provide explicit protocols, which employs the adaptive quantum error correction, to achieve the higher precision limits with the fluctuating fields. Our study provides a completely new perspective on the role of the noises in quantum metrology. It also opens the door for higher precisions beyond the limit that has been believed to be ultimate. ",Kein DOI-Link verfügbar,2003.13010v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Measuring Conversational Uptake: A Case Study on Student-Teacher   Interactions,1970,"  In conversation, uptake happens when a speaker builds on the contribution of their interlocutor by, for example, acknowledging, repeating or reformulating what they have said. In education, teachers' uptake of student contributions has been linked to higher student achievement. Yet measuring and improving teachers' uptake at scale is challenging, as existing methods require expensive annotation by experts. We propose a framework for computationally measuring uptake, by (1) releasing a dataset of student-teacher exchanges extracted from US math classroom transcripts annotated for uptake by experts; (2) formalizing uptake as pointwise Jensen-Shannon Divergence (pJSD), estimated via next utterance classification; (3) conducting a linguistically-motivated comparison of different unsupervised measures and (4) correlating these measures with educational outcomes. We find that although repetition captures a significant part of uptake, pJSD outperforms repetition-based baselines, as it is capable of identifying a wider range of uptake phenomena like question answering and reformulation. We apply our uptake measure to three different educational datasets with outcome indicators. Unlike baseline measures, pJSD correlates significantly with instruction quality in all three, providing evidence for its generalizability and for its potential to serve as an automated professional development tool for teachers. ",Kein DOI-Link verfügbar,2106.03873v1,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Quantum Magnetometer with Dual-Coupling Optomechanics,1970,"  An experimentally feasible magnetometer based on a dual-coupling optomechanical system is proposed, where the radiation-pressure coupling transduces the magnetic signal to the optical phase, and the quadratic optomechanical interaction induces a periodic squeezing effect. The latter not only amplifies the signal to be measured, but also accelerates the signal transducing rate characterized by an experimentally observable phase accumulation efficiency. In the vicinity of opto-mechanical decoupled time, the ultimate bound to the estimability of magnetic signal is proportional to $\exp(-6r)$, and then the optimized accuracy of estimation can be enhanced nearly 3 orders with a controllable squeezing parameter $r<1$. Moreover, our proposal is robust against the mechanical thermal noise, and the sensitivity of a specific measurement can reach to the order of $10^{-17}{\rm T/\sqrt{Hz}}$ in the presence of dissipations and without ground state cooling of mechanical oscillator. Our proposal fundamentally broadens the fields of quantum metrology and cavity optomechanics, with potential application for on-chip magnetic detection with high precision. ",https://doi.org/10.1002/lpor.202100636,2205.00433v2,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Explaining Pulsar Timing Array Observations with Primordial   Gravitational Waves in Parity-Violating Gravity,1970,"  The pulsar timing array (PTA) collaborations have recently suggested the presence of a gravitational wave background at nano-Hertz frequencies. In this paper, we explore potential inflationary interpretation of this signal within the context of a simple and health parity-violating gravity model termed the Nieh-Yan modified Teleparallel Gravity. Through this model, two inflationary scenarios are evaluated, both yielding significant polarized primordial gravitational waves (PGWs) that align well with the results from PTA observations. Furthermore, the resulting PGWs can display strong circular polarization and significant anisotropies in the PTA frequency band, which are distinct features to be verified by observations of both PTA and the cosmic microwave background.The detection of such a distinctive background of PGWs is expected to provide strong evidence supporting our scenarios and insights into inflationary dynamics and gravity theory. ",Kein DOI-Link verfügbar,2308.15329v3,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,Kid-Whisper: Towards Bridging the Performance Gap in Automatic Speech   Recognition for Children VS. Adults,1970,"  Recent advancements in Automatic Speech Recognition (ASR) systems, exemplified by Whisper, have demonstrated the potential of these systems to approach human-level performance given sufficient data. However, this progress doesn't readily extend to ASR for children due to the limited availability of suitable child-specific databases and the distinct characteristics of children's speech. A recent study investigated leveraging the My Science Tutor (MyST) children's speech corpus to enhance Whisper's performance in recognizing children's speech. They were able to demonstrate some improvement on a limited testset. This paper builds on these findings by enhancing the utility of the MyST dataset through more efficient data preprocessing. We reduce the Word Error Rate (WER) on the MyST testset 13.93% to 9.11% with Whisper-Small and from 13.23% to 8.61% with Whisper-Medium and show that this improvement can be generalized to unseen datasets. We also highlight important challenges towards improving children's ASR performance. The results showcase the viable and efficient integration of Whisper for effective children's speech recognition. ",Kein DOI-Link verfügbar,2309.07927v3,Yes,potent(1)
0000-0003-0646-2831,Jing Liu,Karlsruher Institut für Technologie,CCFC++: Enhancing Federated Clustering through Feature Decorrelation,1970,"  In federated clustering, multiple data-holding clients collaboratively group data without exchanging raw data. This field has seen notable advancements through its marriage with contrastive learning, exemplified by Cluster-Contrastive Federated Clustering (CCFC). However, CCFC suffers from heterogeneous data across clients, leading to poor and unrobust performance. Our study conducts both empirical and theoretical analyses to understand the impact of heterogeneous data on CCFC. Findings indicate that increased data heterogeneity exacerbates dimensional collapse in CCFC, evidenced by increased correlations across multiple dimensions of the learned representations. To address this, we introduce a decorrelation regularizer to CCFC. Benefiting from the regularizer, the improved method effectively mitigates the detrimental effects of data heterogeneity, and achieves superior performance, as evidenced by a marked increase in NMI scores, with the gain reaching as high as 0.32 in the most pronounced case. ",Kein DOI-Link verfügbar,2402.12852v1,Yes,notable(1)
0000-0003-0691-3399,Gaurav Yengera,Saarland Universität,Less is More: Surgical Phase Recognition with Less Annotations through   Self-Supervised Pre-training of CNN-LSTM Networks,1970,"  Real-time algorithms for automatically recognizing surgical phases are needed to develop systems that can provide assistance to surgeons, enable better management of operating room (OR) resources and consequently improve safety within the OR. State-of-the-art surgical phase recognition algorithms using laparoscopic videos are based on fully supervised training. This limits their potential for widespread application, since creation of manual annotations is an expensive process considering the numerous types of existing surgeries and the vast amount of laparoscopic videos available. In this work, we propose a new self-supervised pre-training approach based on the prediction of remaining surgery duration (RSD) from laparoscopic videos. The RSD prediction task is used to pre-train a convolutional neural network (CNN) and long short-term memory (LSTM) network in an end-to-end manner. Our proposed approach utilizes all available data and reduces the reliance on annotated data, thereby facilitating the scaling up of surgical phase recognition algorithms to different kinds of surgeries. Additionally, we present EndoN2N, an end-to-end trained CNN-LSTM model for surgical phase recognition and evaluate the performance of our approach on a dataset of 120 Cholecystectomy laparoscopic videos (Cholec120). This work also presents the first systematic study of self-supervised pre-training approaches to understand the amount of annotations required for surgical phase recognition. Interestingly, the proposed RSD pre-training approach leads to performance improvement even when all the training data is manually annotated and outperforms the single pre-training approach for surgical phase recognition presently published in the literature. It is also observed that end-to-end training of CNN-LSTM networks boosts surgical phase recognition performance. ",Kein DOI-Link verfügbar,1805.08569v1,Yes,potent(1)
0000-0003-0753-848X,Eric Bertok,Georg-August-Universität Göttingen,Phonon-induced breakdown of Thouless pumping in the Rice-Mele-Holstein   model,1970,"  Adiabatic and periodic variation of the lattice parameters can make it possible to transport charge through a system even without net external electric or magnetic fields, known as Thouless charge pumping. The amount of charge pumped in a cycle is quantized and entirely determined by the system's topology, which is robust against perturbations such as disorder and interactions. However, coupling to the environment may play a vital role in topological transport in many-body systems. We study the topological Thouless pumping, where the charge carriers interact with local optical phonons. The semi-classical multi-trajectory Ehrenfest method is employed to treat the phonon trajectories classically and charge carriers quantum mechanically. We find a breakdown of the quantized charge transport in the presence of phonons. It happens for any finite electron-phonon coupling strength at the resonance condition when the pumping frequency matches the phonon frequency, and it takes finite phonon coupling strength away from the resonance. Moreover, there exist parameter regimes with non-quantized negative and positive charge transport. The modified effective pumping path due to electron-phonon coupling accurately explains the underlying physics. In the large coupling regime where the pumping disappears, the phonons are found to eliminate the staggering of the onsite potentials, which is necessary for the pumping protocol. Finally, we present a stability diagram of quantized pumping as a function of time period of pumping and phonon coupling strength. ",https://doi.org/10.1103/PhysRevB.106.235118,2209.06124v3,Yes,potent(1)
0000-0003-0764-838X,Sven Reichardt,Universität Konstanz,Modulation of magnetization in BiFeO$_3$ using circularly polarized   light,1970,"  BiFeO$_3$ is a multiferroic material featuring ferroelectricity and noncollinear antiferromagnetism, the latter manifested as a cycloid of spin density. Definitive and efficient control of the characteristic spin texture of BiFeO$_3$ is attractive for emerging quantum devices. In this regard, crystal-field $d\rightarrow d$ excitations localized on Fe atomic sites in BiFeO$_3$ provide an avenue for manipulation of the spin texture as they induce a complex interplay among the spin, charge, and lattice degrees of freedom. In this work, the ab initio GW-BSE method is used to characterize these excitations within an excitonic picture. We find that the $d-d$ transitions appear as strongly bound, chiral, spin-flip excitons deep within the electronic band gap as a result of the intricate competition between the lattice potential, the antiferromagnetic ordering, the spin-orbit coupling, and the electron-hole interaction. Most crucially, these excitons are composed of electron-hole pairs with opposite spins that constitute almost all of their $\pm \hbar$ total angular momentum. These excitons of specific angular momentum can be selectively excited using circularly polarized light, consequently modulating the local magnetic moment giving rise to transient ferrimagnetism. ",Kein DOI-Link verfügbar,2402.05430v2,Yes,"intricate(1), potent(1)"
0000-0003-0764-838X,Sven Reichardt,Universität Konstanz,Understanding electronic excited states in BiFeO$_3$ via ab initio   calculations and symmetry analysis,1970,"  BiFeO$_3$ is a technologically relevant multiferroic perovskite featuring ferroelectricity and antiferromagnetism. Its lattice, magnetic, and ferroelectric degrees of freedoms are coupled to its optically active excitations and thus hold the potential to be reversible probed and controlled by light. In this work, we combine ab initio density functional and many-body perturbation theory methods with an extensive symmetry and atomic-orbital analysis to describe and understand the electronic excited states spectrum and its imprint on the optical absorption spectrum with quantitative accuracy and qualitative insights. We find that the optical absorption spectrum of BiFeO$_3$ contain several strongly bound and spatially localized electronic transitions in which the spin-degree of freedom is almost fully flipped. With our analysis we thoroughly characterize these localized spin-flip transitions in terms of the unusual crystal field splitting of Fe-$3d$ single-electron orbitals. Our symmetry analysis further allows us to thoroughly explain how the spin content and the energetic fine structure of these strongly bound excitons are dictated by the interplay between crystal symmetry, electron-hole attraction, and the spin-orbit coupling. ",Kein DOI-Link verfügbar,2402.05542v2,Yes,potent(1)
0000-0003-0764-838X,Sven Reichardt,Universität Konstanz,Origin of interlayer exciton-phonon coupling in 2D heterostructures,1970,"  The coupling between excitons and phonons across adjacent layers has been experimentally observed in various heterostructures of layered materials. Yet the precise mechanism underlying this phenomenon remains elusive. Using the WSe$_2$@hBN heterostructure as an example, we study the origin of the interlayer exciton-phonon coupling and its signature in resonant Raman scattering through first-principles calculations. Our study emphasizes the central role of crystal symmetries in the interlayer exciton-phonon scattering processes, which are responsible for the anomalous resonant Raman intensities of the in-plane and the out-of-plane hBN phonon modes. We find that the deformation potential induced by the hBN phonon interacts with the hybridized hole density of WSe$_2$ excitons near the hBN interface, leading to interlayer exciton-phonon coupling. ",Kein DOI-Link verfügbar,2407.16111v1,Yes,potent(1)
0000-0003-0764-838X,Sven Reichardt,Universität Konstanz,Engineering tunable strain fields in suspended graphene by   microelectromechanical systems,1970,"  Here, we present a micro-electromechanical system (MEMS) for the investigation of the electromechanical coupling in graphene and potentially related 2D materials. Key innovations of our technique include: (1) the integration of graphene into silicon-MEMS technology; (2) full control over induced strain fields and doping levels within the graphene membrane and their characterization via spatially resolved confocal Raman spectroscopy; and (3) the ability to detect the mechanical coupling of the graphene sheet to the MEMS device with via their mechanical resonator eigenfrequencies. ",https://doi.org/10.1109/TRANSDUCERS.2019.8808807,2103.13652v1,Yes,potent(1)
0000-0003-0764-838X,Sven Reichardt,Universität Konstanz,Reconfigurable Multifunctional van der Waals Ferroelectric Devices and   Logic Circuits,1970,"  In this work, we demonstrate the suitability of Reconfigurable Ferroelectric Field-Effect- Transistors (Re-FeFET) for designing non-volatile reconfigurable logic-in-memory circuits with multifunctional capabilities. Modulation of the energy landscape within a homojunction of a 2D tungsten diselenide (WSe$_2$) layer is achieved by independently controlling two split-gate electrodes made of a ferroelectric 2D copper indium thiophosphate (CuInP$_2$S$_6$) layer. Controlling the state encoded in the Program Gate enables switching between p, n and ambipolar FeFET operating modes. The transistors exhibit on-off ratios exceeding 10$^6$ and hysteresis windows of up to 10 V width. The homojunction can change from ohmic-like to diode behavior, with a large rectification ratio of 10$^4$. When programmed in the diode mode, the large built-in p-n junction electric field enables efficient separation of photogenerated carriers, making the device attractive for energy harvesting applications. The implementation of the Re-FeFET for reconfigurable logic functions shows how a circuit can be reconfigured to emulate either polymorphic ferroelectric NAND/AND logic-in-memory or electronic XNOR logic with long retention time exceeding 10$^4$ seconds. We also illustrate how a circuit design made of just two Re-FeFETs exhibits high logic expressivity with reconfigurability at runtime to implement several key non-volatile 2-input logic functions. Moreover, the Re-FeFET circuit demonstrates remarkable compactness, with an up to 80% reduction in transistor count compared to standard CMOS design. The 2D van de Waals Re-FeFET devices therefore exhibit groundbreaking potential for both More-than-Moore and beyond-Moore future of electronics, in particular for an energy-efficient implementation of in-memory computing and machine learning hardware, due to their multifunctionality and design compactness. ",https://doi.org/10.1021/acsnano.3c07952,2310.14648v1,Yes,potent(1)
0000-0003-0764-838X,Sven Reichardt,Universität Konstanz,Raman spectroscopy as probe of nanometer-scale strain variations in   graphene,1970,"  Confocal Raman spectroscopy is a versatile, non-invasive investigation tool and a major workhorse for graphene characterization. Here we show that the experimentally observed Raman 2D line width is a measure of nanometer-scale strain variations in graphene. By investigating the relation between the G and 2D line at high magnetic fields we find that the 2D line width contains valuable information on nanometer-scale flatness and lattice deformations of graphene, making it a good quantity for classifying the structural quality of graphene even at zero magnetic field. ",https://doi.org/10.1038/ncomms9429,1406.7771v2,Yes,versatile(1)
0000-0003-0764-838X,Sven Reichardt,Universität Konstanz,Symmetry-dependent dielectric screening of optical phonons in monolayer   graphene,1970,"  Quantised lattice vibrations (i.e., phonons) in solids are robust and unambiguous fingerprints of crystal structures and of their symmetry properties. In metals and semimetals, strong electron-phonon coupling may lead to so-called Kohn anomalies in the phonon dispersion, providing an image of the Fermi surface in a non-electronic observable. Kohn anomalies become prominent in low-dimensional systems, in particular in graphene, where they appear as sharp kinks in the in-plane optical phonon branches. However, in spite of intense research efforts on electron-phonon coupling in graphene and related van der Waals heterostructures, little is known regarding the links between the symmetry properties of optical phonons at and near Kohn anomalies and their sensitivity towards the local environment. Here, using inelastic light scattering (Raman) spectroscopy, we investigate a set of custom-designed graphene-based van der Waals heterostructures, wherein dielectric screening is finely controlled at the atomic layer level. We demonstrate experimentally and explain theoretically that, depending exclusively on their symmetry properties, the two main Raman modes of graphene react differently to the surrounding environment. While the Raman-active near-zone-edge optical phonons in graphene undergo changes in their frequencies due to the neighboring dielectric environment, the in-plane, zone-centre optical phonons are symmetry-protected from the influence of the latter. These results shed new light on the unique electron-phonon coupling properties in graphene and related systems and provide invaluable guidelines to characterise dielectric screening in van der Waals heterostructures and moir\'e superlattices. ",Kein DOI-Link verfügbar,2310.13868v1,Yes,invaluable(1)
0000-0003-0786-6811,Yiping Liu,Rheinisch-Westfälische Technische Hochschule Aachen,From the Periphery to the Center: Information Brokerage in an Evolving   Network,1970,"  Interpersonal ties are pivotal to individual efficacy, status and performance in an agent society. This paper explores three important and interrelated themes in social network theory: the center/periphery partition of the network; network dynamics; and social integration of newcomers. We tackle the question: How would a newcomer harness information brokerage to integrate into a dynamic network going from periphery to center? We model integration as the interplay between the newcomer and the dynamics network and capture information brokerage using a process of relationship building. We analyze theoretical guarantees for the newcomer to reach the center through tactics; proving that a winning tactic always exists for certain types of network dynamics. We then propose three tactics and show their superior performance over alternative methods on four real-world datasets and four network models. In general, our tactics place the newcomer to the center by adding very few new edges on dynamic networks with approximately 14000 nodes. ",Kein DOI-Link verfügbar,1805.00751v1,Yes,pivotal(1)
0000-0003-0786-6811,Yiping Liu,Rheinisch-Westfälische Technische Hochschule Aachen,Skewed generalized parton distributions of proton from basis light-front   quantization,1970,"  We obtain all the leading-twist quark generalized parton distributions (GPDs) inside the proton at nonzero skewness within the basis light-front quantization framework. We employ the light-front wave functions of the proton from a light-front quantized Hamiltonian in the valence Fock sector consisting of a three-dimensional confinement potential and a one-gluon exchange interaction with fixed coupling. We find that the qualitative behaviors of our GPDs are similar to those of other theoretical calculations. We further examine the GPDs within the boost-invariant longitudinal coordinate, $\sigma=\frac{1}{2} b^- P^+$, which is identified as the Fourier conjugate of the skewness. The GPDs in the $\sigma$-space show diffraction patterns, which are akin to the diffractive scattering of a wave in optics. ",Kein DOI-Link verfügbar,2403.05922v1,Yes,potent(1)
0000-0003-0786-6811,Yiping Liu,Rheinisch-Westfälische Technische Hochschule Aachen,Angular momentum and generalized parton distributions for the proton   with basis light-front quantization,1970,"  We study the unpolarized and the helicity dependent generalized parton distributions (GPDs) for the valence quarks of the proton in both momentum space and position space within the basis light-front quantization (BLFQ) framework. The GPDs for the valence quarks are computed from the eigenvectors of a light-front effective Hamiltonian in the valence Fock sector consisting of a three-dimensional confinement potential and a one-gluon exchange interaction with fixed coupling. Employing these GPDs, we obtain the spatial distributions of quark angular momentum inside the proton. In our BLFQ approach, we explore various definitions of angular momentum density and illustrate the differences between them arising from terms that integrate to zero. We also discuss the flavor contributions to the quark angular momentum densities. ",https://doi.org/10.1103/PhysRevD.105.094018,2202.00985v1,Yes,potent(1)
0000-0003-0786-6811,Yiping Liu,Rheinisch-Westfälische Technische Hochschule Aachen,Towards a first principles light-front Hamiltonian for the nucleon,1970,"  We solve the nucleon's wave functions from the eigenstates of the light-front quantum chromodynamics Hamiltonian for the first time, using a fully relativistic and nonperturbative approach based on light-front quantization, without an explicit confining potential. These eigenstates are determined for the three-quark, three-quark-gluon, and three-quark-quark-antiquark Fock representations, making them suitable for low-resolution probes. From this, we calculate the nucleon's quark and gluon matter densities, helicity, and transversity distributions, which show qualitative consistency with experimental extractions. We also compute the contributions of quark and gluon helicity to the proton spin and the tensor charges. The obtained light-front wave functions represent a significant advancement towards a unified description of various hadron distribution functions in both longitudinal and transverse momentum space. ",Kein DOI-Link verfügbar,2408.11298v1,Yes,potent(1)
0000-0003-0786-6811,Yiping Liu,Rheinisch-Westfälische Technische Hochschule Aachen,Instruction Multi-Constraint Molecular Generation Using a   Teacher-Student Large Language Model,1970,"  While various models and computational tools have been proposed for structure and property analysis of molecules, generating molecules that conform to all desired structures and properties remains a challenge. Here, we introduce a multi-constraint molecular generation large language model, TSMMG, which, akin to a student, incorporates knowledge from various small models and tools, namely, the 'teachers'. To train TSMMG, we construct a large set of text-molecule pairs by extracting molecular knowledge from these 'teachers', enabling it to generate novel molecules that conform to the descriptions through various text prompts. We experimentally show that TSMMG remarkably performs in generating molecules meeting complex, natural language-described property requirements across two-, three-, and four-constraint tasks, with an average molecular validity of over 99% and success ratio of 82.58%, 68.03%, and 67.48%, respectively. The model also exhibits adaptability through zero-shot testing, creating molecules that satisfy combinations of properties that have not been encountered. It can comprehend text inputs with various language styles, extending beyond the confines of outlined prompts, as confirmed through empirical validation. Additionally, the knowledge distillation feature of TSMMG contributes to the continuous enhancement of small models, while the innovative approach to dataset construction effectively addresses the issues of data scarcity and quality, which positions TSMMG as a promising tool in the domains of drug discovery and materials science. ",Kein DOI-Link verfügbar,2403.13244v3,Yes,innovative(1)
0000-0003-0805-3193,Amrita Mukherjee,Universität des Saarlandes,Flux driven and geometry controlled spin filtering for arbitrary spins   in aperiodic quantum networks,1970,"  We demonstrate that an aperiodic array of certain quantum networks comprising magnetic and non-magnetic atoms can act as perfect spin filters for particles with arbitrary spin state. This can be achieved by introducing minimal quasi-one dimensionality in the basic structural units building up the array, along with an appropriate tuning of the potential of the non-magnetic atoms, the tunnel hopping integral between the non-magnetic atoms and the backbone, and, in some cases, by tuning an external magnetic field. This latter result opens up the interesting possibility of designing a flux controlled spin demultiplexer using quantum networks. The proposed networks have close resemblance with a family of recently developed photonic lattices, and the scheme for spin filtering can thus be linked, in principle, to a possibility of suppressing any one of the two states of polarization of a single photon, almost at will. We use transfer matrices and a real space renormalization group scheme to unravel the conditions under which any aperiodic arrangement of such topologically different structures will filter out any given spin projection. Our results are analytically exact, and corroborated by extensive numerical calculations of the spin polarized transmission and the density of states of such systems. ",https://doi.org/10.1103/PhysRevB.98.075415,1803.02170v1,Yes,potent(1)
0000-0003-0805-3193,Amrita Mukherjee,Universität des Saarlandes,Controlled delocalization of electronic states in a multi-strand   quasiperiodic lattice,1970,"  Finite strips, composed of a periodic stacking of infinite quasiperiodic Fibonacci chains, have been investigated in terms of their electronic properties. The system is described by a tight binding Hamiltonian. The eigenvalue spectrum of such a multi-strand quasiperiodic network is found to be sensitive on the mutual values of the intra-strand and inter-strand tunnel hoppings, whose distribution displays a unique three-subband self-similar pattern in a parameter subspace. In addition, it is observed that special numerical correlations between the nearest and the next-nearest neighbor hopping integrals can render a substantial part of the energy spectrum absolutely continuous. Extended, Bloch like functions populate the above continuous zones, signalling a complete delocalization of single particle states even in such a non-translationally invariant system, and more importantly, a phenomenon that can be engineered by tuning the relative strengths of the hopping parameters. A commutation relation between the potential and the hopping matrices enables us to work out the precise correlation which helps to engineer the extended eigenfunctions and determine the band positions at will. ",https://doi.org/10.1140/epjb/e2017-70700-1,1608.05236v1,Yes,potent(1)
0000-0003-0805-3193,Amrita Mukherjee,Universität des Saarlandes,Spin-polarized localization in a magnetized chain,1970,"  We investigate a simple tight-binding Hamiltonian to understand the stability of spin-polarized transport of states with an arbitrary spin content in the presence of disorder. The general spin state is made to pass through a linear chain of magnetic atoms, and the localization lengths are computed. Depending on the value of spin, the chain of magnetic atoms unravels a hidden transverse dimensionality that can be exploited to engineer energy regimes where only a selected spin state is allowed to retain large localization lengths. An analysis is carried out to understand the roles played by the spin projections in different energy regimes of the range of states. We introduce a new measure, viz, a spin-resolved localization length for this purpose. We study uncorrelated disorder in the potential profile offered by the magnetic substrate or in the orientations of the magnetic moments concerning a given direction in space. Our results show that the spin filtering effect is robust against weak disorder and hence the proposed systems should be good candidates for experimental realizations of spin-selective transport. ",https://doi.org/10.1038/s41598-019-42316-5,1807.02402v2,Yes,potent(1)
0000-0003-1003-7299,Guido Dittrich,Technische Universität Hamburg,Silicon Flexes Muscles: Giant Electrochemical Actuation in a Nanoporous   Silicon-Polypyrrole Hybrid Material,1970,"  The absence of piezoelectricity in silicon makes direct electro-mechanical applications of this mainstream semiconductor impossible. Integrated electrical control of the silicon mechanics, however, would open up new perspectives for on-chip actuorics. Here, we combine wafer-scale nanoporosity in single-crystalline silicon with polymerization of an artificial muscle material inside pore space to synthesize a composite that shows macroscopic electrostrain in aqueous electrolyte. The voltage-strain coupling is 3 orders of magnitude larger than the best-performing ceramics in terms of piezoelectric actuation. We trace this huge electroactuation to the concerted action of 100 billions of nanopores per square centimetre cross-section and to potential-dependent pressures of up to 150 atmospheres at the single-pore scale. The exceptionally small operation voltages (0.4-0.9 V) along with the sustainable and biocompatible base materials make this hybrid promising for bio-actuator applications. ",https://doi.org/10.1126/sciadv.aba1483,2010.03878v1,Yes,potent(1)
0000-0003-1045-8026,Martin Koch,Universität Bielefeld,Nonlinear refraction in CH$_3$NH$_3$PbBr$_3$ single crystals,1970,"  Hybrid lead halide perovskites, such as CH$_3$NH$_3$PbX$_3$ (X=I, Br), are direct gap semiconductors that offer many superior optoelectronic properties combined with extremely simple solution-processing fabrication methods. This makes them very attractive for use in applications like solar cells or light-emitting devices. Recently, also their nonlinear optical properties have received increased attention due to reports of high nonlinear refraction in thin films and nanoparticles. However, understanding of the underlying mechanisms is poor and limited by the lack of knowledge of fundamental parameters like the nonlinear refractive index of the bulk material. Here, we measure both nonlinear absorption and nonlinear refraction in a CH$_3$NH$_3$PbBr$_3$ single crystal using the Z-scan technique with femtosecond laser pulses. At 1000 nm, we obtain values of 5.2 cm/GW and 9.5$\cdot$10$^{-14}$ cm$^2$/W for nonlinear absorption and nonlinear refraction, respectively. Sign and magnitude of the observed refractive nonlinearity are reproduced well by the two-band model. To our knowledge, these measurements mark the first characterization of nonlinear refraction in any metal halide perovskite single crystal and thus will serve as an important reference for assessing the potential of this emerging material class for nonlinear optical applications. ",https://doi.org/10.1364/OL.383917,1910.12721v1,Yes,potent(1)
0000-0003-1133-8261,Benjamin Sliwa,TU Dortmund Universität,Lightweight Simulation of Hybrid Aerial- and Ground-based Vehicular   Communication Networks,1970,"  Cooperating small-scale Unmanned Aerial Vehicles (UAVs) will open up new application fields within next-generation Intelligent Transportation Sytems (ITSs), e.g., airborne near field delivery. In order to allow the exploitation of the potentials of hybrid vehicular scenarios, reliable and efficient bidirectional communication has to be guaranteed in highly dynamic environments. For addressing these novel challenges, we present a lightweight framework for integrated simulation of aerial and ground-based vehicular networks. Mobility and communication are natively brought together using a shared codebase coupling approach, which catalyzes the development of novel context-aware optimization methods that exploit interdependencies between both domains. In a proof-of-concept evaluation, we analyze the exploitation of UAVs as local aerial sensors as well as aerial base stations. In addition, we compare the performance of Long Term Evolution (LTE) and Cellular Vehicle-to-Everything (C-V2X) for connecting the ground- and air-based vehicles. ",https://doi.org/10.1109/VTCFall.2019.8891340,1906.08993v2,Yes,potent(1)
0000-0003-1133-8261,Benjamin Sliwa,TU Dortmund Universität,Simulating Hybrid Aerial- and Ground-based Vehicular Networks with ns-3   and LIMoSim,1970,"  Integrating Unmanned Aerial Vehicles (UAVs) into future Intelligent Transportation Systems (ITSs) allows to exploit their unique mobility potentials for improving the performance of services such as near-field parcel delivery, dynamic network provisioning, and aerial sensing. In order to provide a controllable environment for the methodological performance analysis, simulation frameworks need to support ground- and aerial-based mobility as well as the involved communication technologies. In this paper, we present the open source Lightweight ICT-centric Mobility Simulation (LIMoSim) framework for simulating hybrid vehicular networks within Network Simulator 3 (ns-3). LIMoSim implements a shared codebase coupling approach which integrates all required components in a single simulation process. The low-level mobility behaviors rely on well-known analytical models. Different case studies discussing cutting-edge communication technologies such as Cellular Vehicle-to-Everything (C-V2X) and millimeter Wave (mmWave) are presented in order to illustrate how the proposed framework can be integrated into ns-3-based network simulation setups. ",Kein DOI-Link verfügbar,2003.09829v1,Yes,potent(1)
0000-0003-1133-8261,Benjamin Sliwa,TU Dortmund Universität,PARRoT: Predictive Ad-hoc Routing Fueled by Reinforcement Learning and   Trajectory Knowledge,1970,"  Swarms of collaborating Unmanned Aerial Vehicles (UAVs) that utilize ad-hoc networking technologies for coordinating their actions offer the potential to catalyze emerging research fields such as autonomous exploration of disaster areas, demanddriven network provisioning, and near field packet delivery in Intelligent Transportation Systems (ITSs). As these mobile robotic networks are characterized by high grades of relative mobility, existing routing protocols often fail to adopt their decision making to the implied network topology dynamics. For addressing these challenges, we present Predictive Ad-hoc Routing fueled by Reinforcement learning and Trajectory knowledge (PARRoT) as a novel machine learning-enabled routing protocol which exploits mobility control information for integrating knowledge about the future motion of the mobile agents into the routing process. The performance of the proposed routing approach is evaluated using comprehensive network simulation. In comparison to established routing protocols, PARRoT achieves a massively higher robustness and a significantly lower end-to-end latency. ",Kein DOI-Link verfügbar,2012.05490v1,Yes,potent(1)
0000-0003-1133-8261,Benjamin Sliwa,TU Dortmund Universität,LIMITS: Lightweight Machine Learning for IoT Systems with Resource   Limitations,1970,"  Exploiting big data knowledge on small devices will pave the way for building truly cognitive Internet of Things (IoT) systems. Although machine learning has led to great advancements for IoT-based data analytics, there remains a huge methodological gap for the deployment phase of trained machine learning models. For given resource-constrained platforms such as Microcontroller Units (MCUs), model choice and parametrization are typically performed based on heuristics or analytical models. However, these approaches are only able to provide rough estimates of the required system resources as they do not consider the interplay of hardware, compiler specific optimizations, and code dependencies. In this paper, we present the novel open source framework LIghtweight Machine learning for IoT Systems (LIMITS), which applies a platform-in-the-loop approach explicitly considering the actual compilation toolchain of the target IoT platform. LIMITS focuses on high level tasks such as experiment automation, platform-specific code generation, and sweet spot determination. The solid foundations of validated low-level model implementations are provided by the coupled well-established data analysis framework Waikato Environment for Knowledge Analysis (WEKA). We apply and validate LIMITS in two case studies focusing on cellular data rate prediction and radio-based vehicle classification, where we compare different learning models and real world IoT platforms with memory constraints from 16 kB to 4 MB and demonstrate its potential to catalyze the development of machine learning enabled IoT systems. ",Kein DOI-Link verfügbar,2001.10189v1,Yes,potent(1)
0000-0003-1133-8261,Benjamin Sliwa,TU Dortmund Universität,Modeling and Simulation of Reconfigurable Intelligent Surfaces for   Hybrid Aerial and Ground-based Vehicular Communications,1970,"  The requirements of vehicular communications grow with increasing level of automated driving and future applications of intelligent transportation systems (ITS). Beside the ever-increasing need for high capacity radio links, reliability and latency constraints challenge the mobile network supply. While for example the millimeter-wave spectrum and THz-bands offer a vast amount of radio resources, their applicability is limited due to delicate radio channel conditions and signal propagation characteristics. Reconfigurable intelligent surfaces (RISs) as part of smart radio environments (SREs) of future ITS infrastructure promise improved radio link qualities by means of purposeful cultivation of passive reflections. With this, obstructed mmWave or THz beams can be guided around obstacles through RIS reflection paths to improve the otherwise limited coverage. In this article, application use cases of RIS-enhanced vehicular communications are proposed. Beside static deployments of RISs at exterior walls of buildings, unmanned aerial vehicles (UAV) could provide reflection capabilities on demand, while future vehicles could - in a visionary approach - consist of meta-material allowing for their opportunistic utilization within an enriched SRE. Results of a case study based on our multi-scale mobility and network simulation model clearly highlight the potential of RIS deployment for hybrid vehicular communication scenarios. Path loss and outage percentages can be reduced considerably. ",Kein DOI-Link verfügbar,2108.12825v1,Yes,potent(1)
0000-0003-1133-8261,Benjamin Sliwa,TU Dortmund Universität,Machine Learning-Enabled Data Rate Prediction for 5G NSA   Vehicle-to-Cloud Communications,1970,"  In order to satisfy the ever-growing Quality of Service (QoS) requirements of innovative services, cellular communication networks are constantly evolving. Recently, the 5G NonStandalone (NSA) mode has been deployed as an intermediate strategy to deliver high-speed connectivity to early adopters of 5G by incorporating Long Term Evolution (LTE) network infrastructure. In addition to the technological advancements, novel communication paradigms such as anticipatory mobile networking aim to achieve a more intelligent usage of the available network resources through exploitation of context knowledge. For this purpose, novel methods for proactive prediction of the end-to-end behavior are seen as key enablers. In this paper, we present a first empirical analysis of client-based end-to-end data rate prediction for 5G NSA vehicle-to-cloud communications. Although this operation mode is characterized by massive fluctuations of the observed data rate, the results show that conventional machine learning methods can utilize locally acquirable measurements for achieving comparably accurate estimations of the end-to-end behavior. ",Kein DOI-Link verfügbar,2109.04117v1,Yes,innovative(1)
0000-0003-1133-8261,Benjamin Sliwa,TU Dortmund Universität,Car-to-Cloud Communication Traffic Analysis Based on the Common Vehicle   Information Model,1970,"  Although connectivity services have been introduced already today in many of the most recent car models, the potential of vehicles serving as highly mobile sensor platform in the Internet of Things (IoT) has not been sufficiently exploited yet. The European AutoMat project has therefore defined an open Common Vehicle Information Model (CVIM) in combination with a cross-industry, cloud-based big data marketplace. Thereby, vehicle sensor data can be leveraged for the design of entirely new services even beyond traffic-related applications (such as localized weather forecasts). This paper focuses on the prediction of the achievable data rate making use of an analytical model based on empirical measurements. For an in-depth analysis, the CVIM has been integrated in a vehicle traffic simulator to produce CVIM-complaint data streams as a result of the individual behavior of each vehicle (speed, brake activity, steering activity, etc.). In a next step, a simulation of vehicle traffic in a realistically modeled, large-area street network has been used in combination with a cellular Long Term Evolution (LTE) network to determine the cumulated amount of data produced within each network cell. As a result, a new car-to-cloud communication traffic model has been derived, which quantifies the data rate of aggregated car-to-cloud data producible by vehicles depending on the current traffic situations (free flow and traffic jam). The results provide a reference for network planning and resource scheduling for car-to-cloud type services in the context of smart cities. ",https://doi.org/10.1109/VTCSpring.2017.8108664,1802.07475v1,Yes,potent(1)
0000-0003-1133-8261,Benjamin Sliwa,TU Dortmund Universität,Unmanned Aerial Vehicles in Logistics: Efficiency Gains and   Communication Performance of Hybrid Combinations of Ground and Aerial   Vehicles,1970,"  Unmanned Aerial Vehicles (UAVs) have drastically gained popularity in various Intelligent Transportation System (ITS) applications to improve the safety and efficiency of transportation systems. In this context, the combination of ground vehicles, such as delivery trucks, with drones to assist in the last mile pick-up and delivery of the parcels has been recently proposed. While aerial vehicles promise increased efficiency based on flexible routes and parallelized operation, highly reliable wireless communication is also required for the control and coordination of potentially many drones acting in a self-organized way. In this paper, we analyze the improvements procured by drone usage in parcel delivery compared to traditional delivery and propose a simulation framework to further quantify the efficiency gains of the parcel delivery logistics and to analyze the performance of different wireless communications options. To this end, we consider a heterogeneous vehicle routing problem with various constraints. We consider two approaches regarding the dispatching and recovery of drones and evaluate their benefits as opposed to parcel delivery with a classic truck only. Furthermore, we compare two networking technologies for enabling coordination of the self-organizing teams of drones with a realistically modeled environment: one approach relying on base station oriented Long Term Evolution (LTE) vs. a more decentralized Cellular Vehicle-to-Everything (C-V2X) solution. The results show time savings of nearly 40% can be achieved through drone usage and that the negative impact of urban shadowing on network communications in the base station oriented LTE approach can be compensated by leveraging decentralized C-V2X communications ",Kein DOI-Link verfügbar,1910.10451v2,Yes,potent(1)
0000-0003-1133-8261,Benjamin Sliwa,TU Dortmund Universität,Flying Robots for Safe and Efficient Parcel Delivery Within the COVID-19   Pandemic,1970,"  The integration of small-scale Unmanned Aerial Vehicles (UAVs) into Intelligent Transportation Systems (ITSs) will empower novel smart-city applications and services. After the unforeseen outbreak of the COVID-19 pandemic, the public demand for delivery services has multiplied. Mobile robotic systems inherently offer the potential for minimizing the amount of direct human-to-human interactions with the parcel delivery process. The proposed system-of-systems consists of various complex aspects such as assigning and distributing delivery jobs, establishing and maintaining reliable communication links between the vehicles, as well as path planning and mobility control. In this paper, we apply a system-level perspective for identifying key challenges and promising solution approaches for modeling, analysis, and optimization of UAV-aided parcel delivery. We present a system-of-systems model for UAV-assisted parcel delivery to cope with higher capacity requirements induced by the COVID-19. To demonstrate the benefits of hybrid vehicular delivery, we present a case study focusing on the prioritization of time-critical deliveries such as medical goods. The results further confirm that the capacity of traditional delivery fleets can be upgraded with drone usage. Furthermore, we observe that the delay incurred by prioritizing time-critical deliveries can be compensated with drone deployment. Finally, centralized and decentralized communication approaches for data transmission inside hybrid delivery fleets are compared. ",Kein DOI-Link verfügbar,2101.07877v1,Yes,potent(1)
0000-0003-1133-8261,Benjamin Sliwa,TU Dortmund Universität,DRaGon: Mining Latent Radio Channel Information from Geographical Data   Leveraging Deep Learning,1970,"  Radio channel modeling is one of the most fundamental aspects in the process of designing, optimizing, and simulating wireless communication networks. In this field, long-established approaches such as analytical channel models and ray tracing techniques represent the de-facto standard methodologies. However, as demonstrated by recent results, there remains an untapped potential to innovate this research field by enriching model-based approaches with machine learning techniques. In this paper, we present Deep RAdio channel modeling from GeOinformatioN (DRaGon) as a novel machine learning-enabled method for automatic generation of Radio Environmental Maps (REMs) from geographical data. For achieving accurate path loss prediction results, DRaGon combines determining features extracted from a three-dimensional model of the radio propagation environment with raw images of the receiver area within a deep learning model. In a comprehensive performance evaluation and validation campaign, we compare the accuracy of the proposed approach with real world measurements, ray tracing analyses, and well-known channel models. It is found that the combination of expert knowledge from the communications domain and the data analysis capabilities of deep learning allows to achieve a significantly higher prediction accuracy than the reference methods. ",Kein DOI-Link verfügbar,2112.07941v1,Yes,potent(1)
0000-0003-1189-9288,Felix Schleifer,Universität Bayreuth,Frictionless motion of diffuse interfaces by sharp phase-field modeling,1970,"  Diffuse interface descriptions offer many advantages for the modeling of microstructure evolution. However, the numerical representation of moving diffuse interfaces on discrete numerical grids involves spurious grid friction, which limits the overall performance of the model in many respects. Interestingly, this intricate and detrimental effect can be overcome in Finite Difference (FD) and Fast Fourier Transformation (FFT) based implementations by employing the so-called Sharp Phase-Field Method (SPFM). The key idea is to restore the discretization induced broken Translational Invariance (TI) in the discrete phase-field equation by using analytic properties of the equilibrium interface profile. We proof that this method can indeed eliminate spurious grid friction in the three dimensional space. Focussing on homogeneous driving forces, we quantitatively evaluate the impact of spurious grid friction on the overall operational performance of different phase-field models. We show that the SPFM provides superior degrees of interface isotropy with respect to energy and kinetics. The latter property enables the frictionless motion of arbitrarily oriented diffuse interfaces on a fixed 3D grid. ",Kein DOI-Link verfügbar,1910.05180v3,Yes,intricate(1)
0000-0003-1255-2729,Martin Becker,Friedrich Schiller Universität Jena,Measuring Software Performance on Linux,1970,"  Measuring and analyzing the performance of software has reached a high complexity, caused by more advanced processor designs and the intricate interaction between user programs, the operating system, and the processor's microarchitecture. In this report, we summarize our experience about how performance characteristics of software should be measured when running on a Linux operating system and a modern processor. In particular, (1) We provide a general overview about hardware and operating system features that may have a significant impact on timing and how they interact, (2) we identify sources of errors that need to be controlled in order to obtain unbiased measurement results, and (3) we propose a measurement setup for Linux to minimize errors. Although not the focus of this report, we describe the measurement process using hardware performance counters, which can faithfully reflect the real bottlenecks on a given processor. Our experiments confirm that our measurement setup has a large impact on the results. More surprisingly, however, they also suggest that the setup can be negligible for certain analysis methods. Furthermore, we found that our setup maintains significantly better performance under background load conditions, which means it can be used to improve software in high-performance applications. ",Kein DOI-Link verfügbar,1811.01412v2,Yes,intricate(1)
0000-0003-1255-2729,Martin Becker,Friedrich Schiller Universität Jena,Analyzing Features for the Detection of Happy Endings in German Novels,1970,"  With regard to a computational representation of literary plot, this paper looks at the use of sentiment analysis for happy ending detection in German novels. Its focus lies on the investigation of previously proposed sentiment features in order to gain insight about the relevance of specific features on the one hand and the implications of their performance on the other hand. Therefore, we study various partitionings of novels, considering the highly variable concept of ""ending"". We also show that our approach, even though still rather simple, can potentially lead to substantial findings relevant to literary studies. ",Kein DOI-Link verfügbar,1611.09028v1,Yes,potent(1)
0000-0003-1255-2729,Martin Becker,Friedrich Schiller Universität Jena,Redescription Model Mining,1970,"  This paper introduces Redescription Model Mining, a novel approach to identify interpretable patterns across two datasets that share only a subset of attributes and have no common instances. In particular, Redescription Model Mining aims to find pairs of describable data subsets -- one for each dataset -- that induce similar exceptional models with respect to a prespecified model class. To achieve this, we combine two previously separate research areas: Exceptional Model Mining and Redescription Mining. For this new problem setting, we develop interestingness measures to select promising patterns, propose efficient algorithms, and demonstrate their potential on synthetic and real-world data. Uncovered patterns can hint at common underlying phenomena that manifest themselves across datasets, enabling the discovery of possible associations between (combinations of) attributes that do not appear in the same dataset. ",https://doi.org/10.1145/3447548.3467366,2107.04462v1,Yes,potent(1)
0000-0003-1298-5014,Moritz Müller,Technische Universität Bergakademie Freiberg,Global health science leverages established collaboration network to   fight COVID-19,1970,"  How has the science system reacted to the early stages of the COVID-19 pandemic? Here we compare the (growing) international network for coronavirus research with the broader international health science network. Our findings show that, before the outbreak, coronavirus research realized a relatively small and rather peculiar niche within the global health sciences. As a response to the pandemic, the international network for coronavirus research expanded rapidly along the hierarchical structure laid out by the global health science network. Thus, in face of the crisis, the global health science system proved to be structurally stable yet versatile in research. The observed versatility supports optimistic views on the role of science in meeting future challenges. However, the stability of the global core-periphery structure may be worrying, because it reduces learning opportunities and social capital of scientifically peripheral countries -- not only during this pandemic but also in its ""normal"" mode of operation. ",Kein DOI-Link verfügbar,2102.00298v1,Yes,versatile(1)
0000-0003-1477-8625,Nicolai Lang,Universität Stuttgart,Functional completeness of planar Rydberg blockade structures,1970,"  The construction of Hilbert spaces that are characterized by local constraints as the low-energy sectors of microscopic models is an important step towards the realization of a wide range of quantum phases with long-range entanglement and emergent gauge fields. Here we show that planar structures of trapped atoms in the Rydberg blockade regime are functionally complete: Their ground state manifold can realize any Hilbert space that can be characterized by local constraints in the product basis. We introduce a versatile framework, together with a set of provably minimal logic primitives as building blocks, to implement these constraints. As examples, we present lattice realizations of the string-net Hilbert spaces that underlie the surface code and the Fibonacci anyon model. We discuss possible optimizations of planar Rydberg structures to increase their geometrical robustness. ",https://doi.org/10.1103/PhysRevB.108.085138,2301.01508v2,Yes,versatile(1)
0000-0003-1479-9450,Andreas Mayr,Friedrich-Alexander-Universität Erlangen-Nürnberg,"Gradient boosting in Markov-switching generalized additive models for   location, scale and shape",1970,"  We propose a novel class of flexible latent-state time series regression models which we call Markov-switching generalized additive models for location, scale and shape. In contrast to conventional Markov-switching regression models, the presented methodology allows us to model different state-dependent parameters of the response distribution - not only the mean, but also variance, skewness and kurtosis parameters - as potentially smooth functions of a given set of explanatory variables. In addition, the set of possible distributions that can be specified for the response is not limited to the exponential family but additionally includes, for instance, a variety of Box-Cox-transformed, zero-inflated and mixture distributions. We propose an estimation approach based on the EM algorithm, where we use the gradient boosting framework to prevent overfitting while simultaneously performing variable selection. The feasibility of the suggested approach is assessed in simulation experiments and illustrated in a real-data setting, where we model the conditional distribution of the daily average price of energy in Spain over time. ",Kein DOI-Link verfügbar,1710.02385v2,Yes,potent(1)
0000-0003-1479-9450,Andreas Mayr,Friedrich-Alexander-Universität Erlangen-Nürnberg,Ranking evaluation metrics from a group-theoretic perspective,1970,"  Confronted with the challenge of identifying the most suitable metric to validate the merits of newly proposed models, the decision-making process is anything but straightforward. Given that comparing rankings introduces its own set of formidable challenges and the likely absence of a universal metric applicable to all scenarios, the scenario does not get any better. Furthermore, metrics designed for specific contexts, such as for Recommender Systems, sometimes extend to other domains without a comprehensive grasp of their underlying mechanisms, resulting in unforeseen outcomes and potential misuses. Complicating matters further, distinct metrics may emphasize different aspects of rankings, frequently leading to seemingly contradictory comparisons of model results and hindering the trustworthiness of evaluations.   We unveil these aspects in the domain of ranking evaluation metrics. Firstly, we show instances resulting in inconsistent evaluations, sources of potential mistrust in commonly used metrics; by quantifying the frequency of such disagreements, we prove that these are common in rankings. Afterward, we conceptualize rankings using the mathematical formalism of symmetric groups detaching from possible domains where the metrics have been created; through this approach, we can rigorously and formally establish essential mathematical properties for ranking evaluation metrics, essential for a deeper comprehension of the source of inconsistent evaluations. We conclude with a discussion, connecting our theoretical analysis to the practical applications, highlighting which properties are important in each domain where rankings are commonly evaluated. In conclusion, our analysis sheds light on ranking evaluation metrics, highlighting that inconsistent evaluations should not be seen as a source of mistrust but as the need to carefully choose how to evaluate our models in the future. ",Kein DOI-Link verfügbar,2408.16009v1,Yes,potent(2)
0000-0003-1479-9450,Andreas Mayr,Friedrich-Alexander-Universität Erlangen-Nürnberg,VN-EGNN: E(3)-Equivariant Graph Neural Networks with Virtual Nodes   Enhance Protein Binding Site Identification,1970,"  Being able to identify regions within or around proteins, to which ligands can potentially bind, is an essential step to develop new drugs. Binding site identification methods can now profit from the availability of large amounts of 3D structures in protein structure databases or from AlphaFold predictions. Current binding site identification methods heavily rely on graph neural networks (GNNs), usually designed to output E(3)-equivariant predictions. Such methods turned out to be very beneficial for physics-related tasks like binding energy or motion trajectory prediction. However, the performance of GNNs at binding site identification is still limited potentially due to the lack of dedicated nodes that model hidden geometric entities, such as binding pockets. In this work, we extend E(n)-Equivariant Graph Neural Networks (EGNNs) by adding virtual nodes and applying an extended message passing scheme. The virtual nodes in these graphs are dedicated quantities to learn representations of binding sites, which leads to improved predictive performance. In our experiments, we show that our proposed method VN-EGNN sets a new state-of-the-art at locating binding site centers on COACH420, HOLO4K and PDBbind2020. ",Kein DOI-Link verfügbar,2404.07194v1,Yes,potent(2)
0000-0003-1479-9450,Andreas Mayr,Friedrich-Alexander-Universität Erlangen-Nürnberg,Boosting Multivariate Structured Additive Distributional Regression   Models,1970,"  We develop a model-based boosting approach for multivariate distributional regression within the framework of generalized additive models for location, scale, and shape. Our approach enables the simultaneous modeling of all distribution parameters of an arbitrary parametric distribution of a multivariate response conditional on explanatory variables, while being applicable to potentially high-dimensional data. Moreover, the boosting algorithm incorporates data-driven variable selection, taking various different types of effects into account. As a special merit of our approach, it allows for modelling the association between multiple continuous or discrete outcomes through the relevant covariates. After a detailed simulation study investigating estimation and prediction performance, we demonstrate the full flexibility of our approach in three diverse biomedical applications. The first is based on high-dimensional genomic cohort data from the UK Biobank, considering a bivariate binary response (chronic ischemic heart disease and high cholesterol). Here, we are able to identify genetic variants that are informative for the association between cholesterol and heart disease. The second application considers the demand for health care in Australia with the number of consultations and the number of prescribed medications as a bivariate count response. The third application analyses two dimensions of childhood undernutrition in Nigeria as a bivariate response and we find that the correlation between the two undernutrition scores is considerably different depending on the child's age and the region the child lives in. ",Kein DOI-Link verfügbar,2207.08470v1,Yes,potent(1)
0000-0003-1479-9450,Andreas Mayr,Friedrich-Alexander-Universität Erlangen-Nürnberg,Boosting Joint Models for Longitudinal and Time-to-Event Data,1970,"  Joint Models for longitudinal and time-to-event data have gained a lot of attention in the last few years as they are a helpful technique to approach common a data structure in clinical studies where longitudinal outcomes are recorded alongside event times. Those two processes are often linked and the two outcomes should thus be modeled jointly in order to prevent the potential bias introduced by independent modelling. Commonly, joint models are estimated in likelihood based expectation maximization or Bayesian approaches using frameworks where variable selection is problematic and which do not immediately work for high-dimensional data. In this paper, we propose a boosting algorithm tackling these challenges by being able to simultaneously estimate predictors for joint models and automatically select the most influential variables even in high-dimensional data situations. We analyse the performance of the new algorithm in a simulation study and apply it to the Danish cystic fibrosis registry which collects longitudinal lung function data on patients with cystic fibrosis together with data regarding the onset of pulmonary infections. This is the first approach to combine state-of-the art algorithms from the field of machine-learning with the model class of joint models, providing a fully data-driven mechanism to select variables and predictor effects in a unified framework of boosting joint models. ",Kein DOI-Link verfügbar,1609.02686v2,Yes,potent(1)
0000-0003-1479-9450,Andreas Mayr,Friedrich-Alexander-Universität Erlangen-Nürnberg,Large-scale ligand-based virtual screening for SARS-CoV-2 inhibitors   using deep neural networks,1970,"  Due to the current severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic, there is an urgent need for novel therapies and drugs. We conducted a large-scale virtual screening for small molecules that are potential CoV-2 inhibitors. To this end, we utilized ""ChemAI"", a deep neural network trained on more than 220M data points across 3.6M molecules from three public drug-discovery databases. With ChemAI, we screened and ranked one billion molecules from the ZINC database for favourable effects against CoV-2. We then reduced the result to the 30,000 top-ranked compounds, which are readily accessible and purchasable via the ZINC database. Additionally, we screened the DrugBank using ChemAI to allow for drug repurposing, which would be a fast way towards a therapy. We provide these top-ranked compounds of ZINC and DrugBank as a library for further screening with bioassays at https://github.com/ml-jku/sars-cov-inhibitors-chemai. ",Kein DOI-Link verfügbar,2004.00979v3,Yes,potent(1)
0000-0003-1550-8491,Simon Rupp,Universität Ulm,Towards photoassociation processes of ultracold rubidium trimers,1970,"  We theoretically investigate the prospects for photoassociation (PA) of Rb$_3$, in particular at close range. We provide an overview of accessible states and possible transitions. The major focus is placed on the calculation of equilibrium structures, the survey of spin-orbit effects and the investigation of transition dipole moments. Furthermore we discuss Franck-Condon overlaps and special aspects of trimers including the (pseudo) Jahn-Teller effect and the resulting topology of adiabatic potential-energy surfaces. With this we identify concrete and suitable PA transitions to potentially produce long-lived trimer bound states. Calculations are performed using the multireference configuration-interaction method together with a large-core effective core potential and a core-polarization potential with a large uncontracted even-tempered basis set. ",https://doi.org/10.1103/PhysRevA.103.022820,2102.04779v1,Yes,potent(4)
0000-0003-1624-6542,Orkun Furat,Ulm Universität,Mixed moving average field guided learning for spatio-temporal data,1970,"  Influenced mixed moving average fields are a versatile modeling class for spatio-temporal data. However, their predictive distribution is not generally known. Under this modeling assumption, we define a novel spatio-temporal embedding and a theory-guided machine learning approach that employs a generalized Bayesian algorithm to make ensemble forecasts. We use Lipschitz predictors and determine fixed-time and any-time PAC Bayesian bounds in the batch learning setting. Performing causal forecast is a highlight of our methodology as its potential application to data with spatial and temporal short and long-range dependence. We then test the performance of our learning methodology by using linear predictors and data sets simulated from a spatio-temporal Ornstein-Uhlenbeck process. ",Kein DOI-Link verfügbar,2301.00736v4,Yes,"versatile(1), potent(1)"
0000-0003-1652-0185,Max Langer,Albert-Ludwigs-Universität Freiburg,Simulation of diffraction and scattering using the Wigner Distribution   Function,1970,"  X-ray phase-contrast imaging enhances soft tissue visualization by leveraging the phase shift of X-rays passing through materials. It permits to minimize radiation exposure due to high contrast, as well as high resolution imaging limited by the wavelength of the X-rays. Phase retrieval extracts the phase shift computationally, but simulated images fail to recreate low-frequency noise observed in experimental images. To this end, we propose a new method to simulate phase contrast images using the Wigner Distribution Function. This permits the simulation of wave and particle effects simultaneously and simulates images photon by photon. Here, we give a first demonstration of the method by simulating the Gaussian double-slit experiment. It has the potential for realistic simulation of low-dose imaging. ",Kein DOI-Link verfügbar,2403.05684v2,Yes,potent(1)
0000-0003-1675-8548,Vanessa Junk,Universität Regensburg,Floquet oscillations in periodically driven Dirac systems,1970,"  Electrons in a lattice exhibit time-periodic motion, known as Bloch oscillation, when subject to an additional static electric field. Here we show that a corresponding dynamics can occur upon replacing the spatially periodic potential by a time-periodic driving: Floquet oscillations of charge carriers in a spatially homogeneous system. The time lattice of the driving gives rise to Floquet bands that take on the role of the usual Bloch bands. For two different drivings (harmonic driving and periodic kicking through pulses) of systems with linear dispersion we demonstrate the existence of such oscillations, both by directly propagating wave packets and based on a complementary Floquet analysis. The Floquet oscillations feature richer oscillation patterns than their Bloch counterpart and enable the imaging of Floquet bands. Moreover, their period can be directly tuned through the driving frequency. Such oscillations should be experimentally observable in effective Dirac systems, such as graphene, when illuminated with circularly polarized light. ",https://doi.org/10.1103/PhysRevB.101.134302,1906.04446v2,Yes,potent(1)
0000-0003-1803-3196,Thomas Buchner,Universität Regensburg,Replicating Human Anatomy with Vision Controlled Jetting -- A Pneumatic   Musculoskeletal Hand and Forearm,1970,"  The functional replication and actuation of complex structures inspired by nature is a longstanding goal for humanity. Creating such complex structures combining soft and rigid features and actuating them with artificial muscles would further our understanding of natural kinematic structures. We printed a biomimetic hand in a single print process comprised of a rigid skeleton, soft joint capsules, tendons, and printed touch sensors. We showed it's actuation using electric motors. In this work, we expand on this work by adding a forearm that is also closely modeled after the human anatomy and replacing the hand's motors with 22 independently controlled pneumatic artificial muscles (PAMs). Our thin, high-strain (up to 30.1%) PAMs match the performance of state-of-the-art artificial muscles at a lower cost. The system showcases human-like dexterity with independent finger movements, demonstrating successful grasping of various objects, ranging from a small, lightweight coin to a large can of 272g in weight. The performance evaluation, based on fingertip and grasping forces along with finger joint range of motion, highlights the system's potential. ",Kein DOI-Link verfügbar,2404.19077v1,Yes,potent(1)
0000-0003-1803-3196,Thomas Buchner,Universität Regensburg,SoPrA: Fabrication & Dynamical Modeling of a Scalable Soft Continuum   Robotic Arm with Integrated Proprioceptive Sensing,1970,"  Due to their inherent compliance, soft robots are more versatile than rigid linked robots when they interact with their environment, such as object manipulation or biomimetic motion, and considered the key element in introducing robots to everyday environments. Although various soft robotic actuators exist, past research has focused primarily on designing and analyzing single components. Limited effort has been made to combine each component to create an overall capable, integrated soft robot. Ideally, the behavior of such a robot can be accurately modeled, and its motion within an environment uses its proprioception, without requiring external sensors. This work presents a design and modeling process for a Soft continuum Proprioceptive Arm (SoPrA) actuated by pneumatics. The integrated design is suitable for an analytical model due to its internal capacitive flex sensor for proprioceptive measurements and its fiber-reinforced fluidic elastomer actuators. The proposed analytical dynamical model accounts for the inertial effects of the actuator's mass and the material properties, and predicts in real-time the soft robot's behavior. Our estimation method integrates the analytical model with proprioceptive sensors to calculate external forces, all without relying on an external motion capture system. SoPrA is validated in a series of experiments demonstrating the model's and sensor's accuracy in estimation. SoPrA will enable soft arm manipulation including force sensing while operating in obstructed environments that disallows exteroceptive measurements. ",https://doi.org/10.1109/IROS51168.2021.9636539,2103.10726v3,Yes,versatile(1)
0000-0003-1803-3196,Thomas Buchner,Universität Regensburg,Planar Modeling and Sim-to-Real of a Tethered Multimaterial Soft Swimmer   Driven by Peano-HASELs,1970,"  Soft robotics has the potential to revolutionize robotic locomotion, in particular, soft robotic swimmers offer a minimally invasive and adaptive solution to explore and preserve our oceans. Unfortunately, current soft robotic swimmers are vastly inferior to evolved biological swimmers, especially in terms of controllability, efficiency, maneuverability, and longevity. Additionally, the tedious iterative fabrication and empirical testing required to design soft robots has hindered their optimization. In this work, we tackle this challenge by providing an efficient and straightforward pipeline for designing and fabricating soft robotic swimmers equipped with electrostatic actuation. We streamline the process to allow for rapid additive manufacturing, and show how a differentiable simulation can be used to match a simplified model to the real deformation of a robotic swimmer. We perform several experiments with the fabricated swimmer by varying the voltage and actuation frequency of the swimmer's antagonistic muscles. We show how the voltage and frequency vary the locomotion speed of the swimmer while moving in liquid oil and observe a clear optimum in forward swimming speed. The differentiable simulation model we propose has various downstream applications, such as control and shape optimization of the swimmer; optimization results can be directly mapped back to the real robot through our sim-to-real matching. ",https://doi.org/10.1109/IROS47612.2022.9981192,2208.00731v2,Yes,potent(1)
0000-0003-1811-4885,Michael Winkler,Friedrich-Schiller-Universität Jena,A double critical mass phenomenon in a no-flux-Dirichlet Keller-Segel   system,1970,"  Derived from a biophysical model for the motion of a crawling cell, the system \[(*)~\begin{cases}u_t=\Delta u-\nabla\cdot(u\nabla v)\\0=\Delta v-kv+u\end{cases}\] is investigated in a finite domain $\Omega\subset\mathbb{R}^n$, $n\geq2$, with $k\geq0$. While a comprehensive literature is available for cases with $(*)$ describing chemotaxis systems and hence being accompanied by homogeneous Neumann-type boundary conditions, the presently considered modeling context, besides yet requiring the flux $\partial_\nu u-u\partial_\nu v$ to vanish on $\partial\Omega$, inherently involves homogeneous Dirichlet conditions for the attractant $v$, which in the current setting corresponds to the cell's cytoskeleton being free of pressure at the boundary.   This modification in the boundary setting is shown to go along with a substantial change with respect to the potential to support the emergence of singular structures: It is, inter alia, revealed that in contexts of radial solutions in balls there exist two critical mass levels, distinct from each other whenever $k>0$ or $n\geq3$, that separate ranges within which (i) all solutions are global in time and remain bounded, (ii) both global bounded and exploding solutions exist, or (iii) all nontrivial solutions blow up in finite time. While critical mass phenomena distinguishing between regimes of type (i) and (ii) belong to the well-understood characteristics of $(*)$ when posed under classical no-flux boundary conditions in planar domains, the discovery of a distinct secondary critical mass level related to the occurrence of (iii) seems to have no nearby precedent.   In the planar case with the domain being a disk, the analytical results are supplemented with some numerical illustrations, and it is discussed how the findings can be interpreted biophysically for the situation of a cell on a flat substrate. ",Kein DOI-Link verfügbar,2101.06748v1,Yes,potent(1)
0000-0003-1910-6887,Sergey Danilov,Universität Regensburg,Emerging AI-based weather prediction models as downscaling tools,1970,"  The demand for high-resolution information on climate change is critical for accurate projections and decision-making. Presently, this need is addressed through high-resolution climate models or downscaling. High-resolution models are computationally demanding and creating ensemble simulations with them is typically prohibitively expensive. Downscaling methods are more affordable but are typically limited to small regions. This study proposes the use of existing AI-based numerical weather prediction systems (AI-NWP) to perform global downscaling of climate information from low-resolution climate models. Our results demonstrate that AI-NWP initalized from low-resolution initial conditions can develop detailed forecasts closely resembling the resolution of the training data using a one day lead time. We constructed year-long atmospheric fields using AI-NWP forecasts initialized from smoothed ERA5 and low-resolution CMIP6 models. Our analysis for 2-metre temperature indicates that AI-NWP can generate high-quality, long-term datasets and potentially perform bias correction, bringing climate model outputs closer to observed data. The study highlights the potential for off-the-shelf AI-NWP to enhance climate data downscaling, offering a simple and computationally efficient alternative to traditional downscaling techniques. The downscaled data can be used either directly for localized climate information or as boundary conditions for further dynamical downscaling. ",Kein DOI-Link verfügbar,2406.17977v1,Yes,potent(2)
0000-0003-1924-9183,Anna Krause,Julius-Maximilians-Universität Würzburg,Deep Learning for Climate Model Output Statistics,1970,"  Climate models are an important tool for the assessment of prospective climate change effects but they suffer from systematic and representation errors, especially for precipitation. Model output statistics (MOS) reduce these errors by fitting the model output to observational data with machine learning. In this work, we explore the feasibility and potential of deep learning with convolutional neural networks (CNNs) for MOS. We propose the CNN architecture ConvMOS specifically designed for reducing errors in climate model outputs and apply it to the climate model REMO. Our results show a considerable reduction of errors and mostly improved performance compared to three commonly used MOS approaches. ",Kein DOI-Link verfügbar,2012.10394v1,Yes,potent(1)
0000-0003-1996-4777,Max Horn,Technische Universität Kaiserslautern,Group theory in OSCAR,1970,"  OSCAR is an innovative new computer algebra system which combines and extends the power of its four cornerstone systems - GAP (group theory), Singular (algebra and algebraic geometry), Polymake (polyhedral geometry), and Antic (number theory). Assuming little familiarity with the subject, we give an introduction to computations in group theory using OSCAR, as a chapter of the upcoming OSCAR book. ",Kein DOI-Link verfügbar,2404.05871v2,Yes,innovative(1)
0000-0003-1996-4777,Max Horn,Technische Universität Kaiserslautern,Moufang Twin Trees of prime order,1970,  We prove that the unipotent horocyclic group of a Moufang twin tree of prime order is nilpotent of class at most 2. ,Kein DOI-Link verfügbar,1607.04475v1,Yes,potent(2)
0000-0003-1996-4777,Max Horn,Technische Universität Kaiserslautern,Image retrieval outperforms diffusion models on data augmentation,1970,"  Many approaches have been proposed to use diffusion models to augment training datasets for downstream tasks, such as classification. However, diffusion models are themselves trained on large datasets, often with noisy annotations, and it remains an open question to which extent these models contribute to downstream classification performance. In particular, it remains unclear if they generalize enough to improve over directly using the additional data of their pre-training process for augmentation. We systematically evaluate a range of existing methods to generate images from diffusion models and study new extensions to assess their benefit for data augmentation. Personalizing diffusion models towards the target data outperforms simpler prompting strategies. However, using the pre-training data of the diffusion model alone, via a simple nearest-neighbor retrieval procedure, leads to even stronger downstream performance. Our study explores the potential of diffusion models in generating new training data, and surprisingly finds that these sophisticated models are not yet able to beat a simple and strong image retrieval baseline on simple downstream vision tasks. ",Kein DOI-Link verfügbar,2304.10253v2,Yes,potent(1)
0000-0003-1996-4777,Max Horn,Technische Universität Kaiserslautern,Adaptive Slot Attention: Object Discovery with Dynamic Slot Number,1970,"  Object-centric learning (OCL) extracts the representation of objects with slots, offering an exceptional blend of flexibility and interpretability for abstracting low-level perceptual features. A widely adopted method within OCL is slot attention, which utilizes attention mechanisms to iteratively refine slot representations. However, a major drawback of most object-centric models, including slot attention, is their reliance on predefining the number of slots. This not only necessitates prior knowledge of the dataset but also overlooks the inherent variability in the number of objects present in each instance. To overcome this fundamental limitation, we present a novel complexity-aware object auto-encoder framework. Within this framework, we introduce an adaptive slot attention (AdaSlot) mechanism that dynamically determines the optimal number of slots based on the content of the data. This is achieved by proposing a discrete slot sampling module that is responsible for selecting an appropriate number of slots from a candidate list. Furthermore, we introduce a masked slot decoder that suppresses unselected slots during the decoding process. Our framework, tested extensively on object discovery tasks with various datasets, shows performance matching or exceeding top fixed-slot models. Moreover, our analysis substantiates that our method exhibits the capability to dynamically adapt the slot number according to each instance's complexity, offering the potential for further exploration in slot attention research. Project will be available at https://kfan21.github.io/AdaSlot/ ",Kein DOI-Link verfügbar,2406.09196v1,Yes,potent(1)
0000-0003-2004-1806,Matthias Wolf,Universität Würzburg,Electromagnetic lensing using the Aharonov-Bohm effect,1970,"  We demonstrate theoretically and experimentally a new electromagnetic lensing concept using the magnetic vector potential - in a region free of classical electromagnetic fields - via the Aharonov-Bohm effect. This toroid-shaped lens with poloidal current flow allows for electromagnetic lensing which can be tuned to be convex or concave with a spherical aberration coefficient of opposite polarity to its focal length. This new lens combines the advantages of traditional electromagnetic and electrostatic field-based lenses and opens up new possibilities for the optical design of charged-particle systems. More generally, these results demonstrate that the Aharonov-Bohm effect can shape charged particle wavefronts beyond simple step shifts if topologies beyond simple flux lines are considered and supports the physical significance of the magnetic vector potential. ",https://doi.org/10.1088/1367-2630/ad3b31,2301.09980v2,Yes,potent(2)
0000-0003-2004-1806,Matthias Wolf,Universität Würzburg,Evolutionary distances in the twilight zone -- a rational kernel   approach,1970,"  Phylogenetic tree reconstruction is traditionally based on multiple sequence alignments (MSAs) and heavily depends on the validity of this information bottleneck. With increasing sequence divergence, the quality of MSAs decays quickly. Alignment-free methods, on the other hand, are based on abstract string comparisons and avoid potential alignment problems. However, in general they are not biologically motivated and ignore our knowledge about the evolution of sequences. Thus, it is still a major open question how to define an evolutionary distance metric between divergent sequences that makes use of indel information and known substitution models without the need for a multiple alignment. Here we propose a new evolutionary distance metric to close this gap. It uses finite-state transducers to create a biologically motivated similarity score which models substitutions and indels, and does not depend on a multiple sequence alignment. The sequence similarity score is defined in analogy to pairwise alignments and additionally has the positive semi-definite property. We describe its derivation and show in simulation studies and real-world examples that it is more accurate in reconstructing phylogenies than competing methods. The result is a new and accurate way of determining evolutionary distances in and beyond the twilight zone of sequence alignments that is suitable for large datasets. ",https://doi.org/10.1371/journal.pone.0015788,1011.5096v1,Yes,potent(1)
0000-0003-2043-4319,Matthias Knorr,Universität Regensburg,Deep Neural Networks for Approximating Stream Reasoning with C-SPARQL,1970,"  The amount of information produced, whether by newspapers, blogs and social networks, or by monitoring systems, is increasing rapidly. Processing all this data in real-time, while taking into consideration advanced knowledge about the problem domain, is challenging, but required in scenarios where assessing potential risks in a timely fashion is critical. C-SPARQL, a language for continuous queries over streams of RDF data, is one of the more prominent approaches in stream reasoning that provides such continuous inference capabilities over dynamic data that go beyond mere stream processing. However, it has been shown that, in the presence of huge amounts of data, C-SPARQL may not be able to answer queries in time, in particular when the frequency of incoming data is higher than the time required for reasoning with that data. In this paper, we investigate whether reasoning with C-SPARQL can be approximated using Recurrent Neural Networks and Convolutional Neural Networks, two neural network architectures that have been shown to be well-suited for time series forecasting and time series classification, to leverage on their higher processing speed once the network has been trained. We consider a variety of different kinds of queries and obtain overall positive results with high accuracies while improving processing time often by several orders of magnitude. ",Kein DOI-Link verfügbar,2106.08452v2,Yes,potent(1)
0000-0003-2043-4319,Matthias Knorr,Universität Regensburg,Reactive Multi-Context Systems: Heterogeneous Reasoning in Dynamic   Environments,1970,"  Managed multi-context systems (mMCSs) allow for the integration of heterogeneous knowledge sources in a modular and very general way. They were, however, mainly designed for static scenarios and are therefore not well-suited for dynamic environments in which continuous reasoning over such heterogeneous knowledge with constantly arriving streams of data is necessary. In this paper, we introduce reactive multi-context systems (rMCSs), a framework for reactive reasoning in the presence of heterogeneous knowledge sources and data streams. We show that rMCSs are indeed well-suited for this purpose by illustrating how several typical problems arising in the context of stream reasoning can be handled using them, by showing how inconsistencies possibly occurring in the integration of multiple knowledge sources can be handled, and by arguing that the potential non-determinism of rMCSs can be avoided if needed using an alternative, more skeptical well-founded semantics instead with beneficial computational properties. We also investigate the computational complexity of various reasoning problems related to rMCSs. Finally, we discuss related work, and show that rMCSs do not only generalize mMCSs to dynamic settings, but also capture/extend relevant approaches w.r.t. dynamics in knowledge representation and stream reasoning. ",https://doi.org/10.1016/j.artint.2017.11.007,1609.03438v3,Yes,potent(1)
0000-0003-2043-4319,Matthias Knorr,Universität Regensburg,Faster than LASER -- Towards Stream Reasoning with Deep Neural Networks,1970,"  With the constant increase of available data in various domains, such as the Internet of Things, Social Networks or Smart Cities, it has become fundamental that agents are able to process and reason with such data in real time. Whereas reasoning over time-annotated data with background knowledge may be challenging, due to the volume and velocity in which such data is being produced, such complex reasoning is necessary in scenarios where agents need to discover potential problems and this cannot be done with simple stream processing techniques. Stream Reasoners aim at bridging this gap between reasoning and stream processing and LASER is such a stream reasoner designed to analyse and perform complex reasoning over streams of data. It is based on LARS, a rule-based logical language extending Answer Set Programming, and it has shown better runtime results than other state-of-the-art stream reasoning systems. Nevertheless, for high levels of data throughput even LASER may be unable to compute answers in a timely fashion. In this paper, we study whether Convolutional and Recurrent Neural Networks, which have shown to be particularly well-suited for time series forecasting and classification, can be trained to approximate reasoning with LASER, so that agents can benefit from their high processing speed. ",Kein DOI-Link verfügbar,2106.08457v1,Yes,potent(1)
0000-0003-2056-843X,Ferdinand Gleisberg,Universität Ulm,Factorization with a logarithmic energy spectrum of a central potential,1970,  We propose a method to factor numbers based on two interacting bosonic atoms in a central potential where the single-particle spectrum depends logarithmically on the radial quantum numbers of the zero angular momentum states. The bosons initially prepared in the ground state are excited by a sinusoidally time-dependent interaction into a state characterized by the quantum numbers which represent the factors of a number encoded in the frequency of the perturbation. We also discuss the full single-particle spectrum and limitations of our method caused by decoherence. ,https://doi.org/10.12693/APhysPolA.143.S112,2202.08092v1,Yes,potent(1)
0000-0003-2084-633X,Thomas Hahn,Martin-Luther-Universität Halle-Wittenberg,Microscopic understanding of NMR signals by dynamic mean-field theory   for spins,1970,"  A recently developed dynamic mean-field theory for disordered spins (spinDMFT) is shown to capture the spin dynamics of nuclear spins very well. The key quantities are the spin autocorrelations. In order to compute the free induction decay (FID), pair correlations are needed in addition. They can be computed on spin clusters of moderate size which are coupled to the dynamic mean fields determined in a first step by spinDMFT. We dub this versatile approach non-local spinDMFT (nl-spinDMFT). It is a particular asset of nl-spinDMFT that one knows from where the contributions to the FID stem. We illustrate the strengths of nl-spinDMFT in comparison to experimental data for CaF$_2$. Furthermore, spinDMFT provides the dynamic mean fields explaining the FID of the nuclear spins of $^{13}$C in adamantane up to some static noise. The spin Hahn echo in adamantane is free from effects of static noise and agrees excellently with the spinDMFT results without further fitting. ",https://doi.org/10.1016/j.ssnmr.2024.101936,2403.10465v2,Yes,"versatile(1), excellently(1)"
0000-0003-2084-633X,Thomas Hahn,Martin-Luther-Universität Halle-Wittenberg,Diagrammatic quantum Monte Carlo study of an acoustic lattice polaron,1970,"  We present the first approximation free diagrammatic Monte Carlo study of a lattice polaron interacting with an acoustic phonon branch through the deformation potential. Weak and strong coupling regimes are separated by a self-trapping region where quantum resonance between various possible lattice deformations is seen in the ground state properties, spectral function, and optical conductivity. The unique feature of such polaron is the interplay between long- and short wavelength acoustic vibrations creating a composite phonon cloud and leading to persistent self-trapping due to the existence of multiple quasi-stable states. This results in a spectral response whose structure is much more complex than in any of the previously considered polaron models. ",https://doi.org/10.1103/PhysRevB.104.L161111,2104.13344v1,Yes,potent(1)
0000-0003-2168-1776,Dennis Schlippert,Leibniz Universität Hannover,Evaporative cooling from an optical dipole trap in microgravity,1970,"  In recent years, cold atoms could prove their scientific impact not only on ground but in microgravity environments such as the drop tower in Bremen, sounding rockets and parabolic flights. We investigate the preparation of cold atoms in an optical dipole trap, with an emphasis on evaporative cooling under microgravity. Up to $ 1\times10^{6} $ rubidium-87 atoms were optically trapped from a temporarily dark magneto optical trap during free fall in the droptower in Bremen. The efficiency of evaporation is determined to be equal with and without the effect of gravity. This is confirmed using numerical simulations that prove the dimension of evaporation to be three-dimensional in both cases due to the anharmonicity of optical potentials. These findings pave the way towards various experiments on ultra-cold atoms under microgravity and support other existing experiments based on atom chips but with plans for additional optical dipole traps such as the upcoming follow-up missions to current and past spaceborne experiments. ",https://doi.org/10.1103/PhysRevA.101.013634,1909.03800v1,Yes,potent(1)
0000-0003-2168-1776,Dennis Schlippert,Leibniz Universität Hannover,Interference of Clocks: A Quantum Twin Paradox,1970,"  The phase of matter waves depends on proper time and is therefore susceptible to special-relativistic (kinematic) and gravitational (redshift) time dilation. Hence, it is conceivable that atom interferometers measure general-relativistic time-dilation effects. In contrast to this intuition, we show: (i.) Closed light-pulse interferometers without clock transitions during the pulse sequence are not sensitive to gravitational time dilation in a linear potential. (ii.) They can constitute a quantum version of the special-relativistic twin paradox. (iii.) Our proposed experimental geometry for a quantum-clock interferometer isolates this effect. ",https://doi.org/10.1126/sciadv.aax8966,1905.09102v2,Yes,potent(1)
0000-0003-2168-1776,Dennis Schlippert,Leibniz Universität Hannover,Asymmetric Tunneling of Bose-Einstein Condensates,1970,"  In his celebrated textbook, \textit{Quantum Mechanics: Nonrelativistic Theory}, Landau argued that, for single particle systems in 1D, tunneling probability remains the same for a particle incident from the left or the right of a barrier. This left-right symmetry of tunneling probability holds regardless of the shape of the potential barrier. However, there are a variety of known cases that break this symmetry, e.g. when observing composite particles. We computationally (and analytically, in the simplest case) show this breaking of the left-right tunneling symmetry for Bose-Einstein condensates (BEC) in 1D, modelled by the Gross-Pitaevskii equation (GPE). By varying $g$, the parameter of inter-particle interaction in the BEC, we demonstrate that the transition from symmetric ($g=0$) to asymmetric tunneling is a threshold phenomenon. Our computations employ experimentally feasible parameters such that these results may be experimentally demonstrated in the near future. We conclude by suggesting applications of the phenomena to design atomtronic diodes, synthetic gauge fields, Maxwell's demons, and black-hole analogues. ",https://doi.org/10.1088/1361-6455/acae50,2110.15298v4,Yes,potent(1)
0000-0003-2168-1776,Dennis Schlippert,Leibniz Universität Hannover,Gravity field modelling for the Hannover 10m atom interferometer,1970,"  Absolute gravimeters (AG) are used in geodesy, geophysics, and physics for a wide spectrum of applications. Stable gravimetric measurements over timescales from several days to decades are required to provide relevant insight into geophysical processes. Users of AGs participate in comparisons with a metrological reference in order to monitor the temporal stability of the instruments and determine the bias to that reference. However, since no measurement standard of higher-order accuracy currently exists, users of AGs participate in key comparisons led by the CIPM. These comparisons provide the reference values of highest accuracy compared to the calibration against a single AG. The construction of stationary, large scale atom interferometers paves the way towards a new measurement standard in absolute gravimetry used as a reference with a potential stability up to 1 nm/s$^2$ at 1 s integration time. At the Leibniz University Hannover, we are currently building such a very long baseline atom interferometer with a 10 m long interaction zone. The knowledge of local gravity and its gradient along and around the baseline is required to establish the instrument's uncertainty budget and enable transfers of gravimetric measurements to nearby devices for comparison and calibration purposes. We therefore established a control network for relative gravimeters and repeatedly measured its connections during the construction of the atom interferometer. We additionally developed a 3D model of the host building to investigate the self-attraction effect and studied the impact of mass changes due to groundwater hydrology on the gravity field around the reference instrument. The gravitational effect from the building 3D model is in excellent agreement with the latest gravimetric measurement campaign which opens the possibility to transfer gravity values with an uncertainty below the 10 nm/s$^2$ level. ",https://doi.org/10.1007/s00190-020-01451-y,2003.04875v2,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,What do Deep Networks Like to Read?,1970,"  Recent research towards understanding neural networks probes models in a top-down manner, but is only able to identify model tendencies that are known a priori. We propose Susceptibility Identification through Fine-Tuning (SIFT), a novel abstractive method that uncovers a model's preferences without imposing any prior. By fine-tuning an autoencoder with the gradients from a fixed classifier, we are able to extract propensities that characterize different kinds of classifiers in a bottom-up manner. We further leverage the SIFT architecture to rephrase sentences in order to predict the opposing class of the ground truth label, uncovering potential artifacts encoded in the fixed classification model. We evaluate our method on three diverse tasks with four different models. We contrast the propensities of the models as well as reproduce artifacts reported in the literature. ",Kein DOI-Link verfügbar,1909.04547v1,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Annotation Error Detection: Analyzing the Past and Present for a More   Coherent Future,1970,"  Annotated data is an essential ingredient in natural language processing for training and evaluating machine learning models. It is therefore very desirable for the annotations to be of high quality. Recent work, however, has shown that several popular datasets contain a surprising amount of annotation errors or inconsistencies. To alleviate this issue, many methods for annotation error detection have been devised over the years. While researchers show that their approaches work well on their newly introduced datasets, they rarely compare their methods to previous work or on the same datasets. This raises strong concerns on methods' general performance and makes it difficult to asses their strengths and weaknesses. We therefore reimplement 18 methods for detecting potential annotation errors and evaluate them on 9 English datasets for text classification as well as token and span labeling. In addition, we define a uniform evaluation setup including a new formalization of the annotation error detection task, evaluation protocol and general best practices. To facilitate future research and reproducibility, we release our datasets and implementations in an easy-to-use and open source software package. ",Kein DOI-Link verfügbar,2206.02280v2,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,NLPeer: A Unified Resource for the Computational Study of Peer Review,1970,"  Peer review constitutes a core component of scholarly publishing; yet it demands substantial expertise and training, and is susceptible to errors and biases. Various applications of NLP for peer reviewing assistance aim to support reviewers in this complex process, but the lack of clearly licensed datasets and multi-domain corpora prevent the systematic study of NLP for peer review. To remedy this, we introduce NLPeer -- the first ethically sourced multidomain corpus of more than 5k papers and 11k review reports from five different venues. In addition to the new datasets of paper drafts, camera-ready versions and peer reviews from the NLP community, we establish a unified data representation and augment previous peer review datasets to include parsed and structured paper representations, rich metadata and versioning information. We complement our resource with implementations and analysis of three reviewing assistance tasks, including a novel guided skimming task. Our work paves the path towards systematic, multi-faceted, evidence-based study of peer review in NLP and beyond. The data and code are publicly available. ",Kein DOI-Link verfügbar,2211.06651v2,Yes,scholarly(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,How are Prompts Different in Terms of Sensitivity?,1970,"  In-context learning (ICL) has become one of the most popular learning paradigms. While there is a growing body of literature focusing on prompt engineering, there is a lack of systematic analysis comparing the effects of prompts across different models and tasks. To address this gap, we present a comprehensive prompt analysis based on the sensitivity of a function. Our analysis reveals that sensitivity is an unsupervised proxy for model performance, as it exhibits a strong negative correlation with accuracy. We use gradient-based saliency scores to empirically demonstrate how different prompts affect the relevance of input tokens to the output, resulting in different levels of sensitivity. Furthermore, we introduce sensitivity-aware decoding which incorporates sensitivity estimation as a penalty term in the standard greedy decoding. We show that this approach is particularly helpful when information in the input is scarce. Our work provides a fresh perspective on the analysis of prompts, and contributes to a better understanding of the mechanism of ICL. ",Kein DOI-Link verfügbar,2311.07230v2,Yes,fresh(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,"Learning from Emotions, Demographic Information and Implicit User   Feedback in Task-Oriented Document-Grounded Dialogues",1970,"  The success of task-oriented and document-grounded dialogue systems depends on users accepting and enjoying using them. To achieve this, recently published work in the field of Human-Computer Interaction suggests that the combination of considering demographic information, user emotions and learning from the implicit feedback in their utterances, is particularly important. However, these findings have not yet been transferred to the field of Natural Language Processing, where these data are primarily studied separately. Accordingly, no sufficiently annotated dataset is available. To address this gap, we introduce FEDI, the first English dialogue dataset for task-oriented document-grounded dialogues annotated with demographic information, user emotions and implicit feedback. Our experiments with FLAN-T5, GPT-2 and LLaMA-2 show that these data have the potential to improve task completion and the factual consistency of the generated responses and user acceptance. ",Kein DOI-Link verfügbar,2401.09248v1,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Multimodal Large Language Models to Support Real-World Fact-Checking,1970,"  Multimodal large language models (MLLMs) carry the potential to support humans in processing vast amounts of information. While MLLMs are already being used as a fact-checking tool, their abilities and limitations in this regard are understudied. Here is aim to bridge this gap. In particular, we propose a framework for systematically assessing the capacity of current multimodal models to facilitate real-world fact-checking. Our methodology is evidence-free, leveraging only these models' intrinsic knowledge and reasoning capabilities. By designing prompts that extract models' predictions, explanations, and confidence levels, we delve into research questions concerning model accuracy, robustness, and reasons for failure. We empirically find that (1) GPT-4V exhibits superior performance in identifying malicious and misleading multimodal claims, with the ability to explain the unreasonable aspects and underlying motives, and (2) existing open-source models exhibit strong biases and are highly sensitive to the prompt. Our study offers insights into combating false multimodal information and building secure, trustworthy multimodal models. To the best of our knowledge, we are the first to evaluate MLLMs for real-world fact-checking. ",Kein DOI-Link verfügbar,2403.03627v2,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Re3: A Holistic Framework and Dataset for Modeling Collaborative   Document Revision,1970,"  Collaborative review and revision of textual documents is the core of knowledge work and a promising target for empirical analysis and NLP assistance. Yet, a holistic framework that would allow modeling complex relationships between document revisions, reviews and author responses is lacking. To address this gap, we introduce Re3, a framework for joint analysis of collaborative document revision. We instantiate this framework in the scholarly domain, and present Re3-Sci, a large corpus of aligned scientific paper revisions manually labeled according to their action and intent, and supplemented with the respective peer reviews and human-written edit summaries. We use the new data to provide first empirical insights into collaborative document revision in the academic domain, and to assess the capabilities of state-of-the-art LLMs at automating edit analysis and facilitating text-based collaboration. We make our annotation environment and protocols, the resulting data and experimental code publicly available. ",Kein DOI-Link verfügbar,2406.00197v1,Yes,scholarly(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Systematic Task Exploration with LLMs: A Study in Citation Text   Generation,1970,"  Large language models (LLMs) bring unprecedented flexibility in defining and executing complex, creative natural language generation (NLG) tasks. Yet, this flexibility brings new challenges, as it introduces new degrees of freedom in formulating the task inputs and instructions and in evaluating model performance. To facilitate the exploration of creative NLG tasks, we propose a three-component research framework that consists of systematic input manipulation, reference data, and output measurement. We use this framework to explore citation text generation -- a popular scholarly NLP task that lacks consensus on the task definition and evaluation metric and has not yet been tackled within the LLM paradigm. Our results highlight the importance of systematically investigating both task instruction and input configuration when prompting LLMs, and reveal non-trivial relationships between different evaluation metrics used for citation text generation. Additional human generation and human evaluation experiments provide new qualitative insights into the task to guide future research in citation text generation. We make our code and data publicly available. ",Kein DOI-Link verfügbar,2407.04046v1,Yes,scholarly(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,InferAct: Inferring Safe Actions for LLM-Based Agents Through Preemptive   Evaluation and Human Feedback,1970,"  A crucial requirement for deploying LLM-based agents in real-life applications is robustness against risky or irreversible mistakes. However, existing research lacks a focus on the preemptive evaluation of reasoning trajectories performed by LLM agents, leading to a gap in ensuring safe and reliable operations. To explore better solutions, this paper introduces InferAct, a novel approach that leverages the Theory-of-Mind capability of LLMs to proactively detect potential errors before critical actions are executed (e.g., ""buy-now"" in automatic online trading or web shopping). InferAct is also capable of integrating human feedback to prevent irreversible risks and enhance the actor agent's decision-making process. Experiments on three widely used tasks demonstrate the effectiveness of InferAct. The proposed solution presents a novel approach and concrete contributions toward developing LLM agents that can be safely deployed in different environments involving critical decision-making. ",Kein DOI-Link verfügbar,2407.11843v1,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,How to Handle Different Types of Out-of-Distribution Scenarios in   Computational Argumentation? A Comprehensive and Fine-Grained Field Study,1970,"  The advent of pre-trained Language Models (LMs) has markedly advanced natural language processing, but their efficacy in out-of-distribution (OOD) scenarios remains a significant challenge. Computational argumentation (CA), modeling human argumentation processes, is a field notably impacted by these challenges because complex annotation schemes and high annotation costs naturally lead to resources barely covering the multiplicity of available text sources and topics. Due to this data scarcity, generalization to data from uncovered covariant distributions is a common challenge for CA tasks like stance detection or argument classification. This work systematically assesses LMs' capabilities for such OOD scenarios. While previous work targets specific OOD types like topic shifts or OOD uniformly, we address three prevalent OOD scenarios in CA: topic shift, domain shift, and language shift. Our findings challenge the previously asserted general superiority of in-context learning (ICL) for OOD. We find that the efficacy of such learning paradigms varies with the type of OOD. Specifically, while ICL excels for domain shifts, prompt-based fine-tuning surpasses for topic shifts. To sum up, we navigate the heterogeneity of OOD scenarios in CA and empirically underscore the potential of base-sized LMs in overcoming these challenges. ",Kein DOI-Link verfügbar,2309.08316v3,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Before Name-calling: Dynamics and Triggers of Ad Hominem Fallacies in   Web Argumentation,1970,"  Arguing without committing a fallacy is one of the main requirements of an ideal debate. But even when debating rules are strictly enforced and fallacious arguments punished, arguers often lapse into attacking the opponent by an ad hominem argument. As existing research lacks solid empirical investigation of the typology of ad hominem arguments as well as their potential causes, this paper fills this gap by (1) performing several large-scale annotation studies, (2) experimenting with various neural architectures and validating our working hypotheses, such as controversy or reasonableness, and (3) providing linguistic insights into triggers of ad hominem using explainable neural network architectures. ",https://doi.org/10.18653/v1/N18-1036,1802.06613v2,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,CARE: Collaborative AI-Assisted Reading Environment,1970,"  Recent years have seen impressive progress in AI-assisted writing, yet the developments in AI-assisted reading are lacking. We propose inline commentary as a natural vehicle for AI-based reading assistance, and present CARE: the first open integrated platform for the study of inline commentary and reading. CARE facilitates data collection for inline commentaries in a commonplace collaborative reading environment, and provides a framework for enhancing reading with NLP-based assistance, such as text classification, generation or question answering. The extensible behavioral logging allows unique insights into the reading and commenting behavior, and flexible configuration makes the platform easy to deploy in new scenarios. To evaluate CARE in action, we apply the platform in a user study dedicated to scholarly peer review. CARE facilitates the data collection and study of inline commentary in NLP, extrinsic evaluation of NLP assistance, and application prototyping. We invite the community to explore and build upon the open source implementation of CARE. ",Kein DOI-Link verfügbar,2302.12611v1,Yes,scholarly(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Enabling Natural Zero-Shot Prompting on Encoder Models via   Statement-Tuning,1970,"  While Large Language Models (LLMs) exhibit remarkable capabilities in zero-shot and few-shot scenarios, they often require computationally prohibitive sizes. Conversely, smaller Masked Language Models (MLMs) like BERT and RoBERTa achieve state-of-the-art results through fine-tuning but struggle with extending to few-shot and zero-shot settings due to their architectural constraints. Hence, we propose Statement-Tuning, a technique that models discriminative tasks as a set of finite statements and trains an Encoder model to discriminate between the potential statements to determine the label. We do Statement-Tuning on multiple tasks to enable cross-task generalization. Experimental results demonstrate that Statement Tuning achieves competitive performance compared to state-of-the-art LLMs with significantly fewer parameters. Moreover, the study investigates the impact of several design choices on few-shot and zero-shot generalization, revealing that Statement Tuning can achieve sufficient performance with modest training data and benefits from task and statement diversity for unseen task generalizability. ",Kein DOI-Link verfügbar,2404.12897v2,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,$\textit{GeoHard}$: Towards Measuring Class-wise Hardness through   Modelling Class Semantics,1970,"  Recent advances in measuring hardness-wise properties of data guide language models in sample selection within low-resource scenarios. However, class-specific properties are overlooked for task setup and learning. How will these properties influence model learning and is it generalizable across datasets? To answer this question, this work formally initiates the concept of $\textit{class-wise hardness}$. Experiments across eight natural language understanding (NLU) datasets demonstrate a consistent hardness distribution across learning paradigms, models, and human judgment. Subsequent experiments unveil a notable challenge in measuring such class-wise hardness with instance-level metrics in previous works. To address this, we propose $\textit{GeoHard}$ for class-wise hardness measurement by modeling class geometry in the semantic embedding space. $\textit{GeoHard}$ surpasses instance-level metrics by over 59 percent on $\textit{Pearson}$'s correlation on measuring class-wise hardness. Our analysis theoretically and empirically underscores the generality of $\textit{GeoHard}$ as a fresh perspective on data diagnosis. Additionally, we showcase how understanding class-wise hardness can practically aid in improving task learning. ",Kein DOI-Link verfügbar,2407.12512v1,Yes,"notable(1), fresh(1)"
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,GDPR Compliant Collection of Therapist-Patient-Dialogues,1970,"  According to the Global Burden of Disease list provided by the World Health Organization (WHO), mental disorders are among the most debilitating disorders.To improve the diagnosis and the therapy effectiveness in recent years, researchers have tried to identify individual biomarkers. Gathering neurobiological data however, is costly and time-consuming. Another potential source of information, which is already part of the clinical routine, are therapist-patient dialogues. While there are some pioneering works investigating the role of language as predictors for various therapeutic parameters, for example patient-therapist alliance, there are no large-scale studies. A major obstacle to conduct these studies is the availability of sizeable datasets, which are needed to train machine learning models. While these conversations are part of the daily routine of clinicians, gathering them is usually hindered by various ethical (purpose of data usage), legal (data privacy) and technical (data formatting) limitations. Some of these limitations are particular to the domain of therapy dialogues, like the increased difficulty in anonymisation, or the transcription of the recordings. In this paper, we elaborate on the challenges we faced in starting our collection of therapist-patient dialogues in a psychiatry clinic under the General Data Privacy Regulation of the European Union with the goal to use the data for Natural Language Processing (NLP) research. We give an overview of each step in our procedure and point out the potential pitfalls to motivate further research in this field. ",Kein DOI-Link verfügbar,2211.12360v1,Yes,potent(2)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Romanization-based Large-scale Adaptation of Multilingual Language   Models,1970,"  Large multilingual pretrained language models (mPLMs) have become the de facto state of the art for cross-lingual transfer in NLP. However, their large-scale deployment to many languages, besides pretraining data scarcity, is also hindered by the increase in vocabulary size and limitations in their parameter budget. In order to boost the capacity of mPLMs to deal with low-resource and unseen languages, we explore the potential of leveraging transliteration on a massive scale. In particular, we explore the UROMAN transliteration tool, which provides mappings from UTF-8 to Latin characters for all the writing systems, enabling inexpensive romanization for virtually any language. We first focus on establishing how UROMAN compares against other language-specific and manually curated transliterators for adapting multilingual PLMs. We then study and compare a plethora of data- and parameter-efficient strategies for adapting the mPLMs to romanized and non-romanized corpora of 14 diverse low-resource languages. Our results reveal that UROMAN-based transliteration can offer strong performance for many languages, with particular gains achieved in the most challenging setups: on languages with unseen scripts and with limited training data without any vocabulary augmentation. Further analyses reveal that an improved tokenizer based on romanized data can even outperform non-transliteration-based methods in the majority of languages. ",Kein DOI-Link verfügbar,2304.08865v1,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Smelting Gold and Silver for Improved Multilingual AMR-to-Text   Generation,1970,"  Recent work on multilingual AMR-to-text generation has exclusively focused on data augmentation strategies that utilize silver AMR. However, this assumes a high quality of generated AMRs, potentially limiting the transferability to the target task. In this paper, we investigate different techniques for automatically generating AMR annotations, where we aim to study which source of information yields better multilingual results. Our models trained on gold AMR with silver (machine translated) sentences outperform approaches which leverage generated silver AMR. We find that combining both complementary sources of information further improves multilingual AMR-to-text generation. Our models surpass the previous state of the art for German, Italian, Spanish, and Chinese by a large margin. ",Kein DOI-Link verfügbar,2109.03808v1,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Are Emergent Abilities in Large Language Models just In-Context   Learning?,1970,"  Large language models, comprising billions of parameters and pre-trained on extensive web-scale corpora, have been claimed to acquire certain capabilities without having been specifically trained on them. These capabilities, referred to as ""emergent abilities,"" have been a driving force in discussions regarding the potentials and risks of language models. A key challenge in evaluating emergent abilities is that they are confounded by model competencies that arise through alternative prompting techniques, including in-context learning, which is the ability of models to complete a task based on a few examples. We present a novel theory that explains emergent abilities, taking into account their potential confounding factors, and rigorously substantiate this theory through over 1000 experiments. Our findings suggest that purported emergent abilities are not truly emergent, but result from a combination of in-context learning, model memory, and linguistic knowledge. Our work is a foundational step in explaining language model performance, providing a template for their efficient use and clarifying the paradox of their ability to excel in some instances while faltering in others. Thus, we demonstrate that their capabilities should not be overestimated. ",Kein DOI-Link verfügbar,2309.01809v2,Yes,potent(2)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Measuring Pointwise $\mathcal{V}$-Usable Information In-Context-ly,1970,"  In-context learning (ICL) is a new learning paradigm that has gained popularity along with the development of large language models. In this work, we adapt a recently proposed hardness metric, pointwise $\mathcal{V}$-usable information (PVI), to an in-context version (in-context PVI). Compared to the original PVI, in-context PVI is more efficient in that it requires only a few exemplars and does not require fine-tuning. We conducted a comprehensive empirical analysis to evaluate the reliability of in-context PVI. Our findings indicate that in-context PVI estimates exhibit similar characteristics to the original PVI. Specific to the in-context setting, we show that in-context PVI estimates remain consistent across different exemplar selections and numbers of shots. The variance of in-context PVI estimates across different exemplar selections is insignificant, which suggests that in-context PVI are stable. Furthermore, we demonstrate how in-context PVI can be employed to identify challenging instances. Our work highlights the potential of in-context PVI and provides new insights into the capabilities of ICL. ",Kein DOI-Link verfügbar,2310.12300v2,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,One does not fit all! On the Complementarity of Vision Encoders for   Vision and Language Tasks,1970,"  Current multimodal models, aimed at solving Vision and Language (V+L) tasks, predominantly repurpose Vision Encoders (VE) as feature extractors. While many VEs -- of different architectures, trained on different data and objectives -- are publicly available, they are not designed for the downstream V+L tasks. Nonetheless, most current work assumes that a \textit{single} pre-trained VE can serve as a general-purpose encoder. In this work, we focus on analysis and aim to understand whether the information stored within different VEs is complementary, i.e. if providing the model with features from multiple VEs can improve the performance on a target task, and how they are combined. We exhaustively experiment with three popular VEs on six downstream V+L tasks and analyze the attention and VE-dropout patterns. Our analyses suggest that diverse VEs complement each other, resulting in improved downstream V+L task performance, where the improvements are not due to simple ensemble effects (i.e. the performance does not always improve when increasing the number of encoders). We demonstrate that future VEs, which are not \textit{repurposed}, but explicitly \textit{designed} for V+L tasks, have the potential of improving performance on the target V+L tasks. ",Kein DOI-Link verfügbar,2210.06379v2,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,NLP meets psychotherapy: Using predicted client emotions and   self-reported client emotions to measure emotional coherence,1970,"  Emotions are experienced and expressed through various response systems. Coherence between emotional experience and emotional expression is considered important to clients' well being. To date, emotional coherence (EC) has been studied at a single time point using lab-based tasks with relatively small datasets. No study has examined EC between the subjective experience of emotions and emotion expression in therapy or whether this coherence is associated with clients' well being. Natural language Processing (NLP) approaches have been applied to identify emotions from psychotherapy dialogue, which can be implemented to study emotional processes on a larger scale. However, these methods have yet to be used to study coherence between emotional experience and emotional expression over the course of therapy and whether it relates to clients' well-being. This work presents an end-to-end approach where we use emotion predictions from our transformer based emotion recognition model to study emotional coherence and its diagnostic potential in psychotherapy research. We first employ our transformer based approach on a Hebrew psychotherapy dataset to automatically label clients' emotions at utterance level in psychotherapy dialogues. We subsequently investigate the emotional coherence between clients' self-reported emotional states and our model-based emotion predictions. We also examine the association between emotional coherence and clients' well being. Our findings indicate a significant correlation between clients' self-reported emotions and positive and negative emotions expressed verbally during psychotherapy sessions. Coherence in positive emotions was also highly correlated with clients well-being. These results illustrate how NLP can be applied to identify important emotional processes in psychotherapy to improve diagnosis and treatment for clients suffering from mental-health problems. ",Kein DOI-Link verfügbar,2211.12512v1,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Analysis of Automatic Annotation Suggestions for Hard Discourse-Level   Tasks in Expert Domains,1970,"  Many complex discourse-level tasks can aid domain experts in their work but require costly expert annotations for data creation. To speed up and ease annotations, we investigate the viability of automatically generated annotation suggestions for such tasks. As an example, we choose a task that is particularly hard for both humans and machines: the segmentation and classification of epistemic activities in diagnostic reasoning texts. We create and publish a new dataset covering two domains and carefully analyse the suggested annotations. We find that suggestions have positive effects on annotation speed and performance, while not introducing noteworthy biases. Envisioning suggestion models that improve with newly annotated texts, we contrast methods for continuous model adjustment and suggest the most effective setup for suggestions in future expert tasks. ",Kein DOI-Link verfügbar,1906.02564v1,Yes,noteworthy(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Learning to Reason over Scene Graphs: A Case Study of Finetuning GPT-2   into a Robot Language Model for Grounded Task Planning,1970,"  Long-horizon task planning is essential for the development of intelligent assistive and service robots. In this work, we investigate the applicability of a smaller class of large language models (LLMs), specifically GPT-2, in robotic task planning by learning to decompose tasks into subgoal specifications for a planner to execute sequentially. Our method grounds the input of the LLM on the domain that is represented as a scene graph, enabling it to translate human requests into executable robot plans, thereby learning to reason over long-horizon tasks, as encountered in the ALFRED benchmark. We compare our approach with classical planning and baseline methods to examine the applicability and generalizability of LLM-based planners. Our findings suggest that the knowledge stored in an LLM can be effectively grounded to perform long-horizon task planning, demonstrating the promising potential for the future application of neuro-symbolic planning methods in robotics. ",Kein DOI-Link verfügbar,2305.07716v1,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,Problem Solving Through Human-AI Preference-Based Cooperation,1970,"  While there is a widespread belief that artificial general intelligence (AGI) -- or even superhuman AI -- is imminent, complex problems in expert domains are far from being solved. We argue that such problems require human-AI cooperation and that the current state of the art in generative AI is unable to play the role of a reliable partner due to a multitude of shortcomings, including inability to keep track of a complex solution artifact (e.g., a software program), limited support for versatile human preference expression and lack of adapting to human preference in an interactive setting. To address these challenges, we propose HAI-Co2, a novel human-AI co-construction framework. We formalize HAI-Co2 and discuss the difficult open research problems that it faces. Finally, we present a case study of HAI-Co2 and demonstrate its efficacy compared to monolithic generative AI models. ",Kein DOI-Link verfügbar,2408.07461v2,Yes,versatile(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,AdapterHub: A Framework for Adapting Transformers,1970,"  The current modus operandi in NLP involves downloading and fine-tuning pre-trained models consisting of millions or billions of parameters. Storing and sharing such large trained models is expensive, slow, and time-consuming, which impedes progress towards more general and versatile NLP methods that learn from and for many tasks. Adapters -- small learnt bottleneck layers inserted within each layer of a pre-trained model -- ameliorate this issue by avoiding full fine-tuning of the entire model. However, sharing and integrating adapter layers is not straightforward. We propose AdapterHub, a framework that allows dynamic ""stitching-in"" of pre-trained adapters for different tasks and languages. The framework, built on top of the popular HuggingFace Transformers library, enables extremely easy and quick adaptations of state-of-the-art pre-trained models (e.g., BERT, RoBERTa, XLM-R) across tasks and languages. Downloading, sharing, and training adapters is as seamless as possible using minimal changes to the training scripts and a specialized infrastructure. Our framework enables scalable and easy access to sharing of task-specific models, particularly in low-resource scenarios. AdapterHub includes all recent adapter architectures and can be found at https://AdapterHub.ml. ",Kein DOI-Link verfügbar,2007.07779v3,Yes,versatile(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties   Grounded in Math Reasoning Problems,1970,"  While automatic dialogue tutors hold great potential in making education personalized and more accessible, research on such systems has been hampered by a lack of sufficiently large and high-quality datasets. Collecting such datasets remains challenging, as recording tutoring sessions raises privacy concerns and crowdsourcing leads to insufficient data quality. To address this, we propose a framework to generate such dialogues by pairing human teachers with a Large Language Model (LLM) prompted to represent common student errors. We describe how we use this framework to collect MathDial, a dataset of 3k one-to-one teacher-student tutoring dialogues grounded in multi-step math reasoning problems. While models like GPT-3 are good problem solvers, they fail at tutoring because they generate factually incorrect feedback or are prone to revealing solutions to students too early. To overcome this, we let teachers provide learning opportunities to students by guiding them using various scaffolding questions according to a taxonomy of teacher moves. We demonstrate MathDial and its extensive annotations can be used to finetune models to be more effective tutors (and not just solvers). We confirm this by automatic and human evaluation, notably in an interactive setting that measures the trade-off between student solving success and telling solutions. The dataset is released publicly. ",Kein DOI-Link verfügbar,2305.14536v2,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text   Detection,1970,"  The advent of Large Language Models (LLMs) has brought an unprecedented surge in machine-generated text (MGT) across diverse channels. This raises legitimate concerns about its potential misuse and societal implications. The need to identify and differentiate such content from genuine human-generated text is critical in combating disinformation, preserving the integrity of education and scientific fields, and maintaining trust in communication. In this work, we address this problem by introducing a new benchmark based on a multilingual, multi-domain, and multi-generator corpus of MGTs -- M4GT-Bench. The benchmark is compiled of three tasks: (1) mono-lingual and multi-lingual binary MGT detection; (2) multi-way detection where one need to identify, which particular model generated the text; and (3) mixed human-machine text detection, where a word boundary delimiting MGT from human-written content should be determined. On the developed benchmark, we have tested several MGT detection baselines and also conducted an evaluation of human performance. We see that obtaining good performance in MGT detection usually requires an access to the training data from the same domain and generators. The benchmark is available at https://github.com/mbzuai-nlp/M4GT-Bench. ",Kein DOI-Link verfügbar,2402.11175v2,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,"M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box   Machine-Generated Text Detection",1970,"  Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries. However, this has also raised concerns about the potential misuse of such texts in journalism, education, and academia. In this study, we strive to create automated systems that can detect machine-generated texts and pinpoint potential misuse. We first introduce a large-scale benchmark \textbf{M4}, which is a multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Through an extensive empirical study of this dataset, we show that it is challenging for detectors to generalize well on instances from unseen domains or LLMs. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and that there is a lot of room for improvement. We believe that our dataset will enable future research towards more robust approaches to this pressing societal problem. The dataset is available at https://github.com/mbzuai-nlp/M4. ",Kein DOI-Link verfügbar,2305.14902v2,Yes,potent(2)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,What Can Natural Language Processing Do for Peer Review?,1970,"  The number of scientific articles produced every year is growing rapidly. Providing quality control over them is crucial for scientists and, ultimately, for the public good. In modern science, this process is largely delegated to peer review -- a distributed procedure in which each submission is evaluated by several independent experts in the field. Peer review is widely used, yet it is hard, time-consuming, and prone to error. Since the artifacts involved in peer review -- manuscripts, reviews, discussions -- are largely text-based, Natural Language Processing has great potential to improve reviewing. As the emergence of large language models (LLMs) has enabled NLP assistance for many new tasks, the discussion on machine-assisted peer review is picking up the pace. Yet, where exactly is help needed, where can NLP help, and where should it stand aside? The goal of our paper is to provide a foundation for the future efforts in NLP for peer-reviewing assistance. We discuss peer review as a general process, exemplified by reviewing at AI conferences. We detail each step of the process from manuscript submission to camera-ready revision, and discuss the associated challenges and opportunities for NLP assistance, illustrated by existing work. We then turn to the big challenges in NLP for peer review as a whole, including data acquisition and licensing, operationalization and experimentation, and ethical issues. To help consolidate community efforts, we create a companion repository that aggregates key datasets pertaining to peer review. Finally, we issue a detailed call for action for the scientific community, NLP and AI researchers, policymakers, and funding bodies to help bring the research in NLP for peer review forward. We hope that our work will help set the agenda for research in machine-assisted scientific quality control in the age of AI, within the NLP community and beyond. ",Kein DOI-Link verfügbar,2405.06563v1,Yes,potent(1)
0000-0003-2187-7621,Iryna Gurevych,Technische Universität Darmstadt,LLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection,1970,"  The widespread accessibility of large language models (LLMs) to the general public has significantly amplified the dissemination of machine-generated texts (MGTs). Advancements in prompt manipulation have exacerbated the difficulty in discerning the origin of a text (human-authored vs machinegenerated). This raises concerns regarding the potential misuse of MGTs, particularly within educational and academic domains. In this paper, we present $\textbf{LLM-DetectAIve}$ -- a system designed for fine-grained MGT detection. It is able to classify texts into four categories: human-written, machine-generated, machine-written machine-humanized, and human-written machine-polished. Contrary to previous MGT detectors that perform binary classification, introducing two additional categories in LLM-DetectiAIve offers insights into the varying degrees of LLM intervention during the text creation. This might be useful in some domains like education, where any LLM intervention is usually prohibited. Experiments show that LLM-DetectAIve can effectively identify the authorship of textual content, proving its usefulness in enhancing integrity in education, academia, and other domains. LLM-DetectAIve is publicly accessible at https://huggingface.co/spaces/raj-tomar001/MGT-New. The video describing our system is available at https://youtu.be/E8eT_bE7k8c. ",Kein DOI-Link verfügbar,2408.04284v1,Yes,potent(1)
0000-0003-2200-5649,Felix Brandt,Technische Universität Braunschweig,A Robust Characterization of Nash Equilibrium,1970,"  We characterize Nash equilibrium by postulating coherent behavior across varying games. Nash equilibrium is the only solution concept that satisfies the following axioms: (i) strictly dominant actions are played with positive probability, (ii) if a strategy profile is played in two games, it is also played in every convex combination of these games, and (iii) players can shift probability arbitrarily between two indistinguishable actions, and deleting one of these actions has no effect. Our theorem implies that every equilibrium refinement violates at least one of these axioms. Moreover, every solution concept that approximately satisfies these axioms returns approximate Nash equilibria, even in natural subclasses of games, such as two-player zero-sum games, potential games, and graphical games. ",Kein DOI-Link verfügbar,2307.03079v2,Yes,potent(1)
0000-0003-2200-5649,Felix Brandt,Technische Universität Braunschweig,An Image Processing Pipeline for Automated Packaging Structure   Recognition,1970,"  Dispatching and receiving logistics goods, as well as transportation itself, involve a high amount of manual efforts. The transported goods, including their packaging and labeling, need to be double-checked, verified or recognized at many supply chain network points. These processes hold automation potentials, which we aim to exploit using computer vision techniques. More precisely, we propose a cognitive system for the fully automated recognition of packaging structures for standardized logistics shipments based on single RGB images. Our contribution contains descriptions of a suitable system design and its evaluation on relevant real-world data. Further, we discuss our algorithmic choices. ",Kein DOI-Link verfügbar,2009.13824v1,Yes,potent(1)
0000-0003-2200-5649,Felix Brandt,Technische Universität Braunschweig,Balanced Donor Coordination,1970,"  Charity is typically done either by individual donors, who donate money to the charities that they support, or by centralized organizations such as governments or municipalities, which collect the individual contributions and distribute them among a set of charities. On the one hand, individual charity respects the will of the donors but may be inefficient due to a lack of coordination. On the other hand, centralized charity is potentially more efficient but may ignore the will of individual donors. We present a mechanism that combines the advantages of both methods by distributing the contribution of each donor in an efficient way such that no subset of donors has an incentive to redistribute their donations. Assuming Leontief utilities (i.e., each donor is interested in maximizing an individually weighted minimum of all contributions across the charities), our mechanism is group-strategyproof, preference-monotonic, contribution-monotonic, maximizes Nash welfare, and can be computed using convex programming. ",Kein DOI-Link verfügbar,2305.10286v1,Yes,potent(1)
0000-0003-2200-5649,Felix Brandt,Technische Universität Braunschweig,Reaching Individually Stable Coalition Structures,1970,"  The formal study of coalition formation in multi-agent systems is typically realized in the framework of hedonic games, which originate from economic theory. The main focus of this branch of research has been on the existence and the computational complexity of deciding the existence of coalition structures that satisfy various stability criteria. The actual process of forming coalitions based on individual behavior has received little attention. In this paper, we study the convergence of simple dynamics leading to stable partitions in a variety of established classes of hedonic games including anonymous, dichotomous, fractional, and hedonic diversity games. The dynamics we consider is based on individual stability: an agent will join another coalition if she is better off and no member of the welcoming coalition is worse off.   Our results are threefold. First, we identify conditions for the (fast) convergence of our dynamics. To this end, we develop new techniques based on the simultaneous usage of multiple intertwined potential functions and establish a reduction uncovering a close relationship between anonymous hedonic games and hedonic diversity games. Second, we provide elaborate counterexamples determining tight boundaries for the existence of individually stable partitions. Third, we study the computational complexity of problems related to the coalition formation dynamics. In particular, we settle open problems suggested by Bogomolnaia and Jackson (2002), Brandl et al. (2005), and Boehmer and Elkind (2020). ",Kein DOI-Link verfügbar,2211.09571v1,Yes,potent(1)
0000-0003-2256-0829,Siqi Liu,Friedrich Schiller Universität Jena,Simplex Neural Population Learning: Any-Mixture Bayes-Optimality in   Symmetric Zero-sum Games,1970,"  Learning to play optimally against any mixture over a diverse set of strategies is of important practical interests in competitive games. In this paper, we propose simplex-NeuPL that satisfies two desiderata simultaneously: i) learning a population of strategically diverse basis policies, represented by a single conditional network; ii) using the same network, learn best-responses to any mixture over the simplex of basis policies. We show that the resulting conditional policies incorporate prior information about their opponents effectively, enabling near optimal returns against arbitrary mixture policies in a game with tractable best-responses. We verify that such policies behave Bayes-optimally under uncertainty and offer insights in using this flexibility at test time. Finally, we offer evidence that learning best-responses to any mixture policies is an effective auxiliary task for strategic exploration, which, by itself, can lead to more performant populations. ",Kein DOI-Link verfügbar,2205.15879v4,Yes,strategically(1)
0000-0003-2256-0829,Siqi Liu,Friedrich Schiller Universität Jena,Partial measurements of the total field gradient and the field gradient   tensor using an atomic magnetic gradiometer,1970,"  Magnetic gradiometers have wide practical and academic applications, and two important types of field gradient observables are the total field gradient and field gradient tensor. However, measurements of the field gradient tensor have not been the focus of previous researches on atomic magnetic gradiometers. In this work, we develop an atomic magnetic gradiometer based on two separately optically pumped atomic ensembles in a Herriott-cavity-assisted atomic cell. This gradiometer shows versatile operation modes and functions, and we demonstrate them in measurements of both types of field gradient observables. ",https://doi.org/10.1103/PhysRevA.107.043110,2304.01794v1,Yes,versatile(1)
0000-0003-2256-0829,Siqi Liu,Friedrich Schiller Universität Jena,NfgTransformer: Equivariant Representation Learning for Normal-form   Games,1970,"  Normal-form games (NFGs) are the fundamental model of strategic interaction. We study their representation using neural networks. We describe the inherent equivariance of NFGs -- any permutation of strategies describes an equivalent game -- as well as the challenges this poses for representation learning. We then propose the NfgTransformer architecture that leverages this equivariance, leading to state-of-the-art performance in a range of game-theoretic tasks including equilibrium-solving, deviation gain estimation and ranking, with a common approach to NFG representation. We show that the resulting model is interpretable and versatile, paving the way towards deep learning systems capable of game-theoretic reasoning when interacting with humans and with each other. ",Kein DOI-Link verfügbar,2402.08393v1,Yes,versatile(1)
0000-0003-2256-0829,Siqi Liu,Friedrich Schiller Universität Jena,Enhancing NAC-ABE to Support Access Control for mHealth Applications and   Beyond,1970,"  Name-based access control (NAC) over NDN provides fine-grained data confidentiality and access control by encrypting and signing data at the time of data production. NAC utilizes specially crafted naming conventions to define and enforce access control policies. NAC-ABE, an extension to NAC, uses an attribute-based encryption (ABE) scheme to support access control with improved scalability and flexibility. However, existing NAC-ABE libraries are based on ciphertext-policy ABE (CP-ABE), which requires knowledge of the access policy when encrypting data packets. In some applications, including mHealth, the data access policy is unknown at the time of data generation, while data attributes and properties are known. In this paper, we present an extension to the existing NDN-ABE library which can be used by mHealth and other applications to enforce fine-granularity access control in data sharing. We also discuss the challenges we encountered during the application deployment, and remaining open issues together with potential solution directions. ",Kein DOI-Link verfügbar,2311.07299v1,Yes,potent(1)
0000-0003-2256-0829,Siqi Liu,Friedrich Schiller Universität Jena,Evaluating and Personalizing User-Perceived Quality of Text-to-Speech   Voices for Delivering Mindfulness Meditation with Different Physical   Embodiments,1970,"  Mindfulness-based therapies have been shown to be effective in improving mental health, and technology-based methods have the potential to expand the accessibility of these therapies. To enable real-time personalized content generation for mindfulness practice in these methods, high-quality computer-synthesized text-to-speech (TTS) voices are needed to provide verbal guidance and respond to user performance and preferences. However, the user-perceived quality of state-of-the-art TTS voices has not yet been evaluated for administering mindfulness meditation, which requires emotional expressiveness. In addition, work has not yet been done to study the effect of physical embodiment and personalization on the user-perceived quality of TTS voices for mindfulness. To that end, we designed a two-phase human subject study. In Phase 1, an online Mechanical Turk between-subject study (N=471) evaluated 3 (feminine, masculine, child-like) state-of-the-art TTS voices with 2 (feminine, masculine) human therapists' voices in 3 different physical embodiment settings (no agent, conversational agent, socially assistive robot) with remote participants. Building on findings from Phase 1, in Phase 2, an in-person within-subject study (N=94), we used a novel framework we developed for personalizing TTS voices based on user preferences, and evaluated user-perceived quality compared to best-rated non-personalized voices from Phase 1. We found that the best-rated human voice was perceived better than all TTS voices; the emotional expressiveness and naturalness of TTS voices were poorly rated, while users were satisfied with the clarity of TTS voices. Surprisingly, by allowing users to fine-tune TTS voice features, the user-personalized TTS voices could perform almost as well as human voices, suggesting user personalization could be a simple and very effective tool to improve user-perceived quality of TTS voice. ",https://doi.org/10.1145/3568162.3576987,2401.03581v1,Yes,potent(1)
0000-0003-2256-0829,Siqi Liu,Friedrich Schiller Universität Jena,Screen Them All: High-Throughput Pan-Cancer Genetic and Phenotypic   Biomarker Screening from H&E Whole Slide Images,1970,"  Many molecular alterations serve as clinically prognostic or therapy-predictive biomarkers, typically detected using single or multi-gene molecular assays. However, these assays are expensive, tissue destructive and often take weeks to complete. Using AI on routine H&E WSIs offers a fast and economical approach to screen for multiple molecular biomarkers. We present a high-throughput AI-based system leveraging Virchow2, a foundation model pre-trained on 3 million slides, to interrogate genomic features previously determined by an next-generation sequencing (NGS) assay, using 47,960 scanned hematoxylin and eosin (H&E) whole slide images (WSIs) from 38,984 cancer patients. Unlike traditional methods that train individual models for each biomarker or cancer type, our system employs a unified model to simultaneously predict a wide range of clinically relevant molecular biomarkers across cancer types. By training the network to replicate the MSK-IMPACT targeted biomarker panel of 505 genes, it identified 80 high performing biomarkers with a mean AU-ROC of 0.89 in 15 most common cancer types. In addition, 40 biomarkers demonstrated strong associations with specific cancer histologic subtypes. Furthermore, 58 biomarkers were associated with targets frequently assayed clinically for therapy selection and response prediction. The model can also predict the activity of five canonical signaling pathways, identify defects in DNA repair mechanisms, and predict genomic instability measured by tumor mutation burden, microsatellite instability (MSI), and chromosomal instability (CIN). The proposed model can offer potential to guide therapy selection, improve treatment efficacy, accelerate patient screening for clinical trials and provoke the interrogation of new therapeutic targets. ",Kein DOI-Link verfügbar,2408.09554v2,Yes,potent(1)
0000-0003-2256-0829,Siqi Liu,Friedrich Schiller Universität Jena,Griffon: Reasoning about Job Anomalies with Unlabeled Data in   Cloud-based Platforms,1970,"  Microsoft's internal big data analytics platform is comprised of hundreds of thousands of machines, serving over half a million jobs daily, from thousands of users. The majority of these jobs are recurring and are crucial for the company's operation. Although administrators spend significant effort tuning system performance, some jobs inevitably experience slowdowns, i.e., their execution time degrades over previous runs. Currently, the investigation of such slowdowns is a labor-intensive and error-prone process, which costs Microsoft significant human and machine resources, and negatively impacts several lines of businesses. In this work, we present Griffin, a system we built and have deployed in production last year to automatically discover the root cause of job slowdowns. Existing solutions either rely on labeled data (i.e., resolved incidents with labeled reasons for job slowdowns), which is in most cases non-existent or non-trivial to acquire, or on time-series analysis of individual metrics that do not target specific jobs holistically. In contrast, in Griffin we cast the problem to a corresponding regression one that predicts the runtime of a job, and show how the relative contributions of the features used to train our interpretable model can be exploited to rank the potential causes of job slowdowns. Evaluated over historical incidents, we show that Griffin discovers slowdown causes that are consistent with the ones validated by domain-expert engineers, in a fraction of the time required by them. ",https://doi.org/10.1145/3357223.3362716,1908.09048v1,Yes,potent(1)
0000-0003-2256-0829,Siqi Liu,Friedrich Schiller Universität Jena,Code Smells in Machine Learning Systems,1970,"  As Deep learning (DL) systems continuously evolve and grow, assuring their quality becomes an important yet challenging task. Compared to non-DL systems, DL systems have more complex team compositions and heavier data dependency. These inherent characteristics would potentially cause DL systems to be more vulnerable to bugs and, in the long run, to maintenance issues. Code smells are empirically tested as efficient indicators of non-DL systems. Therefore, we took a step forward into identifying code smells, and understanding their impact on maintenance in this comprehensive study. This is the first study on investigating code smells in the context of DL software systems, which helps researchers and practitioners to get a first look at what kind of maintenance modification made and what code smells developers have been dealing with. Our paper has three major contributions. First, we comprehensively investigated the maintenance modifications that have been made by DL developers via studying the evolution of DL systems, and we identified nine frequently occurred maintenance-related modification categories in DL systems. Second, we summarized five code smells in DL systems. Third, we validated the prevalence, and the impact of our newly identified code smells through a mixture of qualitative and quantitative analysis. We found that our newly identified code smells are prevalent and impactful on the maintenance of DL systems from the developer's perspective. ",Kein DOI-Link verfügbar,2203.00803v1,Yes,potent(1)
0000-0003-2256-0829,Siqi Liu,Friedrich Schiller Universität Jena,Virchow: A Million-Slide Digital Pathology Foundation Model,1970,"  The use of artificial intelligence to enable precision medicine and decision support systems through the analysis of pathology images has the potential to revolutionize the diagnosis and treatment of cancer. Such applications will depend on models' abilities to capture the diverse patterns observed in pathology images. To address this challenge, we present Virchow, a foundation model for computational pathology. Using self-supervised learning empowered by the DINOv2 algorithm, Virchow is a vision transformer model with 632 million parameters trained on 1.5 million hematoxylin and eosin stained whole slide images from diverse tissue and specimen types, which is orders of magnitude more data than previous works. The Virchow model enables the development of a pan-cancer detection system with 0.949 overall specimen-level AUC across 17 different cancer types, while also achieving 0.937 AUC on 7 rare cancer types. The Virchow model sets the state-of-the-art on the internal and external image tile level benchmarks and slide level biomarker prediction tasks. The gains in performance highlight the importance of training on massive pathology image datasets, suggesting scaling up the data and network architecture can improve the accuracy for many high-impact computational pathology applications where limited amounts of training data are available. ",Kein DOI-Link verfügbar,2309.07778v5,Yes,potent(1)
0000-0003-2276-9489,Georg Zimmermann,Universität Hohenheim,Small-sample performance and underlying assumptions of a bootstrap-based   inference method for a general analysis of covariance model with possibly   heteroskedastic and nonnormal errors,1970,"  It is well known that the standard F test is severely affected by heteroskedasticity in unbalanced analysis of covariance (ANCOVA) models. Currently available potential remedies for such a scenario are based on heteroskedasticity-consistent covariance matrix estimation (HCCME). However, the HCCME approach tends to be liberal in small samples. Therefore, in the present manuscript, we propose a combination of HCCME and a wild bootstrap technique, with the aim of improving the small-sample performance. We precisely state a set of assumptions for the general ANCOVA model and discuss their practical interpretation in detail, since this issue may have been somewhat neglected in applied research so far. We prove that these assumptions are sufficient to ensure the asymptotic validity of the combined HCCME-wild bootstrap ANCOVA. The results of our simulation study indicate that our proposed test remedies the problems of the ANCOVA F test and its heteroskedasticity-consistent alternatives in small to moderate sample size scenarios. Our test only requires very mild conditions, thus being applicable in a broad range of real-life settings, as illustrated by the detailed discussion of a dataset from preclinical research on spinal cord injury. Our proposed method is ready-to-use and allows for valid hypothesis testing in frequently encountered settings (e.g., comparing group means while adjusting for baseline measurements in a randomized controlled clinical trial). ",https://doi.org/10.1177/0962280218817796,1709.08031v2,Yes,potent(1)
0000-0003-2276-9489,Georg Zimmermann,Universität Hohenheim,Multivariate analysis of covariance when standard assumptions are   violated,1970,"  In applied research, it is often sensible to account for one or several covariates when testing for differences between multivariate means of several groups. However, the ""classical"" parametric multivariate analysis of covariance (MANCOVA) tests (e.g., Wilks' Lambda) are based on quite restrictive assumptions (homoscedasticity and normality of the errors), which might be difficult to justify in small sample size settings. Furthermore, existing potential remedies (e.g., heteroskedasticity-robust approaches) become inappropriate in cases where the covariance matrices are singular. Nevertheless, such scenarios are frequently encountered in the life sciences and other fields, when for example, in the context of standardized assessments, a summary performance measure as well as its corresponding subscales are analyzed. In the present manuscript, we consider a general MANCOVA model, allowing for potentially heteroskedastic and even singular covariance matrices as well as non-normal errors. We combine heteroskedasticity-consistent covariance matrix estimation methods with our proposed modified MANCOVA ANOVA-type statistic (MANCATS) and apply two different bootstrap approaches. We provide the proofs of the asymptotic validity of the respective testing procedures as well as the results from an extensive simulation study, which indicate that especially the parametric bootstrap version of the MANCATS outperforms its competitors in most scenarios, both in terms of type I error rates and power. These considerations are further illustrated and substantiated by examining real-life data from standardized achievement tests. ",https://doi.org/10.1016/j.jmva.2020.104594,1902.10195v1,Yes,potent(2)
0000-0003-2352-0853,Xinran Zhu,Ruhr-Universität Bochum,Understanding Idea Creation in Collaborative Discourse through Networks:   The Joint Attention-Interaction-Creation (AIC) Framework,1970,"  In Computer-Supported Collaborative Learning, ideas generated through collaborative discourse are informative indicators of students' learning and collaboration. Idea creation is a product of emergent and interactive socio-cognitive endeavors. Therefore, analyzing ideas requires capturing contextual information in addition to the ideas themselves. In this paper, we propose the Joint Attention-Interaction-Creation (AIC) framework, which captures important dynamics in collaborative discourse, from attention and interaction to creation. The framework was developed from the networked lens, informed by natural language processing techniques, and inspired by socio-semantic network analysis. A case study was included to exemplify the framework's application in classrooms and to illustrate its potential in broader contexts. ",Kein DOI-Link verfügbar,2305.16262v1,Yes,potent(1)
0000-0003-2368-2000,Hongli Xu,Universität Siegen,A vision based system for underwater docking,1970,"  Autonomous underwater vehicles (AUVs) have been deployed for underwater exploration. However, its potential is confined by its limited on-board battery energy and data storage capacity. This problem has been addressed using docking systems by underwater recharging and data transfer for AUVs. In this work, we propose a vision based framework for underwater docking following these systems. The proposed framework comprises two modules; (i) a detection module which provides location information on underwater docking stations in 2D images captured by an on-board camera, and (ii) a pose estimation module which recovers the relative 3D position and orientation between docking stations and AUVs from the 2D images. For robust and credible detection of docking stations, we propose a convolutional neural network called Docking Neural Network (DoNN). For accurate pose estimation, a perspective-n-point algorithm is integrated into our framework. In order to examine our framework in underwater docking tasks, we collected a dataset of 2D images, named Underwater Docking Images Dataset (UDID), in an experimental water pool. To the best of our knowledge, UDID is the first publicly available underwater docking dataset. In the experiments, we first evaluate performance of the proposed detection module on UDID and its deformed variations. Next, we assess the accuracy of the pose estimation module by ground experiments, since it is not feasible to obtain true relative position and orientation between docking stations and AUVs under water. Then, we examine the pose estimation module by underwater experiments in our experimental water pool. Experimental results show that the proposed framework can be used to detect docking stations and estimate their relative pose efficiently and successfully, compared to the state-of-the-art baseline systems. ",Kein DOI-Link verfügbar,1712.04138v1,Yes,potent(1)
0000-0003-2388-0613,Bogdan-Vasile Matioc,Universität Regensburg,The Mullins-Sekerka problem via the method of potentials,1970,"  It is shown that the two-dimensional Mullins-Sekerka problem is well-posed in all subcritical Sobolev spaces $H^r(\mathbb{R})$ with $r\in(3/2,2).$ This is the first result where this issue is established in an unbounded geometry. The novelty of our approach is the use of potential theory to formulate the model as an evolution problem with nonlinearities expressed by singular integral operators. ",Kein DOI-Link verfügbar,2308.06083v1,Yes,potent(1)
0000-0003-2388-0613,Bogdan-Vasile Matioc,Universität Regensburg,Two-phase Stokes flow by capillarity in the plane: The case of different   viscosities,1970,"  We study the two-phase Stokes flow driven by surface tension for two fluids of different viscosities, separated by an asymptotically flat interface representable as graph of a differentiable function. The flow is assumed to be two-dimensional with the fluids filling the entire space. We prove well-posedness and parabolic smoothing in Sobolev spaces up to critical regularity. The main technical tools are an analysis of nonlinear singular integral operators arising from the hydrodynamic single and double layer potential, spectral results on the corresponding integral operators, and abstract results on nonlinear parabolic evolution equations. ",Kein DOI-Link verfügbar,2102.12814v1,Yes,potent(1)
0000-0003-2388-0613,Bogdan-Vasile Matioc,Universität Regensburg,Two-phase Stokes flow by capillarity in full 2D space: an approach via   hydrodynamic potentials,1970,"  We study the two-phase Stokes flow driven by surface tension with two fluids of equal viscosity, separated by an asymptotically flat interface with graph geometry. The flow is assumed to be two-dimensional with the fluids filling the entire space. We prove well-posedness and parabolic smoothing in Sobolev spaces up to critical regularity. The main technical tools are an analysis of nonlinear singular integral operators arising from the hydrodynamic single-layer potential and abstract results on nonlinear parabolic evolution equations. ",Kein DOI-Link verfügbar,2003.14010v2,Yes,potent(1)
0000-0003-2388-0613,Bogdan-Vasile Matioc,Universität Regensburg,Well-posedness and stability for the two-phase periodic quasistationary   Stokes flow,1970,"  The two-phase horizontally periodic quasistationary Stokes flow in $\mathbb{R}^2$, describing the motion of two immiscible fluids with equal viscosities that are separated by a sharp interface, which is parameterized as the graph of a function $f=f(t)$, is considered in the general case when both gravity and surface tension effects are included. Using potential theory, the moving boundary problem is formulated as a fully nonlinear and nonlocal parabolic problem for the function $f$. Based on abstract parabolic theory, it is proven that the problem is well-posed in all subcritical spaces $\mathrm{H}^r(\mathbb{S})$, $r\in(3/2,2)$. Moreover, the stability properties of the flat equilibria are analyzed in dependence on the physical properties of the fluids. ",Kein DOI-Link verfügbar,2406.07181v1,Yes,potent(1)
0000-0003-2481-364X,Christian Elbracht,Universität Hamburg,Clustering with Tangles: Algorithmic Framework and Theoretical   Guarantees,1970,"  Originally, tangles were invented as an abstract tool in mathematical graph theory to prove the famous graph minor theorem. In this paper, we showcase the practical potential of tangles in machine learning applications. Given a collection of cuts of any dataset, tangles aggregate these cuts to point in the direction of a dense structure. As a result, a cluster is softly characterized by a set of consistent pointers. This highly flexible approach can solve clustering problems in various setups, ranging from questionnaires over community detection in graphs to clustering points in metric spaces. The output of our proposed framework is hierarchical and induces the notion of a soft dendrogram, which can help explore the cluster structure of a dataset. The computational complexity of aggregating the cuts is linear in the number of data points. Thus the bottleneck of the tangle approach is to generate the cuts, for which simple and fast algorithms form a sufficient basis. In our paper we construct the algorithmic framework for clustering with tangles, prove theoretical guarantees in various settings, and provide extensive simulations and use cases. Python code is available on github. ",Kein DOI-Link verfügbar,2006.14444v3,Yes,potent(1)
0000-0003-2484-3830,Janosch Moos,TU Darmstadt,Learning to Play Foosball: System and Baselines,1970,"  This work stages Foosball as a versatile platform for advancing scientific research, particularly in the realm of robot learning. We present an automated Foosball table along with its corresponding simulated counterpart, showcasing a diverse range of challenges through example tasks within the Foosball environment. Initial findings are shared using a simple baseline approach. Foosball constitutes a versatile learning environment with the potential to yield cutting-edge research in various fields of artificial intelligence and machine learning, notably robust learning, while also extending its applicability to industrial robotics and automation setups. To transform our physical Foosball table into a research-friendly system, we augmented it with a 2 degrees of freedom kinematic chain to control the goalkeeper rod as an initial setup with the intention to be extended to the full game as soon as possible. Our experiments reveal that a realistic simulation is essential for mastering complex robotic tasks, yet translating these accomplishments to the real system remains challenging, often accompanied by a performance decline. This emphasizes the critical importance of research in this direction. In this concern, we spotlight the automated Foosball table as an invaluable tool, possessing numerous desirable attributes, to serve as a demanding learning environment for advancing robotics and automation research. ",Kein DOI-Link verfügbar,2407.16606v1,Yes,"versatile(2), invaluable(1), potent(1)"
0000-0003-2609-0844,Reza Safari,Universität Hamburg,Analytic Structure of all Loop Banana Amplitudes,1970,"  Using the Gelfand-Kapranov-Zelevinsk\u{\i} system for the primitive cohomology of an infinite series of complete intersection Calabi-Yau manifolds, whose dimension is the loop order minus one, we completely clarify the analytic structure of all banana amplitudes with arbitrary masses. In particular, we find that the leading logarithmic structure in the high energy regime, which corresponds to the point of maximal unipotent monodromy, is determined by a novel $\widehat \Gamma$-class evaluation in the ambient spaces of the mirror, while the imaginary part of the amplitude in this regime is determined by the $\widehat \Gamma$-class of the mirror Calabi-Yau manifold itself. We provide simple closed all loop formulas for the former as well as for the Frobenius $\kappa$-constants, which determine the behaviour of the amplitudes, when the momentum square equals the sum of the masses squared, in terms of zeta values. We extend our previous work from three to four loops by providing for the latter case a complete set of (inhomogenous) Picard-Fuchs differential equations for arbitrary masses. This allows to evaluate the amplitude as well as other master integrals with raised powers of the propagators in very short time to very high numerical precision for all values of the physical parameters. Using a recent $p$-adic analysis of the periods we determine the value of the maximal cut equal mass four-loop amplitude at the attractor points in terms of periods of modular weight two and four Hecke eigenforms and the quasiperiods of their meromorphic cousins. ",https://doi.org/10.1007/JHEP05(2021)066,2008.10574v3,Yes,potent(1)
0000-0003-2627-3763,Oliver Witzel,Universität Siegen,Gradient flow step-scaling function for SU(3) with $N_f$ = 6 or 4   fundamental flavors,1970,"  Nonperturbative determinations of the renormalization group (RG) $\beta$ function are crucial to understand properties of gauge-fermion systems at strong coupling and connect lattice simulations and the perturbative ultraviolet regime. Choosing well-understood, QCD-like systems with SU(3) gauge group and either six or four fundamental flavors, we investigate their step-scaling $\beta$ function. In both cases we push the simulations to the boundary of chiral symmetry breaking and study the regime $g^2_{GF} \lesssim 8.2$ with six, and $g^2_{GF} \lesssim 6.6$ with four flavors. We carefully consider the lattice discretization errors by comparing three different gradient flows (GF), and for each flow three operators to estimate the renormalized finite volume coupling. We also consider the tree level improvement of the coupling. Noteworthy outcome is that nonperturbatively determined $\beta$ functions run much slower than perturbatively predicted. ",https://doi.org/10.1103/PhysRevD.106.114509,2209.14224v1,Yes,noteworthy(1)
0000-0003-2627-3763,Oliver Witzel,Universität Siegen,Direct Detection of Stealth Dark Matter through Electromagnetic   Polarizability,1970,"  We calculate the spin-independent scattering cross section for direct detection that results from the electromagnetic polarizability of a composite scalar baryon dark matter candidate -- ""Stealth Dark Matter"", that is based on a dark SU(4) confining gauge theory. In the nonrelativistic limit, electromagnetic polarizability proceeds through a dimension-7 interaction leading to a very small scattering cross section for dark matter with weak scale masses. This represents a lower bound on the scattering cross section for composite dark matter theories with electromagnetically charged constituents. We carry out lattice calculations of the polarizability for the lightest baryons in SU(3) and SU(4) gauge theories using the background field method on quenched configurations. We find the polarizabilities of SU(3) and SU(4) to be comparable (within about 50%) normalized to the baryon mass, which is suggestive for extensions to larger SU(N) groups. The resulting scattering cross sections with a xenon target are shown to be potentially detectable in the dark matter mass range of about 200-700 GeV, where the lower bound is from the existing LUX constraint while the upper bound is the coherent neutrino background. Significant uncertainties in the cross section remain due to the more complicated interaction of the polarizablity operator with nuclear structure, however the steep dependence on the dark matter mass, $1/m_B^6$, suggests the observable dark matter mass range is not appreciably modified. We briefly highlight collider searches for the mesons in the theory as well as the indirect astrophysical effects that may also provide excellent probes of stealth dark matter. ",https://doi.org/10.1103/PhysRevLett.115.171803,1503.04205v2,Yes,potent(1)
0000-0003-2659-6167,Michael Stolz,Universität Tübingen,A novel model-based heuristic for energy optimal motion planning for   automated driving,1970,"  Predictive motion planning is the key to achieve energy-efficient driving, which is one of the main benefits of automated driving. Researchers have been studying the planning of velocity trajectories, a simpler form of motion planning, for over a decade now and many different methods are available. Dynamic programming has shown to be the most common choice due to its numerical background and ability to include nonlinear constraints and models. Although planning of an optimal trajectory is done in a systematic way, dynamic programming does not use any knowledge about the considered problem to guide the exploration and therefore explores all possible trajectories.   A* is a search algorithm which enables using knowledge about the problem to guide the exploration to the most promising solutions first. Knowledge has to be represented in a form of a heuristic function, which gives an optimistic estimate of cost for transitioning to the final state, which is not a straightforward task. This paper presents a novel heuristics incorporating air drag and auxiliary power as well as operational costs of the vehicle, besides kinetic and potential energy and rolling resistance known in the literature. Furthermore, optimal cruising velocity, which depends on vehicle aerodynamic properties and auxiliary power, is derived. Results are compared for different variants of heuristic functions and dynamic programming as well. ",https://doi.org/10.1016/j.ifacol.2018.07.042,1712.03719v2,Yes,potent(1)
0000-0003-2707-4678,Fabian Scheuermann,Heidelberg Universität,The PHANGS-MUSE survey -- Probing the chemo-dynamical evolution of disc   galaxies,1970,"  We present the PHANGS-MUSE survey, a programme using the MUSE IFS at the ESO VLT to map 19 massive $(9.4 < \log(M_{*}/M_\odot) < 11.0)$ nearby (D < 20 Mpc) star-forming disc galaxies. The survey consists of 168 MUSE pointings (1'x1' each), a total of nearly 15 Million spectra, covering ~1.5 Million independent spectra. PHANGS-MUSE provides the first IFS view of star formation across different local environments (including galaxy centres, bars, spiral arms) in external galaxies at a median resolution of 50~pc, better than the mean inter-cloud distance in the ionised interstellar medium. This `cloud-scale' resolution allows detailed demographics and characterisations of HII regions and other ionised nebulae. PHANGS-MUSE further delivers a unique view on the associated gas and stellar kinematics, and provides constraints on the star formation history. The PHANGS-MUSE survey is complemented by dedicated ALMA CO(2-1) and multi-band HST observations, therefore allowing us to probe the key stages of the star formation process from molecular clouds to HII regions and star clusters. This paper describes the scientific motivation, sample selection, observational strategy, data reduction and analysis process of the PHANGS-MUSE survey. We present our bespoke automated data-reduction framework, which is built on the reduction recipes provided by ESO, but additionally allows for mosaicking and homogenisation of the point spread function. We further present a detailed quality assessment and a brief illustration of the potential scientific applications of the large set of PHANGS-MUSE data products generated by our data analysis framework. The data cubes and analysis data products described in this paper represent the basis for the first PHANGS-MUSE public data release and are available in the ESO archive and via the Canadian Astronomy Data Centre. ",https://doi.org/10.1051/0004-6361/202141727,2110.03708v2,Yes,potent(1)
0000-0003-2714-4293,Matthias Laschke,Universität Siegen,Beyond Efficiency and Convenience. Using Post-growth Values as a Nucleus   to Transform Design Education and Society,1970,"  In this position paper we present Municipan, an artefact resulting from a post-growth design experiment, applied in a student design project. In contrast to mainstream human-centered design directed at efficiency and convenience, which we argue leads to deskilling, dependency, and the progression of the climate crisis, we challenged students to envision an opposite user that is willing to invest time and effort and learn new skills. While Municipan is not a direct step towards a postgrowth society, integrating the way it was created in design education can act as a nucleus, bringing forth design professionals inclined to create technologies with potential to gradually transform society towards postgrowth living. Bringing in examples from our own research, we illustrate that designs created in this mindset, such as heating systems that train cold resistance, or navigation systems that train orientation have potential to reskill users, reduce technological dependency and steer consumption within planetary limits. ",Kein DOI-Link verfügbar,2404.17264v1,Yes,potent(2)
0000-0003-2844-0465,Jürgen Pichen,Universität Ulm,Manipulating Drivers' Mental Workload: Neuroergonomic Evaluation of the   Speed Regulation N-Back Task Using NASA-TLX and Auditory P3a,1970,"  Manipulating MW in driving simulator studies without the need to introduce a non-driving-related task remains challenging. This study aims to empirically evaluate the modified speed regulation n-back task, a tool to manipulate drivers' MW. Our experiment involved 23 participants who experienced a 0-back and 2-back driving condition, with task-irrelevant novel environmental sounds used to elicit P3a event-related potentials. Results indicate that the 2-back condition was perceived as more demanding, evidenced by higher NASA-TLX scores (overall score, mental and temporal demand, effort, frustration). The mean P3a amplitude was diminished during the 2-back condition compared to the 0-back condition, suggesting that drivers experienced higher MW and had fewer resources available to process the novel environmental sounds. This study provides empirical evidence indicating that the speed regulation n-back task could be a valid, effective, and reproducible method to manipulate MW in driving research. ",https://doi.org/10.1145/3581961.3609887,2405.18099v1,Yes,potent(1)
0000-0003-2919-3160,Kevin Lam,Universität Regensburg,LegendreTron: Uprising Proper Multiclass Loss Learning,1970,"  Loss functions serve as the foundation of supervised learning and are often chosen prior to model development. To avoid potentially ad hoc choices of losses, statistical decision theory describes a desirable property for losses known as \emph{properness}, which asserts that Bayes' rule is optimal. Recent works have sought to \emph{learn losses} and models jointly. Existing methods do this by fitting an inverse canonical link function which monotonically maps $\mathbb{R}$ to $[0,1]$ to estimate probabilities for binary problems. In this paper, we extend monotonicity to maps between $\mathbb{R}^{C-1}$ and the projected probability simplex $\tilde{\Delta}^{C-1}$ by using monotonicity of gradients of convex functions. We present {\sc LegendreTron} as a novel and practical method that jointly learns \emph{proper canonical losses} and probabilities for multiclass problems. Tested on a benchmark of domains with up to 1,000 classes, our experimental results show that our method consistently outperforms the natural multiclass baseline under a $t$-test at 99% significance on all datasets with greater than 10 classes. ",Kein DOI-Link verfügbar,2301.11695v3,Yes,potent(1)
0000-0003-3111-0811,David Martin,Universität Leipzig,AOUP in the presence of Brownian noise: a perturbative approach,1970,"  By working in the small persistence time limit, we determine the steady-state distribution of an Active Ornstein Uhlenbeck Particle (AOUP) experiencing, in addition to self-propulsion, a Gaussian white noise modelling a bath at temperature T. This allows us to derive analytical formulas for three quantities: the spatial density of a confined particle, the current induced by an asymmetric periodic potential and the entropy production rate. These formulas disentangle the respective roles of the passive and active noises on the steady state of AOUPs, showing that signatures of non-equilibrium can display surprising behaviors as the temperature is varied. Indeed, depending on the potential in which the particle evolves, both the current and the entropy production rate can be non-monotonic functions of T. The latter can even diverge at high temperature for steep enough confining potentials. Thus, depending on context, switching on translational diffusion may drive the particle closer to or further away from equilibrium. We then probe the range of validity of our quantitative derivations by numerical simulations. Finally, we explain how the method presented here to tackle perturbatively an Ornstein Uhlenbeck (OU) noise could be further generalized beyond the Brownian case. ",https://doi.org/10.1088/1742-5468/abefe2,2009.13476v3,Yes,potent(3)
0000-0003-3111-0811,David Martin,Universität Leipzig,Learning Self-Awareness for Autonomous Vehicles: Exploring Multisensory   Incremental Models,1970,"  The technology for autonomous vehicles is close to replacing human drivers by artificial systems endowed with high-level decision-making capabilities. In this regard, systems must learn about the usual vehicle's behavior to predict imminent difficulties before they happen. An autonomous agent should be capable of continuously interacting with multi-modal dynamic environments while learning unseen novel concepts. Such environments are not often available to train the agent on it, so the agent should have an understanding of its own capacities and limitations. This understanding is usually called self-awareness. This paper proposes a multi-modal self-awareness modeling of signals coming from different sources. This paper shows how different machine learning techniques can be used under a generic framework to learn single modality models by using Dynamic Bayesian Networks. In the presented case, a probabilistic switching model and a bank of generative adversarial networks are employed to model a vehicle's positional and visual information respectively. Our results include experiments performed on a real vehicle, highlighting the potentiality of the proposed approach at detecting abnormalities in real scenarios. ",https://doi.org/10.1109/TITS.2020.2984735,2004.10049v1,Yes,potent(1)
0000-0003-3125-8605,Sarah Grube,Hamburg Universität für Technologie,PolypNextLSTM: A lightweight and fast polyp video segmentation network   using ConvNext and ConvLSTM,1970,"  Commonly employed in polyp segmentation, single image UNet architectures lack the temporal insight clinicians gain from video data in diagnosing polyps. To mirror clinical practices more faithfully, our proposed solution, PolypNextLSTM, leverages video-based deep learning, harnessing temporal information for superior segmentation performance with the least parameter overhead, making it possibly suitable for edge devices. PolypNextLSTM employs a UNet-like structure with ConvNext-Tiny as its backbone, strategically omitting the last two layers to reduce parameter overhead. Our temporal fusion module, a Convolutional Long Short Term Memory (ConvLSTM), effectively exploits temporal features. Our primary novelty lies in PolypNextLSTM, which stands out as the leanest in parameters and the fastest model, surpassing the performance of five state-of-the-art image and video-based deep learning models. The evaluation of the SUN-SEG dataset spans easy-to-detect and hard-to-detect polyp scenarios, along with videos containing challenging artefacts like fast motion and occlusion. Comparison against 5 image-based and 5 video-based models demonstrates PolypNextLSTM's superiority, achieving a Dice score of 0.7898 on the hard-to-detect polyp test set, surpassing image-based PraNet (0.7519) and video-based PNSPlusNet (0.7486). Notably, our model excels in videos featuring complex artefacts such as ghosting and occlusion. PolypNextLSTM, integrating pruned ConvNext-Tiny with ConvLSTM for temporal fusion, not only exhibits superior segmentation performance but also maintains the highest frames per speed among evaluated models. Access code here https://github.com/mtec-tuhh/PolypNextLSTM ",Kein DOI-Link verfügbar,2402.11585v3,Yes,strategically(1)
0000-0003-3158-2624,Shivam Agarwal,Universität Duisburg-Essen,"Cryptocurrency Bubble Detection: A New Stock Market Dataset, Financial   Task & Hyperbolic Models",1970,"  The rapid spread of information over social media influences quantitative trading and investments. The growing popularity of speculative trading of highly volatile assets such as cryptocurrencies and meme stocks presents a fresh challenge in the financial realm. Investigating such ""bubbles"" - periods of sudden anomalous behavior of markets are critical in better understanding investor behavior and market dynamics. However, high volatility coupled with massive volumes of chaotic social media texts, especially for underexplored assets like cryptocoins pose a challenge to existing methods. Taking the first step towards NLP for cryptocoins, we present and publicly release CryptoBubbles, a novel multi-span identification task for bubble detection, and a dataset of more than 400 cryptocoins from 9 exchanges over five years spanning over two million tweets. Further, we develop a set of sequence-to-sequence hyperbolic models suited to this multi-span identification task based on the power-law dynamics of cryptocurrencies and user behavior on social media. We further test the effectiveness of our models under zero-shot settings on a test set of Reddit posts pertaining to 29 ""meme stocks"", which see an increase in trade volume due to social media hype. Through quantitative, qualitative, and zero-shot analyses on Reddit and Twitter spanning cryptocoins and meme-stocks, we show the practical applicability of CryptoBubbles and hyperbolic models. ",Kein DOI-Link verfügbar,2206.06320v1,Yes,fresh(1)
0000-0003-3228-6069,Art J. R. Pelling,Technische Universität Berlin,Snapshot-driven Rational Interpolation of Parametric Systems,1970,"  Parametric data-driven modeling is relevant for many applications in which the model depends on parameters that can potentially vary in both space and time. In this paper, we present a method to obtain a global parametric model based on snapshots of the parameter space. The parameter snapshots are interpolated using the classical univariate Loewner framework and the global bivariate transfer function is extracted using a linear fractional transformation (LFT). Rank bounds for the minimal order of the global realization are also derived. The results are supported by various numerical examples. ",Kein DOI-Link verfügbar,2406.01236v1,Yes,potent(1)
0000-0003-3308-4784,Tobias Bischoff,Technische Universität Berlin,Enhancing Score-Based Sampling Methods with Ensembles,1970,"  We introduce ensembles within score-based sampling methods to develop gradient-free approximate sampling techniques that leverage the collective dynamics of particle ensembles to compute approximate reverse diffusion drifts. We introduce the underlying methodology, emphasizing its relationship with generative diffusion models and the previously introduced F\""ollmer sampler. We demonstrate the efficacy of ensemble strategies through various examples, ranging from low- to medium-dimensionality sampling problems, including multi-modal and highly non-Gaussian probability distributions, and provide comparisons to traditional methods like NUTS. Our findings highlight the potential of ensemble strategies for modeling complex probability distributions in situations where gradients are unavailable. Finally, we showcase its application in the context of Bayesian inversion problems within the geophysical sciences. ",Kein DOI-Link verfügbar,2401.17539v1,Yes,potent(1)
0000-0003-3308-4784,Tobias Bischoff,Technische Universität Berlin,Response Theory via Generative Score Modeling,1970,"  We introduce an approach for analyzing the responses of dynamical systems to external perturbations that combines score-based generative modeling with the Generalized Fluctuation-Dissipation Theorem (GFDT). The methodology enables accurate estimation of system responses, including those with non-Gaussian statistics. We numerically validate our approach using time-series data from three different stochastic partial differential equations of increasing complexity: an Ornstein-Uhlenbeck process with spatially correlated noise, a modified stochastic Allen-Cahn equation, and the 2D Navier-Stokes equations. We demonstrate the improved accuracy of the methodology over conventional methods and discuss its potential as a versatile tool for predicting the statistical behavior of complex dynamical systems. ",Kein DOI-Link verfügbar,2402.01029v2,Yes,"versatile(1), potent(1)"
0000-0003-3369-2253,Daniel Schmitt,Goethe Universität Frankfurt,Impact of theoretical uncertainties on model parameter reconstruction   from GW signals sourced by cosmological phase transitions,1970,"  Different computational techniques for cosmological phase transition parameters can impact the Gravitational Wave (GW) spectra predicted in a given particle physics model. To scrutinize the importance of this effect, we perform large-scale parameter scans of the dynamical real-singlet extended Standard Model using three perturbative approximations for the effective potential: the $\overline{\rm MS}$ and on-shell schemes at leading order, and three-dimensional thermal effective theory (3D EFT) at next-to-leading order. While predictions of GW amplitudes are typically unreliable in the absence of higher-order corrections, we show that the reconstructed model parameter spaces are robust up to a few percent in uncertainty. While 3D EFT is accurate from one loop order, theoretical uncertainties of reconstructed model parameters, using four-dimensional standard techniques, remain dominant over the experimental ones even for signals merely strong enough to claim a detection by LISA. ",Kein DOI-Link verfügbar,2403.03769v1,Yes,potent(1)
0000-0003-3377-6799,Yuan Li,"Bayerisches Geoinstitut, Universität Bayreuth",Community Detection with Node Attributes and its Generalization,1970,"  Community detection algorithms are fundamental tools to understand organizational principles in social networks. With the increasing power of social media platforms, when detecting communities there are two possi- ble sources of information one can use: the structure of social network and node attributes. However structure of social networks and node attributes are often interpreted separately in the research of community detection. When these two sources are interpreted simultaneously, one common as- sumption shared by previous studies is that nodes attributes are correlated with communities. In this paper, we present a model that is capable of combining topology information and nodes attributes information with- out assuming correlation. This new model can recover communities with higher accuracy even when node attributes and communities are uncorre- lated. We derive the detectability threshold for this model and use Belief Propagation (BP) to make inference. This algorithm is optimal in the sense that it can recover community all the way down to the threshold. This new model is also with the potential to handle edge content and dynamic settings. ",Kein DOI-Link verfügbar,1604.03601v1,Yes,potent(1)
0000-0003-3377-6799,Yuan Li,"Bayerisches Geoinstitut, Universität Bayreuth",Remark on a special class of Finsler $p$-Laplacian equation,1970,"  We investigate the anisotropic elliptic equation $-\Delta_p^H u = g(u)$. Recently, Esposito, Riey, Sciunzi, and Vuono introduced an anisotropic Kelvin transform in their work \cite{ERSV2022} under the $(H_M)$ condition, where $H(\xi)=\sqrt{\langle M\xi,\xi\rangle}$ with a positive definite symmetric matrix $M$. Here, we emphasize that under the $(H_M)$ assumption, the Finsler $p$-Laplacian and the classical $p$-Laplacian operator are equivalent following a linear transformation. This equivalence offers us a more direct route to derive the pivotal findings presented in \cite{ERSV2022}. While this equivalence is crucial and noteworthy, to our knowledge, it has not been explicitly stated in the current literature. ",https://doi.org/10.3934/dcdss.2024099,2208.03439v3,Yes,"noteworthy(1), pivotal(1)"
0000-0003-3377-6799,Yuan Li,"Bayerisches Geoinstitut, Universität Bayreuth",The structures and decompositions of symmetries involving idempotents,1970,"  Let $\mathcal{H}$ be a separable Hilbert space and $P$ be an idempotent on $\mathcal{H}.$ We denote by $$\Gamma_{P}=\{J: J=J^{\ast}=J^{-1} \hbox{ }\hbox{ and }\hbox{ } JPJ=I-P\}$$ and $$\Delta_{P}=\{J: J=J^{\ast}=J^{-1} \hbox{ }\hbox{ and }\hbox{ } JPJ=I-P^*\}.$$ In this paper, we first get that symmetries $(2P-I)|2P-I|^{-1}$ and $(P+P^{*}-I)|P+P^{*}-I|^{-1}$ are the same. Then we show that $\Gamma_{P}\neq\emptyset$ if and only if $\Delta_{P}\neq\emptyset.$ Also, the specific structures of all symmetries $J\in\Gamma_{P}$ and $J\in\Delta_{P} $ are established, respectively. Moreover,   we prove that $J\in\Delta_{P}$ if and only if $\sqrt{-1}J(2P-I)|2P-I|^{-1}\in\Gamma_{P}.$ ",Kein DOI-Link verfügbar,1903.01746v1,Yes,potent(1)
0000-0003-3377-6799,Yuan Li,"Bayerisches Geoinstitut, Universität Bayreuth",The minus order for idempotents,1970,"  Let $P$ and $Q$ be idempotents on a Hilbert space $\mathcal{H}.$ The minus order $P\preceq Q$ is defined by the equation $PQ=QP=P.$ In this note,   we first present some necessary and sufficient conditions for which the supremum and infimum of idempotents $P$ and $Q$ exist with respect to the minus order. Also, some properties of the minimum $Q^{or}$ are characterized, where $Q^{or}$=min $\{P^{'}: P^{'}$ is an orthogonal projection on $\mathcal{H}$ with $Q \preceq P^{'} \}.$ ",Kein DOI-Link verfügbar,1912.09718v1,Yes,potent(2)
0000-0003-3377-6799,Yuan Li,"Bayerisches Geoinstitut, Universität Bayreuth",Monocular Road Planar Parallax Estimation,1970,"  Estimating the 3D structure of the drivable surface and surrounding environment is a crucial task for assisted and autonomous driving. It is commonly solved either by using 3D sensors such as LiDAR or directly predicting the depth of points via deep learning. However, the former is expensive, and the latter lacks the use of geometry information for the scene. In this paper, instead of following existing methodologies, we propose Road Planar Parallax Attention Network (RPANet), a new deep neural network for 3D sensing from monocular image sequences based on planar parallax, which takes full advantage of the omnipresent road plane geometry in driving scenes. RPANet takes a pair of images aligned by the homography of the road plane as input and outputs a $\gamma$ map (the ratio of height to depth) for 3D reconstruction. The $\gamma$ map has the potential to construct a two-dimensional transformation between two consecutive frames. It implies planar parallax and can be combined with the road plane serving as a reference to estimate the 3D structure by warping the consecutive frames. Furthermore, we introduce a novel cross-attention module to make the network better perceive the displacements caused by planar parallax. To verify the effectiveness of our method, we sample data from the Waymo Open Dataset and construct annotations related to planar parallax. Comprehensive experiments are conducted on the sampled dataset to demonstrate the 3D reconstruction accuracy of our approach in challenging scenarios. ",https://doi.org/10.1109/TIP.2023.3289323,2111.11089v2,Yes,potent(1)
0000-0003-3377-6799,Yuan Li,"Bayerisches Geoinstitut, Universität Bayreuth",Existence of global solutions for the nonlocal derivation nonlinear   Schrödinger equation by the inverse scattering transform method,1970,"  We address the existence of global solutions to the initial value problem for the integrable nonlocal derivative nonlinear Schr\""{o}dinger equation in weighted Sobolev space $H^{2}(\mathbb{R})\cap H^{1,1}(\mathbb{R})$. The key to prove this result is to establish a bijectivity between potential and reflection coefficient by using the inverse scattering transform method in the form of the Riemann-Hilbert problem. ",Kein DOI-Link verfügbar,2307.15837v1,Yes,potent(1)
0000-0003-3377-6799,Yuan Li,"Bayerisches Geoinstitut, Universität Bayreuth",Simulating the Cooling Flow of Cool-Core Clusters,1970,"  We carry out high-resolution adaptive mesh refinement simulations of a cool core cluster, resolving the flow from Mpc scales down to pc scales. We do not (yet) include any AGN heating, focusing instead on cooling in order to understand how gas gets to the supermassive black hole (SMBH) at the center of the cluster. We find that, as the gas cools, the cluster develops a very flat temperature profile, undergoing a cooling catastrophe only in the central 10-100 pc of the cluster. Outside of this region, the flow is smooth, with no local cooling instabilities, and naturally produces very little low-temperature gas (below a few keV), in agreement with observations. The gas cooling in the center of the cluster rapidly forms a thin accretion disk. The amount of cold gas produced at the very center grows rapidly until a reasonable estimate of the resulting AGN heating rate (assuming even a moderate accretion efficiency) would overwhelm cooling. We argue that this naturally produces a thermostat which links the cooling of gas out to 100 kpc with the cold gas accretion in the central 100 pc, potentially closing the loop between cooling and heating. Isotropic heat conduction does not affect the result significantly, but we show that including the potential well of the brightest cluster galaxy is necessary to obtain the correct result. Also, we found that the outcome is sensitive to resolution, requiring very high mass resolution to correctly reproduce the small transition radius. ",https://doi.org/10.1088/0004-637X/747/1/26,1112.2701v1,Yes,potent(2)
0000-0003-3377-6799,Yuan Li,"Bayerisches Geoinstitut, Universität Bayreuth",Concentration Behavior of Nonlinear Hartree-type Equation with almost   Mass Critical Exponent,1970,"  We study the following nonlinear Hartree-type equation \begin{equation*} -\Delta u+V(x)u-a(\frac{1}{|x|^\gamma}\ast |u|^2)u=\lambda u,~\text{in}~\mathbb{R}^N, \end{equation*} where $a>0$, $N\geq3$, $\gamma\in(0,2)$ and $V(x)$ is an external potential. We first study the asymptotic behavior of the ground state of equation for $V(x)\equiv1$, $a=1$ and $\lambda=0$ as $\gamma\nearrow2$. Then we consider the case of some trapping potential $V(x)$, and show that all the mass of ground states concentrate at a global minimum point of $V(x)$ as $\gamma\nearrow2$, which leads to symmetry breaking. Moreover, the concentration rate for maximum points of ground states will be given. ",https://doi.org/10.1007/s00033-019-1172-5,1811.11350v1,Yes,potent(2)
0000-0003-3377-6799,Yuan Li,"Bayerisches Geoinstitut, Universität Bayreuth",Boson Stars with Long-range Perturbations,1970,"  We consider the Boson star equation with long-range perturbation given by   $$i\partial_t \psi=\sqrt{-\triangle+m^2}\,\psi+\beta(\frac{1}{|x|^\alpha}\ast |\psi|^2)\psi-(\frac{1}{|x|}\ast |\psi|^2)\psi\ \ \ \text{on $\mathbb{R}^3$,}$$ where $\frac{1}{|x|^\alpha} (0<\alpha<1)$ denotes the long-range potential. In contrast to the well known fact that for $\beta=0$ no maximal ground state solitary wave exists when the partical number $N=N_c$ (Chandrasekhar limiting mass) [E.H. Lieb, H.T. Yau, \emph{Commun. Math. Phys.}, 112 (1987), pp: 147-174 ], we show that for $\beta>0$ and small enough, there exists at least one maximal ground state at $N=N_c$. Moreover, for $\beta>0$, we find that for initial value $\|\psi_0\|^2_2=N_c$, the solution $\psi(t)$ is global well-posedness, and we obtain an ""orbital stability"" of those maximal ground state solitary waves in some sense, which implies that such long-range perturbation pushes the Boson star system more stable. Finally, we analyse blow-up behaviours of maximal ground states when $\beta\rightarrow 0^+$. ",Kein DOI-Link verfügbar,1911.00389v1,Yes,potent(1)
0000-0003-3377-6799,Yuan Li,"Bayerisches Geoinstitut, Universität Bayreuth",The formation channels of multiphase gas in nearby early-type galaxies,1970,"  The processes responsible for the assembly of cold and warm gas in early-type galaxies (ETGs) are not well-understood. We report on the multiwavelength properties of 15 non-central, nearby ($z \leq$ 0.00889) ETGs primarily through Multi-Unit Spectroscopic Explorer (MUSE) and Chandra X-ray observations, to address the origin of their multiphase gas. The MUSE data reveals 8/15 sources contain warm ionized gas traced by the H$\alpha$ emission line. The morphology of this gas is found to be filamentary in 3/8 sources: NGC 1266, NGC 4374, and NGC 4684 which is similar to that observed in many group and cluster-centered galaxies. All H$\alpha$ filamentary sources have X-ray luminosities exceeding the expected emission from the stellar population, suggesting the presence of diffuse hot gas which likely cooled to form the cooler phases. The morphology of the remaining 5/8 sources are rotating gas disks, not as commonly observed in higher mass systems. Chandra X-ray observations (when available) of the ETGs with rotating H$\alpha$ disks indicate that they are nearly void of hot gas. A mixture of stellar mass loss and external accretion was likely the dominant channel for the cool gas in NGC 4526 and NGC 4710. These ETGs show full kinematic alignment between their stars and gas, and are fast rotators. The H$\alpha$ features within NGC 4191 (clumpy, potentially star-forming ring), NGC 4643 and NGC 5507 (extended structures) along with loosely overlapping stellar and gas populations allow us to attribute external accretion to be the primary formation channel of the cool gas in these systems. ",https://doi.org/10.1093/mnras/stad3209,2310.02352v2,Yes,potent(1)
0000-0003-3407-6030,Birgit Richter,Universität Hamburg,A strictly commutative model for the cochain algebra of a space,1970,"  The commutative differential graded algebra $A_{\mathrm{PL}}(X)$ of polynomial forms on a simplicial set $X$ is a crucial tool in rational homotopy theory. In this note, we construct an integral version $A^{\mathcal{I}}(X)$ of $A_{\mathrm{PL}}(X)$. Our approach uses diagrams of chain complexes indexed by the category of finite sets and injections $\mathcal{I}$ to model $E_{\infty}$ differential graded algebras by strictly commutative objects, called commutative $\mathcal{I}$-dgas. We define a functor $A^{\mathcal{I}}$ from simplicial sets to commutative $\mathcal{I}$-dgas and show that it is a commutative lift of the usual cochain algebra functor. In particular, it gives rise to a new construction of the $E_{\infty}$ dga of cochains.   The functor $A^{\mathcal{I}}$ shares many properties of $A_{\mathrm{PL}}$, and can be viewed as a generalization of $A_{\mathrm{PL}}$ that works over arbitrary commutative ground rings. Working over the integers, a theorem by Mandell implies that $A^{\mathcal{I}}(X)$ determines the homotopy type of $X$ when $X$ is a nilpotent space of finite type. ",https://doi.org/10.1112/S0010437X20007319,1801.01060v3,Yes,potent(1)
0000-0003-3407-6030,Birgit Richter,Universität Hamburg,Inhabitants of interesting subsets of the Bousfield lattice,1970,"  The set of Bousfield classes has some important subsets such as the distributive lattice $\mathbf{DL}$ of all classes $\langle E\rangle$ which are smash idempotent and the complete Boolean algebra $\mathbf{cBA}$ of closed classes. We provide examples of spectra that are in $\mathbf{DL}$, but not in $\mathbf{cBA}$; in particular, for every prime $p$, the Bousfield class of the Eilenberg-MacLane spectrum $\langle H\mathbb{F}_p\rangle\in\mathbf{DL}{\setminus}\mathbf{cBA}$. ",Kein DOI-Link verfügbar,1702.03245v1,Yes,potent(1)
0000-0003-3500-2180,Andreas Distler,Friedrich-Alexander-Universität Erlangen-Nürnberg,Finite nilpotent semigroups of small coclass,1970,"  The parameter coclass has been used successfully in the study of nilpotent algebraic objects of different kinds. In this paper a definition of coclass for nilpotent semigroups is introduced and semigroups of coclass 0, 1, and 2 are classified. Presentations for all such semigroups and formulae for their numbers are obtained. The classification is provided up to isomorphism as well as up to isomorphism or anti-isomorphism. Commutative and self-dual semigroups are identified within the classification. ",https://doi.org/10.1080/00927872.2012.733986,1205.2817v1,Yes,potent(2)
0000-0003-3500-2180,Andreas Distler,Friedrich-Alexander-Universität Erlangen-Nürnberg,The semigroups of order 9 and their automorphism groups,1970,"  We report the number of semigroups with 9 elements up to isomorphism or anti-isomorphism to be 52,989,400,714,478 and up to isomorphism to be 105,978,177,936,292. We obtained these results by combining computer search with recently published formulae for the number of nilpotent semigroups of degree 3. We further provide a complete account of the automorphism groups of the semigroups with at most 9 elements. We use this information to deduce that there are 148,195,347,518,186 distinct associative binary operations on an 8-element set and 38,447,365,355,811,944,462 on a 9-element set. ",https://doi.org/10.1007/s00233-013-9504-9,1301.6023v1,Yes,potent(1)
0000-0003-3500-2180,Andreas Distler,Friedrich-Alexander-Universität Erlangen-Nürnberg,Coclass theory for nilpotent semigroups via their associated algebras,1970,"  Coclass theory has been a highly successful approach towards the investigation and classification of finite nilpotent groups. Here we suggest a similar approach for finite nilpotent semigroups. This differs from the group theory setting in that we additionally use certain algebras associated to the considered semigroups. We propose a series of conjectures on our suggested approach. If these become theorems, then this would reduce the classification of nilpotent semigroups of a fixed coclass to a finite calculation. Our conjectures are supported by the classification of nilpotent semigroups of coclass 0 and 1. Computational experiments suggest that the conjectures also hold for the nilpotent semigroups of coclass 2 and 3. ",https://doi.org/10.1016/j.jalgebra.2012.09.042,1208.4383v1,Yes,potent(5)
0000-0003-3500-2180,Andreas Distler,Friedrich-Alexander-Universität Erlangen-Nürnberg,The number of nilpotent semigroups of degree 3,1970,"  A semigroup is \emph{nilpotent} of degree 3 if it has a zero, every product of 3 elements equals the zero, and some product of 2 elements is non-zero. It is part of the folklore of semigroup theory that almost all finite semigroups are nilpotent of degree 3.   We give formulae for the number of nilpotent semigroups of degree 3 with $n\in\N$ elements up to equality, isomorphism, and isomorphism or anti-isomorphism. Likewise, we give formulae for the number of nilpotent commutative semigroups with $n$ elements up to equality and up to isomorphism. ",Kein DOI-Link verfügbar,1201.3529v1,Yes,potent(4)
0000-0003-3500-2180,Andreas Distler,Friedrich-Alexander-Universität Erlangen-Nürnberg,On the theoretical framework for meniscus-guided manufacturing of   large-area OPV modules,1970,"  For the manufacturing of thin films of solution-processable organic semiconductors, e.g. for organic photovoltaics (OPV), meniscus guided-coating techniques are the method of choice for large-scale industrial applications. However, the process requires an in-depth understanding of the respective fluid dynamics to control the resulting film thickness. In this article, we derive an analytical expression to describe the layer thickness of coatings manufactured with a trapezoidal-shaped applicator as a function of various fluid and process parameters. The analytical calculations are compared with results from computational fluid dynamics (CFD) simulations and experimental data for an industrially relevant OPV active material system. The analytical calculations are compared with results from computational fluid dynamics (CFD) simulations and experimental data for an industrially relevant OPV active material system. The good agreement of all three approaches demonstrates the potential of the analytical and simulative methods to reduce time- and resource-consuming experiments to a minimum. Furthermore, our theoretical model can be used to enhance the homogeneity of large-area coatings by means of an acceleration profile of the applicator that can compensate the liquid loss during the coating process. The respective analytical expression is validated by simulated and experimentally obtained data for long-distance coatings. Finally, this approach is used to fabricate a large-area OPV module with new world record efficiency. ",Kein DOI-Link verfügbar,2401.08439v1,Yes,potent(1)
0000-0003-3514-2167,Christian Scheller,Technische Universität Braunschweig,Flatland-RL : Multi-Agent Reinforcement Learning on Trains,1970,"  Efficient automated scheduling of trains remains a major challenge for modern railway systems. The underlying vehicle rescheduling problem (VRSP) has been a major focus of Operations Research (OR) since decades. Traditional approaches use complex simulators to study VRSP, where experimenting with a broad range of novel ideas is time consuming and has a huge computational overhead. In this paper, we introduce a two-dimensional simplified grid environment called ""Flatland"" that allows for faster experimentation. Flatland does not only reduce the complexity of the full physical simulation, but also provides an easy-to-use interface to test novel approaches for the VRSP, such as Reinforcement Learning (RL) and Imitation Learning (IL). In order to probe the potential of Machine Learning (ML) research on Flatland, we (1) ran a first series of RL and IL experiments and (2) design and executed a public Benchmark at NeurIPS 2020 to engage a large community of researchers to work on this problem. Our own experimental results, on the one hand, demonstrate that ML has potential in solving the VRSP on Flatland. On the other hand, we identify key topics that need further research. Overall, the Flatland environment has proven to be a robust and valuable framework to investigate the VRSP for railway networks. Our experiments provide a good starting point for further research and for the participants of the NeurIPS 2020 Flatland Benchmark. All of these efforts together have the potential to have a substantial impact on shaping the mobility of the future. ",Kein DOI-Link verfügbar,2012.05893v2,Yes,potent(3)
0000-0003-3671-0058,Nikhil Jayakumar,Friedrich-Schiller-Universität Jena,Label-free incoherent super-resolution optical microscopy,1970,"  The photo-kinetics of fluorescent molecules has enabled the circumvention of far-field optical diffraction-limit. Despite its enormous potential, the necessity to label the sample may adversely influence the delicate biology under investigation. Thus, continued development efforts are needed to surpass the far-field label-free diffraction barrier. The coherence of the detected light in label-free mode hinders the application of existing super-resolution methods based on incoherent fluorescence imaging. In this article, we present the physics and propose a methodology to circumvent this challenge by exploiting the photoluminescence of silicon nitride waveguides for near-field illumination of unlabeled samples. The technique is abbreviated EPSLON, Evanescently decaying Photoluminescence Scattering enables Label-free Optical Nanoscopy. We demonstrate that such an illumination has properties that mimics the photo-kinetics of nano-sized fluorescent molecules. This allows to develop a label-free incoherent system that is linear in intensity, and stable with time thereby permitting the application of techniques like structured illumination microscopy (SIM) and intensity-fluctuation based optical nanoscopy (IFON) in label-free mode to circumvent the diffraction limit. We experimentally demonstrate labelfree super-resolution imaging of nanobeads (polystyrene and gold), extra-cellular vesicles, rat kidney sections and human placenta tissue. ",Kein DOI-Link verfügbar,2301.03451v2,Yes,potent(1)
0000-0003-3671-0058,Nikhil Jayakumar,Friedrich-Schiller-Universität Jena,Label-free chip-based evanescent light scattering super-resolution and   superior-contrast optical microscopy (cELS),1970,"  Chip-based Evanescent Light Scattering (cELS) utilizes the multiple modes of a high-index contrast optical waveguide for near-field illumination of unlabeled samples, thereby repositioning the highest spatial frequencies of the sample into the far-field. The multiple modes scattering off the sample with different phase differences is engineered to have random spatial distributions within the integration time of the camera, mitigating the coherent speckle noise. This enables label-free superior-contrast imaging of weakly scattering nanosized specimens such as extra-cellular vesicles (EVs) and liposomes, dynamics of living HeLa cells etc. The article explains and validates experimentally the physics behind cELS by demonstrating a multi-moded straight waveguide as a partially coherent light source. For isotropic super-resolution, spatially incoherent light engineered via multiple-arms waveguide chip and intensity-fluctuation based algorithms are used. The proof-of-concept results are demonstrated on 100 nm polystyrene beads and resolution improvement of close to 2X is shown. cELS also realizes (2-10)X more contrast as opposed to conventional imaging techniques. In addition, cELS platform is miniaturized and enables large field-of-view imaging compared to state of the art label-free techniques. cELS holds a potential for label-free super-resolution imaging of nanosized biological specimens at high-throughput. ",Kein DOI-Link verfügbar,2108.10575v5,Yes,potent(1)
0000-0003-3785-3130,Artur Philipp,Technische Universität Berlin,DID Link: Authentication in TLS with Decentralized Identifiers and   Verifiable Credentials,1970,"  Authentication in TLS is predominately carried out with X.509 digital certificates issued by certificate authorities (CA). The centralized nature of current public key infrastructures, however, comes along with severe risks, such as single points of failure and susceptibility to cyber-attacks, potentially undermining the security and trustworthiness of the entire system. With Decentralized Identifiers (DID) alongside distributed ledger technology, it becomes technically feasible to prove ownership of a unique identifier without requiring an attestation of the proof's public key by a centralized and therefore vulnerable CA. This article presents DID Link, a novel authentication scheme for TLS 1.3 that empowers entities to authenticate in a TLS-compliant way with self-issued X.509 certificates that are equipped with ledger-anchored DIDs instead of CA-issued identifiers. It facilitates the exchange of tamper-proof and 3rd-party attested claims in the form of DID-bound Verifiable Credentials after the TLS handshake to complete the authentication with a full identification of the communication partner. A prototypical implementation shows comparable TLS handshake durations of DID Link if verification material is cached and reasonable prolongations if it is obtained from a ledger. The significant speed improvement of the resulting TLS channel over a widely used, DID-based alternative transport protocol on the application layer demonstrates the potential of DID Link to become a viable solution for the establishment of secure and trustful end-to-end communication links with decentrally managed digital identities. ",Kein DOI-Link verfügbar,2405.07533v2,Yes,potent(2)
0000-0003-3810-9856,Christoph Hennersperger,Technische Universität München,Towards MRI-Based Autonomous Robotic US Acquisitions: A First   Feasibility Study,1970,"  Robotic ultrasound has the potential to assist and guide physicians during interventions. In this work, we present a set of methods and a workflow to enable autonomous MRI-guided ultrasound acquisitions. Our approach uses a structured-light 3D scanner for patient-to-robot and image-to-patient calibration, which in turn is used to plan 3D ultrasound trajectories. These MRI-based trajectories are followed autonomously by the robot and are further refined online using automatic MRI/US registration. Despite the low spatial resolution of structured light scanners, the initial planned acquisition path can be followed with an accuracy of 2.46 +/- 0.96 mm. This leads to a good initialization of the MRI/US registration: the 3D-scan-based alignment for planning and acquisition shows an accuracy (distance between planned ultrasound and MRI) of 4.47 mm, and 0.97 mm after an online-update of the calibration based on a closed loop registration. ",https://doi.org/10.1109/TMI.2016.2620723,1607.08371v1,Yes,potent(1)
0000-0003-3821-3987,Wilhelm Eschen,Friedrich-Schiller-Universität Jena,"PtyLab.m/py/jl: a cross-platform, open-source inverse modeling toolbox   for conventional and Fourier ptychography",1970,"  Conventional (CP) and Fourier (FP) ptychography have emerged as versatile quantitative phase imaging techniques. While the main application cases for each technique are different, namely lens-less short wavelength imaging for CP and lens-based visible light imaging for FP, both methods share a common algorithmic ground. CP and FP have in part independently evolved to include experimentally robust forward models and inversion techniques. This separation has resulted in a plethora of algorithmic extensions, some of which have not crossed the boundary from one modality to the other. Here, we present an open source, cross-platform software, called PtyLab, enabling both CP and FP data analysis in a unified framework. With this framework, we aim to facilitate and accelerate cross-pollination between the two techniques. Moreover, the availability in Matlab, Python, and Julia will set a low barrier to enter each field. ",https://doi.org/10.1364/OE.485370,2301.06595v1,Yes,versatile(1)
0000-0003-3940-4160,Camillo Ballani,Martin-Luther-Universität Halle-Wittenberg,Enhancement of spin mixing conductance in   La$_{0.7}$Sr$_{0.3}$MnO$_{3}$/LaNiO$_{3}$/SrRuO$_{3}$ heterostructures,1970,"  We investigate spin pumping and the effective spin mixing conductance in heterostructures based on magnetic oxide trilayers composed of La$_{0.7}$Sr$_{0.3}$MnO$_3$ (LSMO), LaNiO$_3$ (LNO), and SrRuO$_3$ (SRO). The heterostructures serve as a model system for an estimation of the effective spin mixing conductance at the different interfaces. Our results show that by introducing a LNO interlayer between LSMO and SRO, the total effective spin mixing conductance increases due to the much more favourable interface of LSMO/LNO with respect to the LSMO/SRO interface. Neverheless, the spin current into the SRO does not decrease because of the spin diffusion length of $\lambda_\text{LNO}\approx$3.3 nm in the LNO. This value is two times higher than that of SRO. Our results show the potential of using oxide interfaces to tune the effective spin mixing conductance in heterostructures and to bring novel functionalities into spintronics by implementing complex oxides. ",https://doi.org/10.1002/pssb.201900606,1909.12766v1,Yes,potent(1)
0000-0003-4032-1995,Thomas Zwick,Universität Würzburg,Two-Dimensional Arbitrary Angle of Arrival in Radar Target Simulation,1970,"  Automotive radar sensors play a key role in the current development of advanced driver assistance systems (ADAS). Their ability to detect objects even under adverse weather conditions makes them indispensable for environment-sensing tasks in autonomous vehicles. Since an operational failure presents a potential risk to human life, thorough and practical validation testing must be performed, requiring an integrative test solution. Radar target simulators (RTS) are capable of performing over-the-air validation tests by generating virtual radar echoes that are perceived as targets by the radar under test (RuT). Since the authenticity and credibility of these targets is based on the accuracy with which they are created, their simulated position must be arbitrarily adjustable. In this work, an existing approach to synthesize virtual radar targets at an arbitrary angle of arrival (AoA) is extended to cover both, the azimuth and elevation domain. The concept is based on the superposition of the returning signals from four neighboring RTS channels. A theoretical model describing the basic principle and its constraints is developed. In addition, a measurement campaign is conducted to verify the practical functionality of the proposed approach. ",Kein DOI-Link verfügbar,2202.03203v2,Yes,potent(1)
0000-0003-4032-1995,Thomas Zwick,Universität Würzburg,Freeform terahertz structures fabricated by multi-photon lithography and   metal coating,1970,"  Direct-write multi-photon laser lithography (MPL) combines highest resolution on the nanoscale with essentially unlimited 3D design freedom. Over the previous years, the groundbreaking potential of this technique has been demonstrated in various application fields, including micromechanics, material sciences, microfluidics, life sciences as well as photonics, where in-situ printed optical coupling elements offer new perspectives for package-level system integration. However, millimeter-wave (mmW) and terahertz (THz) devices could not yet leverage the unique strengths of MPL, even though the underlying devices and structures could also greatly benefit from 3D freeform microfabrication. One of the key challenges in this context is the fact that functional mmW and THz structures require materials with high electrical conductivity and low dielectric losses, which are not amenable to structuring by multi-photon polymerization. In this work, we introduce and experimentally demonstrate a novel approach that allows to leverage MPL for fabricating high-performance mmW and THz structures with hitherto unachieved functionalities. Our concept exploits in-situ printed polymer templates that are selectively coated through highly directive metal deposition techniques in combination with precisely aligned 3D-printed shadowing structures. The resulting metal-coated freeform structures offer high surface quality in combination with low dielectric losses and conductivities comparable to bulk material values, while lending themselves to fabrication on planar mmW/THz circuits. We experimentally show the viability of our concept by demonstrating a series of functional THz structures such as THz interconnects, probe tips, and suspended antennas. We believe that our approach offers disruptive potential in the field of mmW and THz technology and may unlock an entirely new realm of laser-based 3D manufacturing. ",Kein DOI-Link verfügbar,2401.03316v1,Yes,potent(2)
0000-0003-4105-9650,Philipp Braun,Technische Universität Hamburg,Transversely isotropic poroelastic behaviour of the Callovo-Oxfordian   claystone: A set of stress-dependent parameters,1970,"  In the framework of a deep geological radioactive waste disposal in France, the hydromechanical properties of the designated host rock, the Callovo-Oxfordian claystone (COx), are investigated in laboratory tests. Experiments presented in this study are carried out to determine several coefficients required within a transversely isotropic material model. They include isotropic compression tests, pore pressure tests, and deviatoric loading tests parallel and perpendicular to the bedding plane. We emphasize the adapted experimental devices and testing procedures, necessary to detect small strains under high pressures, on a material, which is sensitive to water and has a very low permeability. In particular, we discovered a significant decrease of elastic stiffness with decreasing effective stress, which was observed to be reversible. In both isotropic and deviatoric tests, a notable anisotropic strain response was found. The Young modulus parallel to bedding was about 1.8 times higher than the one perpendicular to the bedding plane. A notably low Poisson ratio perpendicular to the bedding plane with values between 0.1 and 0.2 was evidenced. While the anisotropy of the back-calculated Biot coefficient was found to be low, a significant anisotropy of the Skempton coefficient was computed. The performed experiments provide an overdetermined set of material parameters at different stress levels. Using all determined parameters in a least square error regression scheme, seven independent elastic coefficients and their effective stress dependency are characterized. Parameters measured under isotropic loading are well represented by this set of coefficients, while the poroelastic framework with isotropic stress dependency is not sufficient to describe laboratory findings from triaxial loading. ",https://doi.org/10.1007/s00603-020-02268-z,2004.09277v2,Yes,notable(1)
0000-0003-4106-947X,Dieter Müller,Universität Göttingen,Covariance constraints for light front wave functions,1970,"  Light front wave functions (LFWFs) are often utilized to model parton distributions and form factors where their transverse and longitudinal momenta are tied to each other in some manner that is often guided by convenience. On the other hand, the cross talk of transverse and longitudinal momenta is governed by Poincar\'e symmetry and thus popular LFWF models are often not usable to model more intricate quantities such as generalized parton distributions. In this contribution a closer look to this issue is given and it is shown how to overcome the issue for two--body LFWFs. ",https://doi.org/10.1007/s00601-016-1059-3,1512.07999v1,Yes,intricate(1)
0000-0003-4115-4885,Patrik Knopf,Universität Bayreuth,Confined steady states of a Vlasov-Poisson plasma in an infinitely long   cylinder,1970,"  We consider the two-dimensional Vlasov-Poisson system to model a two-component plasma whose distribution function is constant with respect to the third space dimension. First, we show how this two-dimensional Vlasov-Poisson system can be derived from the full three-dimensional system. The existence of compactly supported steady states with vanishing electric potential in a three-dimensional setting has already been investigated by A. L. Skubachevskii [15]. We show that his approach can easily be adapted to the two-dimensional system. However, our main result is to prove the existence of compactly supported steady states even with a nontrivial self-consistent electric potential. ",https://doi.org/10.1002/mma.5728,1805.04009v3,Yes,potent(2)
0000-0003-4115-4885,Patrik Knopf,Universität Bayreuth,Optimal medication for tumors modeled by a Cahn-Hilliard-Brinkman   equation,1970,"  In this paper, we study a distributed optimal control problem for a diffuse interface model for tumor growth. The model consists of a Cahn-Hilliard type equation for the phase field variable coupled to a reaction diffusion equation for the nutrient and a Brinkman type equation for the velocity. The system is equipped with homogeneous Neumann boundary conditions for the tumor variable and the chemical potential, Robin boundary conditions for the nutrient and a ""no-friction"" boundary condition for the velocity. The control acts as a medication by cytotoxic drugs and enters the phase field equation. The cost functional is of standard tracking type and is designed to track the variables of the state equation during the evolution and the distribution of tumor cells at some fixed final time. We prove that the model satisfies the basics for calculus of variations and we establish first-order necessary optimality conditions for the optimal control problem. ",https://doi.org/10.1007/s00526-019-1579-z,1811.07783v3,Yes,potent(1)
0000-0003-4115-4885,Patrik Knopf,Universität Bayreuth,Optimal control theory and advanced optimality conditions for a diffuse   interface model of tumor growth,1970,"  In this paper, we study a distributed optimal control problem for a diffuse interface model for tumor growth. The model consists of a Cahn-Hilliard type equation for the phase field variable coupled to a reaction diffusion equation for the nutrient and a Brinkman type equation for the velocity. The system is equipped with homogeneous Neumann boundary conditions for the tumor variable, the chemical potential and the nutrient as well as a ""no-friction"" boundary condition for the velocity. The control acts as a medication by cytotoxic drugs and enters the phase field equation. The cost functional is of standard tracking type and is designed to track the phase field variable during the evolution and at some fixed final time. We prove that the model satisfies the basics for calculus of variations and we establish first-order and second-order conditions for local optimality. Moreover, we present a globality condition for critical controls and we show that the optimal control is unique on small time intervals. ",https://doi.org/10.1051/cocv/2019059,1903.00333v2,Yes,potent(1)
0000-0003-4115-4885,Patrik Knopf,Universität Bayreuth,On the nonlocal Cahn--Hilliard equation with nonlocal dynamic boundary   condition and boundary penalization,1970,"  The Cahn--Hilliard equation is one of the most common models to describe phase segregation processes in binary mixtures. In recent times, various dynamic boundary conditions have been introduced to model interactions of the materials with the boundary more precisely. To take long-range interactions of the materials into account, we propose a new model consisting of a nonlocal Cahn--Hilliard equation subject to a nonlocal dynamic boundary condition that is also of Cahn--Hilliard type and contains an additional boundary penalization term. We rigorously derive our model as the gradient flow of a nonlocal total free energy with respect to a suitable inner product of order $H^{-1}$ which contains both bulk and surface contributions. The total free energy is considered as nonlocal since it comprises convolutions in the bulk and on the surface of the phase-field variables with certain interaction kernels. The main difficulties arise from defining a suitable kernel on the surface and from handling the resulting boundary convolution. In the main model, the chemical potentials in the bulk and on the surface are coupled by a Robin type boundary condition depending on a specific relaxation parameter related to the rate of chemical reactions. We prove weak and strong well-posedness of this system, and we investigate the singular limits attained when the relaxation parameter tends to zero or infinity. By this approach, we also obtain weak and strong well-posedness of the corresponding limit systems. ",https://doi.org/10.1016/j.jde.2021.01.012,2004.00093v2,Yes,potent(1)
0000-0003-4115-4885,Patrik Knopf,Universität Bayreuth,Strong well-posedness and separation properties for a bulk-surface   convective Cahn--Hilliard system with singular potentials,1970,"  This paper addresses the well-posedness of a general class of bulk-surface convective Cahn--Hilliard systems with singular potentials. For this model, we first prove the existence of a global-in-time weak solution by approximating the singular potentials via a Yosida approximation, applying the corresponding results for regular potentials, and eventually passing to the limit in this approximation scheme. Then, we prove the uniqueness of weak solutions and its continuous dependence on the velocity fields and the initial data. Afterwards, assuming additional regularity of the domain as well as the velocity fields, we establish higher regularity properties of weak solutions and eventually the existence of strong solutions. In the end, we discuss strict separation properties for logarithmic type potentials in both two and three dimensions. ",Kein DOI-Link verfügbar,2407.14089v1,Yes,potent(4)
0000-0003-4115-4885,Patrik Knopf,Universität Bayreuth,Nonlocal-to-local convergence rates for strong solutions to a   Navier-Stokes-Cahn-Hilliard system with singular potential,1970,"  The main goal of this paper is to establish the nonlocal-to-local convergence of strong solutions to a Navier--Stokes--Cahn--Hilliard model with singular potential describing immiscible, viscous two-phase flows with matched densities, which is referred to as the Model H. This means that we show that the strong solutions to the nonlocal Model H converge to the strong solution to the local Model H as the weight function in the nonlocal interaction kernel approaches the delta distribution. Compared to previous results in the literature, our main novelty is to further establish corresponding convergence rates. Before investigating the nonlocal-to-local convergence, we first need to ensure the strong well-posedness of the nonlocal Model H. In two dimensions, this result can already be found in the literature, whereas in three dimensions, it will be shown in the present paper. Moreover, in both two and three dimensions, we establish suitable uniform bounds on the strong solutions of the nonlocal Model H, which are essential to prove the nonlocal-to-local convergence results. ",Kein DOI-Link verfügbar,2403.10947v1,Yes,potent(1)
0000-0003-4115-4885,Patrik Knopf,Universität Bayreuth,Two-phase flows through porous media described by a   Cahn--Hilliard--Brinkman model with dynamic boundary conditions,1970,"  We investigate a new diffuse-interface model that describes creeping two-phase flows (i.e., flows exhibiting a low Reynolds number), especially flows that permeate a porous medium. The system of equations consists of a Brinkman equation for the volume averaged velocity field as well as a convective Cahn--Hilliard equation with dynamic boundary conditions for the phase-field, which describes the location of the two fluids within the domain. The dynamic boundary conditions are incorporated to model the interaction of the fluids with the wall of the container more precisely. In particular, they allow for a dynamic evolution of the contact angle between the interface separating the fluids and the boundary, and also for a convection-induced motion of the corresponding contact line. For our model, we first prove the existence of global-in-time weak solutions in the case where regular potentials are used in the Cahn--Hilliard subsystem. In this case, we can further show the uniqueness of the weak solution under suitable additional assumptions. Moreover, we further prove the existence of weak solutions in the case of singular potentials. Therefore, we regularize such singular potentials by a Yosida approximation, such that the results for regular potentials can be applied, and eventually pass to the limit in this approximation scheme. ",Kein DOI-Link verfügbar,2312.15274v1,Yes,potent(4)
0000-0003-4115-4885,Patrik Knopf,Universität Bayreuth,A diffuse-interface approach for solid-state dewetting with anisotropic   surface energies,1970,"  We present a diffuse-interface model for the solid-state dewetting problem with anisotropic surface energies in ${\mathbb R}^d$ for $d\in\{2,3\}$. The introduced model consists of the anisotropic Cahn--Hilliard equation, with either a smooth or a double-obstacle potential, together with a degenerate mobility function and appropriate boundary conditions on the wall. Upon regularizing the introduced diffuse-interface model, and with the help of suitable asymptotic expansions, we recover as the sharp-interface limit the anisotropic surface diffusion flow for the interface together with an anisotropic Young's law and a zero-flux condition at the contact line of the interface with a fixed external boundary. Furthermore, we show the existence of weak solutions for the regularized model, for both smooth and obstacle potential. Numerical results based on an appropriate finite element approximation are presented to demonstrate the excellent agreement between the proposed diffuse-interface model and its sharp-interface limit. ",https://doi.org/10.1007/s00332-023-09889-y,2210.01698v2,Yes,potent(2)
0000-0003-4130-1400,Christian Schimpf,TU Bergakademie Freiberg,Phonon-assisted two-photon interference from remote quantum emitters,1970,"  Photonic quantum technologies are on the verge of finding applications in everyday life with quantum cryptography and the quantum internet on the horizon. Extensive research has been carried out to determine suitable quantum emitters and single epitaxial quantum dots are emerging as near-optimal sources of bright, on-demand, highly indistinguishable single photons and entangled photon pairs. In order to build up quantum networks, it is now essential to interface remote quantum emitters. However, this is still an outstanding challenge, as the quantum states of dissimilar 'artificial atoms' have to be prepared on-demand with high fidelity, and the generated photons have to be made indistinguishable in all possible degrees of freedom. Here, we overcome this major obstacle and show an unprecedented two-photon interference (visibility of 51+/-5%) from remote strain-tunable GaAs quantum dots, emitting on-demand photon-pairs. We achieve this result by exploiting for the first time the full potential of the novel phonon-assisted two-photon excitation scheme, which allows for the generation of highly indistinguishable (visibility of 71+/-9%) entangled photon-pairs (fidelity of 90+/-2%), it enables push-to button biexciton state preparation (fidelity of 80+/-2%) and it outperforms conventional resonant two-photon excitation schemes in terms of robustness against environmental decoherence. Our results mark an important milestone for the practical realization of quantum repeaters and complex multi-photon entanglement experiments involving dissimilar artificial atoms. ",https://doi.org/10.1021/acs.nanolett.7b00777,1701.07812v3,Yes,potent(1)
0000-0003-4130-1400,Christian Schimpf,TU Bergakademie Freiberg,Full Dynamic Control of In-plane Elastic Stress Tensor in Nanomembranes,1970,"  Strain engineering allows the physical properties of materials and devices to be widely tailored, as paradigmatically demonstrated by strained transistors and semiconductor lasers employed in consumer electronics. For this reason, its potential impact on our society has been compared to that of chemical alloying. Although significant progress has been made in the last years on strained nanomaterials, strain fields (which are of tensorial nature, with six independent components) are still mostly used in a ""scalar"" and/or static fashion. Here we present a new class of strain actuators which allow the three components of the in-plane stress tensor in a nanomembrane to be independently and reversibly controlled. The actuators are based on monolithic piezoelectric substrates, which are micro-machined via femtosecond-laser processing. Their functionality is demonstrated by ""programming"" arbitrary stress states in a semiconductor layer, whose light emission is used as a local and sensitive strain gauge. The results shown in this work open a new route to investigate and make use of strain effects in materials and devices. ",https://doi.org/10.1002/adom.201500779,1511.08192v1,Yes,potent(1)
0000-0003-4130-1400,Christian Schimpf,TU Bergakademie Freiberg,Quantum dot technology for quantum repeaters: from entangled photon   generation towards the integration with quantum memories,1970,"  The realization of a functional quantum repeater is one of the major research goals in long-distance quantum communication. Among the different approaches that are being followed, the one relying on quantum memories interfaced with deterministic quantum emitters is considered as among one of the most promising solutions. In this work, we focus on memory-based quantum-repeater schemes that rely on semiconductor quantum dots for the generation of polarization entangled photons. Going through the most relevant figures of merit related to efficiency of the photon source, we select significant developments in fabrication, processing and tuning techniques aimed at combining high degree of entanglement with on-demand pair generation, with a special focus on the progress achieved in the representative case of the GaAs system. We proceed to offer a perspective on integration with quantum memories, both highlighting preliminary works on natural-artificial atomic interfaces and commenting a wide choice of currently available and potentially viable memory solutions in terms of wavelength, bandwidth and noise-requirements. To complete the overview, we also present recent implementations of entanglement-based quantum communication protocols with quantum dots and highlight the next challenges ahead for the implementation of practical quantum networks. ",Kein DOI-Link verfügbar,2104.07076v1,Yes,potent(1)
0000-0003-4143-182X,Hamidreza Kazemi,Technische Universität Kaiserslautern,Applications and Potentials of Reciprocal Bianisotropic Metasurfaces,1970,"  We discuss different applications and potentials of reciprocal bianisotropic metasurfaces including uniform and gradient metasurfaces, in particular, with anisotropic, chiral, and omega properties. Based on an analytic analysis, we discuss the necessary conditions to observe asymmetric co- and cross- polarization reflection and/or transmission, polarization conversion and rotation, asymmetric absorption, etc. We consider two kinds of incident wave scenarios based on linear and circular polarization. ",Kein DOI-Link verfügbar,1811.04176v1,Yes,potent(1)
0000-0003-4143-182X,Hamidreza Kazemi,Technische Universität Kaiserslautern,Exceptional Points of Degeneracy Induced by Linear Time-Periodic   Variation Hamidreza,1970,"  We present a general theory of exceptional points of degeneracy (EPD) in periodically time-variant systems that do not necessarily require the presence of loss or gain, and we show that even a single resonator with a time-periodic component may develop EPDs. An EPD is a special point in a system parameter space at which two or more eigenmodes coalesce in both their eigenvalues and eigenvectors into a single degenerate eigenmode. We demonstrate the conditions for EPDs to exist in time-periodic systems that are either lossless/gainless or with loss and/or gain and we show that a system with zero time-average loss/gain exhibits EPDs with purely real resonance frequencies, yet the resonator energy grows algebraically in time. We show the occurrence of EPDs in a single LC resonator while the introduced concept is general for any time-periodic system. These findings have significant importance in various electromagnetic/photonic systems and pave the way of applications in areas of sensors, amplifiers and modulators. A potential application of this time varying EPD is highlighted as a highly-sensitive sensor. ",https://doi.org/10.1103/PhysRevApplied.11.014007,1804.01075v3,Yes,potent(1)
0000-0003-4143-182X,Hamidreza Kazemi,Technische Universität Kaiserslautern,Scaling of intrinsic domain wall magneto-resistance with confinement in   electromigrated nanocontacts,1970,"  In this work we study the evolution of intrinsic domain wall magnetoresistance (DWMR) with domain wall confinement. Clean permalloy notched half-ring nanocontacts are fabricated using a special ultra-high vacuum electromigration procedure to tailor the size of the wire in-situ and through the resulting domain wall confinement we tailor the domain wall width from a few tens of nm down to a few nm. Through measurements of the dependence of the resistance with respect to the applied field direction we extract the contribution of a single domain wall to the MR of the device, as a function of the domain wall width in the confining potential at the notch. In this size range, an intrinsic positive MR is found, which dominates over anisotropic MR, as confirmed by comparison to micromagnetic simulations. Moreover, the MR is found to scale monotonically with the size of the domain wall, $\delta_{DW}$, as 1/$\delta_{DW}^b$, with $b=2.31\pm 0.39 $. The experimental result is supported by quantum-mechanical transport simulations based on ab-initio density functional theory calculations. ",https://doi.org/10.1103/PhysRevB.99.214437,1812.05689v1,Yes,potent(1)
0000-0003-4157-8637,Martin Franke,Leipzig Universität,Graph-based Active Learning for Entity Cluster Repair,1970,"  Cluster repair methods aim to determine errors in clusters and modify them so that each cluster consists of records representing the same entity. Current cluster repair methodologies primarily assume duplicate-free data sources, where each record from one source corresponds to a unique record from another. However, real-world data often deviates from this assumption due to quality issues. Recent approaches apply clustering methods in combination with link categorization methods so they can be applied to data sources with duplicates. Nevertheless, the results do not show a clear picture since the quality highly varies depending on the configuration and dataset. In this study, we introduce a novel approach for cluster repair that utilizes graph metrics derived from the underlying similarity graphs. These metrics are pivotal in constructing a classification model to distinguish between correct and incorrect edges. To address the challenge of limited training data, we integrate an active learning mechanism tailored to cluster-specific attributes. The evaluation shows that the method outperforms existing cluster repair methods without distinguishing between duplicate-free or dirty data sources. Notably, our modified active learning strategy exhibits enhanced performance when dealing with datasets containing duplicates, showcasing its effectiveness in such scenarios. ",Kein DOI-Link verfügbar,2401.14992v1,Yes,pivotal(1)
0000-0003-4197-041X,Christian Lehmann,Universität Mannheim,Enhancing Film Grain Coding in VVC: Improving Encoding Quality and   Efficiency,1970,"  This paper presents an in-depth analysis of film grain handling in open-source implementations of the Versatile Video Coding (VVC) standard. We focus on two key components: the Film Grain Analysis (FGA) module implemented in VVenC and the Film Grain Synthesis (FGS) module implemented in VVdeC. We describe the methodologies used to implement these modules and discuss the generation of Supplementary Enhancement Information (SEI) parameters to signal film grain characteristics in the encoded video sequences. Additionally, we conduct subjective and objective evaluations across Full HD videos to assess the effectiveness of film grain handling. Our results demonstrate the capability of the FGA and FGS techniques to accurately analyze and synthesize film grain, thereby improving the visual quality of encoded video content. Overall, our study contributes to advancing the understanding and implementation of film grain handling techniques in VVC open-source implementations, with implications for enhancing the viewing experience in multimedia applications. ",Kein DOI-Link verfügbar,2407.12465v1,Yes,versatile(1)
0000-0003-4197-041X,Christian Lehmann,Universität Mannheim,A Complete End-To-End Open Source Toolchain for the Versatile Video   Coding (VVC) Standard,1970,"  Versatile Video Coding (VVC) is the most recent international video coding standard jointly developed by ITU-T and ISO/IEC, which has been finalized in July 2020. VVC allows for significant bit-rate reductions around 50% for the same subjective video quality compared to its predecessor, High Efficiency Video Coding (HEVC). One year after finalization, VVC support in devices and chipsets is still under development, which is aligned with the typical development cycles of new video coding standards. This paper presents open-source software packages that allow building a complete VVC end-to-end toolchain already one year after its finalization. This includes the Fraunhofer HHI VVenC library for fast and efficient VVC encoding as well as HHI's VVdeC library for live decoding. An experimental integration of VVC in the GPAC software tools and FFmpeg media framework allows packaging VVC bitstreams, e.g. encoded with VVenC, in MP4 file format and using DASH for content creation and streaming. The integration of VVdeC allows playback on the receiver. Given these packages, step-by-step tutorials are provided for two possible application scenarios: VVC file encoding plus playback and adaptive streaming with DASH. ",https://doi.org/10.1145/3474085.3478320,2107.13385v1,Yes,versatile(1)
0000-0003-4197-041X,Christian Lehmann,Universität Mannheim,A limit on variations in the fine-structure constant from spectra of   nearby Sun-like stars,1970,"  The fine structure constant, $\alpha$, sets the strength of the electromagnetic force. The Standard Model of particle physics provides no explanation for its value, which could potentially vary. The wavelengths of stellar absorption lines depend on $\alpha$, but are subject to systematic effects owing to astrophysical processes in stellar atmospheres. We measured precise line wavelengths using 17 stars, selected to have almost identical atmospheric properties to those of the Sun (solar twins), which reduces those systematic effects. We found that $\alpha$ varies by $\lesssim$50 parts-per-billion (ppb) within 50 parsecs from Earth. Combining the results from all 17 stars provides an empirical, local reference for stellar measurements of $\alpha$ with an ensemble precision of 12 ppb. ",https://doi.org/10.1126/science.abi9232,2211.05150v1,Yes,potent(1)
0000-0003-4238-8843,Martin B Plenio,Universität Ulm,Resonance-inclined optical nuclear spin polarization of liquids in   diamond structures,1970,"  Dynamic nuclear polarization (DNP) of molecules in a solution at room temperature has potential to revolutionize nuclear magnetic resonance spectroscopy and imaging. The prevalent methods for achieving DNP in solutions are typically most effective in the regime of small interaction correlation times between the electron and nuclear spins, limiting the size of accessible molecules. To solve this limitation, we design a mechanism for DNP in the liquid phase that is applicable for large interaction correlation times. Importantly, while this mechanism makes use of a resonance condition similar to solid-state DNP, the polarization transfer is robust to a relatively large detuning from the resonance due to molecular motion. We combine this scheme with optically polarized nitrogen vacancy (NV) center spins in nanodiamonds to design a setup that employs optical pumping and is therefore not limited by room temperature electron thermal polarisation. We illustrate numerically the effectiveness of the model in a flow cell containing nanodiamonds immobilized in a hydrogel, polarising flowing water molecules 4700-fold above thermal polarisation in a magnetic field of 0.35 T, in volumes detectable by current NMR scanners. ",https://doi.org/10.1103/PhysRevB.93.060408,1510.03256v1,Yes,potent(1)
0000-0003-4266-449X,Konrad Samwer,Georg-August-Universität Göttingen,Atomic-scale expressions for viscosity and fragile-strong behavior in   metal alloys based on the Zwanzig-Mountain formula,1970,"  We combine the shoving model of $T$-dependent viscosity of supercooled liquids with the Zwanzig-Mountain formula for the high-frequency shear modulus, using the $g(r)$ of MD simulations of metal alloys as the input. This scheme leads to a semi-analytical expression for the viscosity as a function of temperature, which provides a three-parameter model fitting of experimental data of viscosity for the same alloy for which $g(r)$ was calculated. The model provides direct access to the influence of atomic-scale physical quantities such as the interatomic potential $\phi(r)$, on the viscosity and fragile-strong behavior. In particular, it is established that a steeper interatomic repulsion leads to fragile liquids, or, conversely, that ""soft atoms make strong liquids"". ",https://doi.org/10.1103/PhysRevResearch.2.033134,2007.12546v1,Yes,potent(1)
0000-0003-4266-449X,Konrad Samwer,Georg-August-Universität Göttingen,Universal correlations between the fragility and interparticle repulsion   of glass-forming liquids,1970,"  A recently published analytical model, describing and predicting elasticity, viscosity, and fragility of metallic melts, is applied for the analysis of about 30 nonmetallic glassy systems, ranging from oxide network glasses to alcohols, low-molecular-weight liquids, polymers, plastic crystals, and even ionic glass formers. The model is based on the power-law exponent lambda representing the steepness parameter of the repulsive part of the inter-atomic or -molecular potential and the thermal-expansion parameter alpha_T determined by the attractive anharmonic part of the effective interaction. It allows fitting the typical super-Arrhenius temperature variation of the viscosity or dielectric relaxation time for various classes of glass-forming matter, over many decades. We discuss the relation of the model parameters found for all these different glass-forming systems to the fragility parameter m and detect a correlation of lambda and m for the non-metallic glass formers, in accord with the model predictions. Within the framework of this model, thus the fragility of glass formers can be traced back to microscopic model parameters characterizing the intermolecular interactions. ",https://doi.org/10.1063/5.0014457,2009.07742v1,Yes,potent(1)
0000-0003-4266-449X,Konrad Samwer,Georg-August-Universität Göttingen,Universal Origin of Glassy Relaxation as Recognized by Configuration   Pattern-matching,1970,"  Relaxation processes are crucial in understanding the structural rearrangements of liquids and amorphous materials. However, the overarching principle that governs these processes across vastly different materials remains an open question. Substantial analysis has been carried out based on the motions of individual particles. Here, alternatively, we propose viewing the global configuration as a single entity. We introduce a global order parameter, namely the inherent structure minimal displacement (IS Dmin), to quantify the variability of configurations by a pattern-matching technique. Through atomic simulations of seven model glass-forming liquids, we unify the influences of temperature, pressure, and perturbation time on the relaxation dissipation, via a scaling law between the mechanical damping factor and IS Dmin. Fundamentally, this scaling reflects the curvature of the local potential energy landscape. Our findings uncover a universal origin of glassy relaxation and offer an alternative approach to studying disordered systems. ",https://doi.org/10.1093/nsr/nwae091,2403.06175v1,Yes,potent(1)
0000-0003-4266-449X,Konrad Samwer,Georg-August-Universität Göttingen,"Unifying interatomic potential, g(r), elasticity, viscosity, and   fragility of metallic glasses: analytical model, simulations, and experiments",1970,"  An analytical framework is proposed to describe the elasticity, viscosity and fragility of metallic glasses in relation to their atomic-level structure and the effective interatomic interaction. The bottom-up approach starts with forming an effective Ashcroft-Born-Mayer interatomic potential based on Boltzmann inversion of the radial distribution function g(r) and on fitting the short-range part of $g(r)$ by means of a simple power-law approximation. The power exponent $\lambda$ represents a global repulsion steepness parameter. A scaling relation between atomic connectivity and packing fraction $Z \sim \phi^{1+\lambda}$ is derived. This relation is then implemented in a lattice-dynamical model for the high-frequency shear modulus where the attractive anharmonic part of the effective interaction is taken into account through the thermal expansion coefficient which maps the $\phi$-dependence into a $T$-dependence. The shear modulus as a function of temperature calculated in this way is then used within the cooperative shear model of the glass transition to yield the viscosity of the supercooled melt as a double-exponential function of $T$ across the entire Angell plot. The model, which has only one adjustable parameter (the characteristic atomic volume for high-frequency cage deformation) is tested against new experimental data of ZrCu alloys and provides an excellent one-parameter description of the viscosity down to the glass transition temperature. ",https://doi.org/10.1088/1742-5468/2016/08/084001,1608.03834v1,Yes,potent(1)
0000-0003-4405-7925,Tobias Scheffer,Universität Potsdam,Finding Botnets Using Minimal Graph Clusterings,1970,"  We study the problem of identifying botnets and the IP addresses which they comprise, based on the observation of a fraction of the global email spam traffic. Observed mailing campaigns constitute evidence for joint botnet membership, they are represented by cliques in the graph of all messages. No evidence against an association of nodes is ever available. We reduce the problem of identifying botnets to a problem of finding a minimal clustering of the graph of messages. We directly model the distribution of clusterings given the input graph; this avoids potential errors caused by distributional assumptions of a generative model. We report on a case study in which we evaluate the model by its ability to predict the spam campaign that a given IP address is going to participate in. ",Kein DOI-Link verfügbar,1206.4675v1,Yes,potent(1)
0000-0003-4405-7925,Tobias Scheffer,Universität Potsdam,Pre-Trained Language Models Augmented with Synthetic Scanpaths for   Natural Language Understanding,1970,"  Human gaze data offer cognitive information that reflects natural language comprehension. Indeed, augmenting language models with human scanpaths has proven beneficial for a range of NLP tasks, including language understanding. However, the applicability of this approach is hampered because the abundance of text corpora is contrasted by a scarcity of gaze data. Although models for the generation of human-like scanpaths during reading have been developed, the potential of synthetic gaze data across NLP tasks remains largely unexplored. We develop a model that integrates synthetic scanpath generation with a scanpath-augmented language model, eliminating the need for human gaze data. Since the model's error gradient can be propagated throughout all parts of the model, the scanpath generator can be fine-tuned to downstream tasks. We find that the proposed model not only outperforms the underlying language model, but achieves a performance that is comparable to a language model augmented with real human gaze data. Our code is publicly available. ",Kein DOI-Link verfügbar,2310.14676v1,Yes,potent(1)
0000-0003-4405-7925,Tobias Scheffer,Universität Potsdam,Eyettention: An Attention-based Dual-Sequence Model for Predicting Human   Scanpaths during Reading,1970,"  Eye movements during reading offer insights into both the reader's cognitive processes and the characteristics of the text that is being read. Hence, the analysis of scanpaths in reading have attracted increasing attention across fields, ranging from cognitive science over linguistics to computer science. In particular, eye-tracking-while-reading data has been argued to bear the potential to make machine-learning-based language models exhibit a more human-like linguistic behavior. However, one of the main challenges in modeling human scanpaths in reading is their dual-sequence nature: the words are ordered following the grammatical rules of the language, whereas the fixations are chronologically ordered. As humans do not strictly read from left-to-right, but rather skip or refixate words and regress to previous words, the alignment of the linguistic and the temporal sequence is non-trivial. In this paper, we develop Eyettention, the first dual-sequence model that simultaneously processes the sequence of words and the chronological sequence of fixations. The alignment of the two sequences is achieved by a cross-sequence attention mechanism. We show that Eyettention outperforms state-of-the-art models in predicting scanpaths. We provide an extensive within- and across-data set evaluation on different languages. An ablation study and qualitative analysis support an in-depth understanding of the model's behavior. ",Kein DOI-Link verfügbar,2304.10784v2,Yes,potent(1)
0000-0003-4408-3306,Stefan Roth,Ruhr Universität Bochum,Actor-Critic Instance Segmentation,1970,"  Most approaches to visual scene analysis have emphasised parallel processing of the image elements. However, one area in which the sequential nature of vision is apparent, is that of segmenting multiple, potentially similar and partially occluded objects in a scene. In this work, we revisit the recurrent formulation of this challenging problem in the context of reinforcement learning. Motivated by the limitations of the global max-matching assignment of the ground-truth segments to the recurrent states, we develop an actor-critic approach in which the actor recurrently predicts one instance mask at a time and utilises the gradient from a concurrently trained critic network. We formulate the state, action, and the reward such as to let the critic model long-term effects of the current prediction and incorporate this information into the gradient signal. Furthermore, to enable effective exploration in the inherently high-dimensional action space of instance masks, we learn a compact representation using a conditional variational auto-encoder. We show that our actor-critic model consistently provides accuracy benefits over the recurrent baseline on standard instance segmentation benchmarks. ",Kein DOI-Link verfügbar,1904.05126v1,Yes,potent(1)
0000-0003-4408-3306,Stefan Roth,Ruhr Universität Bochum,Optimizing the Age of Information in Mixed-Critical Wireless   Communication Networks,1970,"  Beyond fifth generation wireless communication networks (B5G) are applied in many use-cases, such as industrial control systems, smart public transport, and power grids. Those applications require innovative techniques for timely transmission and increased wireless network capacities. Hence, this paper proposes optimizing the data freshness measured by the age of information (AoI) in dense internet of things (IoT) sensor-actuator networks. Given different priorities of data-streams, i.e., different sensitivities to outdated information, mixed-criticality is introduced by analyzing different functions of the age, i.e., we consider linear and exponential aging functions. An intricate non-convex optimization problem managing the physical transmission time and packet outage probability is derived. Such problem is tackled using stochastic reformulations, successive convex approximations, and fractional programming, resulting in an efficient iterative algorithm for AoI optimization. Simulation results validate the proposed scheme's performance in terms of AoI, mixed-criticality, and scalability. The proposed non-orthogonal transmission is shown to outperform an orthogonal access scheme in various deployment cases. Results emphasize the potential gains for dense B5G empowered IoT networks in minimizing the AoI. ",https://doi.org/10.1109/ICC45041.2023.10279561,2211.05797v1,Yes,"innovative(1), intricate(1), potent(1), fresh(1)"
0000-0003-4408-3306,Stefan Roth,Ruhr Universität Bochum,Enhancing the Secrecy Rate with Direction-range Focusing with FDA and   RIS,1970,"  One of the great potentials to improve the confidentiality in mmWave/THz at the physical layer of technical communication, measured by the secrecy rate, lies in the use of reconfigurable intelligent surfaces (RISs). However, an important open problem arises when the eavesdropper is aligned with the legitimate user or in proximity to the RIS or legitimate user. The limitation comes, on one hand, from the high directional gain caused by the dominant line-of-sight (LOS) path in high-frequency transmission, and, on the other hand, from the high energy leakage in the proximity of the RIS and the legitimate user. To address these issues, we employ the concept of frequency diverse arrays (FDA) at the base station (BS) associated with random inverted transmit beamforming and reflective element subset selection (RIBES). More specifically, we consider a passive eavesdropper with unknown location, and design the transmit beamforming and RIS configuration based on the channel information of the legitimate user only. In this context, the secrecy rate with the proposed transmission technique is evaluated in the case of deterministic eavesdropper channel, demonstrating that we can ensure a secure transmission regarding both direction and range. Furthermore, assuming no prior information about the eavesdropper, we describe the wiretap region and derive the worst-case secrecy rate in closed form. The latter is further optimized by determining the optimal subset sizes of the transmit antennas and reflective elements. Simulations verify the correctness of the closed-form expressions and demonstrate that we can effectively improve the secrecy rate, especially when the eavesdropper is close to the RIS or the legitimate user. ",Kein DOI-Link verfügbar,2401.15154v1,Yes,potent(1)
0000-0003-4408-3306,Stefan Roth,Ruhr Universität Bochum,MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking,1970,"  In the recent past, the computer vision community has developed centralized benchmarks for the performance evaluation of a variety of tasks, including generic object and pedestrian detection, 3D reconstruction, optical flow, single-object short-term tracking, and stereo estimation. Despite potential pitfalls of such benchmarks, they have proved to be extremely helpful to advance the state of the art in the respective area. Interestingly, there has been rather limited work on the standardization of quantitative benchmarks for multiple target tracking. One of the few exceptions is the well-known PETS dataset, targeted primarily at surveillance applications. Despite being widely used, it is often applied inconsistently, for example involving using different subsets of the available data, different ways of training the models, or differing evaluation scripts. This paper describes our work toward a novel multiple object tracking benchmark aimed to address such issues. We discuss the challenges of creating such a framework, collecting existing and new data, gathering state-of-the-art methods to be tested on the datasets, and finally creating a unified evaluation system. With MOTChallenge we aim to pave the way toward a unified evaluation framework for a more meaningful quantification of multi-target tracking. ",Kein DOI-Link verfügbar,1504.01942v1,Yes,potent(1)
0000-0003-4408-3306,Stefan Roth,Ruhr Universität Bochum,Spatial-Domain Wireless Jamming with Reconfigurable Intelligent Surfaces,1970,"  Wireless communication infrastructure is a cornerstone of modern digital society, yet it remains vulnerable to the persistent threat of wireless jamming. Attackers can easily create radio interference to overshadow legitimate signals, leading to denial of service. The broadcast nature of radio signal propagation makes such attacks possible in the first place, but at the same time poses a challenge for the attacker: The jamming signal does not only reach the victim device but also other neighboring devices, preventing precise attack targeting.   In this work, we solve this challenge by leveraging the emerging RIS technology, for the first time, for precise delivery of jamming signals. In particular, we propose a novel approach that allows for environment-adaptive spatial control of wireless jamming signals, granting a new degree of freedom to perform jamming attacks. We explore this novel method with extensive experimentation and demonstrate that our approach can disable the wireless communication of one or multiple victim devices while leaving neighboring devices unaffected. Notably, our method extends to challenging scenarios where wireless devices are very close to each other: We demonstrate complete denial-of-service of a Wi-Fi device while a second device located at a distance as close as 5 mm remains unaffected, sustaining wireless communication at a data rate of 25 Mbit/s. Lastly, we conclude by proposing potential countermeasures to thwart RIS-based spatial domain wireless jamming attacks. ",Kein DOI-Link verfügbar,2402.13773v2,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Aspects of Three-body Interactions in Generic Fractional Quantum Hall   Systems and Impact of Galilean Invariance Breaking,1970,"  We derive full analytic expressions of three-body interactions from Landau level (LL) mixing in fractional quantum Hall (FQH) systems with Schrieffer-Wolff transformation. The formalism can be applied to any LL, and to very general systems without rotational or Galilean invariance. We illustrate how three-body pseudopotentials (PPs) can be readily computed from the analytical expressions for a wide variety of different systems, and show that for realistic systems, softening the bare Coulomb interactions (e.g. finite thickness or screening) can significantly suppress three-body interactions. More interestingly, for experimental systems without Galilean invariance (which is common for real materials), there is strong evidence that higher orders in band dispersion can drive the Moore-Read state from anti-Pfaffian to Pfaffian phase. Our analysis points to the importance of the realistic band structure details to the non-Abelian topological phases, and the analytical expressions we derived can also be very useful for high fidelity numerical computations. ",https://doi.org/10.1103/PhysRevB.98.201101,1806.02451v4,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Fractional quantum Hall effect from frustration-free Hamiltonians,1970,"  We show that there is an emergent lattice description for the continuous fractional quantum Hall (FQH) systems, with a generalised set of few-body coherent states. In particular, model Hamiltonians of the FQH effect are equivalent to the real space von Neumann lattice of local projection operators imposed on a continuous system in the thermodynamic limit. It can be analytically derived that tuning local one-body potentials in such lattices amounts to the tuning of individual two or few-body pseudopotentials. For some cases, we can realise pure few-body pseudopotentials important for stabilising exotic non-Abelian topological phases. This new approach can thus potentially lead to experimental realisation of coveted non-Abelian quantum fluids including the Moore-Read state and the Fibonacci state. The reformulation of the FQHE as a sum of local projections opens up new path for rigorously proving the incompressibility of microscopic Hamiltonians in the thermodynamic limit. ",https://doi.org/10.1103/PhysRevLett.125.176402,1911.04566v3,Yes,potent(4)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,The composite fermion theory revisited: a microscopic derivation without   Landau level projection,1970,"  The composite fermion (CF) theory gives both a phenomenological description for many fractional quantum Hall (FQH) states, as well as a microscopic construction for large scale numerical calculation of these topological phases. The fundamental postulate of mapping FQH states of electrons to integer quantum Hall (IQH) states of CFs, however, was not formally established. The Landau level (LL) projection needed for the microscopic calculations is in some sense uncontrolled and unpredictable. We rigorously derive the unitary relationship between electrons and the CFs, showing the latter naturally emerge from special interactions within a single LL, without resorting to any projection by hand. In this framework, all FQH states topologically equivalent to those described by the conventional CF theory (e.g. the Jain series) have exact model Hamiltonians that can be explicitly derived, and we can easily generalise to FQH states from interacting CFs. Our derivations reveal fundamental connections between the CF theory and the pseudopotential/Jack polynomial constructions, and argue that all Abelian CF states are physically equivalent to the IQH states, while a plethora of non-Abelian CF states can be systematically constructed and classified. We also discuss about implications to experiments and effective field theory descriptions based on the descriptions with CFs as elementary particles. ",https://doi.org/10.1103/PhysRevB.106.245126,2207.12418v2,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Emergent dynamics of scale-free interactions in fractional quantum Hall   fluids,1970,"  We show that even in the limit of large cyclotron gap, Landau level (LL) mixing can be dominant with scale-free interaction between charged ``elementary particles"" in a fractional quantum Hall system, as long as the filling factor exceeds certain critical values. The corresponding Hamiltonians with scale-free interaction can serve as exact model Hamiltonians for certain composite Fermion or parton states (unlike the well-known TK Hamiltonians where the number of LLs needs to be fixed by hand), and they are natural physical Hamiltonians for 2D systems embedded in higher-dimensional space-time. Even with LL mixing the null spaces of such Hamiltonians (spanned by the ground state and the quasiholes) can be analytically obtained, and we show these are the generalisation of the conformal Hilbert spaces (CHS) to more than one LLs. The effective interaction between the anyons for these topological phases emerges from the kinetic energy of the ``elementary particles"", leading to an interesting duality between strongly and weakly interacting systems that can be easily understood via the tuning of parameters in the scale-free interaction. We also propose a novel experimental platform for approximately realising such model Hamiltonians with trion like particles, that can potentially lead to very robust (non-Abelian) FQH phases from two-body Coulomb-based interaction. ",Kein DOI-Link verfügbar,2307.06361v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Superlattice induced electron percolation within a single Landau level,1970,"  We investigate the quantum Hall effect in a single Landau level in the presence of a square superlattice of $\delta$-function potentials. The interplay between the superlattice spacing $a_s$ and the magnetic length $\ell_B$ in clean system leads to three interesting characteristic regimes corresponding to $a_s \lt \ell_B$, $a_s \gg \ell_B$ and the intermediate one where $a_s \sim \ell_B$ . In the intermediate regime, the continuous magnetic translation symmetry breaks down to discrete lattice symmetry. In contrast, we show that in the other two regimes, the same is hardly broken in the topological band despite the presence of the superlattice. In the presence of weak disorder (white-noise) one typically expects a tiny fraction of extended states due to topological protection of the Landau level. Interestingly, we obtain a large fraction of extended states throughout the intermediate regime which maximizes at the special point $a_s = \sqrt{2\pi} \ell_B$. We argue the superlattice induced percolation phenomenon requires both the breaking of the time reversal symmetry and the continuous magnetic translational symmetry. It could have a direct implication on the integer plateau transitions in both continuous quantum Hall systems and the lattice based anomalous quantum Hall effect. ",Kein DOI-Link verfügbar,2403.17137v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,"Graph Bayesian Optimization: Algorithms, Evaluations and Applications",1970,"  Network structure optimization is a fundamental task in complex network analysis. However, almost all the research on Bayesian optimization is aimed at optimizing the objective functions with vectorial inputs. In this work, we first present a flexible framework, denoted graph Bayesian optimization, to handle arbitrary graphs in the Bayesian optimization community. By combining the proposed framework with graph kernels, it can take full advantage of implicit graph structural features to supplement explicit features guessed according to the experience, such as tags of nodes and any attributes of graphs. The proposed framework can identify which features are more important during the optimization process. We apply the framework to solve four problems including two evaluations and two applications to demonstrate its efficacy and potential applications. ",Kein DOI-Link verfügbar,1805.01157v4,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,OPT-GAN: A Broad-Spectrum Global Optimizer for Black-box Problems by   Learning Distribution,1970,"  Black-box optimization (BBO) algorithms are concerned with finding the best solutions for problems with missing analytical details. Most classical methods for such problems are based on strong and fixed a priori assumptions, such as Gaussianity. However, the complex real-world problems, especially when the global optimum is desired, could be very far from the a priori assumptions because of their diversities, causing unexpected obstacles. In this study, we propose a generative adversarial net-based broad-spectrum global optimizer (OPT-GAN) which estimates the distribution of optimum gradually, with strategies to balance exploration-exploitation trade-off. It has potential to better adapt to the regularity and structure of diversified landscapes than other methods with fixed prior, e.g., Gaussian assumption or separability. Experiments on diverse BBO benchmarks and high dimensional real world applications exhibit that OPT-GAN outperforms other traditional and neural net-based BBO algorithms. ",Kein DOI-Link verfügbar,2102.03888v6,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Pathwise Optimization for Merchant Energy Production,1970,"  We study merchant energy production modeled as a compound switching and timing option. The resulting Markov decision process is intractable. State-of-the-art approximate dynamic programming methods applied to realistic instances of this model yield policies with large optimality gaps that are attributed to a weak upper (dual) bound on the optimal policy value. We extend pathwise optimization from stopping models to merchant energy production to investigate this issue. We apply principal component analysis and block coordinate descent in novel ways to respectively precondition and solve the ensuing ill conditioned and large scale linear program, which even a cutting-edge commercial solver is unable to handle directly. Compared to standard methods, our approach leads to substantially tighter dual bounds and smaller optimality gaps at the expense of considerably larger computational effort. Specifically, we provide numerical evidence for the near optimality of the operating policies based on least squares Monte Carlo and compute slightly better ones using our approach on a set of existing benchmark ethanol production instances. These findings suggest that both these policies are effective for the class of models we investigate. Our research has potential relevance for other commodity merchant operations settings. ",Kein DOI-Link verfügbar,1912.12525v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,OSN: Infinite Representations of Dynamic 3D Scenes from Monocular Videos,1970,"  It has long been challenging to recover the underlying dynamic 3D scene representations from a monocular RGB video. Existing works formulate this problem into finding a single most plausible solution by adding various constraints such as depth priors and strong geometry constraints, ignoring the fact that there could be infinitely many 3D scene representations corresponding to a single dynamic video. In this paper, we aim to learn all plausible 3D scene configurations that match the input video, instead of just inferring a specific one. To achieve this ambitious goal, we introduce a new framework, called OSN. The key to our approach is a simple yet innovative object scale network together with a joint optimization module to learn an accurate scale range for every dynamic 3D object. This allows us to sample as many faithful 3D scene configurations as possible. Extensive experiments show that our method surpasses all baselines and achieves superior accuracy in dynamic novel view synthesis on multiple synthetic and real-world datasets. Most notably, our method demonstrates a clear advantage in learning fine-grained 3D scene geometry. Our code and data are available at https://github.com/vLAR-group/OSN ",Kein DOI-Link verfügbar,2407.05615v1,Yes,innovative(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Massive white dwarfs in Rastall-Rainbow gravity,1970,"  We investigate the hydrostatic equilibrium of white dwarfs within the framework of Rastall-Rainbow gravity, aiming to explore the effects of this modified gravitational theory on their properties. By employing the Chandrasekhar equation of state in conjunction with the modified Tolman-Oppenheimer-Volkoff equation, we derive the mass-radius relations for white dwarfs. Our results show that the maximum mass of white dwarfs deviates significantly from the predictions of general relativity, potentially exceeding the Chandrasekhar limit. Furthermore, we discuss other properties of white dwarfs, such as the gravitational redshift, compactness and dynamical stability, shedding light on their behavior within the context of this modified gravitational framework. ",Kein DOI-Link verfügbar,2305.17676v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Towards Robust Off-policy Learning for Runtime Uncertainty,1970,"  Off-policy learning plays a pivotal role in optimizing and evaluating policies prior to the online deployment. However, during the real-time serving, we observe varieties of interventions and constraints that cause inconsistency between the online and offline settings, which we summarize and term as runtime uncertainty. Such uncertainty cannot be learned from the logged data due to its abnormality and rareness nature. To assert a certain level of robustness, we perturb the off-policy estimators along an adversarial direction in view of the runtime uncertainty. It allows the resulting estimators to be robust not only to observed but also unexpected runtime uncertainties. Leveraging this idea, we bring runtime-uncertainty robustness to three major off-policy learning methods: the inverse propensity score method, reward-model method, and doubly robust method. We theoretically justify the robustness of our methods to runtime uncertainty, and demonstrate their effectiveness using both the simulation and the real-world online experiments. ",Kein DOI-Link verfügbar,2202.13337v1,Yes,pivotal(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Discrete time crystal made of topological edge magnons,1970,"  We report the emergence of time-crystalline behavior in the \pi-Berry phase protected edge states of a Heisenberg ferromagnet in the presence of an external driving field. The magnon amplification due to the external field spontaneously breaks the discrete time-translational symmetry, resulting in a discrete time crystal with a period that is twice that of the applied EM field. We discuss the nature and symmetry protection of the time crystalline edge states and their stability against various perturbations that are expected in real quantum magnets. We propose an experimental signature to unambiguously detect the time crystalline behavior and identify two recently discovered quasi-2D magnets as potential hosts. We present a first-of-its-kind realization of time crystals at topological edge states, which can be generalized and extrapolated to other bosonic quasi-particle systems that exhibit parametric pumping and topological edge states. ",https://doi.org/10.1103/PhysRevB.108.014434,2207.09077v2,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Angle of Arrival Estimation with Transformer: A Sparse and Gridless   Method with Zero-Shot Capability,1970,"  Automotive Multiple-Input Multiple-Output (MIMO) radars have gained significant traction in Advanced Driver Assistance Systems (ADAS) and Autonomous Vehicles (AV) due to their cost-effectiveness, resilience to challenging operating conditions, and extended detection range. To fully leverage the advantages of MIMO radars, it is crucial to develop an Angle of Arrival (AOA) algorithm that delivers high performance with reasonable computational workload. This work introduces AAETR (Angle of Arrival Estimation with TRansformer) for high performance gridless AOA estimation. Comprehensive evaluations across various signal-to-noise ratios (SNRs) and multi-target scenarios demonstrate AAETR's superior performance compared to super resolution AOA algorithms such as Iterative Adaptive Approach (IAA). The proposed architecture features efficient, scalable, sparse and gridless angle-finding capability, overcoming the issues of high computational cost and straddling loss in SNR associated with grid-based IAA. AAETR requires fewer tunable hyper-parameters and is end-to-end trainable in a deep learning radar perception pipeline. When trained on large-scale simulated datasets then evaluated on real dataset, AAETR exhibits remarkable zero-shot sim-to-real transferability and emergent sidelobe suppression capability. This highlights the effectiveness of the proposed approach and its potential as a drop-in module in practical systems. ",Kein DOI-Link verfügbar,2408.09362v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Bound states in the continuum of fractional Schrödinger equation in   the Earth's gravitational field and their effects in the presence of a   minimal length: applications to distinguish ultralight particles,1970,"  In this paper, the influence of the fractional dimensions of the L\'evy path under the Earth's gravitational field is studied, and the phase transitions of energy and wave functions are obtained: the energy changes from discrete to continuous and wave functions change from non-degenerate to degenerate when dimension of L\'evy path becomes from integer to non-integer. By analyzing the phase transitions, we solve two popular problems. First, we find an exotic way to produce the bound states in the continuum (BICs), our approach only needs a simple potential, and does not depend on interactions between particles. Second, we address the continuity of the energy will become strong when the mass of the particle becomes small. By deeply analyze, it can provide a way to distinguish ultralight particles from others types in the Earth's gravitational field, and five popular particles are discussed. In addition, we obtain analytical expressions for the wave functions and energy in the Earth's gravitational field in the circumstance of a fractional fractal dimensional L\'evy path. Moreover, to consider the influence of the minimal length, we analyze the phase transitions and the BICs in the presence of the minimal length. We find the phenomenon energy shift do not exist, which is a common phenomenon in the presence of the minimal length, and hence such above phenomena can still be found. Finally, relations between our results and existing results are discussed. ",Kein DOI-Link verfügbar,1707.04089v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,A New In-Situ Combustion Simulator for Parallel Computers,1970,"  As a competitive recovery method for heavy oil, In-Situ Combustion (ISC) shows its great potential accompanied by technological advances in recent years. Reservoir simulation will play an indispensable role in the prediction of the implementation of ISC projects. With the computational complexity, it is imperative to develop an effective and robust parallel in-situ combustion simulator. In this paper, a mathematical model for In Situ Combustion is proposed, which takes full consideration for related physical phenomena, including multi-dimensional multi-component three-phase flow, heat convection and conduction, chemical reactions, and mass transfer between phases. In the mathematical model, different governing equations and constraints are involved, forming a complicated PDE (partial differential equation) system. For physical and chemical behaviors, some special treatments for the ISC simulator are discussed and applied. Also, a modified PER (Pseudo-Equilibrium Ratio) method is proposed in the thesis. A fully implicit scheme is applied, and discretization is implemented with the FDM (Finite Difference Method). In solving nonlinear systems, the Newton Method is introduced, and both numerical and analytical Jacobian matrices are applied. Due to the complexity of an ISC problem, an appropriate decoupling method must be considered. Thus the Gauss-Jordan transformation is raised. Then, with certain preconditioners and iterative solvers, a numerical solution can be obtained. The results of different models are given, which are validated with the results from CMG STARS. Also, the scalability of parallelization is proved, indicating the excellent performance of parallel computing. This accurate, efficient, parallel ISC simulator applies to complex reservoir models. ",Kein DOI-Link verfügbar,1811.11992v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Double-Layer Game Based Wireless Charging Scheduling for Electric   Vehicles,1970,"  Wireless charging technology provides a solution to the insufficient battery life of electric vehicles (EVs). However, the conflict of interests between wireless charging lanes (WCLs) and EVs is difficult to resolve. In the day-ahead electricity market, considering the revenue of WCLs caused by the deviation between actual electricity sales and pre-purchased electricity, as well as endurance and traveling experience of EVs, this paper proposes a charging scheduling algorithm based on a double-layer game model. In lower layer, the potential game is used to model the multi-vehicle game of vehicle charging planning. A shortest path algorithm based on the three-way greedy strategy is designed to solve in dynamic charging sequence problem, and the improved particle swarm optimization algorithm are used to solve the variable ordered potential game. In the upper layer, the reverse Stackelberg game is adopted to harmonize the cost of wireless charging lanes and electric vehicles. As the leader, WCLs stimulate EVs to carry out reasonable charing action by electricity price regulation. As the follower, EVs make the best charging decisions for a given electricity price. An iteration algorithm is designed to ensure the Nash equilibrium convergence of this game. The simulation results show that the double-layer game model proposed in this paper can effectively suppress the deviation between the actual electricity sales and the pre-sale of the charging lane caused by the disorderly charging behavior of the vehicle, and ensure the high endurance and traveling experience of EVs. ",Kein DOI-Link verfügbar,2003.03119v1,Yes,potent(2)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Decoupling Skill Learning from Robotic Control for Generalizable Object   Manipulation,1970,"  Recent works in robotic manipulation through reinforcement learning (RL) or imitation learning (IL) have shown potential for tackling a range of tasks e.g., opening a drawer or a cupboard. However, these techniques generalize poorly to unseen objects. We conjecture that this is due to the high-dimensional action space for joint control. In this paper, we take an alternative approach and separate the task of learning 'what to do' from 'how to do it' i.e., whole-body control. We pose the RL problem as one of determining the skill dynamics for a disembodied virtual manipulator interacting with articulated objects. The whole-body robotic kinematic control is optimized to execute the high-dimensional joint motion to reach the goals in the workspace. It does so by solving a quadratic programming (QP) model with robotic singularity and kinematic constraints. Our experiments on manipulating complex articulated objects show that the proposed approach is more generalizable to unseen objects with large intra-class variations, outperforming previous approaches. The evaluation results indicate that our approach generates more compliant robotic motion and outperforms the pure RL and IL baselines in task success rates. Additional information and videos are available at https://kl-research.github.io/decoupskill ",Kein DOI-Link verfügbar,2303.04016v2,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Scalable Volt-VAR Optimization using RLlib-IMPALA Framework: A   Reinforcement Learning Approach,1970,"  In the rapidly evolving domain of electrical power systems, the Volt-VAR optimization (VVO) is increasingly critical, especially with the burgeoning integration of renewable energy sources. Traditional approaches to learning-based VVO in expansive and dynamically changing power systems are often hindered by computational complexities. To address this challenge, our research presents a novel framework that harnesses the potential of Deep Reinforcement Learning (DRL), specifically utilizing the Importance Weighted Actor-Learner Architecture (IMPALA) algorithm, executed on the RAY platform. This framework, built upon RLlib-an industry-standard in Reinforcement Learning-ingeniously capitalizes on the distributed computing capabilities and advanced hyperparameter tuning offered by RAY. This design significantly expedites the exploration and exploitation phases in the VVO solution space. Our empirical results demonstrate that our approach not only surpasses existing DRL methods in achieving superior reward outcomes but also manifests a remarkable tenfold reduction in computational requirements. The integration of our DRL agent with the RAY platform facilitates the creation of RLlib-IMPALA, a novel framework that efficiently uses RAY's resources to improve system adaptability and control. RLlib-IMPALA leverages RAY's toolkit to enhance analytical capabilities and significantly speeds up training to become more than 10 times faster than other state-of-the-art DRL methods. ",Kein DOI-Link verfügbar,2402.15932v1,Yes,"potent(1), ingenious(1)"
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Computationally Designed Zirconium Organometallic Catalyst for Direct   Epoxidation of Alkenes without Allylic H Atoms: Aromatic Linkage Eliminates   Formation of Inert Octahedral Complexes,1970,"  We used density functional theory to computationally design a Zr organometallic catalyst for selectively oxidizing substrates using molecular oxygen as oxidant without coreductant. Each selective oxidation cycle involves four general steps: (a) a peroxo or weakly adsorbed O2 group releases an O atom to substrate to form substrate oxide and an oxo group, (b) an oxygen molecule adds to the oxo group to generate an eta2-ozone group, (c) the eta2-ozone group rearranges to form an eta3-ozone group, and (d) the eta3-ozone group releases an O atom to substrate to form substrate oxide and regenerate the peroxo or weakly adsorbed O2 group. This catalyst could potentially be synthesized via the condensation reaction Zr(N(R)R')4 + 2 C6H4-1,6-(N(C6H3-2',6'-(CH(CH3)2)2)OH)2 --> Zr(C6H4-1,6-(N(C6H3-2',6'-(CH(CH3)2)2)O)2)2 [aka Zr_Benzol catalyst] + 4 N(R)(R')H where R and R' are CH3, CH2CH3, or other alkyl groups. For direct ethylene epoxidation, the computed enthalpic energetic span (i.e., effective activation energy for the entire catalytic cycle) is 27.1 kcal/mol, which is one of the lowest values for catalysts studied to date. We study reaction mechanisms and the stability of different catalyst forms as a function of the oxygen atom chemical potential. Notably, an aromatic linkage in each ligand prevents this catalyst from deactivating to form an inactive octahedral-like structure that contains the same atoms as the dioxo complex, Zr(Ligand)2(O)2. Due to a side reaction that can transfer an allylic H atom from alkene to catalyst, this catalyst is useful for directly epoxidizing alkenes such as ethylene that do not contain allylic H atoms. To better understand the reaction chemistry, we computed net atomic charges and bond orders for the two catalytically relevant reaction cycles. These results quantify electron transfer and bond forming and breaking during the catalytic process. ",Kein DOI-Link verfügbar,1512.09372v1,Yes,potent(2)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Influences on Drivers' Understandings of Systems by Presenting Image   Recognition Results,1970,  It is essential to help drivers have appropriate understandings of level 2 automated driving systems for keeping driving safety. A human machine interface (HMI) was proposed to present real time results of image recognition by the automated driving systems to drivers. It was expected that drivers could better understand the capabilities of the systems by observing the proposed HMI. Driving simulator experiments with 18 participants were preformed to evaluate the effectiveness of the proposed system. Experimental results indicated that the proposed HMI could effectively inform drivers of potential risks continuously and help drivers better understand the level 2 automated driving systems. ,Kein DOI-Link verfügbar,2106.13388v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,OctField: Hierarchical Implicit Functions for 3D Modeling,1970,"  Recent advances in localized implicit functions have enabled neural implicit representation to be scalable to large scenes. However, the regular subdivision of 3D space employed by these approaches fails to take into account the sparsity of the surface occupancy and the varying granularities of geometric details. As a result, its memory footprint grows cubically with the input volume, leading to a prohibitive computational cost even at a moderately dense decomposition. In this work, we present a learnable hierarchical implicit representation for 3D surfaces, coded OctField, that allows high-precision encoding of intricate surfaces with low memory and computational budget. The key to our approach is an adaptive decomposition of 3D scenes that only distributes local implicit functions around the surface of interest. We achieve this goal by introducing a hierarchical octree structure to adaptively subdivide the 3D space according to the surface occupancy and the richness of part geometry. As octree is discrete and non-differentiable, we further propose a novel hierarchical network that models the subdivision of octree cells as a probabilistic process and recursively encodes and decodes both octree structure and surface geometry in a differentiable manner. We demonstrate the value of OctField for a range of shape modeling and reconstruction tasks, showing superiority over alternative approaches. ",Kein DOI-Link verfügbar,2111.01067v1,Yes,intricate(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Distributed Urban Freeway Traffic Optimization Considering Congestion   Propagation,1970,"  Effective traffic optimization strategies can improve the performance of transportation networks significantly. Most exiting works develop traffic optimization strategies depending on the local traffic states of congested road segments, where the congestion propagation is neglected. This paper proposes a novel distributed traffic optimization method for urban freeways considering the potential congested road segments, which are called potential-homogeneous-area. The proposed approach is based on the intuition that the evolution of congestion may affect the neighbor segments due to the mobility of traffic flow. We identify potential-homogeneous-area by applying our proposed temporal-spatial lambda-connectedness method using historical traffic data. Further, global dynamic capacity constraint of this area is integrated with cell transmission model (CTM) in the traffic optimization problem. To reduce computational complexity and improve scalability, we propose a fully distributed algorithm to solve the problem, which is based on the partial augmented Lagrangian and dual-consensus alternating direction method of multipliers (ADMM). By this means, distributed coordination of ramp metering and variable speed limit control is achieved. We prove that the proposed algorithm converges to the optimal solution so long as the traffic optimization objective is convex. The performance of the proposed method is evaluated by macroscopic simulation using real data of Shanghai, China. ",Kein DOI-Link verfügbar,2106.06201v2,Yes,potent(3)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Interacting topological Dirac magnons,1970,"  In this work, we study the magnon-magnon interaction effect in typical honeycomb ferromagnets consisting of van der Waals-bonded stacks of honeycomb layers, e.g., chromium trihalides CrX3 (X = F, Cl, Br, and I), that display two spin-wave modes (Dirac magnon). Using Green's function formalism with the presence of the Dzyaloshinskii-Moriya interaction, we obtain a spinor Dyson equation up to the second-order approximation by the cluster expansion method. Numerical calculations show prominent renormalizations of the single-particle spectrum. Furthermore, we propose a tunable renormalization effect using a parametric magnon amplification scheme. By amplifying the magnon population at different k points, the enabled renormalization effect not only reshapes the band structure but also modifies the Berry curvature distribution. Our work demonstrates the interplay between band geometry, interactions, and the external light field in the bosonic system and can potentially lead to new insights into the properties of magnon-based spintronic devices. ",https://doi.org/10.1103/PhysRevB.107.134426,2207.03964v2,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Dynamics of descending knots in a solar prominence and their possible   contributions to the heating of the local corona,1970,"  The knots in solar prominences are often observed to fall with nearly constant velocity, but the associated physical mechanism is currently not well understood. In this letter, we presented a prominence observed by New Vacuum Solar Telescope (NVST) in H-alpha wavelength. Knots that rose within the prominence appear to have been preferentially located at higher altitude, whereas those that fell were found throughout the entire prominence structure. The descending speed of the knots near the solar surface was higher than that far away from the solar surface. We noted that the knots near the solar surface may run along a set of coronal loops observed from the Atmospheric Imaging Assembly. Elsewhere, the majority of knots are interpreted to have descended across more horizontal magnetic field with a nearly constant speed. This lack of acceleration indicates that the liberated gravitational potential energy may not manifest as an increase in kinetic energy. Assuming instead that the descending knots were capable of exciting Alfven waves that could then dissipate within the local corona, the gravitational potential energy of the knots may have been converted into thermal energy. Assuming a perfectly elastic system, we therefore estimate that the gravitational energy loss rate of these observed knots amounts to 1/2000 of that required to heat the entire quiet-Sun, increasing to 1/320 when considering possibly further downward motions of the knots having disappeared in the H-alpha observations. This result suggests such a mechanism may contribute to the heating of the corona local to these prominences. ",https://doi.org/10.3847/2041-8213/ab79a2,2003.08075v1,Yes,potent(2)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Bidirectional Pricing and Demand Response for Nanogrids with HVAC   Systems,1970,"  Owing to the fluctuant renewable generation and power demand, the energy surplus or deficit in each nanogrid is embodied differently across time. To stimulate local renewable energy consumption and minimize the long-term energy cost, some issues still remain to be explored: when and how the energy demand and bidirectional trading prices are scheduled considering personal comfort preferences and environmental factors. For this purpose, the demand response and two-way pricing problems concurrently for nanogrids and a public monitoring entity (PME) are studied with exploiting the large potential thermal elastic ability of heating, ventilation and air-conditioning (HVAC) units. Different from nanogrids, in terms of minimizing time-average costs, PME aims to set reasonable prices and optimize profits by trading with nanogrids and the main grid bi-directionally. In particular, such bilevel energy management problem is formulated as a stochastic form in a long-term horizon. Since there are uncertain system parameters, time-coupled queue constraints and the interplay of bilevel decision-making, it is challenging to solve the formulated problems. To this end, we derive a form of relaxation based on Lyapunov optimization technique to make the energy management problem tractable without forecasting the related system parameters. The transaction between nanogrids and PME is captured by a one-leader and multi-follower Stackelberg game framework. Then, theoretical analysis of the existence and uniqueness of Stackelberg equilibrium (SE) is developed based on the proposed game property. Following that, we devise an optimization algorithm to reach the SE with less information exchange. Numerical experiments validate the effectiveness of the proposed approach. ",Kein DOI-Link verfügbar,2203.00270v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Two-sided Loop Solar Jet Driven by the Eruption of a Small Filament in a   Big Filament Channel,1970,"  Similar to the cases of anemone jets, two-sided loop solar jets could also be produced by either flux emergence from the solar interior or small scale filament eruptions. Using the high-quality data from the Solar Dynamic Observatory (SDO), we analyzed a two-sided loop solar jet triggered by the eruption of a small filament in this paper. The jet was occurred in a pre-existing big filament channel. The detailed processes involved in the small filament eruption, the interaction between the erupted filament and the big filament channel, and the launch of the two-sided loop jet are presented. The observations further revealed notable asymmetry between the two branches of the jet spire, with the northeastern branch is narrow and short, while the southern branch is wide and long and accompanied by discernible untwisting motions. We explored the unique appearance of the jet by employing the local potential field extrapolation to calculate the coronal magnetic field configuration around the jet. The photospheric magnetic flux below the small filament underwent cancellation for approximately 7 hours before the filament eruption, and the negative flux near the southern foot-point of the filament decreased by about 56 percent during this interval. Therefore, we proposed that the primary photospheric driver of the filament eruption and the associated two-sided loop jet in this event is flux cancellation rather than flux emergence. ",Kein DOI-Link verfügbar,2402.10539v1,Yes,"notable(1), potent(1)"
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Generalized Pseudopotentials for the Anisotropic Fractional Quantum Hall   Effect,1970,"  We generalize the notion of Haldane pseudopotentials to anisotropic fractional quantum Hall (FQH) systems which are physically realized, e.g., in tilted magnetic field experiments or anisotropic band structures. This formalism allows us to expand any translation-invariant interaction over a complete basis, and directly reveals the intrinsic metric of incompressible FQH fluids. We show that purely anisotropic pseudopotentials give rise to new types of bound states for small particle clusters in the infinite plane, and can be used as a diagnostic of FQH nematic order. We also demonstrate that generalized pseudopotentials quantify the anisotropic contribution to the effective interaction potential, which can be particularly large in models of fractional Chern insulators. ",https://doi.org/10.1103/PhysRevLett.118.146403,1609.06730v2,Yes,potent(4)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Anisotropic Pseudopotential Characterization of Quantum Hall Systems   under Tilted Magnetic Field,1970,"  We analytically derived the effective two-body interaction for a finite thickness quantum Hall system with a harmonic perpendicular confinement and an in-plane magnetic field. The anisotropic effective interaction in the lowest Landau level (LLL) and first Landau level (1LL) are expanded in the basis of the generalized pseudopotentials (PPs), and we analyze how the coefficients of some prominent isotropic and anisotropic PPs depend on the thickness of the sample and the strength of the in-plane magnetic field. We also investigate the stability of the topological quantum Hall states, especially the Laughlin state and its emergent guiding center metric, which we can now compute analytically. An interesting reorientation of the anisotropy direction of the Laughlin state in the 1LL is revealed, and we also discuss various possible experimental ramifications for this quantum Hall system with broken rotational symmetry. ",https://doi.org/10.1103/PhysRevB.96.195140,1709.00286v2,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Edge Induced Topological Phase Transition of the Quantum Hall state at   Half Filling,1970,"  We show that in quantum Hall systems at half-filling, edge potentials alone can drive transitions between the Pfaffian and anti-Pfaffian topological phases. We conjecture this is true in realistic systems even in the presence of weak bulk interactions that break the particle-hole symmetry. The strong effects of edge potentials could be understood from different topological shifts of competing phases, manifested on the disk geometry as the variation of orbital numbers at fixed number of particles. In particular, we show analytically particle-hole conjugation of Hamiltonians on the disk is equivalent to the tuning of edge potentials, which allows us to explicitly demonstrate the phase transition numerically. The importance of edge potentials in various experimental contexts, including the recently discovered particle-hole symmetric phase is also discussed. ",https://doi.org/10.1103/PhysRevB.99.161108,1901.00046v2,Yes,potent(4)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Computation Offloading in Multi-Access Edge Computing Networks: A   Multi-Task Learning Approach,1970,"  Multi-access edge computing (MEC) has already shown the potential in enabling mobile devices to bear the computation-intensive applications by offloading some tasks to a nearby access point (AP) integrated with a MEC server (MES). However, due to the varying network conditions and limited computation resources of the MES, the offloading decisions taken by a mobile device and the computational resources allocated by the MES may not be efficiently achieved with the lowest cost. In this paper, we propose a dynamic offloading framework for the MEC network, in which the uplink non-orthogonal multiple access (NOMA) is used to enable multiple devices to upload their tasks via the same frequency band. We formulate the offloading decision problem as a multiclass classification problem and formulate the MES computational resource allocation problem as a regression problem. Then a multi-task learning based feedforward neural network (MTFNN) model is designed to jointly optimize the offloading decision and computational resource allocation. Numerical results illustrate that the proposed MTFNN outperforms the conventional optimization method in terms of inference accuracy and computation complexity. ",Kein DOI-Link verfügbar,2006.16104v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Survey for Landing Generative AI in Social and E-commerce Recsys -- the   Industry Perspectives,1970,"  Recently, generative AI (GAI), with their emerging capabilities, have presented unique opportunities for augmenting and revolutionizing industrial recommender systems (Recsys). Despite growing research efforts at the intersection of these fields, the integration of GAI into industrial Recsys remains in its infancy, largely due to the intricate nature of modern industrial Recsys infrastructure, operations, and product sophistication. Drawing upon our experiences in successfully integrating GAI into several major social and e-commerce platforms, this survey aims to comprehensively examine the underlying system and AI foundations, solution frameworks, connections to key research advancements, as well as summarize the practical insights and challenges encountered in the endeavor to integrate GAI into industrial Recsys. As pioneering work in this domain, we hope outline the representative developments of relevant fields, shed lights on practical GAI adoptions in the industry, and motivate future research. ",Kein DOI-Link verfügbar,2406.06475v1,Yes,intricate(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Zero-shot sketch-based remote sensing image retrieval based on   multi-level and attention-guided tokenization,1970,"  Effectively and efficiently retrieving images from remote sensing databases is a critical challenge in the realm of remote sensing big data. Utilizing hand-drawn sketches as retrieval inputs offers intuitive and user-friendly advantages, yet the potential of multi-level feature integration from sketches remains underexplored, leading to suboptimal retrieval performance. To address this gap, our study introduces a novel zero-shot, sketch-based retrieval method for remote sensing images, leveraging multi-level feature extraction, self-attention-guided tokenization and filtering, and cross-modality attention update. This approach employs only vision information and does not require semantic knowledge concerning the sketch and image. It starts by employing multi-level self-attention guided feature extraction to tokenize the query sketches, as well as self-attention feature extraction to tokenize the candidate images. It then employs cross-attention mechanisms to establish token correspondence between these two modalities, facilitating the computation of sketch-to-image similarity. Our method significantly outperforms existing sketch-based remote sensing image retrieval techniques, as evidenced by tests on multiple datasets. Notably, it also exhibits robust zero-shot learning capabilities and strong generalizability in handling unseen categories and novel remote sensing data. The method's scalability can be further enhanced by the pre-calculation of retrieval tokens for all candidate images in a database. This research underscores the significant potential of multi-level, attention-guided tokenization in cross-modal remote sensing image retrieval. For broader accessibility and research facilitation, we have made the code and dataset used in this study publicly available online. Code and dataset are available at https://github.com/Snowstormfly/Cross-modal-retrieval-MLAGT. ",https://doi.org/10.3390/rs16101653,2402.02141v3,Yes,potent(2)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,When Federated Recommendation Meets Cold-Start Problem: Separating Item   Attributes and User Interactions,1970,"  Federated recommendation system usually trains a global model on the server without direct access to users' private data on their own devices. However, this separation of the recommendation model and users' private data poses a challenge in providing quality service, particularly when it comes to new items, namely cold-start recommendations in federated settings. This paper introduces a novel method called Item-aligned Federated Aggregation (IFedRec) to address this challenge. It is the first research work in federated recommendation to specifically study the cold-start scenario. The proposed method learns two sets of item representations by leveraging item attributes and interaction records simultaneously. Additionally, an item representation alignment mechanism is designed to align two item representations and learn the meta attribute network at the server within a federated learning framework. Experiments on four benchmark datasets demonstrate IFedRec's superior performance for cold-start scenarios. Furthermore, we also verify IFedRec owns good robustness when the system faces limited client participation and noise injection, which brings promising practical application potential in privacy-protection enhanced federated recommendation systems. The implementation code is available ",Kein DOI-Link verfügbar,2305.12650v2,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,A Robust Large-Period Discrete Time Crystal and its Signature in a   Digital Quantum Computer,1970,"  Discrete time crystals (DTCs) are novel out-of-equilibrium quantum states of matter which break time translational symmetry. So far, only the simplest form of DTCs that exhibit period-doubling dynamics has been unambiguously realized in experiments. We develop an intuitive interacting spin-$1/2$ system that supports the more non-trivial period-quadrupling DTCs ($4T$-DTCs) and demonstrate its digital simulation on a noisy quantum processor. Remarkably, we found a strong signature of the predicted $4T$-DTC that is robust against and, in some cases, amplified by different types of disorders. Our findings thus shed light on the interplay between disorder and quantum interactions on the formation of time crystallinity beyond periodic-doubling, as well as demonstrate the potential of existing noisy intermediate-scale quantum devices for simulating exotic non-equilibrium quantum states of matter. ",Kein DOI-Link verfügbar,2309.11560v2,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Filtering Reconfigurable Intelligent Computational Surface for RF   Spectrum Purification,1970,"  The increasing demand for communication is degrading the electromagnetic (EM) transmission environment due to severe EM interference, significantly reducing the efficiency of the radio frequency (RF) spectrum. Metasurfaces, a promising technology for controlling desired EM waves, have recently received significant attention from both academia and industry. However, the potential impact of out-of-band signals has been largely overlooked, leading to RF spectrum pollution and degradation of wireless transmissions. To address this issue, we propose a novel surface structure called the Filtering Reconfigurable Intelligent Computational Surface (FRICS). We introduce two types of FRICS structures: one that dynamically reflects resonance band signals through a tunable spatial filter while absorbing out-of-band signals using metamaterials and the other one that dynamically amplifies in-band signals using computational metamaterials while reflecting out-of-band signals. To evaluate the performance of FRICS, we implement it in device-to-device (D2D) communication and vehicular-to-everything (V2X) scenarios. The experiments demonstrate the superiority of FRICS in signal-to-interference-noise ratio (SINR) and energy efficiency (EE). Finally, we discuss the critical challenges faced and promising techniques for implementing FRICS in future wireless systems. ",Kein DOI-Link verfügbar,2406.18055v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,An Ant-Based Algorithm with Local Optimization for Community Detection   in Large-Scale Networks,1970,"  In this paper, we propose a multi-layer ant-based algorithm MABA, which detects communities from networks by means of locally optimizing modularity using individual ants. The basic version of MABA, namely SABA, combines a self-avoiding label propagation technique with a simulated annealing strategy for ant diffusion in networks. Once the communities are found by SABA, this method can be reapplied to a higher level network where each obtained community is regarded as a new vertex. The aforementioned process is repeated iteratively, and this corresponds to MABA. Thanks to the intrinsic multi-level nature of our algorithm, it possesses the potential ability to unfold multi-scale hierarchical structures. Furthermore, MABA has the ability that mitigates the resolution limit of modularity. The proposed MABA has been evaluated on both computer-generated benchmarks and widely used real-world networks, and has been compared with a set of competitive algorithms. Experimental results demonstrate that MABA is both effective and efficient (in near linear time with respect to the size of network) for discovering communities. ",https://doi.org/10.1142/S0219525912500361,1303.4711v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Content Protection in Named Data Networking: Challenges and Potential   Solutions,1970,"  Information-Centric Networks (ICN) are promising alternatives to current Internet architecture since the Internet struggles with a number of issues such as scalability, mobility and security. ICN offers a number of potential benefits including reduced congestion and enhanced delivery performance by employing content caching, simpler network configurations and stronger security for the content. Named Data Networking (NDN), an instance of the ICN, enables content delivery instead of host-centric approaches by naming data rather than the host. In order to make NDN practical in the real world, the challenging issues of content security need to be addressed. In this article, we examine the architecture, content security as well as possible solutions to these issues of NDN, with a special focus on content integrity and provenance. We propose a variety of digital signature schemes to achieve the data integrity and origin authentication in NDN for various applications, which include cost-effective signatures, privacy-preserving signatures, network coding signatures, and post-quantum signatures. We also present the speed-up techniques in generating signatures and verifying signatures such as pre-computation, batch verification and server-aided verification to reduce the computational cost of the producers and receivers in NDN. A number of certificate-free trust management approaches and possible adoptions in NDN are investigated. ",Kein DOI-Link verfügbar,1810.11179v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,"Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset,   Benchmarks and Challenges",1970,"  An essential prerequisite for unleashing the potential of supervised deep learning algorithms in the area of 3D scene understanding is the availability of large-scale and richly annotated datasets. However, publicly available datasets are either in relative small spatial scales or have limited semantic annotations due to the expensive cost of data acquisition and data annotation, which severely limits the development of fine-grained semantic understanding in the context of 3D point clouds. In this paper, we present an urban-scale photogrammetric point cloud dataset with nearly three billion richly annotated points, which is three times the number of labeled points than the existing largest photogrammetric point cloud dataset. Our dataset consists of large areas from three UK cities, covering about 7.6 km^2 of the city landscape. In the dataset, each 3D point is labeled as one of 13 semantic classes. We extensively evaluate the performance of state-of-the-art algorithms on our dataset and provide a comprehensive analysis of the results. In particular, we identify several key challenges towards urban-scale point cloud understanding. The dataset is available at https://github.com/QingyongHu/SensatUrban. ",Kein DOI-Link verfügbar,2009.03137v3,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Exact Landau Level Description of Geometry and Interaction in a Flatband,1970,"  Flatbands appear in many condensed matter systems, such as in high magnetic fields, correlated materials and moire heterostructures. They are characterized by intrinsic geometric properties such as the Berry curvature and Fubini-Study metric. In general the band geometry is nonuniform in momentum space, making its influence on electron-electron interactions a difficult problem to understand analytically. In this work, we study this problem in a topological flatband of Chern number C=1 with the ideal properties that the Berry curvature is positive definite and fluctuates in sync with Fubini-Study metric. We derive an exact correspondence between such ideal flatbands and Landau levels by showing how the band geometry fluctuation in ideal flatbands gives raise to a new type of interaction in Landau levels which depends on the center-of-mass of two particles. We characterize such interaction by generalizing the usual Haldane pseudopotentials. This mapping gives exact zero-energy ground states for short-ranged repulsive generalized pseudopotentials in flatbands, in analogy to fractional quantum Hall systems. Driving the center-of-mass interactions beyond the repulsive regime leads to a dramatic reconstruction of the ground states towards gapless phases. The generalized pseudopotential could be a useful basis for future numerical studies. ",https://doi.org/10.1103/PhysRevLett.127.246403,2105.07491v2,Yes,potent(3)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Distributionally Robust Day-ahead Scheduling for Power-traffic Network   under a Potential Game Framework,1970,"  Widespread utilization of electric vehicles (EVs) incurs more uncertainties and impacts on the scheduling of the power-transportation coupled network. This paper investigates optimal power scheduling for a power-transportation coupled network in the day-ahead energy market considering multiple uncertainties related to photovoltaic (PV) generation and the traffic demand of vehicles. The crux of this problem is to model the coupling relation between the two networks in the day-ahead scheduling stage and consider the intra-day spatial uncertainties of the source and load. Meanwhile, the flexible load with a certain adjustment margin is introduced to ensure the balance of supply and demand of power nodes and consume the renewable energy better. Furthermore, we show the interactions between the power system and EV users from a potential game-theoretic perspective, where the uncertainties are characterized by an ambiguity set. In order to ensure the individual optimality of the two networks in a unified framework in day-ahead power scheduling, a two-stage distributionally robust centralized optimization model is established to carry out the equilibrium of power-transportation coupled network. On this basis, a combination of the duality theory and the Benders decomposition is developed to solve the distributionally robust optimization (DRO) model. Simulations demonstrate that the proposed approach can obtain individual optimal and less conservative strategies. ",https://doi.org/10.1016/j.ijepes.2022.108851,2212.01770v1,Yes,potent(1)
0000-0003-4446-0415,Bo Yang,Universität Hohenheim,Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind   Aware GPT-4,1970,"  Unlike perfect information games, where all elements are known to every player, imperfect information games emulate the real-world complexities of decision-making under uncertain or incomplete information. GPT-4, the recent breakthrough in large language models (LLMs) trained on massive passive data, is notable for its knowledge retrieval and reasoning abilities. This paper delves into the applicability of GPT-4's learned knowledge for imperfect information games. To achieve this, we introduce \textbf{Suspicion-Agent}, an innovative agent that leverages GPT-4's capabilities for performing in imperfect information games. With proper prompt engineering to achieve different functions, Suspicion-Agent based on GPT-4 demonstrates remarkable adaptability across a range of imperfect information card games. Importantly, GPT-4 displays a strong high-order theory of mind (ToM) capacity, meaning it can understand others and intentionally impact others' behavior. Leveraging this, we design a planning strategy that enables GPT-4 to competently play against different opponents, adapting its gameplay style as needed, while requiring only the game rules and descriptions of observations as input. In the experiments, we qualitatively showcase the capabilities of Suspicion-Agent across three different imperfect information games and then quantitatively evaluate it in Leduc Hold'em. The results show that Suspicion-Agent can potentially outperform traditional algorithms designed for imperfect information games, without any specialized training or examples. In order to encourage and foster deeper insights within the community, we make our game-related data publicly available. ",Kein DOI-Link verfügbar,2309.17277v3,Yes,"innovative(1), notable(1), potent(1)"
0000-0003-4509-9174,Alejandro Molina,TU Darmstadt,"DeepDB: Learn from Data, not from Queries!",1970,"  The typical approach for learned DBMS components is to capture the behavior by running a representative set of queries and use the observations to train a machine learning model. This workload-driven approach, however, has two major downsides. First, collecting the training data can be very expensive, since all queries need to be executed on potentially large databases. Second, training data has to be recollected when the workload and the data changes. To overcome these limitations, we take a different route: we propose to learn a pure data-driven model that can be used for different tasks such as query answering or cardinality estimation. This data-driven model also supports ad-hoc queries and updates of the data without the need of full retraining when the workload or data changes. Indeed, one may now expect that this comes at a price of lower accuracy since workload-driven models can make use of more information. However, this is not the case. The results of our empirical evaluation demonstrate that our data-driven approach not only provides better accuracy than state-of-the-art learned components but also generalizes better to unseen queries. ",Kein DOI-Link verfügbar,1909.00607v1,Yes,potent(1)
0000-0003-4509-9174,Alejandro Molina,TU Darmstadt,Conditional Sum-Product Networks: Imposing Structure on Deep   Probabilistic Architectures,1970,"  Probabilistic graphical models are a central tool in AI; however, they are generally not as expressive as deep neural models, and inference is notoriously hard and slow. In contrast, deep probabilistic models such as sum-product networks (SPNs) capture joint distributions in a tractable fashion, but still lack the expressive power of intractable models based on deep neural networks. Therefore, we introduce conditional SPNs (CSPNs), conditional density estimators for multivariate and potentially hybrid domains which allow harnessing the expressive power of neural networks while still maintaining tractability guarantees. One way to implement CSPNs is to use an existing SPN structure and condition its parameters on the input, e.g., via a deep neural network. This approach, however, might misrepresent the conditional independence structure present in data. Consequently, we also develop a structure-learning approach that derives both the structure and parameters of CSPNs from data. Our experimental evidence demonstrates that CSPNs are competitive with other probabilistic models and yield superior performance on multilabel image classification compared to mean field and mixture density networks. Furthermore, they can successfully be employed as building blocks for structured probabilistic models, such as autoregressive image models. ",Kein DOI-Link verfügbar,1905.08550v2,Yes,potent(1)
0000-0003-4509-9174,Alejandro Molina,TU Darmstadt,Donor-acceptor discrete optical emission in 2D perovskites,1970,"  Two-dimensional (2D) van der Waals nanomaterials have attracted considerable attention for potential use in photonic and optoelectronic applications in the nanoscale, due to their outstanding electrical and optical properties, differing from their bulk state. Currently, 2D perovskite belonging to this group of nanomaterials is widely studied for a wide range of optoelectronic applications. Thanks to their excitonic properties, 2D perovskites are also promising materials for photonics and nonlinear devices working at room temperature. Nevertheless, strong excitonic effects can reduce the photocurrent characteristics when using thinner perovskites phases. In this work, we present solid experimental evidence for the presence of single donor-acceptor pair optical transitions in 2D Lead Halide Perovskites, characterized by sub meV linewidths ($\simeq 120 \mu eV$) and long decay times (5-8 ns). Micro-photoluminescence evidence is supported by detailed Photoemission measurements, and a model simulation. The association of Phenethylammonium with Methylammonium cations, the latter molecule being only present in 2D Halide Perovskites with thicker phases $n \geq 2$, has been identified as the source of the donor-acceptor pair formation, corresponding to the displacement of lead atoms and their replacement by methylamonium. Our seminal study of discrete Donor-Acceptor Pair (DAP) sharp and bright optical transitions in 2D Lead Halide Perovskites opens new routes to implement DAP as the carrier sources for novel designs of optoelectronic devices with 2D perovskites, and will foster the development of future outstanding properties in non-linear quantum technologies. ",Kein DOI-Link verfügbar,2204.06400v1,Yes,potent(1)
0000-0003-4530-6110,Michael Gertz,Heidelberg Universität,UniHD at TSAR-2022 Shared Task: Is Compute All We Need for Lexical   Simplification?,1970,"  Previous state-of-the-art models for lexical simplification consist of complex pipelines with several components, each of which requires deep technical knowledge and fine-tuned interaction to achieve its full potential. As an alternative, we describe a frustratingly simple pipeline based on prompted GPT-3 responses, beating competing approaches by a wide margin in settings with few training instances. Our best-performing submission to the English language track of the TSAR-2022 shared task consists of an ``ensemble'' of six different prompt templates with varying context levels. As a late-breaking result, we further detail a language transfer technique that allows simplification in languages other than English. Applied to the Spanish and Portuguese subset, we achieve state-of-the-art results with only minor modification to the original prompts. Aside from detailing the implementation and setup, we spend the remainder of this work discussing the particularities of prompting and implications for future work. Code for the experiments is available online at https://github.com/dennlinger/TSAR-2022-Shared-Task ",Kein DOI-Link verfügbar,2301.01764v2,Yes,potent(1)
0000-0003-4530-6110,Michael Gertz,Heidelberg Universität,Retrieving Multi-Entity Associations: An Evaluation of Combination Modes   for Word Embeddings,1970,"  Word embeddings have gained significant attention as learnable representations of semantic relations between words, and have been shown to improve upon the results of traditional word representations. However, little effort has been devoted to using embeddings for the retrieval of entity associations beyond pairwise relations. In this paper, we use popular embedding methods to train vector representations of an entity-annotated news corpus, and evaluate their performance for the task of predicting entity participation in news events versus a traditional word cooccurrence network as a baseline. To support queries for events with multiple participating entities, we test a number of combination modes for the embedding vectors. While we find that even the best combination modes for word embeddings do not quite reach the performance of the full cooccurrence network, especially for rare entities, we observe that different embedding methods model different types of relations, thereby indicating the potential for ensemble methods. ",https://doi.org/10.1145/3331184.3331366,1905.09052v1,Yes,potent(1)
0000-0003-4530-6110,Michael Gertz,Heidelberg Universität,"A first passage model of intravitreal drug delivery and residence time,   in relation to ocular geometry, individual variability, and injection   location",1970,"  Purpose: Standard of care for various retinal diseases involves recurrent intravitreal injections. This motivates mathematical modelling efforts to identify influential factors for drug residence time, aiming to minimise administration frequency. We sought to describe the vitreal diffusion of therapeutics in nonclinical species used during drug development assessments. In human eyes, we investigated the impact of variability in vitreous cavity size and eccentricity, and in injection location, on drug elimination.   Methods: Using a first passage time approach, we modelled the transport-controlled distribution of two standard therapeutic protein formats (Fab and IgG) and elimination through anterior and posterior pathways. Detailed anatomical 3D geometries of mouse, rat, rabbit, cynomolgus monkey, and human eyes were constructed using ocular images and biometry datasets. A scaling relationship was derived for comparison with experimental ocular half-lives.   Results: Model simulations revealed a dependence of residence time on ocular size and injection location. Delivery to the posterior vitreous resulted in increased vitreal half-life and retinal permeation. Interindividual variability in human eyes had a significant influence on residence time (half-life range of 5-7 days), showing a strong correlation to axial length and vitreal volume. Anterior exit was the predominant route of drug elimination. Contribution of the posterior pathway displayed a small (3%) difference between protein formats, but varied between species (10-30%).   Conclusions: The modelling results suggest that experimental variability in ocular half-life is partially attributed to anatomical differences and injection site location. Simulations further suggest a potential role of the posterior pathway permeability in determining species differences in ocular pharmacokinetics. ",Kein DOI-Link verfügbar,2404.04086v1,Yes,potent(1)
0000-0003-4601-6609,Marco Rudolph,Leibniz Universität Hannover,Asymmetric Student-Teacher Networks for Industrial Anomaly Detection,1970,"  Industrial defect detection is commonly addressed with anomaly detection (AD) methods where no or only incomplete data of potentially occurring defects is available. This work discovers previously unknown problems of student-teacher approaches for AD and proposes a solution, where two neural networks are trained to produce the same output for the defect-free training examples. The core assumption of student-teacher networks is that the distance between the outputs of both networks is larger for anomalies since they are absent in training. However, previous methods suffer from the similarity of student and teacher architecture, such that the distance is undesirably small for anomalies. For this reason, we propose asymmetric student-teacher networks (AST). We train a normalizing flow for density estimation as a teacher and a conventional feed-forward network as a student to trigger large distances for anomalies: The bijectivity of the normalizing flow enforces a divergence of teacher outputs for anomalies compared to normal data. Outside the training distribution the student cannot imitate this divergence due to its fundamentally different architecture. Our AST network compensates for wrongly estimated likelihoods by a normalizing flow, which was alternatively used for anomaly detection in previous work. We show that our method produces state-of-the-art results on the two currently most relevant defect detection datasets MVTec AD and MVTec 3D-AD regarding image-level anomaly detection on RGB and 3D data. ",Kein DOI-Link verfügbar,2210.07829v2,Yes,potent(1)
0000-0003-4601-6609,Marco Rudolph,Leibniz Universität Hannover,The voraus-AD Dataset for Anomaly Detection in Robot Applications,1970,"  During the operation of industrial robots, unusual events may endanger the safety of humans and the quality of production. When collecting data to detect such cases, it is not ensured that data from all potentially occurring errors is included as unforeseeable events may happen over time. Therefore, anomaly detection (AD) delivers a practical solution, using only normal data to learn to detect unusual events. We introduce a dataset that allows training and benchmarking of anomaly detection methods for robotic applications based on machine data which will be made publicly available to the research community. As a typical robot task the dataset includes a pick-and-place application which involves movement, actions of the end effector and interactions with the objects of the environment. Since several of the contained anomalies are not task-specific but general, evaluations on our dataset are transferable to other robotics applications as well. Additionally, we present MVT-Flow (multivariate time-series flow) as a new baseline method for anomaly detection: It relies on deep-learning-based density estimation with normalizing flows, tailored to the data domain by taking its structure into account for the architecture. Our evaluation shows that MVT-Flow outperforms baselines from previous work by a large margin of 6.2% in area under ROC. ",Kein DOI-Link verfügbar,2311.04765v1,Yes,potent(1)
0000-0003-4630-4117,Julian Schulz,Technische Universität Kaiserslautern,Broadband mode division multiplexing of OAM-modes by a micro printed   waveguide structure,1970,"  A light beam carrying orbital angular momentum (OAM) is characterized by a helical phase-front that winds around the center of the beam. These beams have unique properties that have found numerous applications. In the field of data transmission, they represent a degree of freedom that could potentially increase capacity by a factor of several distinct OAM modes. While an efficient method for (de)composing beams based on their OAM exists for free-space optics, a device capable of performing this (de)composition in an integrated, compact fiber application without the use of external active optical elements and for multiple OAM modes simultaneously has not been reported. In this study, a waveguide structure is presented that can serve as a broadband OAM (de)multiplexer. The structure design is based on the adiabatic principle used in photonic lanterns for highly efficient conversion of spatially separated single modes into eigenmodes of a few-mode fiber. In addition, an artificial magnetic field is introduced by twisting the structure during the adiabatic evolution, which removes the degeneracy between modes having the same absolute OAM. This structure can simplify, stabilize, and miniaturize the creation or decomposition of OAM beams, making them useful for various applications. ",Kein DOI-Link verfügbar,2310.08489v1,Yes,potent(1)
0000-0003-4630-4117,Julian Schulz,Technische Universität Kaiserslautern,Dimensional Crossover in a Quantum Gas of Light,1970,"  The dimensionality of a system profoundly influences its physical behaviour, leading to the emergence of different states of matter in many-body quantum systems. In lower dimensions, fluctuations increase and lead to the suppression of long-range order. For example, in bosonic gases, Bose-Einstein condensation (BEC) in one dimension requires stronger confinement than in two dimensions. We experimentally study the properties of a harmonically trapped photon gas undergoing Bose-Einstein condensation along the dimensional crossover from one to two dimensions. The photons are trapped in a dye microcavity where polymer nanostructures provide the trapping potential for the photon gas. By varying the aspect ratio of the harmonic trap, we tune from an isotropic two-dimensional confinement to an anisotropic, highly elongated one-dimensional trapping potential. Along this transition we determine the caloric properties of the photon gas and find a softening of the second-order Bose-Einstein condensation phase transition observed in two dimensions to a crossover behaviour in one dimension. ",Kein DOI-Link verfügbar,2311.10485v2,Yes,potent(2)
0000-0003-4630-4117,Julian Schulz,Technische Universität Kaiserslautern,Steering Llama 2 via Contrastive Activation Addition,1970,"  We introduce Contrastive Activation Addition (CAA), an innovative method for steering language models by modifying their activations during forward passes. CAA computes ""steering vectors"" by averaging the difference in residual stream activations between pairs of positive and negative examples of a particular behavior, such as factual versus hallucinatory responses. During inference, these steering vectors are added at all token positions after the user's prompt with either a positive or negative coefficient, allowing precise control over the degree of the targeted behavior. We evaluate CAA's effectiveness on Llama 2 Chat using multiple-choice behavioral question datasets and open-ended generation tasks. We demonstrate that CAA significantly alters model behavior, is effective over and on top of traditional methods like finetuning and system prompt design, and minimally reduces capabilities. Moreover, we gain deeper insights into CAA's mechanisms by employing various activation space interpretation methods. CAA accurately steers model outputs and sheds light on how high-level concepts are represented in Large Language Models (LLMs). ",Kein DOI-Link verfügbar,2312.06681v4,Yes,innovative(1)
0000-0003-4630-4117,Julian Schulz,Technische Universität Kaiserslautern,Generalized Laws of Refraction and Reflection at Interfaces between   Different Photonic Artificial Gauge Fields,1970,"  Artificial gauge fields enable extending the control over dynamics of uncharged particles, by engineering the potential landscape such that the particles behave as if effective external fields are acting on them. Recent years have witnessed a growing interest in artificial gauge fields that are generated either by geometry or by time-dependent modulation, as they have been the enablers for topological phenomena and synthetic dimensions in many physical settings, e.g., photonics, cold atoms and acoustic waves. Here, we formulate and experimentally demonstrate the generalized laws of refraction and reflection from an interface between two regions with different artificial gauge fields. We use the symmetries in the system to obtain the generalized Snell law for such a gauge interface, and solve for reflection and transmission. We identify total internal reflection (TIR) and complete transmission, and demonstrate the concept in experiments. Additionally, we calculate the artificial magnetic flux at the interface of two regions with different artificial gauge, and present a method to concatenate several gauge interfaces. As an example, we propose a scheme to make a gauge imaging system - a device that is able to reconstruct (image) the shape of an arbitrary wavepacket launched at a certain position to a predesigned location. ",https://doi.org/10.1038/s41377-020-00411-7,2104.03706v1,Yes,potent(1)
0000-0003-4650-1110,Mitja Kulczynski,Kiel Universität,The Show Must Go On -- Examination During a Pandemic,1970,"  When unexpected incidents occur, new innovative and flexible solutions are required. If this event is something such radical and dramatic like the COVID-19 pandemic, these solutions must aim to guarantee as much normality as possible while protecting lives. After a moment of shock our university decided that the students have to be able to pursue their studies for guaranteeing a degree in the expected time since most of them faced immediate financial problems due to the loss of their student jobs. This implied, for us as teachers, that we had to reorganise not only the teaching methods from nearly one day to the next, but we also had to come up with an adjusted way of examinations which had to take place in person with pen and paper under strict hygiene rules. On the other hand the correction should avoid personal contacts. We developed a framework which allowed us to correct the digitalised exams safely at home while providing the high standards given by the general data protection regulation of our country. Moreover, the time spent in the offices could be reduced to a minimum thanks to automatically generated exam sheets, automatically re-digitalised and sorted worked-on exams. ",Kein DOI-Link verfügbar,2107.04014v1,Yes,innovative(1)
0000-0003-4713-1131,Rehab Massoud,Universität Bremen,How Deduction Systems Can Help You To Verify Stability Properties,1970,"  Mathematical proofs are a cornerstone of control theory, and it is important to get them right. Deduction systems can help with this by mechanically checking the proofs. However, the structure and level of detail at which a proof is represented in a deduction system differ significantly from a proof read and written by mathematicians and engineers, hampering understanding and adoption of these systems.   This paper aims at helping to bridge the gap between machine-checked proofs and proofs in engineering and mathematics by presenting a machine-checked proof for stability using Lyapunov's theorem in a human-readable way. The structure of the proof is analyzed in detail, and potential benefits of such a proof are discussed, such as generalizability, reusability and increased trust in correctness. ",Kein DOI-Link verfügbar,2404.10747v1,Yes,potent(1)
0000-0003-4778-3703,Myroslav Kryven,Julius-Maximilians-Universität Würzburg,Integral equation approach for the numerical solution of a Robin problem   for the Klein-Gordon equation in a doubly connected domain,1970,  In this paper we consider a Robin problem for the Klein-Gordon equation in a doubly connected domain. The solution domain considered is a bounded smooth doubly connected planar domain bounded by two simple disjoint closed curves. The analysis of the problem is based on the indirect integral equations method. The solution is represented as a sum of two single-layer potentials defined on each of the two boundary curves with unknown densities. To find out the densities the representation is matched with the given Robin data to generate a system of linear integral equations of the second kind with continuous and weakly-singular kernels. It is shown that the operator corresponding to this system is injective and due to its compactness according to Riesz theory there exists a unique solution. To discretize the system we apply Nystrom method with a specifically chosen quadrature rules to obtain an exponential order of convergence of the approximate solution. Numerical experiments are conducted for three testing examples that back up the theoretical reasoning. ,Kein DOI-Link verfügbar,1401.6957v2,Yes,potent(1)
0000-0003-4802-4215,Tobias Bauer,Universität des Saarlandes,#MeTooMaastricht: Building a chatbot to assist survivors of sexual   harassment,1970,"  Inspired by the recent social movement of #MeToo, we are building a chatbot to assist survivors of sexual harassment cases (designed for the city of Maastricht but can easily be extended). The motivation behind this work is twofold: properly assist survivors of such events by directing them to appropriate institutions that can offer them help and increase the incident documentation so as to gather more data about harassment cases which are currently under reported. We break down the problem into three data science/machine learning components: harassment type identification (treated as a classification problem), spatio-temporal information extraction (treated as Named Entity Recognition problem) and dialogue with the users (treated as a slot-filling based chatbot). We are able to achieve a success rate of more than 98% for the identification of a harassment-or-not case and around 80% for the specific type harassment identification. Locations and dates are identified with more than 90% accuracy and time occurrences prove more challenging with almost 80%. Finally, initial validation of the chatbot shows great potential for the further development and deployment of such a beneficial for the whole society tool. ",Kein DOI-Link verfügbar,1909.02809v1,Yes,potent(1)
0000-0003-4820-7126,Enrico Stein,Technische Universität Kaiserslautern,Hartree-Fock Analogue Theory of Thermo-Optic Interaction,1970,"  Thermo-optic interaction significantly differs from the usual particle-particle interactions in physics, as it is retarded in time. A prominent platform for realising this kind of interaction are photon Bose-Einstein condensates, which are created in dye-filled microcavities. The dye solution continually absorbs and re-emits these photons, causing the photon gas to thermalise and to form a Bose-Einstein condensate. Because of a non-ideal quantum efficiency, these cycles heat the dye solution, creating a medium that provides an effective thermo-optic photon-photon interaction. So far, only a mean-field description of this process exists. This paper goes beyond by working out a quantum mechanical description of the effective thermo-optic photon-photon interaction. To this end, the self-consistent modelling of the temperature diffusion builds the backbone of the modelling. Furthermore, the manyfold experimental timescales allow for deriving an approximate Hamiltonian. The resulting quantum theory is applied in the perturbative regime to both a harmonic and a box potential for investigating its prospect for precise measurements of the effective photon-photon interaction strength. ",https://doi.org/10.1088/1367-2630/acc34c,2203.16955v3,Yes,potent(1)
0000-0003-4820-7126,Enrico Stein,Technische Universität Kaiserslautern,Photon BEC with Thermo-Optic Interaction at Dimensional Crossover,1970,"  Since the advent of experiments with photon Bose-Einstein condensates in dye-filled microcavities in 2010, many investigations have focused upon the emerging effective photon-photon interaction. Despite its smallness, it can be identified to stem from two physically distinct mechanisms. On the one hand, a Kerr nonlinearity of the dye medium yields a photon-photon contact interaction. On the other hand, a heating of the dye medium leads to an additional thermo-optic interaction, which is both delayed and non-local. The latter turns out to represent the leading contribution to the effective interaction for the current 2D experiments. Here we analyse theoretically how the effective photon-photon interaction increases when the system dimension is reduced from 2D to 1D. To this end, we consider an anisotropic harmonic trapping potential and determine via a variational approach how the properties of the photon Bose-Einstein condensate in general, and both aforementioned interaction mechanisms in particular, change with increasing anisotropy. We find that the thermo-optic interaction strength increases at first linearly with the trap aspect ratio and lateron saturates at a certain value of the trap aspect ratio. Furthermore, in the strong 1D limit the roles of both interactions get reversed as the thermo-optic interaction remains saturated and the contact Kerr interaction becomes the leading interaction mechanism. Finally, we discuss how the predicted effects can be measured experimentally. ",https://doi.org/10.1088/1367-2630/ac51ec,2109.11211v1,Yes,potent(1)
0000-0003-4820-7126,Enrico Stein,Technische Universität Kaiserslautern,Exact Diagonalisation of Photon Bose-Einstein Condensates with   Thermo-Optic Interaction,1970,"  Although photon Bose-Einstein condensates have already been used for studying many interesting effects, the precise role of the photon-photon interaction is not fully clarified up to now. In view of this, it is advantageous that these systems allow measuring both the intensity of the light leaking out of the cavity and its spectrum at the same time. Therefore, the photon-photon interaction strength can be determined once via analysing the condensate broadening and once via examining the interaction-induced modifications of the cavity modes. As the former method depends crucially on the concrete shape of the trapping potential and the spatial resolution of the used camera, interferometric methods promise more precise measurements. To this end, the present paper works out the impact of the photon-photon interaction upon the cavity modes. A quantum mechanical description of the photon-photon interaction, including the thermal cloud, builds the theoretical backbone of the method. An exact diagonalisation approach introduced here exposes how the effective photon-photon interaction modifies both the spectrum and the width of the photon gas. A comparison with a variational approach based on the Gross-Pitaevskii equation quantifies the contribution of the thermal cloud in the respective applications. ",https://doi.org/10.1088/1367-2630/acc34b,2204.08818v3,Yes,potent(1)
0000-0003-4869-2424,Manuel Flores,Universität Bielefeld,Combinatorics of quasi-hereditary structures,1970,"  A quasi-hereditary algebra is an Artin algebra together with a partial order on its set of isomorphism classes of simple modules which satisfies certain conditions. In this article we investigate all the possible choices that yield to quasi-hereditary structures on a given algebra, in particular we introduce and study what we call the poset of quasi-hereditary structures. Our techniques involve certain quiver decompositions and idempotent reductions. For a path algebra of Dynkin type $\mathbb{A}$, we provide a full classification of its quasi-hereditary structures. For types $\mathbb{D}$ and $\mathbb{E}$, we give a counting method for the number of quasi-hereditary structures. In the case of a hereditary incidence algebra, we present a necessary and sufficient condition for its poset of quasi-hereditary structures to be a lattice. ",https://doi.org/10.1016/j.jcta.2021.105559,2004.04726v3,Yes,potent(1)
0000-0003-4924-3903,Moritz Blum,Universität Bielefeld,Numerical Literals in Link Prediction: A Critical Examination of Models   and Datasets,1970,"  Link Prediction(LP) is an essential task over Knowledge Graphs(KGs), traditionally focussed on using and predicting the relations between entities. Textual entity descriptions have already been shown to be valuable, but models that incorporate numerical literals have shown minor improvements on existing benchmark datasets. It is unclear whether a model is actually better in using numerical literals, or better capable of utilizing the graph structure. This raises doubts about the effectiveness of these methods and about the suitability of the existing benchmark datasets.   We propose a methodology to evaluate LP models that incorporate numerical literals. We propose i) a new synthetic dataset to better understand how well these models use numerical literals and ii) dataset ablations strategies to investigate potential difficulties with the existing datasets. We identify a prevalent trend: many models underutilize literal information and potentially rely on additional parameters for performance gains. Our investigation highlights the need for more extensive evaluations when releasing new models and datasets. ",Kein DOI-Link verfügbar,2407.18241v1,Yes,potent(2)
0000-0003-4957-4753,Yuchen Lin,Rheinisch-Westfälische Technische Hochschule Aachen,CATP: Context-Aware Trajectory Prediction with Competition Symbiosis,1970,"  Contextual information is vital for accurate trajectory prediction. For instance, the intricate flying behavior of migratory birds hinges on their analysis of environmental cues such as wind direction and air pressure. However, the diverse and dynamic nature of contextual information renders it an arduous task for AI models to comprehend its impact on trajectories and consequently predict them accurately. To address this issue, we propose a ``manager-worker'' framework to unleash the full potential of contextual information and construct CATP model, an implementation of the framework for Context-Aware Trajectory Prediction. The framework comprises a manager model, several worker models, and a tailored training mechanism inspired by competition symbiosis in nature. Taking CATP as an example, each worker needs to compete against others for training data and develop an advantage in predicting specific moving patterns. The manager learns the workers' performance in different contexts and selects the best one in the given context to predict trajectories, enabling CATP as a whole to operate in a symbiotic manner. We conducted two comparative experiments and an ablation study to quantitatively evaluate the proposed framework and CATP model. The results showed that CATP could outperform SOTA models, and the framework could be generalized to different context-aware tasks. ",Kein DOI-Link verfügbar,2407.07328v1,Yes,"intricate(1), potent(1)"
0000-0003-4957-4753,Yuchen Lin,Rheinisch-Westfälische Technische Hochschule Aachen,New constraints on Triton's atmosphere from the 6 October 2022 stellar   occultation,1970,"  The atmosphere of Triton was probed directly by observing a ground-based stellar occultation on 6 October 2022. This rare event yielded 23 positive light curves collected from 13 separate observation stations contributing to our campaign. The significance of this event lies in its potential to directly validate the modest pressure fluctuation on Triton, a phenomenon not definitively verified by previous observations, including only five stellar occultations, and the Voyager 2 radio occultation in 1989. Using an approach consistent with a comparable study, we precisely determined a surface pressure of $14.07_{-0.13}^{+0.21}~\mathrm{\mu bar}$ in 2022. This new pressure rules out any significant monotonic variation in pressure between 2017 and 2022 through direct observations, as it is in alignment with the 2017 value. Additionally, both the pressures in 2017 and 2022 align with the 1989 value. This provides further support for the conclusion drawn from the previous volatile transport model simulation, which is consistent with the observed alignment between the pressures in 1989 and 2017; that is to say, the pressure fluctuation is modest. Moreover, this conclusion suggests the existence of a northern polar cap extended down to at least $45^\circ$N$-60^\circ$N and the presence of nitrogen between $30^\circ$S and $0^\circ$. ",https://doi.org/10.1051/0004-6361/202348460,2403.09464v2,Yes,potent(1)
0009-0000-0572-6490,Lars Sipos,Freie Universität Berlin,Identifying Explanation Needs of End-users: Applying and Extending the   XAI Question Bank,1970,"  Explanations in XAI are typically developed by AI experts and focus on algorithmic transparency and the inner workings of AI systems. Research has shown that such explanations do not meet the needs of users who do not have AI expertise. As a result, explanations are often ineffective in making system decisions interpretable and understandable. We aim to strengthen a socio-technical view of AI by following a Human-Centered Explainable Artificial Intelligence (HC-XAI) approach, which investigates the explanation needs of end-users (i.e., subject matter experts and lay users) in specific usage contexts. One of the most influential works in this area is the XAI Question Bank (XAIQB) by Liao et al. The authors propose a set of questions that end-users might ask when using an AI system, which in turn is intended to help developers and designers identify and address explanation needs. Although the XAIQB is widely referenced, there are few reports of its use in practice. In particular, it is unclear to what extent the XAIQB sufficiently captures the explanation needs of end-users and what potential problems exist in the practical application of the XAIQB. To explore these open questions, we used the XAIQB as the basis for analyzing 12 think-aloud software explorations with subject matter experts. We investigated the suitability of the XAIQB as a tool for identifying explanation needs in a specific usage context. Our analysis revealed a number of explanation needs that were missing from the question bank, but that emerged repeatedly as our study participants interacted with an AI system. We also found that some of the XAIQB questions were difficult to distinguish and required interpretation during use. Our contribution is an extension of the XAIQB with 11 new questions. In addition, we have expanded the descriptions of all new and existing questions to facilitate their use. ",https://doi.org/10.1145/3603555.3608551,2307.09369v1,Yes,potent(1)
0009-0000-3820-9721,Ranajay Datta,Johannes Gutenberg Universität Mainz,Viscosity of flexible and semiflexible ring melts -- molecular origins   and flow-induced segregation,1970,"  We investigate with numerical simulations the molecular origin of viscosity in melts of flexible and semiflexible oligomer rings in comparison to corresponding systems with linear chains. The strong increase of viscosity with ring stiffness is linked to the formation of entangled clusters, which dissolve under shear. This shear-induced breakup and alignment of rings in the flow direction lead to pronounced shear-thinning and non-Newtonian behavior. In melts of linear chains, the viscosity can be associated with the (average) number of entanglements between chains, which also dissolve under shear. While blends of flexible and semiflexible rings are mixed at rest, the two species separate under flow. This phenomenon has potential applications in microfluidic devices to segregate ring polymers of similar mass and chemical composition by their bending rigidity. ",Kein DOI-Link verfügbar,2305.15886v2,Yes,potent(1)
0009-0000-6023-2135,Md Hasan Shahriar,Universität Potsdam,Novel Attacks against Contingency Analysis in Power Grids,1970,"  Contingency Analysis (CA) is a core component of the Energy Management System (EMS) in the power grid. The goal of CA is to operate the power system in a secure manner by analyzing the system subject to a contingency (e.g., the outage of a transmission line or a power generator) to determine the setpoints that will allow system operation without violation of constraints. The analysis in CA is conducted based on the output from State Estimation (SE), another core EMS module. However, it is also shown that an adversary can alter certain power measurements to corrupt the system states estimated by SE without being detected. Such a corrupted estimation can severely skew the results of the contingency analysis as it will provide a fake model to deal with. In this research, we formally model necessary interdependency relationships and systematically analyze these novel attacks on the contingency analysis. In particular, this research focuses on Security Constrained Optimal Power Flow (SCOPF) that finds out the optimal economic dispatches considering a single line failure (based on the $n - 1$ contingency analysis) and transmission line capacities. The proposed model is implemented and solved to find out potential threat vectors (i.e., a set of measurements to be altered) that can evade CA so that the system will face overloading situation on one or more transmission lines when some specific contingencies happen. We demonstrate our formal model on an IEEE 14 bus system-based case study and verify the results with a standard PowerWorld model. We further evaluate the model with respect to various attacks and grid characteristics. ",Kein DOI-Link verfügbar,1911.00928v1,Yes,potent(1)
0009-0000-6023-2135,Md Hasan Shahriar,Universität Potsdam,A Formal Approach for Efficient Navigation Management of Hybrid Electric   Vehicles on Long Trips,1970,"  Plug-in Hybrid Electric Vehicles (PHEVs) are gaining popularity due to their economic efficiency as well as their contribution to green management. PHEVs allow the driver to use electric power exclusively for driving and then switch to gasoline as needed. The more gasoline a vehicle uses, the higher cost is required for the trip. However, a PHEV cannot last for a long period on stored electricity without being recharged. Thus, it needs frequent recharging compared to traditional gasoline-powered vehicles. Moreover, the battery recharging time is usually long, which leads to longer delays on a trip. Therefore, it is necessary to provide a flexible navigation management scheme along with an efficient recharging schedule, which allows the driver to choose an optimal route based on the fuel-cost and time-to-destination constraints. In this paper, we present a formal model to solve this PHEV navigation management problem. The model is solved to provide a driver with a comprehensive routing plan including the potential recharging and refueling points that satisfy the given requirements, particularly the maximum fuel cost and the maximum trip time. In addition, we propose a price-based navigation control technique to achieve better load balance for the traffic system. Evaluation results show that the proposed formal models can be solved efficiently even with large road networks. ",Kein DOI-Link verfügbar,1907.00540v1,Yes,potent(1)
0009-0000-6023-2135,Md Hasan Shahriar,Universität Potsdam,A Novel Framework for Threat Analysis of Machine Learning-based Smart   Healthcare Systems,1970,"  Smart healthcare systems (SHSs) are providing fast and efficient disease treatment leveraging wireless body sensor networks (WBSNs) and implantable medical devices (IMDs)-based internet of medical things (IoMT). In addition, IoMT-based SHSs are enabling automated medication, allowing communication among myriad healthcare sensor devices. However, adversaries can launch various attacks on the communication network and the hardware/firmware to introduce false data or cause data unavailability to the automatic medication system endangering the patient's life. In this paper, we propose SHChecker, a novel threat analysis framework that integrates machine learning and formal analysis capabilities to identify potential attacks and corresponding effects on an IoMT-based SHS. Our framework can provide us with all potential attack vectors, each representing a set of sensor measurements to be altered, for an SHS given a specific set of attack attributes, allowing us to realize the system's resiliency, thus the insight to enhance the robustness of the model. We implement SHChecker on a synthetic and a real dataset, which affirms that our framework can reveal potential attack vectors in an IoMT system. This is a novel effort to formally analyze supervised and unsupervised machine learning models for black-box SHS threat analysis. ",Kein DOI-Link verfügbar,2103.03472v1,Yes,potent(3)
0009-0001-0438-0624,Melanie Schmidt,Martin Luther Universität Halle-Wittenberg,A Local-Search Algorithm for Steiner Forest,1970,"  In the Steiner Forest problem, we are given a graph and a collection of source-sink pairs, and the goal is to find a subgraph of minimum total length such that all pairs are connected. The problem is APX-Hard and can be 2-approximated by, e.g., the elegant primal-dual algorithm of Agrawal, Klein, and Ravi from 1995.   We give a local-search-based constant-factor approximation for the problem. Local search brings in new techniques to an area that has for long not seen any improvements and might be a step towards a combinatorial algorithm for the more general survivable network design problem. Moreover, local search was an essential tool to tackle the dynamic MST/Steiner Tree problem, whereas dynamic Steiner Forest is still wide open.   It is easy to see that any constant factor local search algorithm requires steps that add/drop many edges together. We propose natural local moves which, at each step, either (a) add a shortest path in the current graph and then drop a bunch of inessential edges, or (b) add a set of edges to the current solution. This second type of moves is motivated by the potential function we use to measure progress, combining the cost of the solution with a penalty for each connected component. Our carefully-chosen local moves and potential function work in tandem to eliminate bad local minima that arise when using more traditional local moves. ",Kein DOI-Link verfügbar,1707.02753v1,Yes,potent(2)
0009-0001-5618-4326,Eva Sextl,Ludwig-Maximilians-Universität München,Modified Gravity and the Flux-weighted Gravity-Luminosity Relationship   of Blue Supergiant Stars,1970,"  We calculate models of stellar evolution for very massive stars and include the effects of modified gravity to investigate the influence on the physical properties of blue supergiant stars and their use as extragalactic distance indicators. With shielding and fifth force parameters in a similar range as in previous studies of Cepheid and tip of the red giant branch (TRGB) stars we find clear effects on stellar luminosity and flux-weighted gravity. The relationship between flux weighted gravity, g_F = g/Teff^4, and bolometric magnitude M_bol (FGLR), which has been used successfully for accurate distance determinations, is systematically affected. While the stellar evolution FGLRs show a systematic offset from the observed relation, we can use the differential shifts between models with Newtonian and modified gravity to estimate the influence on FGLR distance determinations. Modified gravity leads to a distance increase of 0.05 to 0.15 magnitudes in distance modulus. These change are comparable to the ones found for Cepheid stars. We compare observed FGLR and TRGB distances of nine galaxies to constrain the free parameters of modified gravity. Not accounting for systematic differences between TRGB and FGLR distances shielding parameters of 5*10^-7 and 10^-6 and fifth force parameters of 1/3 and 1 can be ruled out with about 90% confidence. Allowing for potential systematic offsets between TRGB and FGLR distances no determination is possible for a shielding parameter of 10^-6. For 5*10$^-7 a fifth force parameter of 1 can be ruled out to 92% but 1/3 is unlikely only to 60%. ",https://doi.org/10.3847/1538-4357/abfafa,2104.11174v1,Yes,potent(1)
0009-0001-9459-4836,Björn Lindqvist,Universität Rostock,Exploration-RRT: A multi-objective Path Planning and Exploration   Framework for Unknown and Unstructured Environments,1970,"  This article establishes the Exploration-RRT algorithm: A novel general-purpose combined exploration and pathplanning algorithm, based on a multi-goal Rapidly-Exploring Random Trees (RRT) framework. Exploration-RRT (ERRT) has been specifically designed for utilization in 3D exploration missions, with partially or completely unknown and unstructured environments. The novel proposed ERRT is based on a multi-objective optimization framework and it is able to take under consideration the potential information gain, the distance travelled, and the actuation costs, along trajectories to pseudo-random goals, generated from considering the on-board sensor model and the non-linear model of the utilized platform. In this article, the algorithmic pipeline of the ERRT will be established and the overall applicability and efficiency of the proposed scheme will be presented on an application with an Unmanned Aerial Vehicle (UAV) model, equipped with a 3D lidar, in a simulated operating environment, with the goal of exploring a completely unknown area as efficiently and quickly as possible ",Kein DOI-Link verfügbar,2104.03724v1,Yes,potent(1)
0009-0001-9459-4836,Björn Lindqvist,Universität Rostock,COMPRA: A COMPact Reactive Autonomy framework for subterranean MAV based   search-and-rescue operations,1970,"  This work establishes COMPRA, a compact and reactive autonomy framework for fast deployment of Micro Aerial Vehicles (MAVs) in subterranean Search-and-Rescue (SAR) missions. A COMPRA-enabled MAV is able to autonomously explore previously unknown areas while specific mission criteria are considered e.g. an object of interest is identified and localized, the remaining useful battery life, the overall desired exploration mission duration. The proposed architecture follows a low-complexity algorithmic design to facilitate fully on-board computations, including nonlinear control, state-estimation, navigation, exploration behavior and object localization capabilities. The framework is mainly structured around a reactive local avoidance planner, based on enhanced Potential Field concepts and using instantaneous 3D pointclouds, as well as a computationally efficient heading regulation technique, based on depth images from an instantaneous camera stream. Those techniques decouple the collision-free path generation from the dependency of a global map and are capable of handling imprecise localization occasions. Field experimental verification of the overall architecture is performed in relevant unknown Global Positioning System (GPS)-denied environments. ",Kein DOI-Link verfügbar,2108.13105v2,Yes,potent(1)
0009-0002-2019-4597,Mohammad Noaman,Johannes Gutenberg Universität Mainz,Rydberg excitation of cold atoms inside a hollow core fiber,1970,"  We report on a versatile, highly controllable hybrid cold Rydberg atom fiber interface, based on laser cooled atoms transported into a hollow core Kagom\'{e} crystal fiber. Our experiments are the first to demonstrate the feasibility of exciting cold Rydberg atoms inside a hollow core fiber and we study the influence of the fiber on Rydberg electromagnetically induced transparency (EIT) signals. Using a temporally resolved detection method to distinguish between excitation and loss, we observe two different regimes of the Rydberg excitations: one EIT regime and one regime dominated by atom loss. These results are a substantial advancement towards future use of our system for quantum simulation or information. ",https://doi.org/10.1103/PhysRevA.96.041402,1706.07666v2,Yes,versatile(1)
0009-0002-2019-4597,Mohammad Noaman,Johannes Gutenberg Universität Mainz,Highly controlled optical transport of cold atoms into a hollow-core   fiber,1970,"  We report on an efficient and highly controlled cold atom hollow-core fiber interface, suitable for quantum simulation, information, and sensing. The main focus of this manuscript is a detailed study on transporting cold atoms into the fiber using an optical conveyor belt. We discuss how we can precisely control the spatial, thermal, and temporal distribution of the atoms by, e.g., varying the speed at which the atoms are transported or adjusting the depth of the transport potential according to the atomic position. We characterize the transport of atoms to the fiber tip for these different parameters. In particular, we show that by adapting the transport potential we can lower the temperature of the transported atoms by a factor of 6, while reducing the transport efficiency only by a factor 2. For atoms transported inside the fiber, we can obtain a transport efficiency into the fiber of more than 40% and we study the influence of the different transport parameters on the time-dependent optical depth signal. When comparing our measurements to the results of a classical transport simulation, we find a good qualitative agreement. ",https://doi.org/10.1088/1367-2630/aad9bb,1805.06333v1,Yes,potent(2)
0009-0002-3627-7194,Matthias Koschnitzke,Universität Hamburg,Gravitational signatures of ALP dark matter fragmentation,1970,"  The misalignment mechanism for axion-like particles (ALPs) is a leading explanation for dark matter. In this work we investigate ALPs with non-periodic potentials, which allow for large misalignment of the field from the minimum and make it possible for ALPs to match the relic density of dark matter in a large part of the parameter space. Such potentials give rise to self-interactions which can trigger an exponential growth of fluctuations in the ALP field via parametric resonance, leading to the fragmentation of the field. The fluctuations later collapse to halos that can be dense enough to produce observable gravitational effects. These effects would provide a probe of dark matter even if it does not couple to the Standard Model (or too feebly). We determine the relevant regions of parameter space in the (ALP mass, decay constant)-plane and compare predictions in different axion fragmentation models. These proceedings are a short version of arXiv:2305.03756 ",https://doi.org/10.22323/1.449.0116,2402.10313v1,Yes,potent(2)
0009-0002-3627-7194,Matthias Koschnitzke,Universität Hamburg,"ALP dark matter with non-periodic potentials: parametric resonance, halo   formation and gravitational signatures",1970,"  Axion-like particles (ALPs) are leading candidates to explain the dark matter in the universe. Their production via the misalignment mechanism has been extensively studied for cosine potentials characteristic of pseudo-Nambu-Goldstone bosons. In this work we investigate ALPs with non-periodic potentials, which allow for large misalignment of the field from the minimum. As a result, the ALP can match the relic density of dark matter in a large part of the parameter space. Such potentials give rise to self-interactions which can trigger an exponential growth of fluctuations in the ALP field via parametric resonance, leading to the fragmentation of the field. We study these effects with both Floquet analysis and lattice simulations. Using the Press-Schechter formalism, we predict the halo mass function and halo spectrum arising from ALP dark matter. These halos can be dense enough to produce observable gravitational effects such as astrometric lensing, diffraction of gravitational wave signals from black hole mergers, photometric microlensing of highly magnified stars, perturbations of stars in the galactic disk or stellar streams. These effects would provide a probe of dark matter even if it does not couple to the Standard Model. They would not be observable for halos predicted for standard cold dark matter and for ALP dark matter in the standard misalignment mechanism. We determine the relevant regions of parameter space in the (ALP mass, decay constant)-plane and compare predictions in different axion fragmentation models. ",https://doi.org/10.1088/1475-7516/2023/10/068,2305.03756v2,Yes,potent(3)
0009-0002-4359-5780,Simon Stastny,Universität Stuttgart,Functional completeness of planar Rydberg blockade structures,1970,"  The construction of Hilbert spaces that are characterized by local constraints as the low-energy sectors of microscopic models is an important step towards the realization of a wide range of quantum phases with long-range entanglement and emergent gauge fields. Here we show that planar structures of trapped atoms in the Rydberg blockade regime are functionally complete: Their ground state manifold can realize any Hilbert space that can be characterized by local constraints in the product basis. We introduce a versatile framework, together with a set of provably minimal logic primitives as building blocks, to implement these constraints. As examples, we present lattice realizations of the string-net Hilbert spaces that underlie the surface code and the Fibonacci anyon model. We discuss possible optimizations of planar Rydberg structures to increase their geometrical robustness. ",https://doi.org/10.1103/PhysRevB.108.085138,2301.01508v2,Yes,versatile(1)
0009-0002-6364-2687,Zihou Liu,Universität Würzburg,A Survey on Consumer IoT Traffic: Security and Privacy,1970,"  Although CIoT has improved the convenience of daily activities, it also introduces new security and privacy concerns. Network traffic analysis, a common technique employed by the security community, has been extensively utilized to investigate security and privacy concerns, and it has also been applied to CIoT. However, compared to network traffic analysis in other fields such as mobile apps and websites, CIoT presents special new characteristics, which may introduce new challenges and research opportunities. In this study, we reviewed 310 publications on traffic analysis within the CIoT security and privacy domain, covering the period from January 2018 to December 2023. Initially, we summarized the CIoT traffic analysis process, highlighting the newly identified characteristics of CIoT. Subsequently, we classified existing research according to its application objectives: device fingerprinting, user activity inference, malicious traffic detection, and measurement. Lastly, we explore emerging challenges and potential future research avenues. ",Kein DOI-Link verfügbar,2403.16149v2,Yes,potent(1)
0009-0002-9851-2516,Marian Rockenhäuser,Universität Stuttgart,Microscopic 3D printed optical tweezers for atomic quantum technology,1970,"  Trapping of single ultracold atoms is an important tool for applications ranging from quantum computation and communication to sensing. However, most experimental setups, while very precise and versatile, can only be operated in specialized laboratory environments due to their large size, complexity and high cost. Here, we introduce a new trapping concept for ultracold atoms in optical tweezers based on micrometer-scale lenses that are 3D printed onto the tip of standard optical fibers. The unique properties of these lenses make them suitable for both trapping individual atoms and capturing their fluorescence with high efficiency. In an exploratory experiment, we have established the vacuum compatibility and robustness of the structures, and successfully formed a magneto-optical trap for ultracold atoms in their immediate vicinity. This makes them promising components for portable atomic quantum devices. ",https://doi.org/10.1088/2058-9565/ac796c,2206.11090v1,Yes,versatile(1)
0009-0003-4105-1082,Andreas C. Schneider,Universität Göttingen,A General Framework for Interpretable Neural Learning based on Local   Information-Theoretic Goal Functions,1970,"  Despite the impressive performance of biological and artificial networks, an intuitive understanding of how their local learning dynamics contribute to network-level task solutions remains a challenge to this date. Efforts to bring learning to a more local scale indeed lead to valuable insights, however, a general constructive approach to describe local learning goals that is both interpretable and adaptable across diverse tasks is still missing. We have previously formulated a local information processing goal that is highly adaptable and interpretable for a model neuron with compartmental structure. Building on recent advances in Partial Information Decomposition (PID), we here derive a corresponding parametric local learning rule, which allows us to introduce 'infomorphic' neural networks. We demonstrate the versatility of these networks to perform tasks from supervised, unsupervised and memory learning. By leveraging the interpretable nature of the PID framework, infomorphic networks represent a valuable tool to advance our understanding of the intricate structure of local learning. ",Kein DOI-Link verfügbar,2306.02149v2,Yes,intricate(1)
0009-0003-5848-0182,Birkan Düzel,Humboldt-Universität zu Berlin,Low-temperature magnetoresistance hysteresis in Vanadium-doped   Bi$_{2}$Te$_{2.4}$Se$_{0.6}$ bulk topological insulators,1970,"  Bi$_{2}$Te$_{2.4}$Se$_{0.6}$ single crystals show gapless topological surface states and doping ($x$) with Vanadium allows to shift the chemical potential in the bulk band gap. Accordingly, the resistivity, carrier density, and mobility are constant below 10 K and the magnetoresistance shows weak antilocalization as expected for low-temperature transport properties dominated by gapless surface states of so-called three-dimensional topological ""insulators"". However, the magnetoresistance also shows a hysteresis depending on the sweep rate and the magnetic field direction. Here, we provide evidence that such magnetoresistance hysteresis is enhanced if both three-dimensional bulk states and quasi-two-dimensional topological states contribute to the transport ($x$ = 0 and 0.03), and it is mostly suppressed if the topological states govern transport ($x$ = 0.015). The results are discussed in terms of spin-dependent scattering between the different available states ",https://doi.org/10.1063/5.0203789,2212.14078v2,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Parametrizations of canonical bases and irreducible components of   nilpotent varieties,1970,"  It is known that the set of irreducible components of nilpotent varieties provides a geometric realization of the crystal basis for quantum groups. For each reduced expression of a Weyl group element, Gei{\ss}, Leclerc and Schr\""{o}er has recently given a parametrization of irreducible components of nilpotent varieties in studying cluster algebras. In this paper we show that their parametrization coincides with Lusztig's parametrization of the canonical basis. ",Kein DOI-Link verfügbar,1110.2937v2,Yes,potent(2)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Tame quivers and affine enveloping algebras,1970,"  Let $\mathfrak{g}$ be an affine Kac-Moody algebra with symmetric Cartan datum, $\mathfrak{n^{+}}$ be the maximal nilpotent subalgebra of $\mathfrak{g}$. By the Hall algebra approach, we construct integral bases of the $\mathbb{Z}$-form of the enveloping algebra $U(\mathfrak{n^{+}})$. In particular, the representation theory of tame quivers is essentially used in this paper. ",Kein DOI-Link verfügbar,0904.3980v1,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Modeling Label Correlations for Ultra-Fine Entity Typing with Neural   Pairwise Conditional Random Field,1970,"  Ultra-fine entity typing (UFET) aims to predict a wide range of type phrases that correctly describe the categories of a given entity mention in a sentence. Most recent works infer each entity type independently, ignoring the correlations between types, e.g., when an entity is inferred as a president, it should also be a politician and a leader. To this end, we use an undirected graphical model called pairwise conditional random field (PCRF) to formulate the UFET problem, in which the type variables are not only unarily influenced by the input but also pairwisely relate to all the other type variables. We use various modern backbones for entity typing to compute unary potentials, and derive pairwise potentials from type phrase representations that both capture prior semantic information and facilitate accelerated inference. We use mean-field variational inference for efficient type inference on very large type sets and unfold it as a neural network module to enable end-to-end training. Experiments on UFET show that the Neural-PCRF consistently outperforms its backbones with little cost and results in a competitive performance against cross-encoder based SOTA while being thousands of times faster. We also find Neural- PCRF effective on a widely used fine-grained entity typing dataset with a smaller type set. We pack Neural-PCRF as a network module that can be plugged onto multi-label type classifiers with ease and release it in https://github.com/modelscope/adaseq/tree/master/examples/NPCRF. ",Kein DOI-Link verfügbar,2212.01581v1,Yes,potent(2)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,DAL: Dual Adversarial Learning for Dialogue Generation,1970,"  In open-domain dialogue systems, generative approaches have attracted much attention for response generation. However, existing methods are heavily plagued by generating safe responses and unnatural responses. To alleviate these two problems, we propose a novel framework named Dual Adversarial Learning (DAL) for high-quality response generation. DAL is the first work to innovatively utilizes the duality between query generation and response generation to avoid safe responses and increase the diversity of the generated responses. Additionally, DAL uses adversarial learning to mimic human judges and guides the system to generate natural responses. Experimental results demonstrate that DAL effectively improves both diversity and overall quality of the generated responses. DAL outperforms the state-of-the-art methods regarding automatic metrics and human evaluations. ",Kein DOI-Link verfügbar,1906.09556v1,Yes,"innovative(1), innovatively(1)"
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Untargeted Backdoor Attack against Object Detection,1970,"  Recent studies revealed that deep neural networks (DNNs) are exposed to backdoor threats when training with third-party resources (such as training samples or backbones). The backdoored model has promising performance in predicting benign samples, whereas its predictions can be maliciously manipulated by adversaries based on activating its backdoors with pre-defined trigger patterns. Currently, most of the existing backdoor attacks were conducted on the image classification under the targeted manner. In this paper, we reveal that these threats could also happen in object detection, posing threatening risks to many mission-critical applications ($e.g.$, pedestrian detection and intelligent surveillance systems). Specifically, we design a simple yet effective poison-only backdoor attack in an untargeted manner, based on task characteristics. We show that, once the backdoor is embedded into the target model by our attack, it can trick the model to lose detection of any object stamped with our trigger patterns. We conduct extensive experiments on the benchmark dataset, showing its effectiveness in both digital and physical-world settings and its resistance to potential defenses. ",Kein DOI-Link verfügbar,2211.05638v2,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,HierCas: Hierarchical Temporal Graph Attention Networks for Popularity   Prediction in Information Cascades,1970,"  Information cascade popularity prediction is critical for many applications, including but not limited to identifying fake news and accurate recommendations. Traditional feature-based methods heavily rely on handcrafted features, which are domain-specific and lack generalizability to new domains. To address this problem, researchers have turned to neural network-based approaches. However, most existing methods follow a sampling-based modeling approach, potentially losing continuous dynamic information that emerges during the information diffusion process. In this paper, we propose Hierarchical Temporal Graph Attention Networks for cascade popularity prediction (HierCas), which operates on the entire cascade graph by a dynamic graph modeling approach. By leveraging time-aware node embedding, graph attention mechanisms, and hierarchical pooling structures, HierCas effectively captures the popularity trend implicit in the complex cascade. Extensive experiments conducted on two real-world datasets in different scenarios demonstrate that our HierCas significantly outperforms the state-of-the-art approaches. We have released our code at https://github.com/Daisy-zzz/HierCas. ",Kein DOI-Link verfügbar,2310.13219v2,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,A Question-centric Multi-experts Contrastive Learning Framework for   Improving the Accuracy and Interpretability of Deep Sequential Knowledge   Tracing Models,1970,"  Knowledge tracing (KT) plays a crucial role in predicting students' future performance by analyzing their historical learning processes. Deep neural networks (DNNs) have shown great potential in solving the KT problem. However, there still exist some important challenges when applying deep learning techniques to model the KT process. The first challenge lies in taking the individual information of the question into modeling. This is crucial because, despite questions sharing the same knowledge component (KC), students' knowledge acquisition on homogeneous questions can vary significantly. The second challenge lies in interpreting the prediction results from existing deep learning-based KT models. In real-world applications, while it may not be necessary to have complete transparency and interpretability of the model parameters, it is crucial to present the model's prediction results in a manner that teachers find interpretable. This makes teachers accept the rationale behind the prediction results and utilize them to design teaching activities and tailored learning strategies for students. However, the inherent black-box nature of deep learning techniques often poses a hurdle for teachers to fully embrace the model's prediction results. To address these challenges, we propose a Question-centric Multi-experts Contrastive Learning framework for KT called Q-MCKT. We have provided all the datasets and code on our website at https://github.com/rattlesnakey/Q-MCKT. ",Kein DOI-Link verfügbar,2403.07322v3,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,An Investigation of Potential Function Designs for Neural CRF,1970,"  The neural linear-chain CRF model is one of the most widely-used approach to sequence labeling. In this paper, we investigate a series of increasingly expressive potential functions for neural CRF models, which not only integrate the emission and transition functions, but also explicitly take the representations of the contextual words as input. Our extensive experiments show that the decomposed quadrilinear potential function based on the vector representations of two neighboring labels and two neighboring words consistently achieves the best performance. ",Kein DOI-Link verfügbar,2011.05604v1,Yes,potent(2)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Semantic Role Labeling as Dependency Parsing: Exploring Latent Tree   Structures Inside Arguments,1970,"  Semantic role labeling (SRL) is a fundamental yet challenging task in the NLP community. Recent works of SRL mainly fall into two lines: 1) BIO-based; 2) span-based. Despite ubiquity, they share some intrinsic drawbacks of not considering internal argument structures, potentially hindering the model's expressiveness. The key challenge is arguments are flat structures, and there are no determined subtree realizations for words inside arguments. To remedy this, in this paper, we propose to regard flat argument spans as latent subtrees, accordingly reducing SRL to a tree parsing task. In particular, we equip our formulation with a novel span-constrained TreeCRF to make tree structures span-aware and further extend it to the second-order case. We conduct extensive experiments on CoNLL05 and CoNLL12 benchmarks. Results reveal that our methods perform favorably better than all previous syntax-agnostic works, achieving new state-of-the-art under both end-to-end and w/ gold predicates settings. ",Kein DOI-Link verfügbar,2110.06865v2,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Domain-Specific NER via Retrieving Correlated Samples,1970,"  Successful Machine Learning based Named Entity Recognition models could fail on texts from some special domains, for instance, Chinese addresses and e-commerce titles, where requires adequate background knowledge. Such texts are also difficult for human annotators. In fact, we can obtain some potentially helpful information from correlated texts, which have some common entities, to help the text understanding. Then, one can easily reason out the correct answer by referencing correlated samples. In this paper, we suggest enhancing NER models with correlated samples. We draw correlated samples by the sparse BM25 retriever from large-scale in-domain unlabeled data. To explicitly simulate the human reasoning process, we perform a training-free entity type calibrating by majority voting. To capture correlation features in the training stage, we suggest to model correlated samples by the transformer-based multi-instance cross-encoder. Empirical results on datasets of the above two domains show the efficacy of our methods. ",Kein DOI-Link verfügbar,2208.12995v3,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Editing Personality for Large Language Models,1970,"  This paper introduces an innovative task focused on editing the personality traits of Large Language Models (LLMs). This task seeks to adjust the models' responses to opinion-related questions on specified topics since an individual's personality often manifests in the form of their expressed opinions, thereby showcasing different personality traits. Specifically, we construct PersonalityEdit, a new benchmark dataset to address this task. Drawing on the theory in Social Psychology, we isolate three representative traits, namely Neuroticism, Extraversion, and Agreeableness, as the foundation for our benchmark. We then gather data using GPT-4, generating responses that align with a specified topic and embody the targeted personality trait. We conduct comprehensive experiments involving various baselines and discuss the representation of personality behavior in LLMs. Our findings uncover potential challenges of the proposed task, illustrating several remaining issues. We anticipate that our work can stimulate further annotation in model editing and personality-related research. Code is available at https://github.com/zjunlp/EasyEdit. ",Kein DOI-Link verfügbar,2310.02168v4,Yes,"innovative(1), potent(1)"
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Effective Demonstration Annotation for In-Context Learning via Language   Model-Based Determinantal Point Process,1970,"  In-context learning (ICL) is a few-shot learning paradigm that involves learning mappings through input-output pairs and appropriately applying them to new instances. Despite the remarkable ICL capabilities demonstrated by Large Language Models (LLMs), existing works are highly dependent on large-scale labeled support sets, not always feasible in practical scenarios. To refine this approach, we focus primarily on an innovative selective annotation mechanism, which precedes the standard demonstration retrieval. We introduce the Language Model-based Determinant Point Process (LM-DPP) that simultaneously considers the uncertainty and diversity of unlabeled instances for optimal selection. Consequently, this yields a subset for annotation that strikes a trade-off between the two factors. We apply LM-DPP to various language models, including GPT-J, LlaMA, and GPT-3. Experimental results on 9 NLU and 2 Generation datasets demonstrate that LM-DPP can effectively select canonical examples. Further analysis reveals that LLMs benefit most significantly from subsets that are both low uncertainty and high diversity. ",Kein DOI-Link verfügbar,2408.02103v1,Yes,innovative(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,An ACE/CRIS-observation-based Galactic Cosmic Rays heavy nuclei spectra   model II,1970,"  An observation-based Galactic Cosmic Ray (GCR) spectral model for heavy nuclei is developed. Zhao and Qin (J. Geophys. Res. Space Phys.118, 1837(2013)) proposed an empirical elemental GCR spectra model for nuclear charge 5-28 over the energy range from 30 to 500 MeV/nuc, which is proved to be successful in predicting yearly averaged GCR heavy nuclei spectra.Based on the latest highly statistically precise measurements from ACE/CRIS,a further elemental GCR model with monthly averaged spectra is presented. The model can reproduce the past and predict the futureGCR intensity monthly by correlating model parameters with thecontinuous sunspot number (SSN) record. The effects of solar activity on GCR modulation are considered separately for odd and even solar cycles. Compared with other comprehensive GCR models, our modeling results are satisfyingly consistent with the GCR spectral measurements from ACE/SIS and IMP-8, and have comparable prediction accuracy as the Badhwar & O'Neill 2014 model.A detailed error analysis is also provided.Finally, the GCR carbon and iron nuclei fluxes for the subsequent two solar cycles (SC 25 and 26) are predicted and they show a potential trend in reduced flux amplitude, which is suspected to be relevant to possible weak solar cycles. ",https://doi.org/10.1007/s11433-019-9423-3,2005.00627v1,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Few-Shot Backdoor Attacks on Visual Object Tracking,1970,"  Visual object tracking (VOT) has been widely adopted in mission-critical applications, such as autonomous driving and intelligent surveillance systems. In current practice, third-party resources such as datasets, backbone networks, and training platforms are frequently used to train high-performance VOT models. Whilst these resources bring certain convenience, they also introduce new security threats into VOT models. In this paper, we reveal such a threat where an adversary can easily implant hidden backdoors into VOT models by tempering with the training process. Specifically, we propose a simple yet effective few-shot backdoor attack (FSBA) that optimizes two losses alternately: 1) a \emph{feature loss} defined in the hidden feature space, and 2) the standard \emph{tracking loss}. We show that, once the backdoor is embedded into the target model by our FSBA, it can trick the model to lose track of specific objects even when the \emph{trigger} only appears in one or a few frames. We examine our attack in both digital and physical-world settings and show that it can significantly degrade the performance of state-of-the-art VOT trackers. We also show that our attack is resistant to potential defenses, highlighting the vulnerability of VOT models to potential backdoor attacks. ",Kein DOI-Link verfügbar,2201.13178v2,Yes,potent(2)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Named Entity and Relation Extraction with Multi-Modal Retrieval,1970,"  Multi-modal named entity recognition (NER) and relation extraction (RE) aim to leverage relevant image information to improve the performance of NER and RE. Most existing efforts largely focused on directly extracting potentially useful information from images (such as pixel-level features, identified objects, and associated captions). However, such extraction processes may not be knowledge aware, resulting in information that may not be highly relevant. In this paper, we propose a novel Multi-modal Retrieval based framework (MoRe). MoRe contains a text retrieval module and an image-based retrieval module, which retrieve related knowledge of the input text and image in the knowledge corpus respectively. Next, the retrieval results are sent to the textual and visual models respectively for predictions. Finally, a Mixture of Experts (MoE) module combines the predictions from the two models to make the final decision. Our experiments show that both our textual model and visual model can achieve state-of-the-art performance on four multi-modal NER datasets and one multi-modal RE dataset. With MoE, the model performance can be further improved and our analysis demonstrates the benefits of integrating both textual and visual cues for such tasks. ",Kein DOI-Link verfügbar,2212.01612v1,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Who pumps spin current into nonmagnetic-metal (NM) layer in YIG/NM   multilayers at ferromagnetic resonance?,1970,"  Spin pumping in Yttrium-iron-garnet (YIG)/nonmagnetic-metal (NM) layer systems under ferromagnetic resonance (FMR) conditions is a popular method of generating spin current in the NM layer. A good understanding of the spin current source is essential in extracting spin Hall angle of the NM and in potential spintronics applications. It is widely believed that spin current is pumped from precessing YIG magnetization into NM layer. Here, by combining microwave absorption and DC-voltage measurements on YIG/Pt and YIG/NM1/NM2 (NM1=Cu or Al, NM2=Pt or Ta), we unambiguously showed that spin current in NM came from the magnetized NM surface (in contact with YIG) due to the magnetic proximity effect (MPE), rather than the precessing YIG magnetization. This conclusion is reached through our unique detecting method where the FMR microwave absorption of the magnetized NM surface, hardly observed in the conventional FMR experiments, was greatly amplified when the electrical detection circuit was switched on. ",Kein DOI-Link verfügbar,1604.07025v1,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Tunable Rashba spin-orbit coupling and its interplay with multiorbital   effect and magnetic ordering at oxide interfaces,1970,"  The complex oxide heterostructures such as LaAlO3/SrTiO3 (LAO/STO) interface are paradigmatic platforms to explore emerging multi-degrees of freedom coupling and the associated exotic phenomena. In this study, we reveal the effects of multiorbital and magnetic ordering on Rashba spin-orbit coupling (SOC) at the LAO/STO (001) interface. Based on first-principles calculations, we show that the Rashba spin splitting near the conduction band edge can be tuned substantially by the interfacial insulator-metal transition due to the multiorbital effect of the lowest t_2g bands. We further unravel a competition between Rashba SOC and intrinsic magnetism, in which the Rashba SOC induced spin polarization is suppressed by the interfacial magnetic ordering. These results deepen our understanding of intricate electronic and magnetic reconstruction at the perovskite oxide interfaces and shed light on the engineering of oxide heterostructures for all-oxides-based spintronic devices. ",https://doi.org/10.1103/PhysRevB.104.155152,2101.07586v1,Yes,intricate(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Does the price of strategic commodities respond to U.S. Partisan   Conflict?,1970,"  A noteworthy feature of U.S. politics in recent years is serious partisan conflict, which has led to intensifying polarization and exacerbating high policy uncertainty. The US is a significant player in oil and gold markets. Oil and gold also form the basis of important strategic reserves in the US. We investigate whether U.S. partisan conflict affects the returns and price volatility of oil and gold using a parametric test of Granger causality in quantiles. The empirical results suggest that U.S. partisan conflict has an effect on the returns of oil and gold, and the effects are concentrated at the tail of the conditional distribution of returns. More specifically, the partisan conflict mainly affects oil returns when the crude oil market is in a bearish state (lower quantiles). By contrast, partisan conflict matters for gold returns only when the gold market is in a bullish scenario (higher quantiles). In addition, for the volatility of oil and gold, the predictability of partisan conflict index virtually covers the entire distribution of volatility. ",https://doi.org/10.1016/j.resourpol.2020.101617,1810.08396v2,Yes,noteworthy(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Entropy driven reverse-metal-to-insulator transition and   delta-temperatural transports in metastable perovskites of correlated   rare-earth nickelate,1970,"  The metal to insulator transition (MIT) in Mott-Hubbard systems is one of the most important discoveries in condensed matter physics, and results in abrupt orbital transitions from the insulating to metallic phases by elevating temperature across a critical point (TMIT). Although the MIT was previously expected to be mainly driven by the orbital Coulomb repulsion energy, the entropy contribution to the orbital free energy that also determines the relative stability of the metallic and insulating phases was largely overlooked. Herein, we demonstrate an orbital-entropy dominated reversible electronic phase transition in the metastable perovskite family of correlated rare-earth nicklates (ReNiO3), in addition to their previously known MIT driven by orbital Coulomb energies. In reverse to MIT, the resistivity of ReNiO3 abruptly increases by 2-3 orders by elevating T across another critical point (TR-MIT) below TMIT, and such transition is named as reverse-metal to insulator transition (R-MIT). Combining the afterwards exponentially decreasing resistivity in the insulating phase of ReNiO3 at further temperature elevation, a distinguished delta-temperatural transport character is established, which is potentially applicable for locking the working temperatures range for electric devices. The TR-MIT is shown to be enhanced via reducing the compositional complexity and size of Re or imparting bi-axial compressive strains, and meanwhile the transition sharpness of delta-temperatural transport is reduced. Our discovery indicates that temperature range for a thermodynamically stable insulating phase of ReNiO3 is in between of TR-MIT and TMIT, while a new conductive phase with high orbital entropy is formed by further descending temperature below TR-MIT. ",Kein DOI-Link verfügbar,1904.00610v1,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Hydrogen induced electronic transition within correlated perovskite   nickelates with heavy rare-earth composition,1970,"  Although discovery in hydrogen induced electronic transition within perovskite family of rare-earth nickelate (ReNiO3) opens up a new paradigm in exploring both the new materials functionality and device applications, the existing research stays at ReNiO3 with light rare-earth compositions. To further extend the cognition towards heavier rare-earth, herein we demonstrate the hydrogen induced electronic transitions for quasi-single crystalline ReNiO3/LaAlO3 (001) heterostructures, covering a large variety of the rare-earth composition from Nd to Er. The hydrogen induced elevations in the resistivity of ReNiO3 (RH/R0) show an unexpected non-monotonic tendency with the atomic number of the rare-earth composition, e.g., firstly increase from Nd to Dy and afterwards decreases from Dy to Er. Although ReNiO3 with heavy rare-earth composition (e.g. DyNiO3) exhibits large RH/R0 up to 107, their hydrogen induced electronic transition is not reversible. Further probing the electronic structures via near edge X-ray absorption fine structure analysis clearly demonstrates the respective transition in electronic structures of ReNiO3 from Ni3+ based electron itinerant orbital configurations towards the Ni2+ based electron localized state. Balancing the hydrogen induced transition reversibility with the abruption in the variations of material resistivity, we emphasize that the ReNiO3 with middle rare-earth compositions (e.g. Sm) to be most suitable that caters for the potential applications in correlated electronic devices. ",https://doi.org/10.1063/5.0082917,2112.12357v1,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,MOVE: Effective and Harmless Ownership Verification via Embedded   External Features,1970,"  Currently, deep neural networks (DNNs) are widely adopted in different applications. Despite its commercial values, training a well-performed DNN is resource-consuming. Accordingly, the well-trained model is valuable intellectual property for its owner. However, recent studies revealed the threats of model stealing, where the adversaries can obtain a function-similar copy of the victim model, even when they can only query the model. In this paper, we propose an effective and harmless model ownership verification (MOVE) to defend against different types of model stealing simultaneously, without introducing new security risks. In general, we conduct the ownership verification by verifying whether a suspicious model contains the knowledge of defender-specified external features. Specifically, we embed the external features by tempering a few training samples with style transfer. We then train a meta-classifier to determine whether a model is stolen from the victim. This approach is inspired by the understanding that the stolen models should contain the knowledge of features learned by the victim model. In particular, we develop our MOVE method under both white-box and black-box settings to provide comprehensive model protection. Extensive experiments on benchmark datasets verify the effectiveness of our method and its resistance to potential adaptive attacks. The codes for reproducing the main experiments of our method are available at \url{https://github.com/THUYimingLi/MOVE}. ",Kein DOI-Link verfügbar,2208.02820v1,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,One Model for All Domains: Collaborative Domain-Prefix Tuning for   Cross-Domain NER,1970,"  Cross-domain NER is a challenging task to address the low-resource problem in practical scenarios. Previous typical solutions mainly obtain a NER model by pre-trained language models (PLMs) with data from a rich-resource domain and adapt it to the target domain. Owing to the mismatch issue among entity types in different domains, previous approaches normally tune all parameters of PLMs, ending up with an entirely new NER model for each domain. Moreover, current models only focus on leveraging knowledge in one general source domain while failing to successfully transfer knowledge from multiple sources to the target. To address these issues, we introduce Collaborative Domain-Prefix Tuning for cross-domain NER (CP-NER) based on text-to-text generative PLMs. Specifically, we present text-to-text generation grounding domain-related instructors to transfer knowledge to new domain NER tasks without structural modifications. We utilize frozen PLMs and conduct collaborative domain-prefix tuning to stimulate the potential of PLMs to handle NER tasks across various domains. Experimental results on the Cross-NER benchmark show that the proposed approach has flexible transfer ability and performs better on both one-source and multiple-source cross-domain NER tasks. Codes are available in https://github.com/zjunlp/DeepKE/tree/main/example/ner/cross. ",Kein DOI-Link verfügbar,2301.10410v5,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,On the (In)Effectiveness of Large Language Models for Chinese Text   Correction,1970,"  Recently, the development and progress of Large Language Models (LLMs) have amazed the entire Artificial Intelligence community. Benefiting from their emergent abilities, LLMs have attracted more and more researchers to study their capabilities and performance on various downstream Natural Language Processing (NLP) tasks. While marveling at LLMs' incredible performance on all kinds of tasks, we notice that they also have excellent multilingual processing capabilities, such as Chinese. To explore the Chinese processing ability of LLMs, we focus on Chinese Text Correction, a fundamental and challenging Chinese NLP task. Specifically, we evaluate various representative LLMs on the Chinese Grammatical Error Correction (CGEC) and Chinese Spelling Check (CSC) tasks, which are two main Chinese Text Correction scenarios. Additionally, we also fine-tune LLMs for Chinese Text Correction to better observe the potential capabilities of LLMs. From extensive analyses and comparisons with previous state-of-the-art small models, we empirically find that the LLMs currently have both amazing performance and unsatisfactory behavior for Chinese Text Correction. We believe our findings will promote the landing and application of LLMs in the Chinese NLP community. ",Kein DOI-Link verfügbar,2307.09007v2,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,DeviceRadar: Online IoT Device Fingerprinting in ISPs using Programmable   Switches,1970,"  Device fingerprinting can be used by Internet Service Providers (ISPs) to identify vulnerable IoT devices for early prevention of threats. However, due to the wide deployment of middleboxes in ISP networks, some important data, e.g., 5-tuples and flow statistics, are often obscured, rendering many existing approaches invalid. It is further challenged by the high-speed traffic of hundreds of terabytes per day in ISP networks. This paper proposes DeviceRadar, an online IoT device fingerprinting framework that achieves accurate, real-time processing in ISPs using programmable switches. We innovatively exploit ""key packets"" as a basis of fingerprints only using packet sizes and directions, which appear periodically while exhibiting differences across different IoT devices. To utilize them, we propose a packet size embedding model to discover the spatial relationships between packets. Meanwhile, we design an algorithm to extract the ""key packets"" of each device, and propose an approach that jointly considers the spatial relationships and the key packets to produce a neighboring key packet distribution, which can serve as a feature vector for machine learning models for inference. Last, we design a model transformation method and a feature extraction process to deploy the model on a programmable data plane within its constrained arithmetic operations and memory to achieve line-speed processing. Our experiments show that DeviceRadar can achieve state-of-the-art accuracy across 77 IoT devices with 40 Gbps throughput, and requires only 1.3% of the processing time compared to GPU-accelerated approaches. ",https://doi.org/10.1109/TNET.2024.3398778,2404.12738v1,Yes,"innovative(1), innovatively(1)"
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Agent Planning with World Knowledge Model,1970,"  Recent endeavors towards directly using large language models (LLMs) as agent models to execute interactive planning tasks have shown commendable results. Despite their achievements, however, they still struggle with brainless trial-and-error in global planning and generating hallucinatory actions in local planning due to their poor understanding of the ''real'' physical world. Imitating humans' mental world knowledge model which provides global prior knowledge before the task and maintains local dynamic knowledge during the task, in this paper, we introduce parametric World Knowledge Model (WKM) to facilitate agent planning. Concretely, we steer the agent model to self-synthesize knowledge from both expert and sampled trajectories. Then we develop WKM, providing prior task knowledge to guide the global planning and dynamic state knowledge to assist the local planning. Experimental results on three complex real-world simulated datasets with three state-of-the-art open-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B, demonstrate that our method can achieve superior performance compared to various strong baselines. Besides, we analyze to illustrate that our WKM can effectively alleviate the blind trial-and-error and hallucinatory action issues, providing strong support for the agent's understanding of the world. Other interesting findings include: 1) our instance-level task knowledge can generalize better to unseen tasks, 2) weak WKM can guide strong agent model planning, and 3) unified WKM training has promising potential for further development. Code will be available at https://github.com/zjunlp/WKM. ",Kein DOI-Link verfügbar,2405.14205v1,Yes,"commendable(1), potent(1)"
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Supportiveness-based Knowledge Rewriting for Retrieval-augmented   Language Modeling,1970,"  Retrieval-augmented language models (RALMs) have recently shown great potential in mitigating the limitations of implicit knowledge in LLMs, such as untimely updating of the latest expertise and unreliable retention of long-tail knowledge. However, since the external knowledge base, as well as the retriever, can not guarantee reliability, potentially leading to the knowledge retrieved not being helpful or even misleading for LLM generation. In this paper, we introduce Supportiveness-based Knowledge Rewriting (SKR), a robust and pluggable knowledge rewriter inherently optimized for LLM generation. Specifically, we introduce the novel concept of ""supportiveness""--which represents how effectively a knowledge piece facilitates downstream tasks--by considering the perplexity impact of augmented knowledge on the response text of a white-box LLM. Based on knowledge supportiveness, we first design a training data curation strategy for our rewriter model, effectively identifying and filtering out poor or irrelevant rewrites (e.g., with low supportiveness scores) to improve data efficacy. We then introduce the direct preference optimization (DPO) algorithm to align the generated rewrites to optimal supportiveness, guiding the rewriter model to summarize augmented content that better improves the final response. Comprehensive evaluations across six popular knowledge-intensive tasks and four LLMs have demonstrated the effectiveness and superiority of SKR. With only 7B parameters, SKR has shown better knowledge rewriting capability over GPT-4, the current state-of-the-art general-purpose LLM. ",Kein DOI-Link verfügbar,2406.08116v1,Yes,potent(2)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Detecting Suspected Epidemic Cases Using Trajectory Big Data,1970,"  Emerging infectious diseases are existential threats to human health and global stability. The recent outbreaks of the novel coronavirus COVID-19 have rapidly formed a global pandemic, causing hundreds of thousands of infections and huge economic loss. The WHO declares that more precise measures to track, detect and isolate infected people are among the most effective means to quickly contain the outbreak. Based on trajectory provided by the big data and the mean field theory, we establish an aggregated risk mean field that contains information of all risk-spreading particles by proposing a spatio-temporal model named HiRES risk map. It has dynamic fine spatial resolution and high computation efficiency enabling fast update. We then propose an objective individual epidemic risk scoring model named HiRES-p based on HiRES risk maps, and use it to develop statistical inference and machine learning methods for detecting suspected epidemic-infected individuals. We conduct numerical experiments by applying the proposed methods to study the early outbreak of COVID-19 in China. Results show that the HiRES risk map has strong ability in capturing global trend and local variability of the epidemic risk, thus can be applied to monitor epidemic risk at country, province, city and community levels, as well as at specific high-risk locations such as hospital and station. HiRES-p score seems to be an effective measurement of personal epidemic risk. The accuracy of both detecting methods are above 90\% when the population infection rate is under 20\%, which indicates great application potential in epidemic risk prevention and control practice. ",https://doi.org/10.4208/csiam-am.2020-0006,2004.00908v3,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Orbital torque switching in perpendicularly magnetized materials,1970,"  The orbital Hall effect in light materials has attracted considerable attention for developing novel orbitronic devices. Here we investigate the orbital torque efficiency and demonstrate the switching of the perpendicularly magnetized materials through the orbital Hall material (OHM), i.e., Zirconium (Zr). The orbital torque efficiency of approximately 0.78 is achieved in the Zr OHM with the perpendicularly magnetized [Co/Pt]3 sample, which significantly surpasses that of the perpendicularly magnetized CoFeB/Gd/CoFeB sample (approximately 0.04). Such notable difference is attributed to the different spin-orbit correlation strength between the [Co/Pt]3 sample and the CoFeB/Gd/CoFeB sample, which has been confirmed through the theoretical calculations. Furthermore, the full magnetization switching of the [Co/Pt]3 sample with a switching current density of approximately 2.6x106 A/cm2 has been realized through Zr, which even outperforms that of the W spin Hall material. Our finding provides a guideline to understand orbital torque efficiency and paves the way to develop energy-efficient orbitronic devices. ",Kein DOI-Link verfügbar,2403.03043v1,Yes,notable(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Fe3O4@astragalus polysaccharide core-shell nanoparticles for iron   deficiency anemia therapy and magnetic resonance imaging in vivo,1970,"  Fe3O4@astragalus polysaccharide core-shell nanoparticles (Fe3O4@APS NPs) were demonstrated to be an efficient therapeutic drug for treating iron deficiency anemia (IDA) in vivo. The Fe3O4@APS NPs have been synthesized using a two steps approach involving hydrothermal synthesis and subsequent esterification. Transmission electron microscopy (TEM) and Fourier transform infrared (FTIR) spectroscopy studies show that APS are attached on the surfaces of the highly monodisperse Fe3O4 NPs. Dynamic light scatting (DLS) and magnetic characterizations reveal that the Fe3O4@APS NPs have outstanding water solubility and stability. Cytotoxicity assessment using Hela cells and pathological tests in mice demonstrate their good biocompatibility and low toxicity. The IDA treatment in rats shows that they have efficient therapeutic effect, which is contributed to both the iron element supplement from Fe3O4 and the APS-stimulated hematopoietic cell generation. Moreover, the Fe3O4@APS NPs are superparamagnetic and thus able to be used for magnetic resonance imaging (MRI). This study has demonstrated the potential of nanocomposites involving purified natural products from Chinese herb medicine for biomedical applications. ",Kein DOI-Link verfügbar,1806.10740v1,Yes,potent(1)
0009-0003-7376-3818,Yong Jiang,Universität Göttingen,Knowledge Mechanisms in Large Language Models: A Survey and Perspective,1970,"  Understanding knowledge mechanisms in Large Language Models (LLMs) is crucial for advancing towards trustworthy AGI. This paper reviews knowledge mechanism analysis from a novel taxonomy including knowledge utilization and evolution. Knowledge utilization delves into the mechanism of memorization, comprehension and application, and creation. Knowledge evolution focuses on the dynamic progression of knowledge within individual and group LLMs. Moreover, we discuss what knowledge LLMs have learned, the reasons for the fragility of parametric knowledge, and the potential dark knowledge (hypothesis) that will be challenging to address. We hope this work can help understand knowledge in LLMs and provide insights for future research. ",Kein DOI-Link verfügbar,2407.15017v2,Yes,potent(1)
0009-0003-7389-7445,Christian Bruns,Universität Mannheim,LED-based photo-CIDNP hyperpolarization enables 19F MR imaging and 19F   NMR spectroscopy of 3-fluoro-DL-tyrosine at 0.6 T,1970,"  Although 19F has high potential to serve as a background-free molecular marker in bioimaging, the molar amount of marker substance is often too small to enable 19F MR imaging or 19F NMR spectroscopy with a sufficiently high signal-to-noise ratio (SNR). Hyperpolarization methods such as parahydrogen-based hyperpolarization or dynamic nuclear polarization (DNP) can significantly improve the SNR, but require expensive and complex sample preparation and the removal of toxic catalysts and solvents. Therefore, we used the biologically compatible model of the fluorinated amino acid 3-fluoro-DL-tyrosine with riboflavin 5'-monophosphate (FMN) as a chromophore dissolved in D2O with 3.4% H2Odest. allowing to transform light energy into hyperpolarization of the 19F nucleus via photo-chemically induced dynamic nuclear polarization (photo-CIDNP). We used a low-cost high-power blue LED to illuminate the sample replacing traditionally used laser excitation, which is both potentially harmful and costly. For the first time, we present results of hyperpolarized 19F MRI and 19F NMR performed with a low-cost 0.6 T benchtop MRI system. The device allowed simultaneous dual channel 1H/19F NMR. 19F imaging was performed with a (0.94 mm)2 in-plane resolution. This enabled the spatial resolution of different degrees of hyperpolarization within the sample. We estimated the photo-CIDNP-based 19F signal enhancement at 0.6 T to be approximately 465. FMN did not bleach out even after multiple excitations, so that the signal-to-noise ratio could be further improved by averaging hyperpolarized signals. The results show that the easy-to-use experimental setup has a high potential to serve as an efficient preclinical tool for hyperpolarization studies in bioimaging. ",https://doi.org/10.1007/s00723-022-01473-z,2204.06315v1,Yes,potent(3)
0009-0004-0454-1207,Matthias Stein,"Medizinische Fakultät, RWTH Aachen Universität, RWTH Aachen Universität",Reduced basis method for the nonlinear Poisson-Boltzmann equation   regularized by the range-separated canonical tensor format,1970,"  The Poisson-Boltzmann equation (PBE) is a fundamental implicit solvent continuum model for calculating the electrostatic potential of large ionic solvated biomolecules. However, its numerical solution encounters severe challenges arising from its strong singularity and nonlinearity. In [1,2], the effect of strong singularities was eliminated by applying the range-separated (RS) canonical tensor format [3,4] to construct a solution decomposition scheme for the PBE. The RS tensor format allows to derive a smooth approximation to the Dirac delta distribution in order to obtain a regularized PBE (RPBE) model. However, solving the RPBE is still computationally demanding due to its high dimension $\mathcal{N}$, where $\mathcal{N}$ is always in the millions. In this study, we propose to apply the reduced basis method (RBM) and the (discrete) empirical interpolation method ((D)EIM) to the RPBE in order to construct a reduced order model (ROM) of low dimension $N \ll \mathcal{N}$, whose solution accurately approximates the nonlinear RPBE. The long-range potential can be obtained by lifting the ROM solution back to the $\mathcal{N}$-space while the short-range potential is directly precomputed analytically, thanks to the RS tensor format. The sum of both provides the total electrostatic potential. The main computational benefit is the avoidance of computing the numerical approximation of the singular electrostatic potential. We demonstrate in the numerical experiments, the accuracy and efficacy of the reduced basis (RB) approximation to the nonlinear RPBE (NRPBE) solution and the corresponding computational savings over the classical nonlinear PBE (NPBE) as well as over the RBM being applied to the classical NPBE. ",Kein DOI-Link verfügbar,2103.00245v1,Yes,potent(5)
0009-0004-0454-1207,Matthias Stein,"Medizinische Fakultät, RWTH Aachen Universität, RWTH Aachen Universität",Solution decomposition for the nonlinear Poisson-Boltzmann equation   using the range-separated tensor format,1970,"  The Poisson-Boltzmann equation (PBE) is an implicit solvent continuum model for calculating the electrostatic potential and energies of ionic solvated biomolecules. However, its numerical solution remains a significant challenge due strong singularities and nonlinearity caused by the singular source terms and the exponential nonlinear terms, respectively. An efficient method for the treatment of singularities in the linear PBE was introduced in \cite{BeKKKS:18}, that is based on the RS tensor decomposition for both electrostatic potential and the discretized Dirac delta distribution. In this paper, we extend this regularization method to the nonlinear PBE. We apply the PBE only to the regular part of the solution corresponding to the modified right-hand side via extraction of the long-range part in the discretized Dirac delta distribution. The total electrostatic potential is obtained by adding the long-range solution to the directly precomputed short-range potential. The main computational benefit of the approach is the automatic maintaining of the continuity in the Cauchy data on the solute-solvent interface. The boundary conditions are also obtained from the long-range component of the precomputed canonical tensor representation of the Newton kernel. In the numerical experiments, we illustrate the accuracy of the nonlinear regularized PBE (NRPBE) over the classical variant. ",Kein DOI-Link verfügbar,2109.14073v2,Yes,potent(4)
0009-0004-0454-1207,Matthias Stein,"Medizinische Fakultät, RWTH Aachen Universität, RWTH Aachen Universität",Fast Solution of the Linearized Poisson-Boltzmann Equation with   nonaffine Parametrized Boundary Conditions Using the Reduced Basis Method,1970,"  The Poisson-Boltzmann equation (PBE) is a nonlinear elliptic PDE that arises in biomolecular modeling and is a fundamental tool for structural biology. It is used to calculate electrostatic potentials around an ensemble of fixed charges immersed in an ionic solution. Efficient numerical computation of the PBE yields a high number of degrees of freedom in the resultant algebraic system of equations. Coupled with the fact that in most cases the PBE requires to be solved multiple times for a large number of system configurations, this poses great computational challenges to conventional numerical techniques. To accelerate such computations, we here present the reduced basis method (RBM) which greatly reduces this computational complexity by constructing a reduced order model of typically low dimension. In this study, we employ a simple version of the PBE for proof of concept and discretize the linearized PBE (LPBE) with a centered finite difference scheme. The resultant linear system is solved by the aggregation-based algebraic multigrid method at different samples of ionic strength on a three-dimensional Cartesian grid. The discretized LPBE, which we call the high-fidelity full order model (FOM), yields solution as accurate as other LPBE solvers. We then apply the RBM to FOM. The discrete empirical interpolation method (DEIM) is applied to the Dirichlet boundary conditions which are nonaffine with the parameter, to reduce the complexity of the reduced order model (ROM). From the numerical results, we notice that the RBM reduces the model order from $\mathcal{N} = 2\times 10^{6}$ to $N = 6$ at an accuracy of $10^{-9}$ and reduces computational time by a factor of approximately $7,600$. DEIM, on the other hand, is also used in the offline-online phase of solving the ROM for different values of parameters which provides a speed-up of $20$ for a single iteration of the greedy algorithm. ",Kein DOI-Link verfügbar,1705.08349v2,Yes,potent(1)
0009-0004-0454-1207,Matthias Stein,"Medizinische Fakultät, RWTH Aachen Universität, RWTH Aachen Universität",Computing electrostatic potentials using regularization based on the   range-separated tensor format,1970,"  In this paper, we apply the range-separated (RS) tensor format [6] for the construction of new regularization scheme for the Poisson-Boltzmann equation (PBE) describing the electrostatic potential in biomolecules. In our approach, we use the RS tensor representation to the discretized Dirac delta [21] to construct an efficient RS splitting of the PBE solution in the solute (molecular) region. The PBE then needs to be solved with a regularized source term, and thus black-box solvers can be applied. The main computational benefits are due to the localization of the modified right-hand side within the molecular region and automatic maintaining of the continuity in the Cauchy data on the interface. Moreover, this computational scheme only includes solving a single system of FDM/FEM equations for the smooth long-range (i.e., regularized) part of the collective potential represented by a low-rank RS-tensor with a controllable precision. The total potential is obtained by adding this solution to the directly precomputed rank-structured tensor representation for the short-range contribution. Enabling finer grids in PBE computations is another advantage of the proposed techniques. In the numerical experiments, we consider only the free space electrostatic potential for proof of concept. We illustrate that the classical Poisson equation (PE) model does not accurately capture the solution singularities in the numerical approximation as compared to the new approach by the RS tensor format. ",Kein DOI-Link verfügbar,1901.09864v1,Yes,potent(4)
0009-0004-4209-6239,Jannik Thuemmel,Universität Tübingen,Inductive biases in deep learning models for weather prediction,1970,"  Deep learning has gained immense popularity in the Earth sciences as it enables us to formulate purely data-driven models of complex Earth system processes. Deep learning-based weather prediction (DLWP) models have made significant progress in the last few years, achieving forecast skills comparable to established numerical weather prediction models with comparatively lesser computational costs. In order to train accurate, reliable, and tractable DLWP models with several millions of parameters, the model design needs to incorporate suitable inductive biases that encode structural assumptions about the data and the modelled processes. When chosen appropriately, these biases enable faster learning and better generalisation to unseen data. Although inductive biases play a crucial role in successful DLWP models, they are often not stated explicitly and their contribution to model performance remains unclear. Here, we review and analyse the inductive biases of state-of-the-art DLWP models with respect to five key design elements: data selection, learning objective, loss function, architecture, and optimisation method. We identify the most important inductive biases and highlight potential avenues towards more efficient and probabilistic DLWP models. ",Kein DOI-Link verfügbar,2304.04664v2,Yes,potent(1)
0009-0004-4660-4544,Alexander Maier,Saarland Universität,A Paradigm Shift in Catheter Development: Thermally Drawn Polymeric   Fibers for MR-Guided Cardiovascular Interventions,1970,"  Cardiovascular diseases (CVDs) and congenital heart diseases (CHD) pose significant global health challenges. Fluoroscopy-guided endovascular interventions, though effective, are accompanied by ionizing radiation concerns, especially in pediatric cases. Magnetic resonance imaging (MRI) emerges as a radiation-free alternative, offering superior soft tissue visualization and functional insights. However, the lack of compatible instruments remains a hurdle. We present two novel catheter systems, a tendon-driven steerable catheter and an active tracking Tiger-shaped catheter, fabricated using a unique fiber drawing technique. These catheters, showcasing mechanical properties similar to commercial counterparts, have undergone rigorous in-vitro and in-vivo testing, yielding promising outcomes. This innovative approach has the potential to streamline medical device development, thus enhancing patient care in MR-guided interventions. ",Kein DOI-Link verfügbar,2403.05485v1,Yes,"innovative(1), potent(1)"
0009-0004-6858-4791,Tao Sun,Technische Universität München,DPSNN: Spiking Neural Network for Low-Latency Streaming Speech   Enhancement,1970,"  Speech enhancement (SE) improves communication in noisy environments, affecting areas such as automatic speech recognition, hearing aids, and telecommunications. With these domains typically being power-constrained and event-based while requiring low latency, neuromorphic algorithms in the form of spiking neural networks (SNNs) have great potential. Yet, current effective SNN solutions require a contextual sampling window imposing substantial latency, typically around 32ms, too long for many applications. Inspired by Dual-Path Spiking Neural Networks (DPSNNs) in classical neural networks, we develop a two-phase time-domain streaming SNN framework -- the Dual-Path Spiking Neural Network (DPSNN). In the DPSNN, the first phase uses Spiking Convolutional Neural Networks (SCNNs) to capture global contextual information, while the second phase uses Spiking Recurrent Neural Networks (SRNNs) to focus on frequency-related features. In addition, the regularizer suppresses activation to further enhance energy efficiency of our DPSNNs. Evaluating on the VCTK and Intel DNS Datasets, we demonstrate that our approach achieves the very low latency (approximately 5ms) required for applications like hearing aids, while demonstrating excellent signal-to-noise ratio (SNR), perceptual quality, and energy efficiency. ",Kein DOI-Link verfügbar,2408.07388v1,Yes,potent(1)
0009-0004-6858-4791,Tao Sun,Technische Universität München,Markov Chain Block Coordinate Descent,1970,"  The method of block coordinate gradient descent (BCD) has been a powerful method for large-scale optimization. This paper considers the BCD method that successively updates a series of blocks selected according to a Markov chain. This kind of block selection is neither i.i.d. random nor cyclic. On the other hand, it is a natural choice for some applications in distributed optimization and Markov decision process, where i.i.d. random and cyclic selections are either infeasible or very expensive. By applying mixing-time properties of a Markov chain, we prove convergence of Markov chain BCD for minimizing Lipschitz differentiable functions, which can be nonconvex. When the functions are convex and strongly convex, we establish both sublinear and linear convergence rates, respectively. We also present a method of Markov chain inertial BCD. Finally, we discuss potential applications. ",Kein DOI-Link verfügbar,1811.08990v1,Yes,potent(1)
0009-0004-6858-4791,Tao Sun,Technische Universität München,Asynchronous Coordinate Descent under More Realistic Assumptions,1970,"  Asynchronous-parallel algorithms have the potential to vastly speed up algorithms by eliminating costly synchronization. However, our understanding to these algorithms is limited because the current convergence of asynchronous (block) coordinate descent algorithms are based on somewhat unrealistic assumptions. In particular, the age of the shared optimization variables being used to update a block is assumed to be independent of the block being updated. Also, it is assumed that the updates are applied to randomly chosen blocks. In this paper, we argue that these assumptions either fail to hold or will imply less efficient implementations. We then prove the convergence of asynchronous-parallel block coordinate descent under more realistic assumptions, in particular, always without the independence assumption. The analysis permits both the deterministic (essentially) cyclic and random rules for block choices. Because a bound on the asynchronous delays may or may not be available, we establish convergence for both bounded delays and unbounded delays. The analysis also covers nonconvex, weakly convex, and strongly convex functions. We construct Lyapunov functions that directly model both objective progress and delays, so delays are not treated errors or noise. A continuous-time ODE is provided to explain the construction at a high level. ",Kein DOI-Link verfügbar,1705.08494v2,Yes,potent(1)
0009-0004-6858-4791,Tao Sun,Technische Universität München,Backdoor Cleansing with Unlabeled Data,1970,"  Due to the increasing computational demand of Deep Neural Networks (DNNs), companies and organizations have begun to outsource the training process. However, the externally trained DNNs can potentially be backdoor attacked. It is crucial to defend against such attacks, i.e., to postprocess a suspicious model so that its backdoor behavior is mitigated while its normal prediction power on clean inputs remain uncompromised. To remove the abnormal backdoor behavior, existing methods mostly rely on additional labeled clean samples. However, such requirement may be unrealistic as the training data are often unavailable to end users. In this paper, we investigate the possibility of circumventing such barrier. We propose a novel defense method that does not require training labels. Through a carefully designed layer-wise weight re-initialization and knowledge distillation, our method can effectively cleanse backdoor behaviors of a suspicious network with negligible compromise in its normal behavior. In experiments, we show that our method, trained without labels, is on-par with state-of-the-art defense methods trained using labels. We also observe promising defense results even on out-of-distribution data. This makes our method very practical. Code is available at: https://github.com/luluppang/BCU. ",Kein DOI-Link verfügbar,2211.12044v4,Yes,potent(1)
0009-0004-6858-4791,Tao Sun,Technische Universität München,TraceCaps: A Capsule-based Neural Network for Semantic Segmentation,1970,"  In this paper, we propose a capsule-based neural network model to solve the semantic segmentation problem. By taking advantage of the extractable part-whole dependencies available in capsule layers, we derive the probabilities of the class labels for individual capsules through a recursive, layer-by-layer procedure. We model this procedure as a traceback pipeline and take it as a central piece to build an end-to-end segmentation network. Under the proposed framework, image-level class labels and object boundaries are jointly sought in an explicit manner, which poses a significant advantage over the state-of-the-art fully convolutional network (FCN) solutions. With the capability to extracted part-whole information, our traceback pipeline can potentially be utilized as the building blocks to design interpretable neural networks. Experiments conducted on modified MNIST and neuroimages demonstrate that our model considerably enhance the segmentation performance compared to the leading FCN variants. ",Kein DOI-Link verfügbar,1901.02920v2,Yes,potent(1)
0009-0004-6858-4791,Tao Sun,Technische Universität München,Mapping the Depths: A Stocktake of Underground Power Distribution in   United States,1970,"  A resilient energy infrastructure is crucial for addressing increasing extreme weather and climate risks. The undergrounding of the power system is one approach to building such resiliency. In this study, we introduce Grid Underground Distribution Statistics (GUDS) for the US, the first nationwide comprehensive assessment of underground electricity distribution at a high spatial granularity. In analyzing this dataset, we find regional differences in underground distribution rates, with generally higher rates for east and west coasts and in northern states, and lower rates in the central US. We also observe relationships between underground rates and factors such as household income levels, degree of urbanization, and vulnerability to natural hazards. Notably, regions with higher electricity rates are not associated with greater proportions of underground distribution, highlighting potential equity issues in infrastructure distribution. By presenting this granular information and insights on underground distribution, our study offers valuable guidance for informing planning and decision-making by policymakers, Independent System Operators, utilities, and end-users. ",Kein DOI-Link verfügbar,2402.06668v1,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Formation of galactic nuclei with multiple supermassive black holes at   high redshifts,1970,"  We examine the formation of groups of multiple supermassive black holes (SMBHs) in gas-poor galactic nuclei due to the high merger rate of galaxies at high redshifts. We calculate the relative likelihood of binary, triple, and quadruple SMBH systems, by considering the timescales for relevant processes and combining merger trees with N-body simulations for the dynamics of stars and SMBHs in galactic nuclei. Typical haloes today with mass $M_0\approx 10^{14}$ M$_\odot$ have an average mass $M_{z=6}=5\times 10^{11}$ M$_\odot$ at $z\sim 6$, while rare haloes with current mass $M_0\gtrsim 10^{15}$ M$_\odot$ have an average mass $M_{z=6}=5\times 10^{12}$ M$_\odot$ at that redshift. These cluster-size haloes are expected to host single galaxies at $z\sim 6$. We expect about 30% galaxies within haloes with present-day mass $M_0\approx 10^{14}$ M$_\odot$ to contain more than two SMBHs at redshifts $2\lesssim z\lesssim 6$. For larger present-day haloes, with $M_0\gtrsim 10^{15}$ M$_\odot$, this fraction is almost 60%. The existence of multiple SMBHs at high redshifts can potentially explain the mass deficiencies observed in the cores of massive elliptical galaxies, which are up to 5 times the mass of their central BHs. Multiple SMBHs would also lead to an enhanced rate of tidal disruption of stars, modified gravitational wave signals compared to isolated BH binaries, and slingshot ejection of SMBHs from galaxies at high speeds in excess of 2000 km s$^{-1}$. ",https://doi.org/10.1111/j.1365-2966.2012.20699.x,1107.0517v1,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Radio Crickets: Chirping Jets from Black Hole Binaries Entering their   Gravitational Wave Inspiral,1970,"  We study a novel electromagnetic signature of supermassive black hole binaries whose inspiral starts being dominated by gravitational wave (GW) emission. Recent simulations suggest that the binary's member BHs can continue to accrete gas from the circumbinary accretion disk in this phase of the binary's evolution, all the way until coalescence. If one of the binary members produces a radio jet as a result of accretion, the jet precesses along a biconical surface due to the binary's orbital motion. When the binary enters the GW phase of its evolution, the opening angle widens, the jet exhibits milliarcsecond scale wiggles, and the conical surface of jet precession is twisted due to apparant superluminal motion. The rapidly increasing orbital velocity of the binary gives the jet an appearance of a ""chirp."" This helical chirping morphology of the jet can be used to infer the binary parameters. For binaries with mass 10^7--10^10 Msun at redshifts z<0.5, monitoring these features in current and archival data will place a lower limit on sources that could be detected by eLISA and Pulsar Timing Arrays. In the future, microarcsecond interferometry with the Square Kilometer Array will increase the potential usefulness of this technique. ",https://doi.org/10.1093/mnras/stv2940,1507.06990v3,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Implications of the cosmological 21-cm absorption profile for   high-redshift star formation and deep JWST surveys,1970,"  Apart from its anomalously large depth, the cosmological 21-cm absorption signal measured by the EDGES collaboration also has a shape that is distinctly different from theoretical predictions. Models with non-traditional components such as super-adiabatic baryonic cooling or an excess radio background explain the depth of the observed profile, but still conspicuously fail to explain its shape. In this paper, we quantify the requirements imposed by the EDGES measurement on sources of Ly $\alpha$ and X-ray photons in the presence of excess radio background at cosmic dawn. In extreme cases, the Ly $\alpha$ and X-ray emissivities require to be enhanced by up to an order of magnitude relative to traditional models. Furthermore, this enhancement needs to be active only for a short duration. We find that under conventional assumptions for the cosmic star formation rate density, standard stellar populations are incapable of meeting these conditions. Only highly unusual models of massive metal-free stars seem to provide a possible mechanism. Conversely, if the sources of Ly $\alpha$ and X-ray photons are compelled to have standard properties, the EDGES measurement puts strong demands on the cosmic star formation rate density. This provides interesting falsifiable predictions for high-redshift galaxy surveys enabled by \textit{James Webb Space Telescope} (\textit{JWST}). We derive predictions for galaxy UV luminosity functions and number densities, and show that a deep \textit{JWST} survey with a limiting UV magnitude of $m_\mathrm{UV,lim}=32$ would potentially be able to rule out the predictions enforced by the EDGES measurement. ",https://doi.org/10.1093/mnras/stac1961,2203.07733v3,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Experimental generation of polarization entanglement from spontaneous   parametric down-conversion pumped by spatiotemporally highly incoherent light,1970,"  The influence of pump coherence on the entanglement produced in spontaneous parametric down-conversion (SPDC) is important to understand, both from a fundamental perspective, and from a practical standpoint for controlled generation of entangled states. In this context, it is known that in the absence of postselection, the pump coherence in a given degree of freedom (DOF) imposes an upper limit on the generated entanglement in the same DOF. However, the cross-influence of the pump coherence on the generated entanglement in a different DOF is not well-understood. Here, we experimentally investigate the effect of a spatiotemporally highly-incoherent (STHI) light-emitting diode (LED) pump on the polarization entanglement generated in SPDC. Our quantum state tomography measurements using multimode collection fibers to reduce the influence of postselection yield a two-qubit state with a concurrence of 0.531+/-0.006 and a purity of 0.647+/-0.005, in excellent agreement with our theoretically predicted concurrence of 0.552 and purity of 0.652. Therefore, while the use of an STHI pump causes reduction in the entanglement and purity of the output polarization two-qubit state, the viability of SPDC with STHI pumps is nevertheless important for two reasons: (i) STHI sources are ubiquitous and available at a wider range of wavelengths than lasers, and (ii) the generated STHI polarization-entangled two-photon states could potentially be useful in long-distance quantum communication schemes due to their robustness to scattering. ",https://doi.org/10.1103/PhysRevA.107.L041701,2210.16229v2,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Prospects for Observing the low-density Cosmic Web in Lyman-alpha   Emission,1970,"  Mapping the intergalactic medium (IGM) in Lyman-$\alpha$ emission would yield unprecedented tomographic information on the large-scale distribution of baryons and potentially provide new constraints on the UV background and various feedback processes relevant to galaxy formation. Here, we use a cosmological hydrodynamical simulation to examine the Lyman-$\alpha$ emission of the IGM due to collisional excitations and recombinations in the presence of a UV background. We focus on gas in large-scale-structure filaments in which Lyman-$\alpha$ radiative transfer effects are expected to be moderate. At low density the emission is primarily due to fluorescent re-emission of the ionising UV background due to recombinations, while collisional excitations dominate at higher densities. We discuss prospects of current and future observational facilities to detect this emission and find that the emission of filaments of the cosmic web will typically be dominated by the halos and galaxies embedded in them, rather than by the lower density filament gas outside halos. Detecting filament gas directly would require a very long exposure with a MUSE-like instrument on the ELT. Our most robust predictions that act as lower limits indicate this would be slightly less challenging at lower redshifts ($z \lesssim 4$). We also find that there is a large amount of variance between fields in our mock observations. High-redshift protoclusters appear to be the most promising environment to observe the filamentary IGM in Lyman-$\alpha$ emission. ",https://doi.org/10.1051/0004-6361/202040187,1905.06954v3,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Robustness of direct measurements of the mean free path of ionizing   photons in the epoch of reionization,1970,"  Measurements of the mean free path of Lyman-continuum photons in the intergalactic medium during the epoch of reionization can help constrain the nature of the sources as well as sinks of hydrogen-ionizing radiation. A recent approach to this measurement has been to utilize composite spectra of multiple quasars at $z\sim 6$, and infer the mean free path after correcting the spectra for the presence of quasar proximity zones. This has revealed not only a steep drop in the mean free path from $z=5$ to $z=6$, but also potentially a mild tension with reionization simulations. We critically examine such direct measurements of the mean free path for biases due to quasar environment, incomplete reionization, and quasar proximity zones. Using cosmological radiative transfer simulations of reionization combined with one-dimensional radiative transfer calculations of quasar proximity zones, we find that the bias in the mean free path due to overdensities around quasars is minimal at $z\sim 6$. Patchiness of reionization at this redshift also does not affect the measurements significantly. Fitting our model to the data results in a mean free path of $\lambda_{\mathrm{mfp}}=1.49^{+0.47}_{-0.52}$~pMpc at $z=6$, which is consistent with the recent measurements in the literature, indicating robustness with respect to the modelling of quasar proximity zones. We also compare various ways in which the mean free path has been defined in simulations before the end of reionization. Overall, our finding is that recent measurements of the mean free path appear to be robust relative to several sources of potential bias. ",Kein DOI-Link verfügbar,2311.06344v2,Yes,potent(2)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Impact of extragalactic point sources on the low-frequency sky spectrum   and cosmic dawn global 21-cm measurements,1970,"  Contribution of resolved and unresolved extragalactic point sources to the low-frequency sky spectrum is a potentially non-negligible part of the astrophysical foregrounds for cosmic dawn 21-cm experiments. The clustering of such point sources on the sky, combined with the frequency-dependence of the antenna beam, can also make this contribution chromatic. By combining low-frequency measurements of the luminosity function and the angular correlation function of extragalactic point sources, we develop a model for the contribution of these sources to the low-frequency sky spectrum. Using this model, we find that the contribution of sources with flux density $>10^{-6}\,$Jy to the sky-averaged spectrum is smooth and of the order of a few kelvins at 50 - $200\,$MHz. We combine this model with measurements of the galactic foreground spectrum and convolve the result with the beam of the conical log-spiral antenna planned as part of the Radio Experiment for the Analysis of Cosmic Hydrogen (REACH) project. We find that the contribution of point sources to resultant spectrum is $\sim0.4\%$ of the total foregrounds, but still larger by at least an order of magnitude than the standard predictions for the cosmological 21-cm signal. As a result, not accounting for the point-source contribution leads to a systematic bias in 21-cm signal recovery. We show, however, that in the REACH case, this reconstruction bias can be removed by modelling the point-source contribution as a power law with a running spectral index. We make our code publicly available as a Python package labelled epspy. ",Kein DOI-Link verfügbar,2406.17031v1,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Revised estimates of CMB $B$-mode polarization induced by patchy   reionization,1970,"  The search for primordial gravitational waves through the $B$-mode polarization pattern in the CMB is one of the major goals of current and future CMB experiments. Besides foregrounds, a potential hurdle in this search is the anisotropic secondary $B$-mode polarization generated by the scattering of CMB photons off free electrons produced during patchy cosmological reionization. Robust predictions of these secondary anisotropies are challenging because of uncertainties in the reionization history. In this paper, we revise estimates of the reionization-induced $B$-mode signal by incorporating recent advances in the understanding of reionization through observations of the Lyman-$\alpha$ forest. To derive these $B$-mode estimates, we use high-dynamic-range radiative transfer simulations of reionization that are calibrated to the Ly$\alpha$ data. These simulations are also consistent with a variety of other high-redshift observations. We find that around multipoles $\ell\approx 100$, reionization induces $B$-mode power with $\ell(\ell+1)C_\ell^{BB}/2\pi\approx 4\times 10^{-6}\,\mu$K$^2$. This secondary signal is thus at the level of the primordial signal with the tensor-to-scalar ratio $r<10^{-4}$, and can increase by a factor of $\sim 50$ if reionization is sourced by highly clustered sources residing in haloes with mass of $\sim 10^{11}$ M$_\odot$. Our findings suggest that the contribution of patchy reionization to the search for primordial gravitational waves is unlikely to be a concern for currently planned CMB experiments. ",https://doi.org/10.1088/1475-7516/2021/01/003,2004.02927v2,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Implications of the $z>5$ Lyman-$α$ forest for the 21-cm power   spectrum from the epoch of reionization,1970,"  Our understanding of the intergalactic medium at redshifts $z=5$-$6$ has improved considerably in the last few years due to the discovery of quasars with $z>6$ that enable Lyman-$\alpha$ forest studies at these redshifts. A realisation from this has been that hydrogen reionization could end much later than previously thought, so that large ""islands"" of cold, neutral hydrogen could exist in the IGM at redshifts $z=5$-$6$. By using radiative transfer simulations of the IGM, we consider the implications of the presence of these neutral hydrogen islands for the 21-cm power spectrum signal and its potential detection by experiments such as HERA, SKA, LOFAR, and MWA. In contrast with previous models of the 21-cm signal, we find that thanks to the late end of reionization the 21-cm power in our simulation continues to be as high as $\Delta^2_{21}=10~\mathrm{mK}^2$ at $k\sim 0.1~h/$cMpc at $z=5$-$6$. This value of the power spectrum is several orders of magnitude higher than that in the conventional models considered in the literature for these redshifts. Such high values of the 21-cm power spectrum should be detectable by HERA and SKA1-LOW in $\sim 1000$ hours, assuming optimistic foreground subtraction. This redshift range is also attractive due to relatively low sky temperature and potentially greater abundance of multiwavelength data. ",https://doi.org/10.1093/mnras/stab2424,2103.03261v2,Yes,potent(2)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,The correlation of high-redshift galaxies with the thermal   Sunyaev-Zel'dovich effect traces reionization,1970,"  We explore a potential new probe of reionization: the cross-correlation of high-redshift galaxies with maps of the thermal Sunyaev-Zel'dovich (tSZ) effect. We consider two types of high redshift galaxies: Lyman break galaxies (LBGs) and Lyman-$\alpha$ emitters (LAEs). LBGs and LAEs will be detected in large numbers at high redshift ($z \approx$ 4 to 7) by ongoing and future surveys. We consider a LBG sample like that expected from the The Rubin Observatory Legacy Survey of Space and Time (LSST), and a selection of LAEs modelled after the Subaru SILVERRUSH program, but covering a much larger sky fraction. The tSZ effect is sensitive to a line-of-sight integral of the ionized gas pressure, and can be measured across large patches of the sky using multi-frequency CMB surveys. We consider forecast tSZ maps from CMB Stage 4 and more futuristic observations. Using a suite of hydrodynamical simulations, we show that the high-redshift galaxies are correlated with the tSZ signal from reionization, with cross-power amplitude of order $10^{-15}$ at $\ell \sim 1000$. The cross-spectra between LBGs/LAEs with tSZ maps contain information about the reionization history of the Universe, such as the distribution of bubble sizes, and could in principle be used to directly measure the timing of reionization. The amplitude of the signal is small, however, and its detectability is hindered by low-redshift contributions to tSZ maps and by instrumental noise. If the the low-redshift contribution to the observed tSZ signal is suppressed by masking of massive halos, a combination of overlapping futuristic CMB and galaxy surveys could potentially probe this signal. ",https://doi.org/10.1093/mnras/stab016,2006.09742v2,Yes,potent(2)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,The Sherwood-Relics simulations: overview and impact of patchy   reionization and pressure smoothing on the intergalactic medium,1970,"  We present the Sherwood-Relics simulations, a new suite of large cosmological hydrodynamical simulations aimed at modelling the intergalactic medium (IGM) during and after the cosmic reionization of hydrogen. The suite consists of over 200 simulations that cover a wide range of astrophysical and cosmological parameters. It also includes simulations that use a new lightweight hybrid scheme for treating radiative transfer effects. This scheme follows the spatial variations in the ionizing radiation field, as well as the associated fluctuations in IGM temperature and pressure smoothing. It is computationally much cheaper than full radiation hydrodynamics simulations and circumvents the difficult task of calibrating a galaxy formation model to observational constraints on cosmic reionization. Using this hybrid technique, we study the spatial fluctuations in IGM properties that are seeded by patchy cosmic reionization. We investigate the relevant physical processes and assess their impact on the z > 4 Lyman-alpha forest. Our main findings are: (i) Consistent with previous studies patchy reionization causes large scale temperature fluctuations that persist well after the end of reionization, (ii) these increase the Lyman-alpha forest flux power spectrum on large scales, and (iii) result in a spatially varying pressure smoothing that correlates well with the local reionization redshift. (iv) Structures evaporated or puffed up by photoheating cause notable features in the Lyman-alpha forest, such as flat-bottom or double-dip absorption profiles. ",https://doi.org/10.1093/mnras/stac3761,2207.13098v2,Yes,notable(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Chasing the Tail of Cosmic Reionization with Dark Gap Statistics in the   Ly$α$ Forest over $5 < z < 6$,1970,"  We present a new investigation of the intergalactic medium (IGM) near the end of reionization using ""dark gaps"" in the Lyman-alpha (Ly$\alpha$) forest. Using spectra of 55 QSOs at $z_{\rm em}>5.5$, including new data from the XQR-30 VLT Large Programme, we identify gaps in the Ly$\alpha$ forest where the transmission averaged over 1 comoving $h^{-1}\,{\rm Mpc}$ bins falls below 5%. Nine ultra-long ($L > 80~h^{-1}\,{\rm Mpc}$) dark gaps are identified at $z<6$. In addition, we quantify the fraction of QSO spectra exhibiting gaps longer than $30~h^{-1}\,{\rm Mpc}$, $F_{30}$, as a function of redshift. We measure $F_{30} \simeq 0.9$, 0.6, and 0.15 at $z = 6.0$, 5.8, and 5.6, respectively, with the last of these long dark gaps persisting down to $z \simeq 5.3$. Comparing our results with predictions from hydrodynamical simulations, we find that the data are consistent with models wherein reionization extends significantly below redshift six. Models wherein the IGM is essentially fully reionized that retain large-scale fluctuations in the ionizing UV background at $z \lesssim 6$ are also potentially consistent with the data. Overall, our results suggest that signature of reionization in the form of islands of neutral hydrogen and/or large-scale fluctuations in the ionizing background remain present in the IGM until at least $z \simeq 5.3$. ",https://doi.org/10.3847/1538-4357/ac26c2,2109.06295v1,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,New quasar proximity zone size measurements at $z\sim 6$ using the   enlarged XQR-30 sample,1970,"  Proximity zones of high-redshift quasars are unique probes of their central supermassive black holes as well as the intergalactic medium in the last stages of reionization. We present 22 new measurements of proximity zones of quasars with redshifts between 5.8 and 6.6, using the enlarged XQR-30 sample of high-resolution, high-SNR quasar spectra. The quasars in our sample have UV magnitudes of $M_{1450}\sim -27$ and black hole masses of $10^9$$\unicode{x2013}$$10^{10}$ M$_\odot$. Our inferred proximity zone sizes are 2$\unicode{x2013}$7 physical Mpc, with a typical uncertainty of less than 0.5 physical Mpc, which, for the first time, also includes uncertainty in the quasar continuum. We find that the correlation between proximity zone sizes and the quasar redshift, luminosity, or black hole mass, indicates a large diversity of quasar lifetimes. Two of our proximity zone sizes are exceptionally small. The spectrum of one of these quasars, with $z=6.02$, displays, unusually for this redshift, damping wing absorption without any detectable metal lines, which could potentially originate from the IGM. The other quasar has a high-ionization absorber $\sim$0.5 pMpc from the edge of the proximity zone. This work increases the number of proximity zone measurements available in the last stages of cosmic reionization to 87. This data will lead to better constraints on quasar lifetimes and obscuration fractions at high redshift, which in turn will help probe the seed mass and formation redshift of supermassive black holes. ",https://doi.org/10.1093/mnras/stad1326,2305.00998v1,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Evidence of Pop~III stars' chemical signature in neutral gas at z~6. A   study based on the E-XQR-30 spectroscopic sample,1970,"  This study explores the metal enrichment signatures attributed to the first generation of stars (PopIII) in the Universe, focusing on the E-XQR-30 sample. We aim to identify traces of Pop III metal enrichment by analyzing neutral gas in the interstellar medium of primordial galaxies and their satellite clumps, detected in absorption. To chase the chemical signature of PopIII stars, we studied metal absorption systems in the E-XQR-30 sample, selected through the detection of the OI absorption line at 1302A. The OI line is a reliable tracer of HI and allowed us to overcome the challenges posed by the Lyman-$\alpha$ forest's increasing saturation at redshifts above $\sim5$ to identify Damped Lyman-$\alpha$ systems (DLA). We detected and analyzed 29 OI systems at $z\geq5.4$, differentiating between proximate DLAs (PDLA) and intervening DLAs. Voigt function fits were applied to obtain ionic column densities, and relative chemical abundances were determined for 28 systems. These were then compared with the predictions of theoretical models. Our findings expand the study of OI systems at $z\geq5.4$ fourfold. No systematic differences were observed in the average chemical abundances between PDLAs and intervening DLAs. The chemical abundances in our sample align with literature systems at $z>4.5$, suggesting a similar enrichment pattern for this class of absorption systems. A comparison between these DLA-analogues at $4.5<z<6.5$ with a sample of very metal-poor DLAs at $2<z<4.5$ shows in general similar average values for the relative abundances, with the exception of [C/O], [Si/Fe] and [Si/O] which are significantly larger for the high-$z$ sample. Furthermore, the dispersion of the measurements significantly increases in the high-redshift bin. This increase is predicted by the theoretical models and indicates a potential retention of PopIII signatures in the probed gas. (Abridged) ",https://doi.org/10.1051/0004-6361/202349062,2404.10722v2,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,Long Dark Gaps in the Ly$β$ Forest at $z<6$: Evidence of Ultra Late   Reionization from XQR-30 Spectra,1970,"  We present a new investigation of the intergalactic medium (IGM) near reionization using dark gaps in the Lyman-$\beta$ (Ly$\beta$) forest. With its lower optical depth, Ly$\beta$ offers a potentially more sensitive probe to any remaining neutral gas compared to commonly used Ly$\alpha$ line. We identify dark gaps in the Ly$\beta$ forest using spectra of 42 QSOs at $z_{\rm em}>5.5$, including new data from the XQR-30 VLT Large Programme. Approximately $40\%$ of these QSO spectra exhibit dark gaps longer than $10h^{-1}{\rm Mpc}$ at $z\simeq5.8$. By comparing the results to predictions from simulations, we find that the data are broadly consistent both with models where fluctuations in the Ly$\alpha$ forest are caused solely by ionizing ultraviolet background (UVB) fluctuations and with models that include large neutral hydrogen patches at $z<6$ due to a late end to reionization. Of particular interest is a very long ($L=28h^{-1}{\rm Mpc}$) and dark ($\tau_{\rm eff} \gtrsim 6$) gap persisting down to $z\simeq 5.5$ in the Ly$\beta$ forest of the $z_{\rm}=5.85$ QSO PSO J025$-$11. This gap may support late reionization models with a volume-weighted average neutral hydrogen fraction of $ \langle x_{\rm HI}\rangle \gtrsim 5\%$ by $z=5.6$. Finally, we infer constraints on $\langle x_{\rm HI}\rangle$ over $5.5 \lesssim z \lesssim 6.0$ based on the observed Ly$\beta$ dark gap length distribution and a conservative relationship between gap length and neutral fraction derived from simulations. We find $\langle x_{\rm HI}\rangle \leq 0.05$, 0.17, and 0.29 at $z\simeq 5.55$, 5.75, and 5.95, respectively. These constraints are consistent with models where reionization ends significantly later than $z = 6$. ",https://doi.org/10.3847/1538-4357/ac6e60,2205.04569v1,Yes,potent(1)
0009-0005-1088-7519,Girish Kulkarni,Heinrich-Heine-Universität Düsseldorf,A SPectroscopic survey of biased halos In the Reionization Era (ASPIRE):   JWST Reveals a Filamentary Structure around a z=6.61 Quasar,1970,"  We present the first results from the JWST ASPIRE program (A SPectroscopic survey of biased halos In the Reionization Era). This program represents an imaging and spectroscopic survey of 25 reionization-era quasars and their environments by utilizing the unprecedented capabilities of NIRCam Wide Field Slitless Spectroscopy (WFSS) mode. ASPIRE will deliver the largest ($\sim280~{\rm arcmin}^2$) galaxy redshift survey at 3-4 $\mu$m among JWST Cycle-1 programs and provide extensive legacy values for studying the formation of the earliest supermassive black holes (SMBHs), the assembly of galaxies, early metal enrichment, and cosmic reionization. In this first ASPIRE paper, we report the discovery of a filamentary structure traced by the luminous quasar J0305-3150 and ten [OIII] emitters at $z=6.6$. This structure has a 3D galaxy overdensity of $\delta_{\rm gal}=12.6$ over 637 cMpc$^3$, one of the most overdense structures known in the early universe, and could eventually evolve into a massive galaxy cluster. Together with existing VLT/MUSE and ALMA observations of this field, our JWST observations reveal that J0305-3150 traces a complex environment where both UV-bright and dusty galaxies are present, and indicate that the early evolution of galaxies around the quasar is not simultaneous. In addition, we discovered 31 [OIII] emitters in this field at other redshifts, $5.3<z<6.7$, with half of them situated at $z\sim5.4$ and $z\sim6.2$. This indicates that star-forming galaxies, such as [OIII] emitters, are generally clustered at high redshifts. These discoveries demonstrate the unparalleled redshift survey capabilities of NIRCam WFSS and the potential of the full ASPIRE survey dataset. ",https://doi.org/10.3847/2041-8213/accd6f,2304.09894v1,Yes,potent(1)
0009-0005-1209-503X,Manuel Blickle,Johannes Gutenberg Universität Mainz,The intersection homology D--module in finite characteristic,1970,"  Let R be a regular, local and F-finite ring defined over a field of finite characteristic. Let I be an ideal of height c with normal quotient $A=R/I$. It is shown that the local cohomology module H^c_I(R) contains a unique simple D_R--submodule L(A,R). This should be viewed as a finite characteristic analog of the Kashiwara--Brylinski D_R--module in characteristic zero which corresponds to the intersection cohomology complex via the Riemann--Hilbert correspondence. Besides the existence of L(A,R), more importantly, we give its construction as a certain dual of the tight closure of zero in $H^d_m(A)$. We obtain a precise D_R--simplicity criterion for H^c_I(R), namely H^c_I(R) is D_R--simple if and only if the tight closure of zero in H^d_m(A) is Frobenius nilpotent, in particular this is the case if A is F--rational.   Furthermore, the techniques developed imply a result in tight closure theory, saying that the parameter test module commutes with completion. ",Kein DOI-Link verfügbar,math/0110244v1,Yes,potent(1)
0009-0005-1209-503X,Manuel Blickle,Johannes Gutenberg Universität Mainz,Cartier Crystals,1970,"  Building on our previous work ""Cartier modules: finiteness results"" we start in this manuscript an in depth study of the derived category of Cartier modules and the cohomological operations which are defined on them. After localizing at the sub-category of locally nilpotent objects we show that for a morphism essentially of finite type $f$ the operations $Rf_*$ and $f^!$ are defined for Cartier crystals. We show that, if $f$ is of finite type (but not necessarily proper) $Rf_*$ preserves coherent cohomology (up to nilpotence) and that $f^!$ has bounded cohomological dimension. In a sequel we will explain how Grothendieck-Serre Duality relates our theory of Cartier Crystals to the theory of $\tau$-crystals as developed by Pink and the second author. ",Kein DOI-Link verfügbar,1309.1035v1,Yes,potent(1)
0009-0005-1360-8976,Jingzhi Li,Universität Würzburg,A Direct Sampling Method for Inverse Scattering Using Far-Field Data,1970,"  This work is concerned with a direct sampling method (DSM) for inverse acoustic scattering problems using far-field data. The method characterizes some unknown obstacles, inhomogeneous media or cracks, directly through an indicator function computed from the measured data. Using one or very few incident waves, the DSM provides quite reasonable profiles of scatterers in time-harmonic inverse acoustic scattering without a priori knowledge of either the physical properties or the number of disconnected components of the scatterer. We shall first derive the DSM using far-field data, then carry out a systematic evaluation of the performances and distinctions of the DSM using both near-field and far-field data. The numerical simulations are shown to demonstrate interesting and promising potentials of the DSM: a) ability to identify not only medium scatterers, but also obstacles, and even cracks, using measurement data from one or few incident directions, b) robustness with respect to large noise, and c) computational efficiency with only inner products involved. ",Kein DOI-Link verfügbar,1206.0727v2,Yes,potent(1)
0009-0005-1360-8976,Jingzhi Li,Universität Würzburg,Spatiotemporal Monitoring of Epidemics via Solution of a Coefficient   Inverse Problem,1970,"  Let S,I and R be susceptible, infected and recovered populations in a city affected by an epidemic. The SIR model of Lee, Liu, Tembine, Li and Osher, \emph{SIAM J. Appl. Math.},~81, 190--207, 2021 of the spatiotemoral spread of epidemics is considered. This model consists of a system of three nonlinear coupled parabolic Partial Differential Equations with respect to the space and time dependent functions S,I and R. For the first time, a Coefficient Inverse Problem (CIP) for this system is posed. The so-called \textquotedblleft convexification"" numerical method for this inverse problem is constructed. The presence of the Carleman Weight Function (CWF) in the resulting regularization functional ensures the global convergence of the gradient descent method of the minimization of this functional to the true solution of the CIP, as long as the noise level tends to zero. The CWF is the function, which is used as the weight in the Carleman estimate for the corresponding Partial Differential Operator. Numerical studies demonstrate an accurate reconstruction of unknown coefficients as well as S,I,R functions inside of that city. As a by-product, uniqueness theorem for this CIP is proven. Since the minimal measured input data are required, then the proposed methodology has a potential of a significant decrease of the cost of monitoring of epidemics. ",Kein DOI-Link verfügbar,2401.02070v1,Yes,potent(1)
0009-0005-1360-8976,Jingzhi Li,Universität Würzburg,Determining a random Schrödinger equation with unknown source and   potential,1970,"  We are concerned with the direct and inverse scattering problems associated with a time-harmonic random Schr\""odinger equation with unknown source and potential terms. The well-posedness of the direct scattering problem is first established. Three uniqueness results are then obtained for the corresponding inverse problems in determining the variance of the source, the potential and the expectation of the source, respectively, by the associated far-field measurements. First, a single realization of the passive scattering measurement can uniquely recover the variance of the source without the a priori knowledge of the other unknowns. Second, if active scattering measurement can be further obtained, a single realization can uniquely recover the potential function without knowing the source. Finally, both the potential and the first two statistic moments of the random source can be uniquely recovered with full measurement data. The major novelty of our study is that on the one hand, both the random source and the potential are unknown, and on the other hand, both passive and active scattering measurements are used for the recovery in different scenarios. ",https://doi.org/10.1137/18M1225276,1811.00880v4,Yes,potent(5)
0009-0005-1360-8976,Jingzhi Li,Universität Würzburg,Determining a random Schrödinger operator: both potential and source   are random,1970,"  We study an inverse scattering problem associated with a Schr\""odinger system where both the potential and source terms are random and unknown. The well-posedness of the forward scattering problem is first established in a proper sense. We then derive two unique recovery results in determining the rough strengths of the random source and the random potential, by using the corresponding far-field data. The first recovery result shows that a single realization of the passive scattering measurements uniquely recovers the rough strength of the random source. The second one shows that, by a single realization of the backscattering data, the rough strength of the random potential can be recovered. The ergodicity is used to establish the single realization recovery. The asymptotic arguments in our study are based on the theories of pseudodifferential operators and microlocal analysis. ",https://doi.org/10.1007/s00220-020-03889-9,1906.01240v3,Yes,potent(3)
0009-0005-4063-124X,Paul Weinbrenner,Universität Rostock,ChiSCAT: unsupervised learning of recurrent cellular micro-motion   patterns from a chaotic speckle pattern,1970,"  There is considerable evidence that action potentials are accompanied by ""intrinsic optical signals"", such as a nanometer-scale motion of the cell membrane. Here we present ChiSCAT, a technically simple imaging scheme that detects such signals with interferometric sensitivity. ChiSCAT combines illumination by a {\bf ch}aotic speckle pattern and interferometric scattering microscopy ({\bf iSCAT}) to sensitively detect motion in any point and any direction. The technique features reflective high-NA illumination, common-path suppression of vibrations and a large field of view. This approach maximizes sensitivity to motion, but does not produce a visually interpretable image. We show that unsupervised learning based on matched filtering and motif discovery can recover underlying motion patterns and detect action potentials. We demonstrate these claims in an experiment on blebbistatin-paralyzed cardiomyocytes. ChiSCAT promises to even work in scattering tissue, including a living brain. ",Kein DOI-Link verfügbar,2405.16931v1,Yes,potent(2)
0009-0005-6437-7020,Akash Kumar,Friedrich-Alexander-Universität Erlangen-Nürnberg,Solar Potential Analysis of Rooftops Using Satellite Imagery,1970,"  Solar energy is one of the most important sources of renewable energy and the cleanest form of energy. In India, where solar energy could produce power around trillion kilowatt-hours in a year, our country is only able to produce power of around in gigawatts only. Many people are not aware of the solar potential of their rooftop, and hence they always think that installing solar panels is very much expensive. In this work, we introduce an approach through which we can generate a report remotely that provides the amount of solar potential of a building using only its latitude and longitude. We further evaluated various types of rooftops to make our solution more robust. We also provide an approximate area of rooftop that can be used for solar panels placement and a visual analysis of how solar panels can be placed to maximize the output of solar power at a location. ",Kein DOI-Link verfügbar,1812.11606v2,Yes,potent(2)
0009-0005-6437-7020,Akash Kumar,Friedrich-Alexander-Universität Erlangen-Nürnberg,ParaLarH: Parallel FPGA Router based upon Lagrange Heuristics,1970,"  Routing of the nets in Field Programmable Gate Array (FPGA) design flow is one of the most time consuming steps. Although Versatile Place and Route (VPR), which is a commonly used algorithm for this purpose, routes effectively, it is slow in execution. One way to accelerate this design flow is to use parallelization. Since VPR is intrinsically sequential, a set of parallel algorithms have been recently proposed for this purpose (ParaLaR and ParaLarPD).   These algorithms formulate the routing process as a Linear Program (LP) and solve it using the Lagrange relaxation, the sub-gradient method, and the Steiner tree algorithm. Out of the many metrics available to check the effectiveness of routing, ParaLarPD, which is an improved version of ParaLaR, suffers from large violations in the constraints of the LP problem (which is related to the minimum channel width metric) as well as an easily measurable critical path delay metric that can be improved further.   In this paper, we introduce a set of novel Lagrange heuristics that improve the Lagrange relaxation process. When tested on the MCNC benchmark circuits, on an average, this leads to halving of the constraints violation, up to 10% improvement in the minimum channel width, and up to 8% reduction in the critical path delay as obtained from ParaLarPD. We term our new algorithm as ParaLarH. Due to the increased work in the Lagrange relaxation process, as compared to ParaLarPD, ParaLarH does slightly deteriorate the speedup obtained because of parallelization, however, this aspect is easily compensated by using more number of threads. ",Kein DOI-Link verfügbar,2010.11893v1,Yes,versatile(1)
0009-0005-6437-7020,Akash Kumar,Friedrich-Alexander-Universität Erlangen-Nürnberg,IceBreaker: Solving Cold Start Problem for Video Recommendation Engines,1970,"  Internet has brought about a tremendous increase in content of all forms and, in that, video content constitutes the major backbone of the total content being published as well as watched. Thus it becomes imperative for video recommendation engines such as Hulu to look for novel and innovative ways to recommend the newly added videos to their users. However, the problem with new videos is that they lack any sort of metadata and user interaction so as to be able to rate the videos for the consumers. To this effect, this paper introduces the several techniques we develop for the Content Based Video Relevance Prediction (CBVRP) Challenge being hosted by Hulu for the ACM Multimedia Conference 2018. We employ different architectures on the CBVRP dataset to make use of the provided frame and video level features and generate predictions of videos that are similar to the other videos. We also implement several ensemble strategies to explore complementarity between both the types of provided features. The obtained results are encouraging and will impel the boundaries of research for multimedia based video recommendation systems. ",Kein DOI-Link verfügbar,1808.05636v1,Yes,innovative(1)
0009-0005-6437-7020,Akash Kumar,Friedrich-Alexander-Universität Erlangen-Nürnberg,Temporal Decisions: Leveraging Temporal Correlation for Efficient   Decisions in Early Exit Neural Networks,1970,"  Deep Learning is becoming increasingly relevant in Embedded and Internet-of-things applications. However, deploying models on embedded devices poses a challenge due to their resource limitations. This can impact the model's inference accuracy and latency. One potential solution are Early Exit Neural Networks, which adjust model depth dynamically through additional classifiers attached between their hidden layers. However, the real-time termination decision mechanism is critical for the system's efficiency, latency, and sustained accuracy.   This paper introduces Difference Detection and Temporal Patience as decision mechanisms for Early Exit Neural Networks. They leverage the temporal correlation present in sensor data streams to efficiently terminate the inference. We evaluate their effectiveness in health monitoring, image classification, and wake-word detection tasks. Our novel contributions were able to reduce the computational footprint compared to established decision mechanisms significantly while maintaining higher accuracy scores. We achieved a reduction of mean operations per inference by up to 80% while maintaining accuracy levels within 5% of the original model.   These findings highlight the importance of considering temporal correlation in sensor data to improve the termination decision. ",Kein DOI-Link verfügbar,2403.07958v1,Yes,potent(1)
0009-0005-6437-7020,Akash Kumar,Friedrich-Alexander-Universität Erlangen-Nürnberg,Efficient Post-Training Augmentation for Adaptive Inference in   Heterogeneous and Distributed IoT Environments,1970,"  Early Exit Neural Networks (EENNs) present a solution to enhance the efficiency of neural network deployments. However, creating EENNs is challenging and requires specialized domain knowledge, due to the large amount of additional design choices. To address this issue, we propose an automated augmentation flow that focuses on converting an existing model into an EENN. It performs all required design decisions for the deployment to heterogeneous or distributed hardware targets: Our framework constructs the EENN architecture, maps its subgraphs to the hardware targets, and configures its decision mechanism. To the best of our knowledge, it is the first framework that is able to perform all of these steps.   We evaluated our approach on a collection of Internet-of-Things and standard image classification use cases. For a speech command detection task, our solution was able to reduce the mean operations per inference by 59.67%. For an ECG classification task, it was able to terminate all samples early, reducing the mean inference energy by 74.9% and computations by 78.3%. On CIFAR-10, our solution was able to achieve up to a 58.75% reduction in computations.   The search on a ResNet-152 base model for CIFAR-10 took less than nine hours on a laptop CPU. Our proposed approach enables the creation of EENN optimized for IoT environments and can reduce the inference cost of Deep Learning applications on embedded and fog platforms, while also significantly reducing the search cost - making it more accessible for scientists and engineers in industry and research. The low search cost improves the accessibility of EENNs, with the potential to improve the efficiency of neural networks in a wide range of practical applications. ",Kein DOI-Link verfügbar,2403.07957v1,Yes,potent(1)
0009-0005-6437-7020,Akash Kumar,Friedrich-Alexander-Universität Erlangen-Nürnberg,Large spin Hall conductivity in epitaxial thin films of kagome   antiferromagnet Mn$_3$Sn at room temperature,1970,"  Mn$_3$Sn is a non-collinear antiferromagnetic quantum material that exhibits a magnetic Weyl semimetallic state and has great potential for efficient memory devices. High-quality epitaxial $c$-plane Mn$_3$Sn thin films have been grown on a sapphire substrate using a Ru seed layer. Using spin pumping induced inverse spin Hall effect measurements on $c$-plane epitaxial Mn$_3$Sn/Ni$_{80}$Fe$_{20}$, we measure spin-diffusion length ($\lambda_{\rm Mn_3Sn}$), and spin Hall conductivity ($\sigma_{\rm{SH}}$) of Mn$_3$Sn thin films: $\lambda_{\rm Mn_3Sn}=0.42\pm 0.04$ nm and $\sigma_{\rm{SH}}=-702~\hbar/ e~\Omega^{-1}$cm$^{-1}$. While $\lambda_{\rm Mn_3Sn}$ is consistent with earlier studies, $\sigma_{\rm{SH}}$ is an order of magnitude higher and of the opposite sign. The behavior is explained on the basis of excess Mn, which shifts the Fermi level in our films, leading to the observed behavior. Our findings demonstrate a technique for engineering $\sigma_{\rm{SH}}$ of Mn$_3$Sn films by employing Mn composition for functional spintronic devices. ",Kein DOI-Link verfügbar,2209.02647v1,Yes,potent(1)
0009-0005-6437-7020,Akash Kumar,Friedrich-Alexander-Universität Erlangen-Nürnberg,Mutual synchronization in spin torque and spin Hall nano-oscillators,1970,"  This chapter reviews the state of the art in mutually synchronized spin-torque and spin Hall nano-oscillator (STNO and SHNO) arrays. After briefly introducing the underlying physics, we discuss different nano-oscillator implementations and their functional properties with respect to frequency range, output power, phase noise, and modulation rates. We then introduce the concepts and the theory of mutual synchronization and discuss the possible coupling mechanisms in spintronic nano-oscillators, such as dipolar, electrical, and spin-wave coupling. We review the experimental literature on mutually synchronized STNOs and SHNOs in one- and two-dimensional arrays and discuss ways to increase the number of mutually synchronized nano-oscillators. Finally, the potential for applications ranging from microwave signal sources/detectors and ultrafast spectrum analyzers to neuromorphic computing elements and Ising machines is discussed together with the specific electronic circuitry that has been designed so far to harness this potential. ",Kein DOI-Link verfügbar,2312.09656v1,Yes,potent(2)
0009-0005-6437-7020,Akash Kumar,Friedrich-Alexander-Universität Erlangen-Nürnberg,Spin wave-driven variable-phase mutual synchronization in spin Hall   nano-oscillators,1970,"  Spin-orbit torque can drive auto-oscillations of propagating spin wave (PSW) modes in nano-constriction spin Hall nano-oscillators (SHNOs). These modes allow both long-range coupling and the potential of controlling its phase -- critical aspect for nano-magnonics, spin wave logic, and Ising machines. Here, we demonstrate PSW-driven variable-phase coupling between two nano-constriction SHNOs and study how their separation and the PSW wave vector impact their mutual synchronization. In addition to ordinary in-phase mutual synchronization, we observe, using both electrical measurements and phase-resolved $\mu-$Brillouin Light Scattering microscopy, mutual synchronization with a phase that can be tuned from 0 to $\pi$ using the drive current or the applied field. Micromagnetic simulations corroborate the experiments and visualize how the PSW patterns in the bridge connecting the two nano-constrictions govern the coupling. These results advance the capabilities of mutually synchronized SHNOs and open up new possibilities for applications in spin wave logic, unconventional computing, and Ising Machines. ",Kein DOI-Link verfügbar,2402.00586v1,Yes,potent(1)
0009-0005-6437-7020,Akash Kumar,Friedrich-Alexander-Universität Erlangen-Nürnberg,Spin Hall Nano-Oscillator Empirical Electrical Model for Optimal On-chip   Detector Design,1970,"  As nascent nonlinear oscillators, nano-constriction spin Hall nano-oscillators (SHNOs) represent a promising potential for integration into more complicated systems such as neural networks, magnetic field sensors, and radio frequency (RF) signal classification, their tunable high-frequency operating regime, easy synchronization, and CMOS compatibility can streamline the process. To implement SHNOs in any of these networks, the electrical features of a single device are needed before designing the signal detection CMOS circuitry. This study centers on presenting an empirical electrical model of the SHNO based on a comprehensive characterization of the output impedance of a single SHNO, and its available output power in the range of 2-10 GHz at various bias currents. ",https://doi.org/10.1109/TED.2024.3410245,2404.10334v1,Yes,potent(1)
0009-0005-6437-7020,Akash Kumar,Friedrich-Alexander-Universität Erlangen-Nürnberg,Magnetic Proximity induced efficient charge-to-spin conversion in large   area PtSe$_{2}$/Ni$_{80}$Fe$_{20}$ heterostructures,1970,"  As a topological Dirac semimetal with controllable spin-orbit coupling and conductivity, PtSe$_2$, a transition-metal dichalcogenide, is a promising material for several applications from optoelectric to sensors. However, its potential for spintronics applications is yet to be explored. In this work, we demonstrate that PtSe$_{2}$/Ni$_{80}$Fe$_{20}$ heterostructure can generate a large damping-like current-induced spin-orbit torques (SOT), despite the absence of spin-splitting in bulk PtSe$_{2}$. The efficiency of charge-to-spin conversion is found to be $(-0.1 \pm 0.02)$~nm$^{-1}$ in PtSe$_{2}$/Ni$_{80}$Fe$_{20}$, which is three times that of the control sample, Ni$_{80}$Fe$_{20}$/Pt. Our band structure calculations show that the SOT due to the PtSe$_2$ arises from an unexpectedly large spin splitting in the interfacial region of PtSe$_2$ introduced by the proximity magnetic field of the Ni$_{80}$Fe$_{20}$ layer. Our results open up the possibilities of using large-area PtSe$_{2}$ for energy-efficient nanoscale devices by utilizing the proximity-induced SOT. ",https://doi.org/10.1021/acs.nanolett.3c04060,2307.11524v1,Yes,potent(1)
0009-0006-5824-9919,Jaskaran Singh,Universität Göttingen,VBSF-TLD: Validation-Based Approach for Soft Computing-Inspired Transfer   Learning in Drone Detection,1970,"  With the increasing utilization of Internet of Things (IoT) enabled drones in diverse applications like photography, delivery, and surveillance, concerns regarding privacy and security have become more prominent. Drones have the ability to capture sensitive information, compromise privacy, and pose security risks. As a result, the demand for advanced technology to automate drone detection has become crucial. This paper presents a project on a transfer-based drone detection scheme, which forms an integral part of a computer vision-based module and leverages transfer learning to enhance performance. By harnessing the knowledge of pre-trained models from a related domain, transfer learning enables improved results even with limited training data. To evaluate the scheme's performance, we conducted tests on benchmark datasets, including the Drone-vs-Bird Dataset and the UAVDT dataset. Notably, the scheme's effectiveness is highlighted by its IOU-based validation results, demonstrating the potential of deep learning-based technology in automating drone detection in critical areas such as airports, military bases, and other high-security zones. ",Kein DOI-Link verfügbar,2306.06797v1,Yes,potent(1)
0009-0006-5824-9919,Jaskaran Singh,Universität Göttingen,On-demand quantum key distribution using superconducting rings with a   mesoscopic Josephson junction,1970,"  We present a quantum key distribution (QKD) protocol based on long lived coherent states prepared on superconducting rings with a mesoscopic Josephson junction (dc-SQUIDs). This enables storage of the prepared states for long durations before actually performing the key distribution. Our on-demand QKD protocol is closely related to the coherent state based continuous variable quantum key distribution protocol. A detailed analysis of preparation, evolution and different measurement schemes that are required to be implemented on dc-SQUIDs to carry out the QKD is provided. We present two variants of the protocol, one requiring time stamping of states and offering a higher key rate and the other without time stamping and a lower key rate. This is a step towards having non-photon based QKD protocols which will be eventually desirable as photon states cannot be stored for long and therefore the key distribution has to be implemented immediately after photon exchange has occurred. Our protocol offers an innovative scheme to perform QKD and can be realized using current experimental techniques. ",Kein DOI-Link verfügbar,1808.06471v1,Yes,innovative(1)
0009-0006-5824-9919,Jaskaran Singh,Universität Göttingen,Analyzing LLM Usage in an Advanced Computing Class in India,1970,"  This study examines the use of large language models (LLMs) by undergraduate and graduate students for programming assignments in advanced computing classes. Unlike existing research, which primarily focuses on introductory classes and lacks in-depth analysis of actual student-LLM interactions, our work fills this gap. We conducted a comprehensive analysis involving 411 students from a Distributed Systems class at an Indian university, where they completed three programming assignments and shared their experiences through Google Form surveys.   Our findings reveal that students leveraged LLMs for a variety of tasks, including code generation, debugging, conceptual inquiries, and test case creation. They employed a spectrum of prompting strategies, ranging from basic contextual prompts to advanced techniques like chain-of-thought prompting and iterative refinement. While students generally viewed LLMs as beneficial for enhancing productivity and learning, we noted a concerning trend of over-reliance, with many students submitting entire assignment descriptions to obtain complete solutions. Given the increasing use of LLMs in the software industry, our study highlights the need to update undergraduate curricula to include training on effective prompting strategies and to raise awareness about the benefits and potential drawbacks of LLM usage in academic settings. ",Kein DOI-Link verfügbar,2404.04603v3,Yes,potent(1)
0009-0006-6023-8557,Mihaela Pilca,Universität Regensburg,LcK structures with holomorphic Lee vector field on Vaisman-type   manifolds,1970,"  We give a complete description of all locally conformally K\""ahler structures with holomorphic Lee vector field on a compact complex manifold of Vaisman type. This provides in particular examples of such structures whose Lee vector field is not homothetic to the Lee vector field of a Vaisman structure. More generally, dropping the condition of being of Vaisman type, we show that on a compact complex manifold, any lcK metric with potential and with holomorphic Lee vector field admits a potential which is positive and invariant along the anti-Lee vector field. ",https://doi.org/10.1007/s10711-020-00578-8,1905.07300v1,Yes,potent(2)
0009-0006-9679-5654,Paul Hagemann,Technische Universität Berlin,PatchNR: Learning from Very Few Images by Patch Normalizing Flow   Regularization,1970,"  Learning neural networks using only few available information is an important ongoing research topic with tremendous potential for applications. In this paper, we introduce a powerful regularizer for the variational modeling of inverse problems in imaging. Our regularizer, called patch normalizing flow regularizer (patchNR), involves a normalizing flow learned on small patches of very few images. In particular, the training is independent of the considered inverse problem such that the same regularizer can be applied for different forward operators acting on the same class of images. By investigating the distribution of patches versus those of the whole image class, we prove that our model is indeed a MAP approach. Numerical examples for low-dose and limited-angle computed tomography (CT) as well as superresolution of material images demonstrate that our method provides very high quality results. The training set consists of just six images for CT and one image for superresolution. Finally, we combine our patchNR with ideas from internal learning for performing superresolution of natural images directly from the low-resolution observation without knowledge of any high-resolution image. ",https://doi.org/10.1088/1361-6420/acce5e,2205.12021v3,Yes,potent(1)
0009-0006-9679-5654,Paul Hagemann,Technische Universität Berlin,Learning from small data sets: Patch-based regularizers in inverse   problems for image reconstruction,1970,"  The solution of inverse problems is of fundamental interest in medical and astronomical imaging, geophysics as well as engineering and life sciences. Recent advances were made by using methods from machine learning, in particular deep neural networks. Most of these methods require a huge amount of (paired) data and computer capacity to train the networks, which often may not be available. Our paper addresses the issue of learning from small data sets by taking patches of very few images into account. We focus on the combination of model-based and data-driven methods by approximating just the image prior, also known as regularizer in the variational model. We review two methodically different approaches, namely optimizing the maximum log-likelihood of the patch distribution, and penalizing Wasserstein-like discrepancies of whole empirical patch distributions. From the point of view of Bayesian inverse problems, we show how we can achieve uncertainty quantification by approximating the posterior using Langevin Monte Carlo methods. We demonstrate the power of the methods in computed tomography, image super-resolution, and inpainting. Indeed, the approach provides also high-quality results in zero-shot super-resolution, where only a low-resolution image is available. The paper is accompanied by a GitHub repository containing implementations of all methods as well as data examples so that the reader can get their own insight into the performance. ",Kein DOI-Link verfügbar,2312.16611v1,Yes,methodically(1)
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Mapping System Level Behaviors with Android APIs via System Call   Dependence Graphs,1970,"  Due to Android's open source feature and low barriers to entry for developers, millions of developers and third-party organizations have been attracted into the Android ecosystem. However, over 90 percent of mobile malware are found targeted on Android. Though Android provides multiple security features and layers to protect user data and system resources, there are still some over-privileged applications in Google Play Store or third-party Android app stores at wild. In this paper, we proposed an approach to map system level behavior and Android APIs, based on the observation that system level behaviors cannot be avoided but sensitive Android APIs could be evaded. To the best of our knowledge, our approach provides the first work to map system level behavior and Android APIs through System Call Dependence Graphs. The study also shows that our approach can effectively identify potential permission abusing, with almost negligible performance impact. ",https://doi.org/10.5121/csit.2019.90612,1906.10238v1,Yes,potent(1)
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Automatically growing global reactive neural network potential energy   surfaces: a trajectory free active learning strategy,1970,"  An efficient and trajectory-free active learning method is proposed to automatically sample data points for constructing globally accurate reactive potential energy surfaces (PESs) using neural networks (NNs). Although NNs do not provide the predictive variance as the Gaussian process regression does, we can alternatively minimize the negative of the squared difference surface (NSDS) given by two different NN models to actively locate the point where the PES is least confident. A batch of points in the minima of this NSDS can be iteratively added into the training set to improve the PES. The configuration space is gradually and globally covered with no need to run classical trajectory (or equivalently molecular dynamics) simulations. Through refitting the available analytical PESs of H3 and OH3 reactive systems, we demonstrate the efficiency and robustness of this new strategy, which enables fast convergence of the reactive PESs with respect to the number of points in terms of quantum scattering probabilities. ",https://doi.org/10.1063/5.0004944,2002.05912v1,Yes,potent(1)
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Control of laser-plasma instabilities by non-collinear polychromatic   light,1970,"  Normal broadband lasers with collinear polychromatic components have immense potential for mitigating laser plasma instabilities (LPIs). However, the projection complexity of collinear polychromatic light (CPL) is a significant challenge owing to the demand for a large bandwidth and beamlet number. Here, we propose a theoretical LPI model and optical design for non-collinear polychromatic light (NCPL), which has a small angle $\sim4^\circ$ and large frequency difference $\sim$1\% between the double-color beamlets. LPI models of the NCPL demonstrate a decoupling threshold for the shared daughter waves under a multibeam configuration. Compared with the CPL, the wavevector couplings are further reduced by the introduced angle. Therefore, both the growth rate and saturation level of LPIs are greatly reduced by using the NCPL. The two- and three-dimensional simulation results indicate that the NCPL reduces the absolute and convective decoupling thresholds of the CPL and is sufficient to effectively mitigate the reflectivity, hot-electron generation, and intensity of cross-beam energy transfer. An optical design for the efficient generation of ultraviolet NCPL has been presented based on the unsaturated optical parametric amplification and non-collinear sum-frequency generation. ",Kein DOI-Link verfügbar,2306.06964v2,Yes,potent(1)
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Reconstructive Sequence-Graph Network for Video Summarization,1970,"  Exploiting the inner-shot and inter-shot dependencies is essential for key-shot based video summarization. Current approaches mainly devote to modeling the video as a frame sequence by recurrent neural networks. However, one potential limitation of the sequence models is that they focus on capturing local neighborhood dependencies while the high-order dependencies in long distance are not fully exploited. In general, the frames in each shot record a certain activity and vary smoothly over time, but the multi-hop relationships occur frequently among shots. In this case, both the local and global dependencies are important for understanding the video content. Motivated by this point, we propose a Reconstructive Sequence-Graph Network (RSGN) to encode the frames and shots as sequence and graph hierarchically, where the frame-level dependencies are encoded by Long Short-Term Memory (LSTM), and the shot-level dependencies are captured by the Graph Convolutional Network (GCN). Then, the videos are summarized by exploiting both the local and global dependencies among shots. Besides, a reconstructor is developed to reward the summary generator, so that the generator can be optimized in an unsupervised manner, which can avert the lack of annotated data in video summarization. Furthermore, under the guidance of reconstruction loss, the predicted summary can better preserve the main video content and shot-level dependencies. Practically, the experimental results on three popular datasets i.e., SumMe, TVsum and VTW) have demonstrated the superiority of our proposed approach to the summarization task. ",https://doi.org/10.1109/TPAMI.2021.3072117,2105.04066v1,Yes,potent(1)
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,CrossMatch: Enhance Semi-Supervised Medical Image Segmentation with   Perturbation Strategies and Knowledge Distillation,1970,"  Semi-supervised learning for medical image segmentation presents a unique challenge of efficiently using limited labeled data while leveraging abundant unlabeled data. Despite advancements, existing methods often do not fully exploit the potential of the unlabeled data for enhancing model robustness and accuracy. In this paper, we introduce CrossMatch, a novel framework that integrates knowledge distillation with dual perturbation strategies-image-level and feature-level-to improve the model's learning from both labeled and unlabeled data. CrossMatch employs multiple encoders and decoders to generate diverse data streams, which undergo self-knowledge distillation to enhance consistency and reliability of predictions across varied perturbations. Our method significantly surpasses other state-of-the-art techniques in standard benchmarks by effectively minimizing the gap between training on labeled and unlabeled data and improving edge accuracy and generalization in medical image segmentation. The efficacy of CrossMatch is demonstrated through extensive experimental validations, showing remarkable performance improvements without increasing computational costs. Code for this implementation is made available at https://github.com/AiEson/CrossMatch.git. ",Kein DOI-Link verfügbar,2405.00354v2,Yes,potent(1)
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Vehicle Perception from Satellite,1970,"  Satellites are capable of capturing high-resolution videos. It makes vehicle perception from satellite become possible. Compared to street surveillance, drive recorder or other equipments, satellite videos provide a much broader city-scale view, so that the global dynamic scene of the traffic are captured and displayed. Traffic monitoring from satellite is a new task with great potential applications, including traffic jams prediction, path planning, vehicle dispatching, \emph{etc.}. Practically, limited by the resolution and view, the captured vehicles are very tiny (a few pixels) and move slowly. Worse still, these satellites are in Low Earth Orbit (LEO) to capture such high-resolution videos, so the background is also moving. Under this circumstance, traffic monitoring from the satellite view is an extremely challenging task. To attract more researchers into this field, we build a large-scale benchmark for traffic monitoring from satellite. It supports several tasks, including tiny object detection, counting and density estimation. The dataset is constructed based on 12 satellite videos and 14 synthetic videos recorded from GTA-V. They are separated into 408 video clips, which contain 7,336 real satellite images and 1,960 synthetic images. 128,801 vehicles are annotated totally, and the number of vehicles in each image varies from 0 to 101. Several classic and state-of-the-art approaches in traditional computer vision are evaluated on the datasets, so as to compare the performance of different approaches, analyze the challenges in this task, and discuss the future prospects. The dataset is available at: https://github.com/Chenxi1510/Vehicle-Perception-from-Satellite-Videos. ",https://doi.org/10.1109/TPAMI.2023.3335953,2402.00703v1,Yes,potent(1)
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Remarkably strong chemisorption of nitric oxide on insulating oxide   films promoted by hybrid structure,1970,"  The remarkably strong chemical adsorption behaviors of nitric oxide on magnesia (001) film deposited on metal substrate have been investigated by employing periodic density functional calculations with Van der Waals corrections. The molybdenum supported magnesia (001) show significantly enhanced adsorption properties and the nitric oxide is chemisorbed strongly and preferably trapped in flat adsorption configuration on metal supported oxide film, due to the substantially large adsorption energies and transformation barriers. The analysis of Bader charges, projected density of states, differential charge densities, electron localization function, highest occupied orbital and particular orbital with largest Mg-NO-Mg bonding coefficients, are applied to reveal the electronic adsorption properties and characteristics of bonding between nitric oxide and surface as well as the bonding within the hybrid structure. The strong chemical binding of nitric oxide on magnesia deposited on molybdenum slab offers new opportunities for toxic gas detection and treatment. We anticipate that hybrid structure promoted remarkable chemical adsorption of nitric oxide on magnesia in this study will provide versatile strategy for enhancing chemical reactivity and properties of insulating oxide. ",https://doi.org/10.1021/acs.jpcc.7b06912,1705.02590v1,Yes,versatile(1)
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Motion-Aware Video Frame Interpolation,1970,"  Video frame interpolation methodologies endeavor to create novel frames betwixt extant ones, with the intent of augmenting the video's frame frequency. However, current methods are prone to image blurring and spurious artifacts in challenging scenarios involving occlusions and discontinuous motion. Moreover, they typically rely on optical flow estimation, which adds complexity to modeling and computational costs. To address these issues, we introduce a Motion-Aware Video Frame Interpolation (MA-VFI) network, which directly estimates intermediate optical flow from consecutive frames by introducing a novel hierarchical pyramid module. It not only extracts global semantic relationships and spatial details from input frames with different receptive fields, enabling the model to capture intricate motion patterns, but also effectively reduces the required computational cost and complexity. Subsequently, a cross-scale motion structure is presented to estimate and refine intermediate flow maps by the extracted features. This approach facilitates the interplay between input frame features and flow maps during the frame interpolation process and markedly heightens the precision of the intervening flow delineations. Finally, a discerningly fashioned loss centered around an intermediate flow is meticulously contrived, serving as a deft rudder to skillfully guide the prognostication of said intermediate flow, thereby substantially refining the precision of the intervening flow mappings. Experiments illustrate that MA-VFI surpasses several representative VFI methods across various datasets, and can enhance efficiency while maintaining commendable efficacy. ",Kein DOI-Link verfügbar,2402.02892v1,Yes,"commendable(1), meticulous(1), intricate(1), meticulously(1)"
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Lensless fiber endomicroscopic phase imaging with speckle-conditioned   diffusion model,1970,"  Lensless fiber endomicroscope is an emerging tool for in-vivo microscopic imaging, where quantitative phase imaging (QPI) can be utilized as a label-free method to enhance image contrast. However, existing single-shot phase reconstruction methods through lensless fiber endomicroscope typically perform well on simple images but struggle with complex microscopic structures. Here, we propose a speckle-conditioned diffusion model (SpecDiffusion), which reconstructs phase images directly from speckles captured at the detection side of a multi-core fiber (MCF). Unlike conventional neural networks, SpecDiffusion employs iterative phase denoising steps for speckle-driven phase reconstruction. The iteration scheme allows SpecDiffusion to break down the phase reconstruction process into multiple steps, gradually building up to the final phase image. This attribute alleviates the computation challenge at each step and enables the reconstruction of rich details in complex microscopic images. To validate its efficacy, we build an optical system to capture speckles from MCF and construct a dataset consisting of 100,000 paired images. SpecDiffusion provides high-fidelity phase reconstruction results and shows powerful generalization capacity for unseen objects, such as test charts and biological tissues, reducing the average mean absolute error of the reconstructed tissue images by 7 times. Furthermore, the reconstructed tissue images using SpecDiffusion shows higher accuracy in zero-shot cell segmentation tasks compared to the conventional method, demonstrating the potential for further cell morphology analysis through the learning-based lensless fiber endomicroscope. SpecDiffusion offers a precise and generalized method to phase reconstruction through scattering media, including MCFs, opening new perspective in lensless fiber endomicroscopic imaging. ",Kein DOI-Link verfügbar,2407.18456v1,Yes,potent(1)
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Large-Scale Actionless Video Pre-Training via Discrete Diffusion for   Efficient Policy Learning,1970,"  Learning a generalist embodied agent capable of completing multiple tasks poses challenges, primarily stemming from the scarcity of action-labeled robotic datasets. In contrast, a vast amount of human videos exist, capturing intricate tasks and interactions with the physical world. Promising prospects arise for utilizing actionless human videos for pre-training and transferring the knowledge to facilitate robot policy learning through limited robot demonstrations. In this paper, we introduce a novel framework that leverages a unified discrete diffusion to combine generative pre-training on human videos and policy fine-tuning on a small number of action-labeled robot videos. We start by compressing both human and robot videos into unified video tokens. In the pre-training stage, we employ a discrete diffusion model with a mask-and-replace diffusion strategy to predict future video tokens in the latent space. In the fine-tuning stage, we harness the imagined future videos to guide low-level action learning trained on a limited set of robot data. Experiments demonstrate that our method generates high-fidelity future videos for planning and enhances the fine-tuned policies compared to previous state-of-the-art approaches with superior generalization ability. Our project website is available at https://video-diff.github.io/. ",Kein DOI-Link verfügbar,2402.14407v1,Yes,intricate(1)
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Calibration-free quantitative phase imaging in multi-core fiber   endoscopes using end-to-end deep learning,1970,"  Quantitative phase imaging (QPI) through multi-core fibers (MCFs) has been an emerging in vivo label-free endoscopic imaging modality with minimal invasiveness. However, the computational demands of conventional iterative phase retrieval algorithms have limited their real-time imaging potential. We demonstrate a learning-based MCF phase imaging method, that significantly reduced the phase reconstruction time to 5.5 ms, enabling video-rate imaging at 181 fps. Moreover, we introduce an innovative optical system that automatically generated the first open-source dataset tailored for MCF phase imaging, comprising 50,176 paired speckle and phase images. Our trained deep neural network (DNN) demonstrates robust phase reconstruction performance in experiments with a mean fidelity of up to 99.8\%. Such an efficient fiber phase imaging approach can broaden the applications of QPI in hard-to-reach areas. ",Kein DOI-Link verfügbar,2312.07102v1,Yes,"innovative(1), potent(1)"
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud   Pre-training,1970,"  Masked Autoencoders (MAE) have shown great potentials in self-supervised pre-training for language and 2D image transformers. However, it still remains an open question on how to exploit masked autoencoding for learning 3D representations of irregular point clouds. In this paper, we propose Point-M2AE, a strong Multi-scale MAE pre-training framework for hierarchical self-supervised learning of 3D point clouds. Unlike the standard transformer in MAE, we modify the encoder and decoder into pyramid architectures to progressively model spatial geometries and capture both fine-grained and high-level semantics of 3D shapes. For the encoder that downsamples point tokens by stages, we design a multi-scale masking strategy to generate consistent visible regions across scales, and adopt a local spatial self-attention mechanism during fine-tuning to focus on neighboring patterns. By multi-scale token propagation, the lightweight decoder gradually upsamples point tokens with complementary skip connections from the encoder, which further promotes the reconstruction from a global-to-local perspective. Extensive experiments demonstrate the state-of-the-art performance of Point-M2AE for 3D representation learning. With a frozen encoder after pre-training, Point-M2AE achieves 92.9% accuracy for linear SVM on ModelNet40, even surpassing some fully trained methods. By fine-tuning on downstream tasks, Point-M2AE achieves 86.43% accuracy on ScanObjectNN, +3.36% to the second-best, and largely benefits the few-shot classification, part segmentation and 3D object detection with the hierarchical pre-training scheme. Code is available at https://github.com/ZrrSkywalker/Point-M2AE. ",Kein DOI-Link verfügbar,2205.14401v2,Yes,potent(1)
0009-0007-5164-9861,Bin Zhao,Albert-Ludwigs-Universität Freiburg,Spectral self-adaptive absorber/emitter for harvesting energy from the   sun and outer space,1970,"  The sun (~6000 K) and outer space (~3 K) are the original heat source and sink for human beings on Earth. The energy applications of absorbing solar irradiation and harvesting the coldness of outer space for energy utilization have attracted considerable interest from researchers. However, combining these two functions in a static device for continuous energy harvesting is unachievable due to the intrinsic infrared spectral conflict. In this study, we developed spectral self-adaptive absorber/emitter (SSA/E) for daytime photothermal and nighttime radiative sky cooling modes depending on the phase transition of the vanadium dioxide coated layer. A 24-hour day-night test showed that the fabricated SSA/E has continuous energy harvesting ability and improved overall energy utilization performance, thus showing remarkable potential in future energy applications. ",https://doi.org/10.1073/pnas.2120557119,2004.00459v1,Yes,potent(1)
0009-0007-7282-7970,Kapil Goswami,Universität Hamburg,Integer Programming Using A Single Atom,1970,"  Integer programming (IP), as the name suggests is an integer-variable-based approach commonly used to formulate real-world optimization problems with constraints. Currently, quantum algorithms reformulate the IP into an unconstrained form through the use of binary variables, which is an indirect and resource-consuming way of solving it. We develop an algorithm that maps and solves an IP problem in its original form to any quantum system possessing a large number of accessible internal degrees of freedom that are controlled with sufficient accuracy. This work leverages the principle of superposition to solve the optimization problem. Using a single Rydberg atom as an example, we associate the integer values to electronic states belonging to different manifolds and implement a selective superposition of different states to solve the full IP problem. The optimal solution is found within a few microseconds for prototypical IP problems with up to eight variables and four constraints. This also includes non-linear IP problems, which are usually harder to solve with classical algorithms when compared to their linear counterparts. Our algorithm for solving IP is benchmarked by a well-known classical algorithm (branch and bound) in terms of the number of steps needed for convergence to the solution. This approach carries the potential to improve the solutions obtained for larger-size problems using hybrid quantum-classical algorithms. ",https://doi.org/10.1088/2058-9565/ad6735,2402.16541v3,Yes,potent(1)
0009-0007-7282-7970,Kapil Goswami,Universität Hamburg,Solving The Travelling Salesman Problem Using A Single Qubit,1970,"  The travelling salesman problem (TSP) is a popular NP-hard-combinatorial optimization problem that requires finding the optimal way for a salesman to travel through different cities once and return to the initial city. The existing methods of solving TSPs on quantum systems are either gate-based or binary variable-based encoding. Both approaches are resource-expensive in terms of the number of qubits while performing worse compared to existing classical algorithms even for small-size problems. We present an algorithm that solves an arbitrary TSP using a single qubit by invoking the principle of quantum parallelism. The cities are represented as quantum states on the Bloch sphere while the preparation of superposition states allows us to traverse multiple paths at once. The underlying framework of our algorithm is a quantum version of the classical Brachistochrone approach. Optimal control methods are employed to create a selective superposition of the quantum states to find the shortest route of a given TSP. The numerical simulations solve a sample of four to nine cities for which exact solutions are obtained. The algorithm can be implemented on any quantum platform capable of efficiently rotating a qubit and allowing state tomography measurements. For the TSP problem sizes considered in this work, our algorithm is more resource-efficient and accurate than existing quantum algorithms with the potential for scalability. A potential speed-up of polynomial time over classical algorithms is discussed. ",Kein DOI-Link verfügbar,2407.17207v1,Yes,potent(2)
0009-0007-9590-0181,Nikolas Longen,Rheinische Friedrich-Wilhelms-Universität Bonn,Visualizing Entanglement in multi-Qubit Systems,1970,"  In the field of quantum information science and technology, the representation and visualization of quantum states and related processes are essential for both research and education. In this context, a focus especially lies on ensembles of few qubits. There exist many powerful representations for single-qubit and multi-qubit systems, such as the famous Bloch sphere and generalizations. Here, we utilize the dimensional circle notation as a representation of such ensembles, adapting the so-called circle notation of qubits and the idea of representing the n-particle system in an n-dimensional space. We show that the mathematical conditions for separability lead to symmetry conditions of the quantum state visualized, offering a new perspective on entanglement in few-qubit systems and therefore on various quantum algorithms. In this way, dimensional notations promise significant potential for conveying nontrivial quantum entanglement properties and processes in few-qubit systems to a broader audience, and could enhance understanding of these concepts as a bridge between intuitive quantum insight and formal mathematical descriptions. ",Kein DOI-Link verfügbar,2305.07596v4,Yes,potent(1)
0009-0008-3183-4426,Michael Werner,Leibniz Universität Hannover,Spitzer Space Telescope Observations of the Aftermath of Microlensing   Event MACHO-LMC-5,1970,"  We have carried out photometry of the microlensing event MACHO-LMC-5 with Spitzer's IRAC ten years after the magnification of the LMC source star was recorded. This event is unique in the annals of gravitational microlensing: the lensing star itself has been observed using HST (once with WFPC2 and twice with ACS/HRC). Since the separation between the source and lens at the epoch of the Spitzer observations was $\sim0.24''$, the two stars cannot be resolved in the Spitzer images. However, the IRAC photometry clearly establishes that the lens is a M5 dwarf star from its infrared excess, which in turn yields a mass of $\sim0.2 M_{\odot}$. This demonstrates the potential of Spitzer to detect the lenses in other gravitational microlensing events. ",Kein DOI-Link verfügbar,astro-ph/0406040v1,Yes,potent(1)
0009-0008-3183-4426,Michael Werner,Leibniz Universität Hannover,Temperate super-Earths/mini-Neptunes around M/K dwarfs Consist of 2   Populations Distinguished by Their Atmospheres,1970,"  Studies of the atmospheres of hot Jupiters reveal a diversity of atmospheric composition and haze properties. Similar studies on individual smaller, temperate planets are rare due to the inherent difficulty of the observations and also to the average faintness of their host stars. To investigate their ensemble atmospheric properties, we construct a sample of 28 similar planets, all possess equilibrium temperature within 300-500K, have similar size (1-3 R_e), and orbit early M dwarfs and late K dwarfs with effective temperatures within a few hundred Kelvin of one another. In addition, NASA's Kepler/K2 and Spitzer missions gathered transit observations of each planet, producing an uniform transit data set both in wavelength and coarse planetary type. With the transits measured in Kepler's broad optical bandpass and Spitzer's 4.5 micron wavelength bandpass, we measure the transmission spectral slope, alpha, for the entire sample. While this measurement is too uncertain in nearly all cases to infer the properties of any individual planet, the distribution of alpha among several dozen similar planets encodes a key trend. We find that the distribution of alpha is not well-described by a single Gaussian distribution. Rather, a ratio of the Bayesian evidences between the likeliest 1-component and 2-component Gaussian models favors the latter by a ratio of 100:1. One Gaussian is centered around an average alpha=-1.3, indicating hazy/cloudy atmospheres or bare cores with atmosphere evaporated. A smaller but significant second population (20+\-10% of all) is necessary to model significantly higher alpha values, which indicate atmospheres with potentially detectable molecular features. We conclude that the atmospheres of small and temperate planets are far from uniformly flat, and that a subset are particularly favorable for follow-up observation from space-based platforms like HST and JWST. ",https://doi.org/10.3847/1538-4357/ab24be,1804.00071v1,Yes,potent(1)
0009-0008-3183-4426,Michael Werner,Leibniz Universität Hannover,Astrophysics with New Horizons: Making the Most of a Generational   Opportunity,1970,"  The outer solar system provides a unique, quiet vantage point from which to observe the universe around us, where measurements could enable several niche astrophysical science cases that are too difficult to perform near Earth. NASA's New Horizons mission comprises an instrument package that provides imaging capability from ultraviolet (UV) to near-infrared (near-IR) wavelengths with moderate spectral resolution located beyond the orbit of Pluto. A carefully designed survey with New Horizons can optimize the use of expendable propellant and the limited data telemetry bandwidth to allow several measurements, including a detailed understanding of the cosmic extragalactic background light; studies of the local and extragalactic UV background; measurements of the properties of dust and ice in the outer solar system; confirmation and characterization of transiting exoplanets; determinations of the mass of dark objects using gravitational microlensing; and rapid follow-up of transient events. New Horizons is currently in an extended mission designed to focus on Kuiper Belt science that will conclude in 2021. The astrophysics community has a unique, generational opportunity to use this mission for astronomical observation at heliocentric distances beyond 50 au in the next decade. In this paper, we discuss the potential science cases for such an extended mission, and provide an initial assessment of the most important operational requirements and observation strategies it would require. We conclude that New Horizons is capable of transformative science, and that it would make a valuable and unique asset for astrophysical science that is unlikely to be replicated in the near future. ",https://doi.org/10.1088/1538-3873/aadb77,1802.09536v2,Yes,potent(1)
0009-0008-5948-4181,Akhil Varri,Universität Münster,Probabilistic Photonic Computing with Chaotic Light,1970,"  Biological neural networks effortlessly tackle complex computational problems and excel at predicting outcomes from noisy, incomplete data, a task that poses significant challenges to traditional processors. Artificial neural networks (ANNs), inspired by these biological counterparts, have emerged as powerful tools for deciphering intricate data patterns and making predictions. However, conventional ANNs can be viewed as ""point estimates"" that do not capture the uncertainty of prediction, which is an inherently probabilistic process. In contrast, treating an ANN as a probabilistic model derived via Bayesian inference poses significant challenges for conventional deterministic computing architectures. Here, we use chaotic light in combination with incoherent photonic data processing to enable high-speed probabilistic computation and uncertainty quantification. Since both the chaotic light source and the photonic crossbar support multiple independent computational wavelength channels, we sample from the output distributions in parallel at a sampling rate of 70.4 GS/s, limited only by the electronic interface. We exploit the photonic probabilistic architecture to simultaneously perform image classification and uncertainty prediction via a Bayesian neural network. Our prototype demonstrates the seamless cointegration of a physical entropy source and a computational architecture that enables ultrafast probabilistic computation by parallel sampling. ",Kein DOI-Link verfügbar,2401.17915v1,Yes,intricate(1)
0009-0008-6025-1617,Andreas Schenk,Karlsruhe Institut für Technologie,A Generalizable TCAD Framework for Silicon FinFET Spin Qubit Devices   with Electrical Control,1970,"  We present a TCAD-based simulation framework established for quantum dot spin qubits in a silicon FinFET platform with all-electrical control of the spin state. The framework works down to 1K and consists of a two-step simulation chain, from definition of the quantum dot confinement potential with DC bias voltages, to calculation of microwave response electric field at qubit locations using small-signal AC analysis. An average field polarization vector at each quantum dot is extracted via a post-processing step. We demonstrate functionality of this approach by simulation of a recently reported two-qubit device in the form of a 5-gate silicon FinFET. The impact of the number of holes in each quantum dot on the MW response E-field polarization direction is further investigated for this device. The framework is easily generalizable to study future multi-qubit large-scale systems. ",https://doi.org/10.1016/j.sse.2022.108550,2306.03213v1,Yes,potent(1)
0009-0008-6025-1617,Andreas Schenk,Karlsruhe Institut für Technologie,Compositional bowing of band energies and their deformation potentials   in strained InGaAs ternary alloys: a first-principles study,1970,"  Using first-principles calculations, we show that the conduction and valence band energies and their deformation potentials exhibit a non-negligible compositional bowing in strained ternary semiconductor alloys such as InGaAs. The electronic structure of these compounds has been calculated within the framework of local density approximation and hybrid functional approach for large cubic supercells and special quasi-random structures, which represent two kinds of model structures for random alloys. We find that the predicted bowing effect for the band energy deformation potentials is rather insensitive to the choice of the functional and alloy structural model. The direction of bowing is determined by In cations that give a stronger contribution to the formation of the In$_{x}$Ga$_{1-x}$As valence band states with $x\gtrsim 0.5$, compared to Ga cations. ",https://doi.org/10.1063/1.4928539,1505.05659v2,Yes,potent(2)
0009-0008-6025-1617,Andreas Schenk,Karlsruhe Institut für Technologie,Novel View Synthesis with Neural Radiance Fields for Industrial Robot   Applications,1970,"  Neural Radiance Fields (NeRFs) have become a rapidly growing research field with the potential to revolutionize typical photogrammetric workflows, such as those used for 3D scene reconstruction. As input, NeRFs require multi-view images with corresponding camera poses as well as the interior orientation. In the typical NeRF workflow, the camera poses and the interior orientation are estimated in advance with Structure from Motion (SfM). But the quality of the resulting novel views, which depends on different parameters such as the number and distribution of available images, as well as the accuracy of the related camera poses and interior orientation, is difficult to predict. In addition, SfM is a time-consuming pre-processing step, and its quality strongly depends on the image content. Furthermore, the undefined scaling factor of SfM hinders subsequent steps in which metric information is required. In this paper, we evaluate the potential of NeRFs for industrial robot applications. We propose an alternative to SfM pre-processing: we capture the input images with a calibrated camera that is attached to the end effector of an industrial robot and determine accurate camera poses with metric scale based on the robot kinematics. We then investigate the quality of the novel views by comparing them to ground truth, and by computing an internal quality measure based on ensemble methods. For evaluation purposes, we acquire multiple datasets that pose challenges for reconstruction typical of industrial applications, like reflective objects, poor texture, and fine structures. We show that the robot-based pose determination reaches similar accuracy as SfM in non-demanding cases, while having clear advantages in more challenging scenarios. Finally, we present first results of applying the ensemble method to estimate the quality of the synthetic novel view in the absence of a ground truth. ",Kein DOI-Link verfügbar,2405.04345v1,Yes,potent(2)
0009-0008-7281-6195,Bowen Song,Universität Stuttgart,The Role of Identification in Data-driven Policy Iteration: A System   Theoretic Study,1970,"  The goal of this article is to study fundamental mechanisms behind so-called indirect and direct data-driven control for unknown systems. Specifically, we consider policy iteration applied to the linear quadratic regulator problem. Two iterative procedures, where data collected from the system are repeatedly used to compute new estimates of the desired optimal controller, are considered. In indirect policy iteration, data are used to obtain an updated model estimate through a recursive identification scheme, which is used in a certainty-equivalent fashion to perform the classic policy iteration update. By casting the concurrent model identification and control design as a feedback interconnection between two algorithmic systems, we provide a closed-loop analysis that shows convergence and robustness properties for arbitrary levels of excitation in the data. In direct policy iteration, data are used to approximate the value function and design the associated controller without requiring the intermediate identification step. After proposing an extension to a recently proposed scheme that overcomes potential identifiability issues, we establish under which conditions this procedure is guaranteed to deliver the optimal controller. Based on these analyses we are able to compare the strengths and limitations of the two approaches, highlighting aspects such as the required samples, convergence properties, and excitation requirement. Simulations are also provided to illustrate the results. ",Kein DOI-Link verfügbar,2401.06721v2,Yes,potent(1)
0009-0008-7281-6195,Bowen Song,Universität Stuttgart,CoSIGN: Few-Step Guidance of ConSIstency Model to Solve General INverse   Problems,1970,"  Diffusion models have been demonstrated as strong priors for solving general inverse problems. Most existing Diffusion model-based Inverse Problem Solvers (DIS) employ a plug-and-play approach to guide the sampling trajectory with either projections or gradients. Though effective, these methods generally necessitate hundreds of sampling steps, posing a dilemma between inference time and reconstruction quality. In this work, we try to push the boundary of inference steps to 1-2 NFEs while still maintaining high reconstruction quality. To achieve this, we propose to leverage a pretrained distillation of diffusion model, namely consistency model, as the data prior. The key to achieving few-step guidance is to enforce two types of constraints during the sampling process of the consistency model: soft measurement constraint with ControlNet and hard measurement constraint via optimization. Supporting both single-step reconstruction and multistep refinement, the proposed framework further provides a way to trade image quality with additional computational cost. Within comparable NFEs, our method achieves new state-of-the-art in diffusion-based inverse problem solving, showcasing the significant potential of employing prior-based inverse problem solvers for real-world applications. Code is available at: https://github.com/BioMed-AI-Lab-U-Michgan/cosign. ",Kein DOI-Link verfügbar,2407.12676v1,Yes,potent(1)
0009-0008-7281-6195,Bowen Song,Universität Stuttgart,Latent Space Disentanglement in Diffusion Transformers Enables Zero-shot   Fine-grained Semantic Editing,1970,"  Diffusion Transformers (DiTs) have achieved remarkable success in diverse and high-quality text-to-image(T2I) generation. However, how text and image latents individually and jointly contribute to the semantics of generated images, remain largely unexplored. Through our investigation of DiT's latent space, we have uncovered key findings that unlock the potential for zero-shot fine-grained semantic editing: (1) Both the text and image spaces in DiTs are inherently decomposable. (2) These spaces collectively form a disentangled semantic representation space, enabling precise and fine-grained semantic control. (3) Effective image editing requires the combined use of both text and image latent spaces. Leveraging these insights, we propose a simple and effective Extract-Manipulate-Sample (EMS) framework for zero-shot fine-grained image editing. Our approach first utilizes a multi-modal Large Language Model to convert input images and editing targets into text descriptions. We then linearly manipulate text embeddings based on the desired editing degree and employ constrained score distillation sampling to manipulate image embeddings. We quantify the disentanglement degree of the latent space of diffusion models by proposing a new metric. To evaluate fine-grained editing performance, we introduce a comprehensive benchmark incorporating both human annotations, manual evaluation, and automatic metrics. We have conducted extensive experimental results and in-depth analysis to thoroughly uncover the semantic disentanglement properties of the diffusion transformer, as well as the effectiveness of our proposed method. Our annotated benchmark dataset is publicly available at https://anonymous.com/anonymous/EMS-Benchmark, facilitating reproducible research in this domain. ",Kein DOI-Link verfügbar,2408.13335v1,Yes,potent(1)
0009-0008-7281-6195,Bowen Song,Universität Stuttgart,SAD: Semi-Supervised Anomaly Detection on Dynamic Graphs,1970,"  Anomaly detection aims to distinguish abnormal instances that deviate significantly from the majority of benign ones. As instances that appear in the real world are naturally connected and can be represented with graphs, graph neural networks become increasingly popular in tackling the anomaly detection problem. Despite the promising results, research on anomaly detection has almost exclusively focused on static graphs while the mining of anomalous patterns from dynamic graphs is rarely studied but has significant application value. In addition, anomaly detection is typically tackled from semi-supervised perspectives due to the lack of sufficient labeled data. However, most proposed methods are limited to merely exploiting labeled data, leaving a large number of unlabeled samples unexplored. In this work, we present semi-supervised anomaly detection (SAD), an end-to-end framework for anomaly detection on dynamic graphs. By a combination of a time-equipped memory bank and a pseudo-label contrastive learning module, SAD is able to fully exploit the potential of large unlabeled samples and uncover underlying anomalies on evolving graph streams. Extensive experiments on four real-world datasets demonstrate that SAD efficiently discovers anomalies from dynamic graphs and outperforms existing advanced methods even when provided with only little labeled data. ",Kein DOI-Link verfügbar,2305.13573v1,Yes,potent(1)
0009-0008-7281-6195,Bowen Song,Universität Stuttgart,Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author   Prompt Editing,1970,"  Large language models (LLMs) have made impressive progress in natural language processing. These models rely on proper human instructions (or prompts) to generate suitable responses. However, the potential of LLMs are not fully harnessed by commonly-used prompting methods: many human-in-the-loop algorithms employ ad-hoc procedures for prompt selection; while auto prompt generation approaches are essentially searching all possible prompts randomly and inefficiently. We propose Evoke, an automatic prompt refinement framework. In Evoke, there are two instances of a same LLM: one as a reviewer (LLM-Reviewer), it scores the current prompt; the other as an author (LLM-Author), it edits the prompt by considering the edit history and the reviewer's feedback. Such an author-reviewer feedback loop ensures that the prompt is refined in each iteration. We further aggregate a data selection approach to Evoke, where only the hard samples are exposed to the LLM. The hard samples are more important because the LLM can develop deeper understanding of the tasks out of them, while the model may already know how to solve the easier cases. Experimental results show that Evoke significantly outperforms existing methods. For instance, in the challenging task of logical fallacy detection, Evoke scores above 80, while all other baseline methods struggle to reach 20. ",Kein DOI-Link verfügbar,2310.13855v1,Yes,potent(1)
0009-0008-7884-631X,Denis Kovalev,Technische Universität Berlin,Using Microbenchmark Suites to Detect Application Performance Changes,1970,"  Software performance changes are costly and often hard to detect pre-release. Similar to software testing frameworks, either application benchmarks or microbenchmarks can be integrated into quality assurance pipelines to detect performance changes before releasing a new application version. Unfortunately, extensive benchmarking studies usually take several hours which is problematic when examining dozens of daily code changes in detail; hence, trade-offs have to be made. Optimized microbenchmark suites, which only include a small subset of the full suite, are a potential solution for this problem, given that they still reliably detect the majority of the application performance changes such as an increased request latency. It is, however, unclear whether microbenchmarks and application benchmarks detect the same performance problems and one can be a proxy for the other.   In this paper, we explore whether microbenchmark suites can detect the same application performance changes as an application benchmark. For this, we run extensive benchmark experiments with both the complete and the optimized microbenchmark suites of the two time-series database systems InuxDB and VictoriaMetrics and compare their results to the results of corresponding application benchmarks. We do this for 70 and 110 commits, respectively. Our results show that it is possible to detect application performance changes using an optimized microbenchmark suite if frequent false-positive alarms can be tolerated. ",https://doi.org/10.1109/TCC.2022.3217947,2212.09515v1,Yes,potent(1)
0009-0008-9921-4127,Baerbel Rethfeld,RPTU Kaiserslautern-Landau,Intertwined relaxation processes maintain athermal electron distribution   in laser-excited dielectrics,1970,"  We study the relaxation dynamics of laser-excited non-equilibrium electron distributions in the valence- and conduction band of a dielectric. We apply Boltzmann collision integrals to trace the influence of different scattering mechanisms on the energy- and particle density of electrons and holes. Our results show a two-timescale behavior of the equilibration process: Thermalization within each band towards a respective Fermi distribution as well as equilibration of the band-resolved temperatures occur within a few femtoseconds. In contrast, the equilibration of the respective chemical potentials, driven by scattering processes involving particle exchange like impact ionization and Auger recombination, requires timescales in the range of hundreds of femtoseconds. We evaluate the effect of our model assumptions for distinct material parameters on the extracted specific relaxation times. All these timescales, however, strongly increase, when the additional scattering channel with the cold phonon system is considered: Our simulations demonstrate that an athermal non-Fermi electron distribution can be maintained well up to the picosecond range. ",Kein DOI-Link verfügbar,2304.14362v1,Yes,potent(1)
0009-0009-1647-4896,Johannes Schmidt,Philipps Universität Marburg,The Cost of Undisturbed Landscapes,1970,"  By 2030 Austria aims to meet 100% of its electricity demand from domestic renewable sources, with most of the additional generation coming from wind and solar energy. Apart from the benefit of reducing CO2 emissions and, potentially, system cost, wind power is associated with negative impacts at the local level, such as interference with landscape aesthetics. Some of these impacts might be avoided by using alternative renewable energy technologies. Thus, we quantify the opportunity cost of wind power versus its best feasible alternative solar photovoltaics, using the power system model medea. Our findings suggest that the cost of undisturbed landscapes is considerable, particularly when solar PV is mainly realized on roof-tops. Under a wide range of assumptions, the opportunity cost of wind power is high enough to allow for significant compensation of the ones affected by local, negative wind turbine externalities. ",https://doi.org/10.1016/j.enpol.2021.112617,2006.08009v3,Yes,potent(1)
0009-0009-1647-4896,Johannes Schmidt,Philipps Universität Marburg,The perils of automated fitting of datasets: the case of a wind turbine   cost model,1970,"  Rinne et al. conduct an interesting analysis of the impact of wind turbine technology and land-use on wind power potentials, which allows profound insights into each factors contribution to overall potentials. The paper presents a detailed model of site-specific wind turbine investment cost (i.e. road- and grid access costs) complemented by a model used to estimate site-independent costs. We believe that propose a cutting edge model of site-specific investment costs. However, the site-independent cost model is flawed in our opinion. This flaw most likely does not impact the results presented in the paper, although we expect a considerable generalization error. Thus the application of the wind turbine cost model in other contexts may lead to unreasonable results. More generally, the derivation of the wind turbine cost model serves as an example of how applications of automated regression analysis can go wrong. ",Kein DOI-Link verfügbar,1905.08870v2,Yes,potent(2)
0009-0009-1647-4896,Johannes Schmidt,Philipps Universität Marburg,Towards a global dynamic wind atlas: A multi-country validation of wind   power simulation from MERRA-2 and ERA-5 reanalyses bias-corrected with the   Global Wind Atlas,1970,"  Reanalysis data are widely used for simulating renewable energy and in particular wind power generation. While MERRA-2 has been a de-facto standard in many studies, the newer ERA5- reanalysis recently gained importance. Here, we use these two datasets to simulate wind power generation and evaluate the respective quality in terms of correlations and errors when validated against historical wind power generation. However, due to their coarse spatial resolution, reanalyses fail to adequately represent local climatic conditions. We therefore additionally apply mean bias correction with two versions of the Global Wind Atlas (GWA) and assess the respective quality of resulting simulations. Potential users of the dataset can also benefit from our analysis of the impact of spatial and temporal aggregation on simulation quality indicators. While similar studies have been conducted, they mainly cover limited areas in Europe. In contrast, we look into regions, which globally differ significantly in terms of the prevailing climate: the US, Brazil, South-Africa, and New Zealand. Our principal findings are that (i) ERA5 outperforms MERRA-2, (ii) no major improvements can be expected by using bias-correction with GWA2, while GWA3 even reduces simulation quality, and (iii) temporal aggregation increases correlations and reduces errors, while spatial aggregation does so only consistently when comparing very low and very high aggregation levels. ",Kein DOI-Link verfügbar,2012.05648v1,Yes,potent(1)
0009-0009-1647-4896,Johannes Schmidt,Philipps Universität Marburg,Terahertz Saturable Absorption from Relativistic High-Temperature   Thermodynamics in Black Phosphorus,1970,"  Thanks to its tunable infrared band-gap and to its anisotropic conduction properties, black phosphorus represents a very unique 2D material, whose potential in the engineering of new devices still needs to be fully explored. We investigate here the nonlinear terahertz (THz) electrodynamics of black phosphorus along the more conducting armchair direction. Similarly to the case of other 2D systems like graphene and topological insulators, the THz saturable absorption properties of black phosphorus can be understood within a thermodynamic model by assuming a fast thermalization of the electron bath. While black phosphorus does not display the presence of massless fermions at ambient pressure and temperature, our analysis shows that its anomalous THz nonlinear properties can be accounted for by a relativistic massive Dirac dispersion, provided the Fermi temperature is low enough. An optimal tuning of the Fermi level therefore represents a strategy to engineer strong THz nonlinear response in other massive Dirac materials as in transition metal dichalchogenides or high-temperature superconductors. ",Kein DOI-Link verfügbar,2310.13587v1,Yes,potent(1)
0009-0009-2401-817X,Niklas Euler,Heidelberg Universität,A metronome spin stabilizes time-crystalline dynamics,1970,"  We investigate a disorder-free quantum Ising chain subject to a time-periodic drive that rotates each spin by an angle $\pi(1-\epsilon_i)$. In case all spins experience the same deviation $\epsilon$ and the system is initialized in a fully polarized state, the dynamics is known to be time-crystalline: the magnetization of the system exhibits period-doubled oscillations for timescales that grow exponentially with the length of the chain. In this work, we study the effect of a deviation $\epsilon$ that differs between spins. We find that reducing $\epsilon$ for a single spin drastically enhances the lifetime of spatio-temporal order, suggesting the name ``metronome"" spin. Employing perturbative arguments in an average Hamiltonian picture, we explain this observation for initial states with macroscopic bulk magnetization. Furthermore, in the case of random bitstring initial states, we report the enhancement of the lifetime of a topological edge mode, which can also be understood in the same picture. Finally, we discuss an altered geometry in which the metronome spin is not directly part of the chain, affecting the dynamics in different ways in the two scenarios considered. Our findings unveil the intricate dynamics that emerge in Floquet systems under the influence of a spatially varying drive, thereby uncovering new avenues for Floquet engineering. ",https://doi.org/10.1103/PhysRevB.109.224301,2402.04078v1,Yes,intricate(1)
0009-0009-5890-3134,Lukas Kalkhoff,Universität Duisburg-Essen,Non-equilibrium dynamics of electron emission from cold and hot graphene   under proton irradiation,1970,"  Characteristic properties of secondary electrons emitted from irradiated two-dimensional materials arise from multi-length and time-scale relaxation processes that connect the initial non-equilibrium excited electron distribution with their eventual emission. To understand these processes, which are critical for using secondary electrons as high-resolution thermalization probes, we combine first-principles real-time electron dynamics with modern experiments. Our data for cold and hot proton-irradiated graphene shows signatures of kinetic and potential emission and generally good agreement for electron yields between experiment and theory. The duration of the emission pulse is about 1.5 femtoseconds, indicating high time resolution when used as a probe. Our newly developed method to predict kinetic energy spectra shows good agreement with electron and ion irradiation experiments and prior models. We find that lattice temperature significantly increases secondary electron emission, whereas electron temperature has a negligible effect. ",Kein DOI-Link verfügbar,2311.18784v2,Yes,potent(1)
0009-0009-6710-748X,Florian Martin,Bielefeld Universität,"Synergy, suppression and immorality: forward differences of the entropy   function",1970,"  Conditional mutual information is important in the selection and interpretation of graphical models. Its empirical version is well known as a generalised likelihood ratio test and that it may be represented as a difference in entropy. We consider the forward difference expansion of the entropy function defined on all subsets of the variables under study. The elements of this expansion are invariant to permutation of their suffices and relate higher order mutual informations to lower order ones. The third order difference is expressible as an, apparently assymmetric, difference between a marginal and a conditional mutual information. Its role in the decomposition for explained information provides a technical definition for synergy between three random variables. Positive values occur when two variables provide alternative explanations for a third; negative values, termed synergies, occur when the sum of explained information is greater than the sum of its parts. Synergies tend to be infrequent; they connect the seemingly unrelated concepts of suppressor variables in regression, on the one hand, and unshielded colliders in Bayes networks (immoralities), on the other. We give novel characterizations of these phenomena that generalise to categorical variables and to higher dimensions. We propose an algorithm for systematically computing low order differences from a given graph. Examples from small scale real-life studies indicate the potential of these techniques for empirical statistical analysis. ",Kein DOI-Link verfügbar,1501.04368v1,Yes,potent(1)
0009-0009-9570-8901,Eslam Ibrahim,Ruhr-Universität Bochum,Efficient parameterization of transferable Atomic Cluster Expansion for   water,1970,"  We present a highly accurate and transferable parameterization of water using the atomic cluster expansion (ACE). To efficiently sample liquid water, we propose a novel approach that involves sampling static calculations of various ice phases and utilizing the active learning (AL) feature of ACE-based D-optimality algorithm to select relevant liquid water configurations, bypassing computationally intensive ab-initio molecular dynamics (AIMD) simulations. Our results demonstrate that the ACE descriptors enable a potential initially-fitted solely on ice structures which is later upfitted with few configurations of liquid, identified with active learning to provide an excellent description of liquid water. The developed potential exhibits remarkable agreement with first-principles reference, accurately capturing various properties of liquid water, including structural characteristics such as pair correlation functions, covalent bonding profiles, and hydrogen bonding profiles, as well as dynamic properties like the vibrational density of states, diffusion coefficient and thermodynamic properties such as the melting point of the ice Ih. Our research introduces a new and efficient sampling technique for machine learning potentials in water simulations, while also presenting a transferable interatomic potential for water that reveals the accuracy of first principles reference. This advancement not only enhances our understanding the relationship between ice and liquid water at the atomic level, but also opens up new avenues for studying complex aqueous systems. ",Kein DOI-Link verfügbar,2406.14306v1,Yes,potent(4)
0009-0009-9570-8901,Eslam Ibrahim,Ruhr-Universität Bochum,Atomic Cluster Expansion for a General-Purpose Interatomic Potential of   Magnesium,1970,"  We present a general-purpose parameterization of the atomic cluster expansion (ACE) for magnesium. The ACE shows outstanding transferability over a broad range of atomic environments and captures physical properties of bulk as well as defective Mg phases in excellent agreement with reference first-principles calculations. We demonstrate the computational efficiency and the predictive power of ACE by calculating properties of extended defects and by evaluating the P-T phase diagram covering temperatures up to 3000 K and pressures up to 80 GPa. We compare the ACE predictions with those of other interatomic potentials, including the embedded-atom method, an angular-dependent potential, and a recently developed neural network potential. The comparison reveals that ACE is the only model that is able to predict correctly the phase diagram in close agreement with experimental observations. ",Kein DOI-Link verfügbar,2305.03577v1,Yes,potent(3)
